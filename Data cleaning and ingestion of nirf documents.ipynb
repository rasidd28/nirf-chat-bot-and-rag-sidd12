{"cells":[{"cell_type":"code","source":["import requests\n","import json\n","\n","# Qdrant connection details\n","QDRANT_URL = \"https://b5651607-31ce-49ba-916d-c35c89d731d2.us-east4-0.gcp.cloud.qdrant.io\"\n","QDRANT_API_KEY = \"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJhY2Nlc3MiOiJtIn0.0ApHZL4Qn_A8bx7FCC62nx-IOrHI84W7GZlUZEyVgKk\"\n","\n","# Ask user for collection name\n","collection_name = input(\"Enter the name of the collection to create: \")\n","\n","# Define the collection configuration\n","collection_config = {\n","    \"vectors\": {\n","        \"size\": 384,\n","        \"distance\": \"Cosine\"\n","    }\n","}\n","\n","# HTTP headers with API Key\n","headers = {\n","    \"Content-Type\": \"application/json\",\n","    \"api-key\": QDRANT_API_KEY\n","}\n","\n","# Make the request to create the collection\n","response = requests.put(\n","    f\"{QDRANT_URL}/collections/{collection_name}\",\n","    headers=headers,\n","    data=json.dumps(collection_config)\n",")\n","\n","# Check response\n","if response.status_code == 200:\n","    print(f\"Collection '{collection_name}' created successfully!\")\n","else:\n","    print(f\"Failed to create collection: {response.status_code}\")\n","    print(response.text)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"458snLiCcHY-","executionInfo":{"status":"ok","timestamp":1762971176755,"user_tz":-330,"elapsed":10775,"user":{"displayName":"Rahul Siddhu","userId":"12007764243202946991"}},"outputId":"5cd109c2-f3c5-4d5b-bbce-98298c4470b4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Enter the name of the collection to create: durden\n","Collection 'durden' created successfully!\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LPetgnKcFGdk","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1762967823219,"user_tz":-330,"elapsed":13864,"user":{"displayName":"Rahul Siddhu","userId":"12007764243202946991"}},"outputId":"0505fe74-af35-4dd0-c0a8-3ef9d7c83f5b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Reading package lists... Done\n","Building dependency tree... Done\n","Reading state information... Done\n","tesseract-ocr is already the newest version (4.1.1-2.1build1).\n","0 upgraded, 0 newly installed, 0 to remove and 41 not upgraded.\n","Collecting PyPDF2\n","  Downloading pypdf2-3.0.1-py3-none-any.whl.metadata (6.8 kB)\n","Collecting pdfplumber\n","  Downloading pdfplumber-0.11.8-py3-none-any.whl.metadata (43 kB)\n","\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting pymupdf\n","  Downloading pymupdf-1.26.6-cp310-abi3-manylinux_2_28_x86_64.whl.metadata (3.4 kB)\n","Collecting pytesseract\n","  Downloading pytesseract-0.3.13-py3-none-any.whl.metadata (11 kB)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (11.3.0)\n","Collecting pdfminer.six==20251107 (from pdfplumber)\n","  Downloading pdfminer_six-20251107-py3-none-any.whl.metadata (4.2 kB)\n","Collecting pypdfium2>=4.18.0 (from pdfplumber)\n","  Downloading pypdfium2-5.0.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (67 kB)\n","\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m67.9/67.9 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from pdfminer.six==20251107->pdfplumber) (3.4.4)\n","Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.12/dist-packages (from pdfminer.six==20251107->pdfplumber) (43.0.3)\n","Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.12/dist-packages (from pytesseract) (25.0)\n","Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.12/dist-packages (from cryptography>=36.0.0->pdfminer.six==20251107->pdfplumber) (2.0.0)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20251107->pdfplumber) (2.23)\n","Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n","\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pdfplumber-0.11.8-py3-none-any.whl (60 kB)\n","\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m60.0/60.0 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pdfminer_six-20251107-py3-none-any.whl (5.6 MB)\n","\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m72.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pymupdf-1.26.6-cp310-abi3-manylinux_2_28_x86_64.whl (24.1 MB)\n","\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m24.1/24.1 MB\u001b[0m \u001b[31m63.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pytesseract-0.3.13-py3-none-any.whl (14 kB)\n","Downloading pypdfium2-5.0.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n","\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m78.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: pytesseract, pypdfium2, PyPDF2, pymupdf, pdfminer.six, pdfplumber\n","Successfully installed PyPDF2-3.0.1 pdfminer.six-20251107 pdfplumber-0.11.8 pymupdf-1.26.6 pypdfium2-5.0.0 pytesseract-0.3.13\n"]}],"source":["!apt-get install -y tesseract-ocr\n","!pip install PyPDF2 pdfplumber pymupdf pytesseract Pillow\n"]},{"cell_type":"code","source":["import os\n","import PyPDF2\n","import pdfplumber\n","import fitz  # PyMuPDF\n","from pathlib import Path\n","import pandas as pd\n","from datetime import datetime\n","import re\n","from PIL import Image\n","import pytesseract\n","import io\n","import json\n","import shutil\n","import platform\n","import zipfile\n","import tempfile\n","\n","class PDFIngesterFlat:\n","    def __init__(self, root_folder_path, output_folder_path=None):\n","        self.root_folder_path = Path(root_folder_path)\n","        self.output_folder_path = Path(output_folder_path) if output_folder_path else Path(f\"{root_folder_path}_extracted\")\n","        self.all_pdfs = []  # List to hold info for all PDFs\n","        self.ingestion_log = []\n","\n","        # Define specific section patterns based on your requirements\n","        self.section_patterns = {\n","            'SANCTIONED_INTAKE': [\n","                r'sanctioned.*intake', r'approved.*intake', r'sanctioned.*approved.*intake'\n","            ],\n","            'STUDENT_STRENGTH': [\n","                r'total.*actual.*student.*strength.*program.*offered.*by.*your.*institution',\n","                r'total.*actual.*student.*strength.*program.*offered',\n","                r'total.*actual.*student.*strength.*all.*programs',\n","                r'total.*actual.*student.*strength',\n","                r'student.*strength.*program.*offered',\n","                r'actual.*student.*strength'\n","            ],\n","            'PLACEMENT_STUDIES': [\n","                r'placement.*higher.*studies', r'placement.*studies', r'higher.*studies'\n","            ],\n","            'UG_PLACEMENT': [\n","                r'ug.*\\[.*years?.*program.*\\].*placement.*higher.*studies',\n","                r'ug.*\\[.*years?.*program.*\\].*placement.*studies',\n","                r'ug.*4.*years?.*program.*placement'\n","            ],\n","            'PG_PLACEMENT': [\n","                r'pg.*\\[.*years?.*program.*\\].*placement.*higher.*studies',\n","                r'pg.*\\[.*years?.*program.*\\].*placement.*studies',\n","                r'pg.*2.*years?.*program.*placement'\n","            ],\n","            'UG_PROGRAM': [\n","                r'^ug.*\\[.*years?.*program.*\\](?!.*placement)',\n","                r'undergraduate.*program'\n","            ],\n","            'PG_PROGRAM': [\n","                r'^pg.*\\[.*years?.*program.*\\](?!.*placement)',\n","                r'postgraduate.*program'\n","            ],\n","            'PHD_DETAILS': [\n","                r'ph\\.?d.*student.*details', r'ph\\.?d.*details', r'doctoral.*program'\n","            ],\n","            'FINANCIAL_RESOURCES': [\n","                r'financial.*resources', r'utilised.*amount', r'capital.*expenditure', r'operational.*expenditure'\n","            ],\n","            'IPR': [\n","                r'^ipr$', r'intellectual.*property', r'patents'\n","            ],\n","            'SPONSORED_RESEARCH': [\n","                r'sponsored.*research.*details', r'sponsored.*research', r'research.*funding'\n","            ],\n","            'CONSULTANCY_PROJECTS': [\n","                r'consultancy.*project.*details', r'consultancy.*projects'\n","            ],\n","            'PCS_FACILITIES': [\n","                r'pcs.*facilities', r'physically.*challenged.*students', r'handicapped.*students'\n","            ],\n","            'FACULTY_DETAILS': [\n","                r'faculty.*details', r'number.*faculty.*members'\n","            ]\n","        }\n","        # Table exclusion patterns\n","        self.table_exclusion_patterns = [\n","            r'^\\d+\\s+\\d+\\s+\\d+',\n","            r'academic.*year.*\\d{4}',\n","            r'no\\.\\s*of.*students.*\\d+',\n","            r'rs\\.\\s*\\d+',\n","            r'within.*state.*outside.*state',\n","            r'male.*female.*total',\n","        ]\n","\n","        # Create output directory structure (ONLY text_files now)\n","        self.create_output_structure()\n","\n","    def create_output_structure(self):\n","        \"\"\"Create the output directory structure - ONLY text_files folder\"\"\"\n","        print(f\"Creating output directory structure at: {self.output_folder_path}\")\n","        self.output_folder_path.mkdir(parents=True, exist_ok=True)\n","        (self.output_folder_path / \"text_files\").mkdir(exist_ok=True)\n","        print(f\"‚úì Output structure created at: {self.output_folder_path}\")\n","\n","    def safe_filename(self, filename):\n","        \"\"\"Create a safe filename for output files\"\"\"\n","        safe_name = re.sub(r'[<>:\"/\\\\|?*]', '_', filename)\n","        safe_name = re.sub(r'[^\\w\\s.-]', '_', safe_name)\n","        return safe_name\n","\n","    def extract_pdf_text(self, pdf_path):\n","        \"\"\"Extract text content from PDF file using multiple methods for best results\"\"\"\n","        print(f\"    Extracting text from: {pdf_path.name}\")\n","\n","        text_pymupdf = self._extract_with_pymupdf(pdf_path)\n","        text_pdfplumber = self._extract_with_pdfplumber(pdf_path)\n","        text_pypdf2 = self._extract_with_pypdf2(pdf_path)\n","\n","        text_ocr = None\n","        if not any([text_pymupdf, text_pdfplumber, text_pypdf2]) or \\\n","            all(len(text.strip()) < 100 for text in [text_pymupdf, text_pdfplumber, text_pypdf2] if text):\n","            print(f\"      Performing OCR (document appears to be scanned)...\")\n","            text_ocr = self._extract_with_ocr(pdf_path)\n","\n","        best_text = self._choose_best_text(text_pymupdf, text_pdfplumber, text_pypdf2, text_ocr)\n","\n","        if best_text:\n","            cleaned_text = self._clean_text(best_text)\n","            print(f\"      ‚úì Extracted {len(cleaned_text)} characters\")\n","            return cleaned_text\n","        else:\n","            print(f\"      ‚úó Failed to extract text\")\n","            return None\n","\n","    def _is_table_content(self, text):\n","        \"\"\"Check if text appears to be table content\"\"\"\n","        text_lower = text.lower().strip()\n","        if len(text_lower) < 5:\n","            return False\n","\n","        strong_table_indicators = [\n","            r'^\\d+\\s+\\d+\\s+\\d+',\n","            r'academic.*year.*\\d{4}-\\d{2}',\n","            r'no\\.\\s*of.*first.*year.*students',\n","            r'no\\.\\s*of.*students.*intake',\n","            r'no\\.\\s*of.*students.*admitted',\n","            r'no\\.\\s*of.*students.*graduating',\n","            r'median.*salary.*placed.*graduates',\n","            r'within.*state.*outside.*state.*outside.*country',\n","            r'male.*female.*total.*students.*within',\n","            r'utilised.*amount.*utilised.*amount',\n","            r'financial.*year.*\\d{4}-\\d{2}.*\\d{4}-\\d{2}',\n","            r'\\d+.*lacs?.*crores?',\n","            r'rs\\.\\s*\\d+',\n","        ]\n","\n","        for pattern in strong_table_indicators:\n","            if re.search(pattern, text_lower):\n","                return True\n","\n","        structure_indicators = [\n","            len(re.findall(r'\\b\\d+\\b', text)) >= 4,\n","            '|' in text,\n","            text.count('\\t') >= 3,\n","            len(text.split()) >= 12,\n","        ]\n","\n","        if sum(structure_indicators) >= 2:\n","            return True\n","\n","        table_column_words = ['no.', 'total', 'male', 'female', 'within', 'outside', 'amount', 'year', 'students']\n","        word_matches = sum(1 for word in table_column_words if word in text_lower)\n","\n","        if word_matches >= 4 and len(text.split()) >= 10:\n","            return True\n","\n","        return False\n","\n","    def _detect_section_type(self, text, line):\n","        \"\"\"Enhanced section detection that treats complete lines as headings\"\"\"\n","        text_lower = text.lower().strip()\n","\n","        if self._is_table_content(text):\n","            return None\n","\n","        font_size = line[0].get(\"size\", 12) if line else 12\n","        font_name = line[0].get(\"fontname\", \"\").lower() if line else \"\"\n","\n","        complete_heading_patterns = [\n","            r'ug.*\\[.*years?.*program.*\\].*placement.*higher.*studies.*previous.*years?',\n","            r'pg.*\\[.*years?.*program.*\\].*placement.*higher.*studies.*previous.*years?',\n","            r'total.*actual.*student.*strength.*program.*offered.*by.*your.*institution',\n","            r'total.*actual.*student.*strength.*all.*programs',\n","            r'sanctioned.*approved.*intake',\n","            r'ph\\.?d.*student.*details',\n","            r'financial.*resources.*utilised.*amount.*capital.*expenditure',\n","            r'financial.*resources.*utilised.*amount.*operational.*expenditure',\n","            r'consultancy.*project.*details',\n","            r'sponsored.*research.*details',\n","            r'pcs.*facilities.*physically.*challenged.*students',\n","            r'faculty.*details',\n","        ]\n","\n","        is_complete_heading = any(re.search(pattern, text_lower) for pattern in complete_heading_patterns)\n","\n","        is_likely_heading = (\n","            is_complete_heading or\n","            font_size > 12 or\n","            'bold' in font_name or\n","            (text.isupper() and len(text.split()) <= 8) or\n","            text.endswith(':') or\n","            text.startswith(('Do your', 'Does your')) or\n","            (len(text.split()) <= 8 and any(key in text_lower for key in ['sanctioned', 'placement', 'faculty', 'financial']))\n","        )\n","\n","        if not is_likely_heading:\n","            return None\n","\n","        for section_type, patterns in self.section_patterns.items():\n","            for pattern in patterns:\n","                if re.search(pattern, text_lower, re.IGNORECASE):\n","                    if self._validate_section_match(section_type, text_lower, text):\n","                        return section_type\n","        return None\n","\n","    def _validate_section_match(self, section_type, text_lower, original_text):\n","        \"\"\"Enhanced validation with original text length consideration\"\"\"\n","        complete_section_types = ['UG_PLACEMENT', 'PG_PLACEMENT', 'STUDENT_STRENGTH', 'FINANCIAL_RESOURCES']\n","        max_length = 150 if section_type in complete_section_types else 80\n","\n","        if len(original_text) > max_length:\n","            return False\n","\n","        validations = {\n","            'SANCTIONED_INTAKE': lambda t: ('sanctioned' in t or 'approved' in t) and 'intake' in t,\n","            'STUDENT_STRENGTH': lambda t: 'student' in t and 'strength' in t and 'placement' not in t,\n","            'PLACEMENT_STUDIES': lambda t: 'placement' in t and ('studies' in t or 'higher' in t),\n","            'UG_PLACEMENT': lambda t: ('ug' in t or 'undergraduate' in t) and 'placement' in t and 'years' in t,\n","            'PG_PLACEMENT': lambda t: ('pg' in t or 'postgraduate' in t) and 'placement' in t and 'years' in t,\n","            'UG_PROGRAM': lambda t: ('ug' in t or 'undergraduate' in t) and 'program' in t and 'placement' not in t,\n","            'PG_PROGRAM': lambda t: ('pg' in t or 'postgraduate' in t) and 'program' in t and 'placement' not in t,\n","            'PHD_DETAILS': lambda t: ('ph.d' in t or 'phd' in t or 'doctoral' in t) and 'placement' not in t,\n","            'FINANCIAL_RESOURCES': lambda t: ('financial' in t or 'utilised' in t or 'expenditure' in t) and 'placement' not in t,\n","            'IPR': lambda t: t.strip() == 'ipr' or 'intellectual' in t or 'patent' in t,\n","            'SPONSORED_RESEARCH': lambda t: 'sponsored' in t and 'research' in t,\n","            'CONSULTANCY_PROJECTS': lambda t: 'consultancy' in t and 'project' in t,\n","            'PCS_FACILITIES': lambda t: ('pcs' in t or 'physically' in t or 'challenged' in t) and 'placement' not in t,\n","            'FACULTY_DETAILS': lambda t: 'faculty' in t and 'placement' not in t,\n","        }\n","\n","        validator = validations.get(section_type)\n","        return validator(text_lower) if validator else True\n","\n","    def _extract_with_pdfplumber(self, pdf_path):\n","        \"\"\"Extract text using pdfplumber with enhanced section detection\"\"\"\n","        try:\n","            full_text = []\n","            with pdfplumber.open(pdf_path) as pdf:\n","                for page in pdf.pages:\n","                    words = page.extract_words(x_tolerance=1, y_tolerance=1, extra_attrs=[\"size\", \"fontname\"])\n","                    if not words:\n","                        text = page.extract_text()\n","                        if text:\n","                            full_text.append(text + \"\\n\")\n","                        continue\n","                    lines = self._group_words_into_lines(words)\n","                    for i, line in enumerate(lines):\n","                        if not line:\n","                            continue\n","                        text = \" \".join([w[\"text\"] for w in line]).strip()\n","                        if not text:\n","                            continue\n","                        if self._is_table_content(text):\n","                            full_text.append(f\"{text}\\n\")\n","                            continue\n","                        section_type = self._detect_section_type(text, line)\n","                        if section_type:\n","                            full_text.append(f\"###SECTION:{section_type}### {text}\\n\")\n","                        else:\n","                            full_text.append(f\"{text}\\n\")\n","                    tables = page.extract_tables()\n","                    for table_idx, table in enumerate(tables):\n","                        full_text.append(f\"\\n###TABLE:{table_idx}###\\n\")\n","                        for row in table:\n","                            if row:\n","                                full_text.append(\" | \".join(str(cell) if cell else \"\" for cell in row) + \"\\n\")\n","                        full_text.append(\"###END_TABLE###\\n\")\n","            return \"\".join(full_text).strip() if full_text else None\n","        except Exception as e:\n","            print(f\"      pdfplumber failed: {str(e)}\")\n","            return None\n","\n","    def _extract_with_pymupdf(self, pdf_path):\n","        \"\"\"Extract text using PyMuPDF with enhanced section detection\"\"\"\n","        try:\n","            doc = fitz.open(pdf_path)\n","            full_text = []\n","            for page in doc:\n","                blocks = page.get_text(\"dict\")[\"blocks\"]\n","                for block in blocks:\n","                    if block['type'] == 0 and \"lines\" in block:\n","                        for line in block['lines']:\n","                            line_text = \"\"\n","                            line_info = {'size': 12, 'bold': False, 'color': 0}\n","                            for span in line['spans']:\n","                                text = span['text'].strip()\n","                                if text:\n","                                    line_text += text + \" \"\n","                                    line_info['size'] = max(line_info['size'], span['size'])\n","                                    line_info['bold'] = line_info['bold'] or (span['flags'] & 2) != 0\n","                                    line_info['color'] = span.get('color', 0)\n","                            line_text = line_text.strip()\n","                            if not line_text:\n","                                continue\n","                            if self._is_table_content(line_text):\n","                                full_text.append(f\"{line_text}\\n\")\n","                                continue\n","                            mock_line = [{'size': line_info['size'], 'fontname': 'bold' if line_info['bold'] else ''}]\n","                            section_type = self._detect_section_type(line_text, mock_line)\n","                            if section_type:\n","                                full_text.append(f\"###SECTION:{section_type}### {line_text}\\n\")\n","                            else:\n","                                full_text.append(f\"{line_text}\\n\")\n","            doc.close()\n","            return \"\".join(full_text).strip() if full_text else None\n","        except Exception as e:\n","            print(f\"      PyMuPDF failed: {str(e)}\")\n","            return None\n","\n","    def _group_words_into_lines(self, words):\n","        \"\"\"Group words into lines based on vertical position\"\"\"\n","        if not words:\n","            return []\n","        lines = []\n","        current_line = []\n","        current_top = None\n","        for word in words:\n","            word_top = round(word[\"top\"], 1)\n","            if current_top is None or abs(word_top - current_top) <= 2:\n","                current_line.append(word)\n","                current_top = word_top\n","            else:\n","                if current_line:\n","                    lines.append(current_line)\n","                current_line = [word]\n","                current_top = word_top\n","        if current_line:\n","            lines.append(current_line)\n","        return lines\n","\n","    def _extract_with_pypdf2(self, pdf_path):\n","        \"\"\"Extract text using PyPDF2 (fallback method)\"\"\"\n","        try:\n","            with open(pdf_path, 'rb') as file:\n","                pdf_reader = PyPDF2.PdfReader(file)\n","                text = \"\"\n","                for page in pdf_reader.pages:\n","                    page_text = page.extract_text()\n","                    if page_text:\n","                        text += page_text + \"\\n\"\n","                return text.strip() if text.strip() else None\n","        except Exception as e:\n","            print(f\"      PyPDF2 failed: {str(e)}\")\n","            return None\n","\n","    def _extract_with_ocr(self, pdf_path):\n","        \"\"\"Extract text using OCR for scanned PDFs\"\"\"\n","        try:\n","            doc = fitz.open(pdf_path)\n","            text = \"\"\n","            for page_num in range(len(doc)):\n","                page = doc.load_page(page_num)\n","                mat = fitz.Matrix(2, 2)\n","                pix = page.get_pixmap(matrix=mat)\n","                img_data = pix.tobytes(\"png\")\n","                image = Image.open(io.BytesIO(img_data))\n","                page_text = pytesseract.image_to_string(image, lang='eng')\n","                if page_text:\n","                    text += page_text + \"\\n\"\n","            doc.close()\n","            return text.strip() if text.strip() else None\n","        except Exception as e:\n","            print(f\"      OCR failed: {str(e)}\")\n","            return None\n","\n","    def _choose_best_text(self, text_pymupdf, text_pdfplumber, text_pypdf2, text_ocr):\n","        \"\"\"Choose the best text extraction result\"\"\"\n","        texts = [\n","            (\"PyMuPDF\", text_pymupdf),\n","            (\"pdfplumber\", text_pdfplumber),\n","            (\"PyPDF2\", text_pypdf2),\n","            (\"OCR\", text_ocr)\n","        ]\n","        valid_texts = [(method, text) for method, text in texts if text and text.strip()]\n","        if not valid_texts:\n","            return None\n","        priority_methods = [\"PyMuPDF\", \"pdfplumber\"]\n","        for method in priority_methods:\n","            for m, t in valid_texts:\n","                if m == method:\n","                    return t\n","        best_method, best_text = max(valid_texts, key=lambda x: len(x[1]))\n","        print(f\"      Best method: {best_method}\")\n","        return best_text\n","\n","    def _clean_text(self, text):\n","        \"\"\"Clean and normalize extracted text\"\"\"\n","        if not text:\n","            return \"\"\n","        cleaned_text = re.sub(r'([a-z])([A-Z])', r'\\1 \\2', text)\n","        cleaned_text = re.sub(r'(\\d)([A-Za-z])', r'\\1 \\2', cleaned_text)\n","        cleaned_text = re.sub(r'([A-Za-z])(\\d)', r'\\1 \\2', cleaned_text)\n","        cleaned_text = re.sub(r'\\n\\s*\\n', '\\n\\n', cleaned_text)\n","        return cleaned_text.strip()\n","\n","    def save_individual_files(self, pdf_info):\n","        \"\"\"Save ONLY text files for each PDF\"\"\"\n","        safe_name = self.safe_filename(pdf_info['file_name'])\n","        base_name = safe_name.replace('.pdf', '')\n","        text_output_dir = self.output_folder_path / \"text_files\"\n","        text_file_path = None\n","\n","        if pdf_info.get('text_content'):\n","            text_file_path = text_output_dir / f\"{base_name}.txt\"\n","            with open(text_file_path, 'w', encoding='utf-8') as f:\n","                f.write(pdf_info['text_content'])\n","            print(f\"      ‚úì Text saved to: {text_file_path}\")\n","        else:\n","            print(f\"      ‚ö† No text content to save for: {pdf_info['file_name']}\")\n","\n","        return text_file_path\n","\n","    def ingest_all(self):\n","        \"\"\"Ingest all PDF files from the root folder and any subfolders\"\"\"\n","        print(f\"Starting PDF ingestion from: {self.root_folder_path}\")\n","        print(f\"Output will be saved to: {self.output_folder_path}\")\n","        print(\"=\"*70)\n","        pdf_count = 0\n","        for dirpath, dirnames, filenames in os.walk(self.root_folder_path):\n","            for filename in filenames:\n","                if filename.lower().endswith('.pdf'):\n","                    file_path = Path(dirpath) / filename\n","                    print(f\"  Processing file: {file_path.relative_to(self.root_folder_path)}\")\n","                    pdf_info = {\n","                        'file_path': str(file_path),\n","                        'file_name': filename,\n","                        'relative_path': str(file_path.relative_to(self.root_folder_path)),\n","                        'file_size': file_path.stat().st_size,\n","                        'ingestion_time': datetime.now().isoformat()\n","                    }\n","                    text_content = self.extract_pdf_text(file_path)\n","                    pdf_info['text_content'] = text_content\n","                    self.save_individual_files(pdf_info)\n","                    self.all_pdfs.append(pdf_info)\n","                    self.ingestion_log.append(f\"Ingested PDF: {pdf_info['relative_path']}\")\n","                    pdf_count += 1\n","        print(\"\\n\" + \"=\"*70)\n","        print(\"Ingestion Summary:\")\n","        print(f\"üìä Total PDFs processed: {pdf_count}\")\n","        print(f\"üíæ Output saved to: {self.output_folder_path}\")\n","\n","    def search_content(self, search_term, case_sensitive=False):\n","        \"\"\"Search for specific content across all ingested PDFs\"\"\"\n","        results = []\n","        term = search_term if case_sensitive else search_term.lower()\n","        for pdf in self.all_pdfs:\n","            if pdf.get('text_content'):\n","                content = pdf['text_content'] if case_sensitive else pdf['text_content'].lower()\n","                if term in content:\n","                    results.append({\n","                        'file_name': pdf['file_name'],\n","                        'relative_path': pdf['relative_path'],\n","                        'file_path': pdf['file_path']\n","                    })\n","        return results\n","\n","\n","def is_colab():\n","    try:\n","        import google.colab\n","        return True\n","    except ImportError:\n","        return False\n","\n","\n","def get_paths(local_input, local_output):\n","    if is_colab():\n","        from google.colab import drive, files\n","        print(\"üîπ Running in Google Colab environment.\")\n","        try:\n","            drive.mount('/content/drive', force_remount=True)\n","            gdrive_input_folder = \"/content/drive/MyDrive/\" + os.path.basename(local_input)\n","            if os.path.exists(gdrive_input_folder):\n","                print(\"‚úì Found input folder on Google Drive.\")\n","                return gdrive_input_folder, gdrive_input_folder + \"_extracted\"\n","        except Exception as e:\n","            print(f\"‚ö† Could not mount Google Drive or find folder: {e}\")\n","            print(\"Falling back to ZIP upload.\")\n","        print(\"\\nüìÇ Please upload your ZIP file now.\")\n","        uploaded = files.upload()\n","        if not uploaded:\n","            print(\"‚ùå No file uploaded. Exiting.\")\n","            return None, None\n","        zip_name = next(iter(uploaded))\n","        extract_path = \"/content/\" + os.path.splitext(zip_name)[0]\n","        print(f\"üì¶ Extracting {zip_name} to {extract_path}...\")\n","        with zipfile.ZipFile(zip_name, 'r') as zip_ref:\n","            zip_ref.extractall(extract_path)\n","        print(\"‚úì Extraction complete.\")\n","        input_folder = extract_path\n","        output_folder = extract_path + \"_extracted\"\n","        print(\"üîπ Using ZIP Upload paths:\")\n","        return input_folder, output_folder\n","    else:\n","        print(\"üîπ Running on Local PC.\")\n","        return local_input, local_output\n","\n","\n","def download_results_from_colab(output_folder_path):\n","    \"\"\"IMPROVED: Download with better error handling and file checks\"\"\"\n","    if not is_colab():\n","        print(\"üîπ Running locally - no download needed.\")\n","        return\n","\n","    try:\n","        from google.colab import files\n","\n","        print(\"\\nüì¶ Preparing output files for download...\")\n","\n","        # Check if output folder exists\n","        if not os.path.exists(output_folder_path):\n","            print(f\"‚ùå Output folder not found: {output_folder_path}\")\n","            return\n","\n","        # Check if there are any files to download\n","        file_count = sum([len(files_list) for r, d, files_list in os.walk(output_folder_path)])\n","        if file_count == 0:\n","            print(\"‚ùå No files found in output folder!\")\n","            return\n","\n","        print(f\"‚úì Found {file_count} files to package\")\n","\n","        # Create ZIP file name\n","        output_zip_name = f\"{os.path.basename(output_folder_path)}.zip\"\n","        zip_path = f\"/content/{output_zip_name}\"\n","\n","        # Remove existing ZIP if present\n","        if os.path.exists(zip_path):\n","            os.remove(zip_path)\n","            print(f\"üßπ Removed existing ZIP file\")\n","\n","        # Create ZIP file\n","        print(\"üì¶ Creating ZIP file...\")\n","        with zipfile.ZipFile(zip_path, 'w', zipfile.ZIP_DEFLATED) as zipf:\n","            for root, dirs, files_to_add in os.walk(output_folder_path):\n","                for file_to_add in files_to_add:\n","                    file_path = os.path.join(root, file_to_add)\n","                    arcname = os.path.relpath(file_path, output_folder_path)\n","                    zipf.write(file_path, arcname)\n","                    print(f\"  ‚úì Added: {arcname}\")\n","\n","        # Check ZIP file was created successfully\n","        if not os.path.exists(zip_path):\n","            print(\"‚ùå Failed to create ZIP file!\")\n","            return\n","\n","        zip_size_mb = os.path.getsize(zip_path) / (1024 * 1024)\n","        print(f\"\\n‚úì ZIP file created successfully!\")\n","        print(f\"üìä ZIP file size: {zip_size_mb:.2f} MB\")\n","        print(f\"üìç ZIP file location: {zip_path}\")\n","\n","        # Download the ZIP file\n","        print(\"\\n‚¨áÔ∏è Starting download...\")\n","        print(\"üí° Check your browser's download folder (usually at bottom of browser window)\")\n","\n","        files.download(zip_path)\n","\n","        print(\"\\n‚úÖ Download initiated successfully!\")\n","        print(\"üì• If download didn't start automatically:\")\n","        print(\"   1. Check your browser's download folder\")\n","        print(\"   2. Look for pop-up blocker notifications\")\n","        print(f\"   3. The file is also available at: {zip_path}\")\n","\n","    except Exception as e:\n","        print(f\"\\n‚ùå Error during download: {str(e)}\")\n","        print(f\"üìÅ You can manually download from: {output_folder_path}\")\n","        print(\"üí° Alternative: Use the Colab file browser (folder icon on the left)\")\n","\n","\n","if __name__ == \"__main__\":\n","    print(\"PDF Ingestion Tool - Simplified Edition (Text Files Only)\")\n","    print(\"=\" * 60)\n","\n","    # Set your local paths here\n","    local_input = r\"C:\\Users\\siddhu\\Desktop\\NIRF(151 to 200)\"\n","    local_output = r\"C:\\Users\\siddhu\\Desktop\\NIRF(151 to 200)_extracted\"\n","\n","    # Get appropriate paths based on environment\n","    input_folder, output_folder = get_paths(local_input, local_output)\n","    if not input_folder:\n","        exit(1)\n","\n","    print(f\"\\nInput folder: {input_folder}\")\n","    print(f\"Output folder: {output_folder}\")\n","    print(\"=\" * 60)\n","\n","    # Create ingester and process files\n","    ingester = PDFIngesterFlat(input_folder, output_folder)\n","    ingester.ingest_all()\n","\n","    # Display output structure\n","    print(\"\\n\" + \"=\"*60)\n","    print(\"OUTPUT STRUCTURE:\")\n","    print(\"=\"*60)\n","    print(f\"üìÅ {ingester.output_folder_path}/\")\n","    print(\"‚îî‚îÄ‚îÄ üìÑ text_files/\")\n","    print(\"    ‚îî‚îÄ‚îÄ [all_pdfs_as_txt]\")\n","\n","    print(\"\\n\" + \"=\"*60)\n","    print(\"PROCESSING COMPLETE!\")\n","    print(f\"‚úì All extracted text files saved to: {ingester.output_folder_path}/text_files/\")\n","    print(\"=\"*60)\n","\n","    # Auto-download results if running in Colab\n","    if is_colab():\n","        print(\"\\nüîπ Google Colab detected - preparing download...\")\n","        print(\"‚è≥ This may take a moment for large outputs...\")\n","        download_results_from_colab(ingester.output_folder_path)\n","\n","    # Interactive search functionality\n","    print(\"\\n\" + \"=\"*60)\n","    print(\"SEARCH FUNCTIONALITY:\")\n","    print(\"=\"*60)\n","    while True:\n","        search_term = input(\"\\nEnter search term (or 'quit' to exit): \").strip()\n","        if search_term.lower() in ['quit', 'exit', 'q', '']:\n","            break\n","\n","        search_results = ingester.search_content(search_term)\n","        if search_results:\n","            print(f\"\\nüîç Found '{search_term}' in {len(search_results)} files:\")\n","            for result in search_results:\n","                print(f\"  ‚úì {result['file_name']}\")\n","        else:\n","            print(f\"‚ùå No results found for '{search_term}'\")\n","\n","    print(\"\\nüëã Thanks for using PDF Ingestion Tool!\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"Qt3FuxN7M5hq","executionInfo":{"status":"error","timestamp":1762970638399,"user_tz":-330,"elapsed":512978,"user":{"displayName":"Rahul Siddhu","userId":"12007764243202946991"}},"outputId":"1948fb39-af40-41c0-be85-234c802dd0cf"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["PDF Ingestion Tool - Simplified Edition (Text Files Only)\n","============================================================\n","üîπ Running in Google Colab environment.\n","‚ö† Could not mount Google Drive or find folder: Error: credential propagation was unsuccessful\n","Falling back to ZIP upload.\n","\n","üìÇ Please upload your ZIP file now.\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","     <input type=\"file\" id=\"files-a955def6-ce84-44e9-b364-025152206df9\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-a955def6-ce84-44e9-b364-025152206df9\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script>// Copyright 2017 Google LLC\n","//\n","// Licensed under the Apache License, Version 2.0 (the \"License\");\n","// you may not use this file except in compliance with the License.\n","// You may obtain a copy of the License at\n","//\n","//      http://www.apache.org/licenses/LICENSE-2.0\n","//\n","// Unless required by applicable law or agreed to in writing, software\n","// distributed under the License is distributed on an \"AS IS\" BASIS,\n","// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","// See the License for the specific language governing permissions and\n","// limitations under the License.\n","\n","/**\n"," * @fileoverview Helpers for google.colab Python module.\n"," */\n","(function(scope) {\n","function span(text, styleAttributes = {}) {\n","  const element = document.createElement('span');\n","  element.textContent = text;\n","  for (const key of Object.keys(styleAttributes)) {\n","    element.style[key] = styleAttributes[key];\n","  }\n","  return element;\n","}\n","\n","// Max number of bytes which will be uploaded at a time.\n","const MAX_PAYLOAD_SIZE = 100 * 1024;\n","\n","function _uploadFiles(inputId, outputId) {\n","  const steps = uploadFilesStep(inputId, outputId);\n","  const outputElement = document.getElementById(outputId);\n","  // Cache steps on the outputElement to make it available for the next call\n","  // to uploadFilesContinue from Python.\n","  outputElement.steps = steps;\n","\n","  return _uploadFilesContinue(outputId);\n","}\n","\n","// This is roughly an async generator (not supported in the browser yet),\n","// where there are multiple asynchronous steps and the Python side is going\n","// to poll for completion of each step.\n","// This uses a Promise to block the python side on completion of each step,\n","// then passes the result of the previous step as the input to the next step.\n","function _uploadFilesContinue(outputId) {\n","  const outputElement = document.getElementById(outputId);\n","  const steps = outputElement.steps;\n","\n","  const next = steps.next(outputElement.lastPromiseValue);\n","  return Promise.resolve(next.value.promise).then((value) => {\n","    // Cache the last promise value to make it available to the next\n","    // step of the generator.\n","    outputElement.lastPromiseValue = value;\n","    return next.value.response;\n","  });\n","}\n","\n","/**\n"," * Generator function which is called between each async step of the upload\n"," * process.\n"," * @param {string} inputId Element ID of the input file picker element.\n"," * @param {string} outputId Element ID of the output display.\n"," * @return {!Iterable<!Object>} Iterable of next steps.\n"," */\n","function* uploadFilesStep(inputId, outputId) {\n","  const inputElement = document.getElementById(inputId);\n","  inputElement.disabled = false;\n","\n","  const outputElement = document.getElementById(outputId);\n","  outputElement.innerHTML = '';\n","\n","  const pickedPromise = new Promise((resolve) => {\n","    inputElement.addEventListener('change', (e) => {\n","      resolve(e.target.files);\n","    });\n","  });\n","\n","  const cancel = document.createElement('button');\n","  inputElement.parentElement.appendChild(cancel);\n","  cancel.textContent = 'Cancel upload';\n","  const cancelPromise = new Promise((resolve) => {\n","    cancel.onclick = () => {\n","      resolve(null);\n","    };\n","  });\n","\n","  // Wait for the user to pick the files.\n","  const files = yield {\n","    promise: Promise.race([pickedPromise, cancelPromise]),\n","    response: {\n","      action: 'starting',\n","    }\n","  };\n","\n","  cancel.remove();\n","\n","  // Disable the input element since further picks are not allowed.\n","  inputElement.disabled = true;\n","\n","  if (!files) {\n","    return {\n","      response: {\n","        action: 'complete',\n","      }\n","    };\n","  }\n","\n","  for (const file of files) {\n","    const li = document.createElement('li');\n","    li.append(span(file.name, {fontWeight: 'bold'}));\n","    li.append(span(\n","        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n","        `last modified: ${\n","            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n","                                    'n/a'} - `));\n","    const percent = span('0% done');\n","    li.appendChild(percent);\n","\n","    outputElement.appendChild(li);\n","\n","    const fileDataPromise = new Promise((resolve) => {\n","      const reader = new FileReader();\n","      reader.onload = (e) => {\n","        resolve(e.target.result);\n","      };\n","      reader.readAsArrayBuffer(file);\n","    });\n","    // Wait for the data to be ready.\n","    let fileData = yield {\n","      promise: fileDataPromise,\n","      response: {\n","        action: 'continue',\n","      }\n","    };\n","\n","    // Use a chunked sending to avoid message size limits. See b/62115660.\n","    let position = 0;\n","    do {\n","      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n","      const chunk = new Uint8Array(fileData, position, length);\n","      position += length;\n","\n","      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n","      yield {\n","        response: {\n","          action: 'append',\n","          file: file.name,\n","          data: base64,\n","        },\n","      };\n","\n","      let percentDone = fileData.byteLength === 0 ?\n","          100 :\n","          Math.round((position / fileData.byteLength) * 100);\n","      percent.textContent = `${percentDone}% done`;\n","\n","    } while (position < fileData.byteLength);\n","  }\n","\n","  // All done.\n","  yield {\n","    response: {\n","      action: 'complete',\n","    }\n","  };\n","}\n","\n","scope.google = scope.google || {};\n","scope.google.colab = scope.google.colab || {};\n","scope.google.colab._files = {\n","  _uploadFiles,\n","  _uploadFilesContinue,\n","};\n","})(self);\n","</script> "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Saving Engineering (1 to 100) 2024.zip to Engineering (1 to 100) 2024 (1).zip\n","üì¶ Extracting Engineering (1 to 100) 2024 (1).zip to /content/Engineering (1 to 100) 2024 (1)...\n","‚úì Extraction complete.\n","üîπ Using ZIP Upload paths:\n","\n","Input folder: /content/Engineering (1 to 100) 2024 (1)\n","Output folder: /content/Engineering (1 to 100) 2024 (1)_extracted\n","============================================================\n","Creating output directory structure at: /content/Engineering (1 to 100) 2024 (1)_extracted\n","‚úì Output structure created at: /content/Engineering (1 to 100) 2024 (1)_extracted\n","Starting PDF ingestion from: /content/Engineering (1 to 100) 2024 (1)\n","Output will be saved to: /content/Engineering (1 to 100) 2024 (1)_extracted\n","======================================================================\n","  Processing file: Engineering (1 to 100) 2024/Rajiv Gandhi Institute of Petroleum Technology.pdf\n","    Extracting text from: Rajiv Gandhi Institute of Petroleum Technology.pdf\n","      ‚úì Extracted 7114 characters\n","      ‚úì Text saved to: /content/Engineering (1 to 100) 2024 (1)_extracted/text_files/Rajiv Gandhi Institute of Petroleum Technology.txt\n","  Processing file: Engineering (1 to 100) 2024/IIT Madras.pdf\n","    Extracting text from: IIT Madras.pdf\n","      ‚úì Extracted 9330 characters\n","      ‚úì Text saved to: /content/Engineering (1 to 100) 2024 (1)_extracted/text_files/IIT Madras.txt\n","  Processing file: Engineering (1 to 100) 2024/IIT Ropar.pdf\n","    Extracting text from: IIT Ropar.pdf\n","      ‚úì Extracted 8027 characters\n","      ‚úì Text saved to: /content/Engineering (1 to 100) 2024 (1)_extracted/text_files/IIT Ropar.txt\n","  Processing file: Engineering (1 to 100) 2024/K L College of Engineering(Vaddeswaram).pdf\n","    Extracting text from: K L College of Engineering(Vaddeswaram).pdf\n","      ‚úì Extracted 7294 characters\n","      ‚úì Text saved to: /content/Engineering (1 to 100) 2024 (1)_extracted/text_files/K L College of Engineering_Vaddeswaram_.txt\n","  Processing file: Engineering (1 to 100) 2024/COEP Technological University.pdf\n","    Extracting text from: COEP Technological University.pdf\n","      ‚úì Extracted 7335 characters\n","      ‚úì Text saved to: /content/Engineering (1 to 100) 2024 (1)_extracted/text_files/COEP Technological University.txt\n","  Processing file: Engineering (1 to 100) 2024/Guru Gobind Singh Indraprastha University.pdf\n","    Extracting text from: Guru Gobind Singh Indraprastha University.pdf\n","      ‚úì Extracted 6800 characters\n","      ‚úì Text saved to: /content/Engineering (1 to 100) 2024 (1)_extracted/text_files/Guru Gobind Singh Indraprastha University.txt\n","  Processing file: Engineering (1 to 100) 2024/NIT  Agartala.pdf\n","    Extracting text from: NIT  Agartala.pdf\n","      ‚úì Extracted 6873 characters\n","      ‚úì Text saved to: /content/Engineering (1 to 100) 2024 (1)_extracted/text_files/NIT  Agartala.txt\n","  Processing file: Engineering (1 to 100) 2024/International Institute of Information Technology Bangalore.pdf\n","    Extracting text from: International Institute of Information Technology Bangalore.pdf\n","      ‚úì Extracted 7009 characters\n","      ‚úì Text saved to: /content/Engineering (1 to 100) 2024 (1)_extracted/text_files/International Institute of Information Technology Bangalore.txt\n","  Processing file: Engineering (1 to 100) 2024/Vel Tech Rangarajan Dr. Sagunthala R & D Institute of Science and Technology.pdf\n","    Extracting text from: Vel Tech Rangarajan Dr. Sagunthala R & D Institute of Science and Technology.pdf\n","      ‚úì Extracted 7367 characters\n","      ‚úì Text saved to: /content/Engineering (1 to 100) 2024 (1)_extracted/text_files/Vel Tech Rangarajan Dr. Sagunthala R _ D Institute of Science and Technology.txt\n","  Processing file: Engineering (1 to 100) 2024/IIIT Allahabad.pdf\n","    Extracting text from: IIIT Allahabad.pdf\n","      ‚úì Extracted 6526 characters\n","      ‚úì Text saved to: /content/Engineering (1 to 100) 2024 (1)_extracted/text_files/IIIT Allahabad.txt\n","  Processing file: Engineering (1 to 100) 2024/Amrita Vishwa Vidyapeetham.pdf\n","    Extracting text from: Amrita Vishwa Vidyapeetham.pdf\n","      ‚úì Extracted 90204 characters\n","      ‚úì Text saved to: /content/Engineering (1 to 100) 2024 (1)_extracted/text_files/Amrita Vishwa Vidyapeetham.txt\n","  Processing file: Engineering (1 to 100) 2024/Indian Institute of Technology (Indian School of Mines) Dhanbad.pdf\n","    Extracting text from: Indian Institute of Technology (Indian School of Mines) Dhanbad.pdf\n","      ‚úì Extracted 8246 characters\n","      ‚úì Text saved to: /content/Engineering (1 to 100) 2024 (1)_extracted/text_files/Indian Institute of Technology _Indian School of Mines_ Dhanbad.txt\n","  Processing file: Engineering (1 to 100) 2024/Delhi Technological University.pdf\n","    Extracting text from: Delhi Technological University.pdf\n","      ‚úì Extracted 7329 characters\n","      ‚úì Text saved to: /content/Engineering (1 to 100) 2024 (1)_extracted/text_files/Delhi Technological University.txt\n","  Processing file: Engineering (1 to 100) 2024/Dr. B R Ambedkar National Institute of Technology Jalandhar.pdf\n","    Extracting text from: Dr. B R Ambedkar National Institute of Technology Jalandhar.pdf\n","      ‚úì Extracted 7204 characters\n","      ‚úì Text saved to: /content/Engineering (1 to 100) 2024 (1)_extracted/text_files/Dr. B R Ambedkar National Institute of Technology Jalandhar.txt\n","  Processing file: Engineering (1 to 100) 2024/IIT Kanpur.pdf\n","    Extracting text from: IIT Kanpur.pdf\n","      ‚úì Extracted 6847 characters\n","      ‚úì Text saved to: /content/Engineering (1 to 100) 2024 (1)_extracted/text_files/IIT Kanpur.txt\n","  Processing file: Engineering (1 to 100) 2024/Shanmugha Arts Science Technology and Research Academy.pdf\n","    Extracting text from: Shanmugha Arts Science Technology and Research Academy.pdf\n","      ‚úì Extracted 7840 characters\n","      ‚úì Text saved to: /content/Engineering (1 to 100) 2024 (1)_extracted/text_files/Shanmugha Arts Science Technology and Research Academy.txt\n","  Processing file: Engineering (1 to 100) 2024/Thapar Institute of Engineering and Technology (Deemed-to-be-university.pdf\n","    Extracting text from: Thapar Institute of Engineering and Technology (Deemed-to-be-university.pdf\n","      ‚úì Extracted 7275 characters\n","      ‚úì Text saved to: /content/Engineering (1 to 100) 2024 (1)_extracted/text_files/Thapar Institute of Engineering and Technology _Deemed-to-be-university.txt\n","  Processing file: Engineering (1 to 100) 2024/Shoolini University of Biotechnology and Management Science.pdf\n","    Extracting text from: Shoolini University of Biotechnology and Management Science.pdf\n","      ‚úì Extracted 6506 characters\n","      ‚úì Text saved to: /content/Engineering (1 to 100) 2024 (1)_extracted/text_files/Shoolini University of Biotechnology and Management Science.txt\n","  Processing file: Engineering (1 to 100) 2024/Jawaharlal Nehru Technological University.pdf\n","    Extracting text from: Jawaharlal Nehru Technological University.pdf\n","      ‚úì Extracted 7718 characters\n","      ‚úì Text saved to: /content/Engineering (1 to 100) 2024 (1)_extracted/text_files/Jawaharlal Nehru Technological University.txt\n","  Processing file: Engineering (1 to 100) 2024/Amity University.pdf\n","    Extracting text from: Amity University.pdf\n","      ‚úì Extracted 7531 characters\n","      ‚úì Text saved to: /content/Engineering (1 to 100) 2024 (1)_extracted/text_files/Amity University.txt\n","  Processing file: Engineering (1 to 100) 2024/NIT Tiruchirappalli.pdf\n","    Extracting text from: NIT Tiruchirappalli.pdf\n","      ‚úì Extracted 7610 characters\n","      ‚úì Text saved to: /content/Engineering (1 to 100) 2024 (1)_extracted/text_files/NIT Tiruchirappalli.txt\n","  Processing file: Engineering (1 to 100) 2024/Madan Mohan Malaviya University of Technology.pdf\n","    Extracting text from: Madan Mohan Malaviya University of Technology.pdf\n","      ‚úì Extracted 7087 characters\n","      ‚úì Text saved to: /content/Engineering (1 to 100) 2024 (1)_extracted/text_files/Madan Mohan Malaviya University of Technology.txt\n","  Processing file: Engineering (1 to 100) 2024/Anna University.pdf\n","    Extracting text from: Anna University.pdf\n","      ‚úì Extracted 80499 characters\n","      ‚úì Text saved to: /content/Engineering (1 to 100) 2024 (1)_extracted/text_files/Anna University.txt\n","  Processing file: Engineering (1 to 100) 2024/Chandigarh University.pdf\n","    Extracting text from: Chandigarh University.pdf\n","      ‚úì Extracted 7898 characters\n","      ‚úì Text saved to: /content/Engineering (1 to 100) 2024 (1)_extracted/text_files/Chandigarh University.txt\n","  Processing file: Engineering (1 to 100) 2024/NIT  Puducherry.pdf\n","    Extracting text from: NIT  Puducherry.pdf\n","      ‚úì Extracted 7366 characters\n","      ‚úì Text saved to: /content/Engineering (1 to 100) 2024 (1)_extracted/text_files/NIT  Puducherry.txt\n","  Processing file: Engineering (1 to 100) 2024/IIT Gandhinagar.pdf\n","    Extracting text from: IIT Gandhinagar.pdf\n","      ‚úì Extracted 7907 characters\n","      ‚úì Text saved to: /content/Engineering (1 to 100) 2024 (1)_extracted/text_files/IIT Gandhinagar.txt\n","  Processing file: Engineering (1 to 100) 2024/R.V. College of Engineering.pdf\n","    Extracting text from: R.V. College of Engineering.pdf\n","      ‚úì Extracted 7341 characters\n","      ‚úì Text saved to: /content/Engineering (1 to 100) 2024 (1)_extracted/text_files/R.V. College of Engineering.txt\n","  Processing file: Engineering (1 to 100) 2024/IIT Indore.pdf\n","    Extracting text from: IIT Indore.pdf\n","      ‚úì Extracted 7124 characters\n","      ‚úì Text saved to: /content/Engineering (1 to 100) 2024 (1)_extracted/text_files/IIT Indore.txt\n","  Processing file: Engineering (1 to 100) 2024/Birla Institute of Technology  and Science, Pilani.pdf\n","    Extracting text from: Birla Institute of Technology  and Science, Pilani.pdf\n","      ‚úì Extracted 7331 characters\n","      ‚úì Text saved to: /content/Engineering (1 to 100) 2024 (1)_extracted/text_files/Birla Institute of Technology  and Science_ Pilani.txt\n","  Processing file: Engineering (1 to 100) 2024/Sardar Vallabhbhai National Institute of Technology.pdf\n","    Extracting text from: Sardar Vallabhbhai National Institute of Technology.pdf\n","      ‚úì Extracted 7486 characters\n","      ‚úì Text saved to: /content/Engineering (1 to 100) 2024 (1)_extracted/text_files/Sardar Vallabhbhai National Institute of Technology.txt\n","  Processing file: Engineering (1 to 100) 2024/IIT Bhilai.pdf\n","    Extracting text from: IIT Bhilai.pdf\n","      ‚úì Extracted 7122 characters\n","      ‚úì Text saved to: /content/Engineering (1 to 100) 2024 (1)_extracted/text_files/IIT Bhilai.txt\n","  Processing file: Engineering (1 to 100) 2024/Institute of Chemical Technology.pdf\n","    Extracting text from: Institute of Chemical Technology.pdf\n","      ‚úì Extracted 7801 characters\n","      ‚úì Text saved to: /content/Engineering (1 to 100) 2024 (1)_extracted/text_files/Institute of Chemical Technology.txt\n","  Processing file: Engineering (1 to 100) 2024/NIT Silchar.pdf\n","    Extracting text from: NIT Silchar.pdf\n","      ‚úì Extracted 7220 characters\n","      ‚úì Text saved to: /content/Engineering (1 to 100) 2024 (1)_extracted/text_files/NIT Silchar.txt\n","  Processing file: Engineering (1 to 100) 2024/NIT Delhi.pdf\n","    Extracting text from: NIT Delhi.pdf\n","      ‚úì Extracted 6870 characters\n","      ‚úì Text saved to: /content/Engineering (1 to 100) 2024 (1)_extracted/text_files/NIT Delhi.txt\n","  Processing file: Engineering (1 to 100) 2024/Malaviya National Institute of Technology.pdf\n","    Extracting text from: Malaviya National Institute of Technology.pdf\n","      ‚úì Extracted 7208 characters\n","      ‚úì Text saved to: /content/Engineering (1 to 100) 2024 (1)_extracted/text_files/Malaviya National Institute of Technology.txt\n","  Processing file: Engineering (1 to 100) 2024/Kalinga Institute of Industrial Technology.pdf\n","    Extracting text from: Kalinga Institute of Industrial Technology.pdf\n","      ‚úì Extracted 7422 characters\n","      ‚úì Text saved to: /content/Engineering (1 to 100) 2024 (1)_extracted/text_files/Kalinga Institute of Industrial Technology.txt\n","  Processing file: Engineering (1 to 100) 2024/Aligarh Muslim University.pdf\n","    Extracting text from: Aligarh Muslim University.pdf\n","      ‚úì Extracted 25555 characters\n","      ‚úì Text saved to: /content/Engineering (1 to 100) 2024 (1)_extracted/text_files/Aligarh Muslim University.txt\n","  Processing file: Engineering (1 to 100) 2024/Visvesvaraya National Institute of Technology Nagpur.pdf\n","    Extracting text from: Visvesvaraya National Institute of Technology Nagpur.pdf\n","      ‚úì Extracted 7301 characters\n","      ‚úì Text saved to: /content/Engineering (1 to 100) 2024 (1)_extracted/text_files/Visvesvaraya National Institute of Technology Nagpur.txt\n","  Processing file: Engineering (1 to 100) 2024/Sant Longowal Institute of Engineering and Technology.pdf\n","    Extracting text from: Sant Longowal Institute of Engineering and Technology.pdf\n","      ‚úì Extracted 7172 characters\n","      ‚úì Text saved to: /content/Engineering (1 to 100) 2024 (1)_extracted/text_files/Sant Longowal Institute of Engineering and Technology.txt\n","  Processing file: Engineering (1 to 100) 2024/IIT Roorkee 2024.pdf\n","    Extracting text from: IIT Roorkee 2024.pdf\n","      ‚úì Extracted 8318 characters\n","      ‚úì Text saved to: /content/Engineering (1 to 100) 2024 (1)_extracted/text_files/IIT Roorkee 2024.txt\n","  Processing file: Engineering (1 to 100) 2024/Jain University, Bangalore.pdf\n","    Extracting text from: Jain University, Bangalore.pdf\n","      ‚úì Extracted 7383 characters\n","      ‚úì Text saved to: /content/Engineering (1 to 100) 2024 (1)_extracted/text_files/Jain University_ Bangalore.txt\n","  Processing file: Engineering (1 to 100) 2024/Sri Sivasubramaniya Nadar College of Engineering.pdf\n","    Extracting text from: Sri Sivasubramaniya Nadar College of Engineering.pdf\n","      ‚úì Extracted 7106 characters\n","      ‚úì Text saved to: /content/Engineering (1 to 100) 2024 (1)_extracted/text_files/Sri Sivasubramaniya Nadar College of Engineering.txt\n","  Processing file: Engineering (1 to 100) 2024/IIT Patna.pdf\n","    Extracting text from: IIT Patna.pdf\n","      ‚úì Extracted 7515 characters\n","      ‚úì Text saved to: /content/Engineering (1 to 100) 2024 (1)_extracted/text_files/IIT Patna.txt\n","  Processing file: Engineering (1 to 100) 2024/NIT Raipur.pdf\n","    Extracting text from: NIT Raipur.pdf\n","      ‚úì Extracted 8076 characters\n","      ‚úì Text saved to: /content/Engineering (1 to 100) 2024 (1)_extracted/text_files/NIT Raipur.txt\n","  Processing file: Engineering (1 to 100) 2024/Jamia Millia Islamia.pdf\n","    Extracting text from: Jamia Millia Islamia.pdf\n","      ‚úì Extracted 6904 characters\n","      ‚úì Text saved to: /content/Engineering (1 to 100) 2024 (1)_extracted/text_files/Jamia Millia Islamia.txt\n","  Processing file: Engineering (1 to 100) 2024/Netaji Subhas University of Technology (NSUT).pdf\n","    Extracting text from: Netaji Subhas University of Technology (NSUT).pdf\n","      ‚úì Extracted 7177 characters\n","      ‚úì Text saved to: /content/Engineering (1 to 100) 2024 (1)_extracted/text_files/Netaji Subhas University of Technology _NSUT_.txt\n","  Processing file: Engineering (1 to 100) 2024/IIT Jammu.pdf\n","    Extracting text from: IIT Jammu.pdf\n","      ‚úì Extracted 7932 characters\n","      ‚úì Text saved to: /content/Engineering (1 to 100) 2024 (1)_extracted/text_files/IIT Jammu.txt\n","  Processing file: Engineering (1 to 100) 2024/UPES.pdf\n","    Extracting text from: UPES.pdf\n","      ‚úì Extracted 7103 characters\n","      ‚úì Text saved to: /content/Engineering (1 to 100) 2024 (1)_extracted/text_files/UPES.txt\n","  Processing file: Engineering (1 to 100) 2024/VIT Vellore.pdf\n","    Extracting text from: VIT Vellore.pdf\n","      ‚úì Extracted 8146 characters\n","      ‚úì Text saved to: /content/Engineering (1 to 100) 2024 (1)_extracted/text_files/VIT Vellore.txt\n","  Processing file: Engineering (1 to 100) 2024/IIT Guwahati.pdf\n","    Extracting text from: IIT Guwahati.pdf\n","      ‚úì Extracted 7245 characters\n","      ‚úì Text saved to: /content/Engineering (1 to 100) 2024 (1)_extracted/text_files/IIT Guwahati.txt\n","  Processing file: Engineering (1 to 100) 2024/Kalasalingam Academy of Research and Education.pdf\n","    Extracting text from: Kalasalingam Academy of Research and Education.pdf\n","      ‚úì Extracted 7310 characters\n","      ‚úì Text saved to: /content/Engineering (1 to 100) 2024 (1)_extracted/text_files/Kalasalingam Academy of Research and Education.txt\n","  Processing file: Engineering (1 to 100) 2024/IIEST Shibpur.pdf\n","    Extracting text from: IIEST Shibpur.pdf\n","      ‚úì Extracted 7058 characters\n","      ‚úì Text saved to: /content/Engineering (1 to 100) 2024 (1)_extracted/text_files/IIEST Shibpur.txt\n","  Processing file: Engineering (1 to 100) 2024/Jadavpur University.pdf\n","    Extracting text from: Jadavpur University.pdf\n","      ‚úì Extracted 7705 characters\n","      ‚úì Text saved to: /content/Engineering (1 to 100) 2024 (1)_extracted/text_files/Jadavpur University.txt\n","  Processing file: Engineering (1 to 100) 2024/Vignan's Foundation for Science, Technology and Research.pdf\n","    Extracting text from: Vignan's Foundation for Science, Technology and Research.pdf\n","      ‚úì Extracted 7335 characters\n","      ‚úì Text saved to: /content/Engineering (1 to 100) 2024 (1)_extracted/text_files/Vignan_s Foundation for Science_ Technology and Research.txt\n","  Processing file: Engineering (1 to 100) 2024/Manipal Institute of Technology.pdf\n","    Extracting text from: Manipal Institute of Technology.pdf\n","      ‚úì Extracted 7251 characters\n","      ‚úì Text saved to: /content/Engineering (1 to 100) 2024 (1)_extracted/text_files/Manipal Institute of Technology.txt\n","  Processing file: Engineering (1 to 100) 2024/NIT Srinagar.pdf\n","    Extracting text from: NIT Srinagar.pdf\n","      ‚úì Extracted 7274 characters\n","      ‚úì Text saved to: /content/Engineering (1 to 100) 2024 (1)_extracted/text_files/NIT Srinagar.txt\n","  Processing file: Engineering (1 to 100) 2024/IIT Delhi.pdf\n","    Extracting text from: IIT Delhi.pdf\n","      ‚úì Extracted 8376 characters\n","      ‚úì Text saved to: /content/Engineering (1 to 100) 2024 (1)_extracted/text_files/IIT Delhi.txt\n","  Processing file: Engineering (1 to 100) 2024/M. S. Ramaiah Institute of Technology.pdf\n","    Extracting text from: M. S. Ramaiah Institute of Technology.pdf\n","      ‚úì Extracted 7135 characters\n","      ‚úì Text saved to: /content/Engineering (1 to 100) 2024 (1)_extracted/text_files/M. S. Ramaiah Institute of Technology.txt\n","  Processing file: Engineering (1 to 100) 2024/SR University Warangal.pdf\n","    Extracting text from: SR University Warangal.pdf\n","      ‚úì Extracted 6894 characters\n","      ‚úì Text saved to: /content/Engineering (1 to 100) 2024 (1)_extracted/text_files/SR University Warangal.txt\n","  Processing file: Engineering (1 to 100) 2024/Engineering  2024.pdf\n","    Extracting text from: Engineering  2024.pdf\n","      ‚úì Extracted 7099 characters\n","      ‚úì Text saved to: /content/Engineering (1 to 100) 2024 (1)_extracted/text_files/Engineering  2024.txt\n","  Processing file: Engineering (1 to 100) 2024/NIT Warangal.pdf\n","    Extracting text from: NIT Warangal.pdf\n","      ‚úì Extracted 7443 characters\n","      ‚úì Text saved to: /content/Engineering (1 to 100) 2024 (1)_extracted/text_files/NIT Warangal.txt\n","  Processing file: Engineering (1 to 100) 2024/IIT Mandi.pdf\n","    Extracting text from: IIT Mandi.pdf\n","      ‚úì Extracted 7764 characters\n","      ‚úì Text saved to: /content/Engineering (1 to 100) 2024 (1)_extracted/text_files/IIT Mandi.txt\n","  Processing file: Engineering (1 to 100) 2024/PSG College of Technology.pdf\n","    Extracting text from: PSG College of Technology.pdf\n","      ‚úì Extracted 7531 characters\n","      ‚úì Text saved to: /content/Engineering (1 to 100) 2024 (1)_extracted/text_files/PSG College of Technology.txt\n","  Processing file: Engineering (1 to 100) 2024/Defence Institute of Adavanced Technology.pdf\n","    Extracting text from: Defence Institute of Adavanced Technology.pdf\n","      ‚úì Extracted 6328 characters\n","      ‚úì Text saved to: /content/Engineering (1 to 100) 2024 (1)_extracted/text_files/Defence Institute of Adavanced Technology.txt\n","  Processing file: Engineering (1 to 100) 2024/NIT Durgapur.pdf\n","    Extracting text from: NIT Durgapur.pdf\n","      ‚úì Extracted 8017 characters\n","      ‚úì Text saved to: /content/Engineering (1 to 100) 2024 (1)_extracted/text_files/NIT Durgapur.txt\n","  Processing file: Engineering (1 to 100) 2024/Manipal University, Jaipur.pdf\n","    Extracting text from: Manipal University, Jaipur.pdf\n","      ‚úì Extracted 6797 characters\n","      ‚úì Text saved to: /content/Engineering (1 to 100) 2024 (1)_extracted/text_files/Manipal University_ Jaipur.txt\n","  Processing file: Engineering (1 to 100) 2024/Banasthali Vidyapith.pdf\n","    Extracting text from: Banasthali Vidyapith.pdf\n","      ‚úì Extracted 6988 characters\n","      ‚úì Text saved to: /content/Engineering (1 to 100) 2024 (1)_extracted/text_files/Banasthali Vidyapith.txt\n","  Processing file: Engineering (1 to 100) 2024/Indian Institute of Space Science and Technology.pdf\n","    Extracting text from: Indian Institute of Space Science and Technology.pdf\n","      ‚úì Extracted 8135 characters\n","      ‚úì Text saved to: /content/Engineering (1 to 100) 2024 (1)_extracted/text_files/Indian Institute of Space Science and Technology.txt\n","  Processing file: Engineering (1 to 100) 2024/Sathyabama Institute of Science and Technology Chennai.pdf\n","    Extracting text from: Sathyabama Institute of Science and Technology Chennai.pdf\n","      ‚úì Extracted 7384 characters\n","      ‚úì Text saved to: /content/Engineering (1 to 100) 2024 (1)_extracted/text_files/Sathyabama Institute of Science and Technology Chennai.txt\n","  Processing file: Engineering (1 to 100) 2024/Indraprastha Institute of Information Technology.pdf\n","    Extracting text from: Indraprastha Institute of Information Technology.pdf\n","      ‚úì Extracted 7300 characters\n","      ‚úì Text saved to: /content/Engineering (1 to 100) 2024 (1)_extracted/text_files/Indraprastha Institute of Information Technology.txt\n","  Processing file: Engineering (1 to 100) 2024/Birla Institute of Technology Ranchi.pdf\n","    Extracting text from: Birla Institute of Technology Ranchi.pdf\n","      ‚úì Extracted 7221 characters\n","      ‚úì Text saved to: /content/Engineering (1 to 100) 2024 (1)_extracted/text_files/Birla Institute of Technology Ranchi.txt\n","  Processing file: Engineering (1 to 100) 2024/Maulana Azad National Institute of Technology.pdf\n","    Extracting text from: Maulana Azad National Institute of Technology.pdf\n","      ‚úì Extracted 7922 characters\n","      ‚úì Text saved to: /content/Engineering (1 to 100) 2024 (1)_extracted/text_files/Maulana Azad National Institute of Technology.txt\n","  Processing file: Engineering (1 to 100) 2024/IIT Bhuvaneswar.pdf\n","    Extracting text from: IIT Bhuvaneswar.pdf\n","      ‚úì Extracted 8079 characters\n","      ‚úì Text saved to: /content/Engineering (1 to 100) 2024 (1)_extracted/text_files/IIT Bhuvaneswar.txt\n","  Processing file: Engineering (1 to 100) 2024/Lovely Professional University.pdf\n","    Extracting text from: Lovely Professional University.pdf\n","      ‚úì Extracted 7889 characters\n","      ‚úì Text saved to: /content/Engineering (1 to 100) 2024 (1)_extracted/text_files/Lovely Professional University.txt\n","  Processing file: Engineering (1 to 100) 2024/C.V. Raman Global University, Odisha.pdf\n","    Extracting text from: C.V. Raman Global University, Odisha.pdf\n","      ‚úì Extracted 7346 characters\n","      ‚úì Text saved to: /content/Engineering (1 to 100) 2024 (1)_extracted/text_files/C.V. Raman Global University_ Odisha.txt\n","  Processing file: Engineering (1 to 100) 2024/IIT Tirupati.pdf\n","    Extracting text from: IIT Tirupati.pdf\n","      ‚úì Extracted 7807 characters\n","      ‚úì Text saved to: /content/Engineering (1 to 100) 2024 (1)_extracted/text_files/IIT Tirupati.txt\n","  Processing file: Engineering (1 to 100) 2024/NIT Meghalaya.pdf\n","    Extracting text from: NIT Meghalaya.pdf\n","      ‚úì Extracted 7218 characters\n","      ‚úì Text saved to: /content/Engineering (1 to 100) 2024 (1)_extracted/text_files/NIT Meghalaya.txt\n","  Processing file: Engineering (1 to 100) 2024/IIT Palakkad.pdf\n","    Extracting text from: IIT Palakkad.pdf\n","      ‚úì Extracted 7301 characters\n","      ‚úì Text saved to: /content/Engineering (1 to 100) 2024 (1)_extracted/text_files/IIT Palakkad.txt\n","  Processing file: Engineering (1 to 100) 2024/IIT Jodhpur.pdf\n","    Extracting text from: IIT Jodhpur.pdf\n","      ‚úì Extracted 7277 characters\n","      ‚úì Text saved to: /content/Engineering (1 to 100) 2024 (1)_extracted/text_files/IIT Jodhpur.txt\n","  Processing file: Engineering (1 to 100) 2024/NIT Surathkal.pdf\n","    Extracting text from: NIT Surathkal.pdf\n","      ‚úì Extracted 7442 characters\n","      ‚úì Text saved to: /content/Engineering (1 to 100) 2024 (1)_extracted/text_files/NIT Surathkal.txt\n","  Processing file: Engineering (1 to 100) 2024/NIT calicut.pdf\n","    Extracting text from: NIT calicut.pdf\n","      ‚úì Extracted 7415 characters\n","      ‚úì Text saved to: /content/Engineering (1 to 100) 2024 (1)_extracted/text_files/NIT calicut.txt\n","  Processing file: Engineering (1 to 100) 2024/IIT Kharagpur.pdf\n","    Extracting text from: IIT Kharagpur.pdf\n","      ‚úì Extracted 8884 characters\n","      ‚úì Text saved to: /content/Engineering (1 to 100) 2024 (1)_extracted/text_files/IIT Kharagpur.txt\n","  Processing file: Engineering (1 to 100) 2024/University of Hyderabad.pdf\n","    Extracting text from: University of Hyderabad.pdf\n","      ‚úì Extracted 6243 characters\n","      ‚úì Text saved to: /content/Engineering (1 to 100) 2024 (1)_extracted/text_files/University of Hyderabad.txt\n","  Processing file: Engineering (1 to 100) 2024/IIT Varanasi(Banaras Hindu University).pdf\n","    Extracting text from: IIT Varanasi(Banaras Hindu University).pdf\n","      ‚úì Extracted 8658 characters\n","      ‚úì Text saved to: /content/Engineering (1 to 100) 2024 (1)_extracted/text_files/IIT Varanasi_Banaras Hindu University_.txt\n","  Processing file: Engineering (1 to 100) 2024/Visvesvaraya Technological University.pdf\n","    Extracting text from: Visvesvaraya Technological University.pdf\n","      ‚úì Extracted 6906 characters\n","      ‚úì Text saved to: /content/Engineering (1 to 100) 2024 (1)_extracted/text_files/Visvesvaraya Technological University.txt\n","  Processing file: Engineering (1 to 100) 2024/Saveetha Institute of Medical and Technical Sciences.pdf\n","    Extracting text from: Saveetha Institute of Medical and Technical Sciences.pdf\n","      ‚úì Extracted 6924 characters\n","      ‚úì Text saved to: /content/Engineering (1 to 100) 2024 (1)_extracted/text_files/Saveetha Institute of Medical and Technical Sciences.txt\n","  Processing file: Engineering (1 to 100) 2024/Motilal Nehru National Institute of Technology.pdf\n","    Extracting text from: Motilal Nehru National Institute of Technology.pdf\n","      ‚úì Extracted 7308 characters\n","      ‚úì Text saved to: /content/Engineering (1 to 100) 2024 (1)_extracted/text_files/Motilal Nehru National Institute of Technology.txt\n","  Processing file: Engineering (1 to 100) 2024/Chithara University.pdf\n","    Extracting text from: Chithara University.pdf\n","      ‚úì Extracted 7507 characters\n","      ‚úì Text saved to: /content/Engineering (1 to 100) 2024 (1)_extracted/text_files/Chithara University.txt\n","  Processing file: Engineering (1 to 100) 2024/NIT Patna.pdf\n","    Extracting text from: NIT Patna.pdf\n","      ‚úì Extracted 7106 characters\n","      ‚úì Text saved to: /content/Engineering (1 to 100) 2024 (1)_extracted/text_files/NIT Patna.txt\n","  Processing file: Engineering (1 to 100) 2024/IIIT Hyderabad .pdf\n","    Extracting text from: IIIT Hyderabad .pdf\n","      ‚úì Extracted 8053 characters\n","      ‚úì Text saved to: /content/Engineering (1 to 100) 2024 (1)_extracted/text_files/IIIT Hyderabad .txt\n","  Processing file: Engineering (1 to 100) 2024/IIT Bombay.pdf\n","    Extracting text from: IIT Bombay.pdf\n","      ‚úì Extracted 8420 characters\n","      ‚úì Text saved to: /content/Engineering (1 to 100) 2024 (1)_extracted/text_files/IIT Bombay.txt\n","  Processing file: Engineering (1 to 100) 2024/AU College of Enginnering.pdf\n","    Extracting text from: AU College of Enginnering.pdf\n","      ‚úì Extracted 7372 characters\n","      ‚úì Text saved to: /content/Engineering (1 to 100) 2024 (1)_extracted/text_files/AU College of Enginnering.txt\n","  Processing file: Engineering (1 to 100) 2024/IIT Hyderabad.pdf\n","    Extracting text from: IIT Hyderabad.pdf\n","      ‚úì Extracted 8142 characters\n","      ‚úì Text saved to: /content/Engineering (1 to 100) 2024 (1)_extracted/text_files/IIT Hyderabad.txt\n","  Processing file: Engineering (1 to 100) 2024/NIT Kurukshetra.pdf\n","    Extracting text from: NIT Kurukshetra.pdf\n","      ‚úì Extracted 7207 characters\n","      ‚úì Text saved to: /content/Engineering (1 to 100) 2024 (1)_extracted/text_files/NIT Kurukshetra.txt\n","  Processing file: Engineering (1 to 100) 2024/SRM Chennai.pdf\n","    Extracting text from: SRM Chennai.pdf\n","      ‚úì Extracted 8056 characters\n","      ‚úì Text saved to: /content/Engineering (1 to 100) 2024 (1)_extracted/text_files/SRM Chennai.txt\n","  Processing file: Engineering (1 to 100) 2024/Siddaganga Institute of Technology.pdf\n","    Extracting text from: Siddaganga Institute of Technology.pdf\n","      ‚úì Extracted 7021 characters\n","      ‚úì Text saved to: /content/Engineering (1 to 100) 2024 (1)_extracted/text_files/Siddaganga Institute of Technology.txt\n","  Processing file: Engineering (1 to 100) 2024/NIT Rourkela.pdf\n","    Extracting text from: NIT Rourkela.pdf\n","      ‚úì Extracted 8507 characters\n","      ‚úì Text saved to: /content/Engineering (1 to 100) 2024 (1)_extracted/text_files/NIT Rourkela.txt\n","  Processing file: Engineering (1 to 100) 2024/Sri Krishna College of Engineering and Technology.pdf\n","    Extracting text from: Sri Krishna College of Engineering and Technology.pdf\n","      ‚úì Extracted 7863 characters\n","      ‚úì Text saved to: /content/Engineering (1 to 100) 2024 (1)_extracted/text_files/Sri Krishna College of Engineering and Technology.txt\n","\n","======================================================================\n","Ingestion Summary:\n","üìä Total PDFs processed: 98\n","üíæ Output saved to: /content/Engineering (1 to 100) 2024 (1)_extracted\n","\n","============================================================\n","OUTPUT STRUCTURE:\n","============================================================\n","üìÅ /content/Engineering (1 to 100) 2024 (1)_extracted/\n","‚îî‚îÄ‚îÄ üìÑ text_files/\n","    ‚îî‚îÄ‚îÄ [all_pdfs_as_txt]\n","\n","============================================================\n","PROCESSING COMPLETE!\n","‚úì All extracted text files saved to: /content/Engineering (1 to 100) 2024 (1)_extracted/text_files/\n","============================================================\n","\n","üîπ Google Colab detected - preparing download...\n","‚è≥ This may take a moment for large outputs...\n","\n","üì¶ Preparing output files for download...\n","‚úì Found 98 files to package\n","üì¶ Creating ZIP file...\n","  ‚úì Added: text_files/International Institute of Information Technology Bangalore.txt\n","  ‚úì Added: text_files/NIT  Puducherry.txt\n","  ‚úì Added: text_files/M. S. Ramaiah Institute of Technology.txt\n","  ‚úì Added: text_files/Sardar Vallabhbhai National Institute of Technology.txt\n","  ‚úì Added: text_files/PSG College of Technology.txt\n","  ‚úì Added: text_files/IIT Jammu.txt\n","  ‚úì Added: text_files/Sathyabama Institute of Science and Technology Chennai.txt\n","  ‚úì Added: text_files/IIIT Allahabad.txt\n","  ‚úì Added: text_files/Banasthali Vidyapith.txt\n","  ‚úì Added: text_files/Dr. B R Ambedkar National Institute of Technology Jalandhar.txt\n","  ‚úì Added: text_files/NIT calicut.txt\n","  ‚úì Added: text_files/NIT Delhi.txt\n","  ‚úì Added: text_files/NIT Warangal.txt\n","  ‚úì Added: text_files/Amrita Vishwa Vidyapeetham.txt\n","  ‚úì Added: text_files/Jamia Millia Islamia.txt\n","  ‚úì Added: text_files/NIT Srinagar.txt\n","  ‚úì Added: text_files/Netaji Subhas University of Technology _NSUT_.txt\n","  ‚úì Added: text_files/Thapar Institute of Engineering and Technology _Deemed-to-be-university.txt\n","  ‚úì Added: text_files/Visvesvaraya Technological University.txt\n","  ‚úì Added: text_files/IIT Mandi.txt\n","  ‚úì Added: text_files/Delhi Technological University.txt\n","  ‚úì Added: text_files/Indian Institute of Space Science and Technology.txt\n","  ‚úì Added: text_files/NIT Rourkela.txt\n","  ‚úì Added: text_files/IIT Patna.txt\n","  ‚úì Added: text_files/Jadavpur University.txt\n","  ‚úì Added: text_files/Guru Gobind Singh Indraprastha University.txt\n","  ‚úì Added: text_files/NIT Silchar.txt\n","  ‚úì Added: text_files/Vel Tech Rangarajan Dr. Sagunthala R _ D Institute of Science and Technology.txt\n","  ‚úì Added: text_files/IIT Hyderabad.txt\n","  ‚úì Added: text_files/Visvesvaraya National Institute of Technology Nagpur.txt\n","  ‚úì Added: text_files/NIT Raipur.txt\n","  ‚úì Added: text_files/IIT Tirupati.txt\n","  ‚úì Added: text_files/Sant Longowal Institute of Engineering and Technology.txt\n","  ‚úì Added: text_files/SRM Chennai.txt\n","  ‚úì Added: text_files/IIT Delhi.txt\n","  ‚úì Added: text_files/IIT Kharagpur.txt\n","  ‚úì Added: text_files/NIT Durgapur.txt\n","  ‚úì Added: text_files/Kalinga Institute of Industrial Technology.txt\n","  ‚úì Added: text_files/Shanmugha Arts Science Technology and Research Academy.txt\n","  ‚úì Added: text_files/Saveetha Institute of Medical and Technical Sciences.txt\n","  ‚úì Added: text_files/Siddaganga Institute of Technology.txt\n","  ‚úì Added: text_files/Jain University_ Bangalore.txt\n","  ‚úì Added: text_files/NIT Kurukshetra.txt\n","  ‚úì Added: text_files/Birla Institute of Technology Ranchi.txt\n","  ‚úì Added: text_files/NIT Surathkal.txt\n","  ‚úì Added: text_files/IIEST Shibpur.txt\n","  ‚úì Added: text_files/UPES.txt\n","  ‚úì Added: text_files/Anna University.txt\n","  ‚úì Added: text_files/Jawaharlal Nehru Technological University.txt\n","  ‚úì Added: text_files/Manipal Institute of Technology.txt\n","  ‚úì Added: text_files/IIT Indore.txt\n","  ‚úì Added: text_files/IIT Ropar.txt\n","  ‚úì Added: text_files/NIT  Agartala.txt\n","  ‚úì Added: text_files/IIT Roorkee 2024.txt\n","  ‚úì Added: text_files/VIT Vellore.txt\n","  ‚úì Added: text_files/Chithara University.txt\n","  ‚úì Added: text_files/Engineering  2024.txt\n","  ‚úì Added: text_files/IIT Kanpur.txt\n","  ‚úì Added: text_files/IIIT Hyderabad .txt\n","  ‚úì Added: text_files/COEP Technological University.txt\n","  ‚úì Added: text_files/Defence Institute of Adavanced Technology.txt\n","  ‚úì Added: text_files/Indraprastha Institute of Information Technology.txt\n","  ‚úì Added: text_files/IIT Bhuvaneswar.txt\n","  ‚úì Added: text_files/SR University Warangal.txt\n","  ‚úì Added: text_files/Maulana Azad National Institute of Technology.txt\n","  ‚úì Added: text_files/Birla Institute of Technology  and Science_ Pilani.txt\n","  ‚úì Added: text_files/Institute of Chemical Technology.txt\n","  ‚úì Added: text_files/IIT Bhilai.txt\n","  ‚úì Added: text_files/IIT Bombay.txt\n","  ‚úì Added: text_files/Aligarh Muslim University.txt\n","  ‚úì Added: text_files/Lovely Professional University.txt\n","  ‚úì Added: text_files/NIT Patna.txt\n","  ‚úì Added: text_files/Madan Mohan Malaviya University of Technology.txt\n","  ‚úì Added: text_files/Vignan_s Foundation for Science_ Technology and Research.txt\n","  ‚úì Added: text_files/NIT Meghalaya.txt\n","  ‚úì Added: text_files/Sri Sivasubramaniya Nadar College of Engineering.txt\n","  ‚úì Added: text_files/Chandigarh University.txt\n","  ‚úì Added: text_files/R.V. College of Engineering.txt\n","  ‚úì Added: text_files/IIT Varanasi_Banaras Hindu University_.txt\n","  ‚úì Added: text_files/IIT Guwahati.txt\n","  ‚úì Added: text_files/Malaviya National Institute of Technology.txt\n","  ‚úì Added: text_files/Shoolini University of Biotechnology and Management Science.txt\n","  ‚úì Added: text_files/IIT Palakkad.txt\n","  ‚úì Added: text_files/Motilal Nehru National Institute of Technology.txt\n","  ‚úì Added: text_files/NIT Tiruchirappalli.txt\n","  ‚úì Added: text_files/University of Hyderabad.txt\n","  ‚úì Added: text_files/C.V. Raman Global University_ Odisha.txt\n","  ‚úì Added: text_files/Kalasalingam Academy of Research and Education.txt\n","  ‚úì Added: text_files/IIT Gandhinagar.txt\n","  ‚úì Added: text_files/AU College of Enginnering.txt\n","  ‚úì Added: text_files/Manipal University_ Jaipur.txt\n","  ‚úì Added: text_files/Indian Institute of Technology _Indian School of Mines_ Dhanbad.txt\n","  ‚úì Added: text_files/Rajiv Gandhi Institute of Petroleum Technology.txt\n","  ‚úì Added: text_files/IIT Madras.txt\n","  ‚úì Added: text_files/Sri Krishna College of Engineering and Technology.txt\n","  ‚úì Added: text_files/IIT Jodhpur.txt\n","  ‚úì Added: text_files/Amity University.txt\n","  ‚úì Added: text_files/K L College of Engineering_Vaddeswaram_.txt\n","\n","‚úì ZIP file created successfully!\n","üìä ZIP file size: 0.30 MB\n","üìç ZIP file location: /content/Engineering (1 to 100) 2024 (1)_extracted.zip\n","\n","‚¨áÔ∏è Starting download...\n","üí° Check your browser's download folder (usually at bottom of browser window)\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["download(\"download_ecb61fcc-0498-4257-9337-f1cae890518c\", \"Engineering (1 to 100) 2024 (1)_extracted.zip\", 316517)"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","‚úÖ Download initiated successfully!\n","üì• If download didn't start automatically:\n","   1. Check your browser's download folder\n","   2. Look for pop-up blocker notifications\n","   3. The file is also available at: /content/Engineering (1 to 100) 2024 (1)_extracted.zip\n","\n","============================================================\n","SEARCH FUNCTIONALITY:\n","============================================================\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"Interrupted by user","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-1827224756.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    629\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"=\"\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m60\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 631\u001b[0;31m         \u001b[0msearch_term\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nEnter search term (or 'quit' to exit): \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    632\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msearch_term\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'quit'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'exit'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'q'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m   1175\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1176\u001b[0m             )\n\u001b[0;32m-> 1177\u001b[0;31m         return self._input_request(\n\u001b[0m\u001b[1;32m   1178\u001b[0m             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"shell\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m   1217\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1219\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1220\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1221\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZGF3r6ONFjHG","colab":{"base_uri":"https://localhost:8080/","height":499},"executionInfo":{"status":"error","timestamp":1762970770941,"user_tz":-330,"elapsed":36214,"user":{"displayName":"Rahul Siddhu","userId":"12007764243202946991"}},"outputId":"fd5c7594-d880-48e5-b3da-242993980e94"},"outputs":[{"output_type":"stream","name":"stdout","text":["PDF Ingestion Tool - Flat Edition with Auto-Download\n","============================================================\n","üîπ Running in Google Colab environment.\n","‚ö† Could not mount Google Drive or find folder: Error: credential propagation was unsuccessful\n","Falling back to ZIP upload.\n","\n","üìÇ Please upload your ZIP file now.\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","     <input type=\"file\" id=\"files-033dfba3-9d8f-4706-b7fd-2c24724ecba5\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-033dfba3-9d8f-4706-b7fd-2c24724ecba5\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script>// Copyright 2017 Google LLC\n","//\n","// Licensed under the Apache License, Version 2.0 (the \"License\");\n","// you may not use this file except in compliance with the License.\n","// You may obtain a copy of the License at\n","//\n","//      http://www.apache.org/licenses/LICENSE-2.0\n","//\n","// Unless required by applicable law or agreed to in writing, software\n","// distributed under the License is distributed on an \"AS IS\" BASIS,\n","// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","// See the License for the specific language governing permissions and\n","// limitations under the License.\n","\n","/**\n"," * @fileoverview Helpers for google.colab Python module.\n"," */\n","(function(scope) {\n","function span(text, styleAttributes = {}) {\n","  const element = document.createElement('span');\n","  element.textContent = text;\n","  for (const key of Object.keys(styleAttributes)) {\n","    element.style[key] = styleAttributes[key];\n","  }\n","  return element;\n","}\n","\n","// Max number of bytes which will be uploaded at a time.\n","const MAX_PAYLOAD_SIZE = 100 * 1024;\n","\n","function _uploadFiles(inputId, outputId) {\n","  const steps = uploadFilesStep(inputId, outputId);\n","  const outputElement = document.getElementById(outputId);\n","  // Cache steps on the outputElement to make it available for the next call\n","  // to uploadFilesContinue from Python.\n","  outputElement.steps = steps;\n","\n","  return _uploadFilesContinue(outputId);\n","}\n","\n","// This is roughly an async generator (not supported in the browser yet),\n","// where there are multiple asynchronous steps and the Python side is going\n","// to poll for completion of each step.\n","// This uses a Promise to block the python side on completion of each step,\n","// then passes the result of the previous step as the input to the next step.\n","function _uploadFilesContinue(outputId) {\n","  const outputElement = document.getElementById(outputId);\n","  const steps = outputElement.steps;\n","\n","  const next = steps.next(outputElement.lastPromiseValue);\n","  return Promise.resolve(next.value.promise).then((value) => {\n","    // Cache the last promise value to make it available to the next\n","    // step of the generator.\n","    outputElement.lastPromiseValue = value;\n","    return next.value.response;\n","  });\n","}\n","\n","/**\n"," * Generator function which is called between each async step of the upload\n"," * process.\n"," * @param {string} inputId Element ID of the input file picker element.\n"," * @param {string} outputId Element ID of the output display.\n"," * @return {!Iterable<!Object>} Iterable of next steps.\n"," */\n","function* uploadFilesStep(inputId, outputId) {\n","  const inputElement = document.getElementById(inputId);\n","  inputElement.disabled = false;\n","\n","  const outputElement = document.getElementById(outputId);\n","  outputElement.innerHTML = '';\n","\n","  const pickedPromise = new Promise((resolve) => {\n","    inputElement.addEventListener('change', (e) => {\n","      resolve(e.target.files);\n","    });\n","  });\n","\n","  const cancel = document.createElement('button');\n","  inputElement.parentElement.appendChild(cancel);\n","  cancel.textContent = 'Cancel upload';\n","  const cancelPromise = new Promise((resolve) => {\n","    cancel.onclick = () => {\n","      resolve(null);\n","    };\n","  });\n","\n","  // Wait for the user to pick the files.\n","  const files = yield {\n","    promise: Promise.race([pickedPromise, cancelPromise]),\n","    response: {\n","      action: 'starting',\n","    }\n","  };\n","\n","  cancel.remove();\n","\n","  // Disable the input element since further picks are not allowed.\n","  inputElement.disabled = true;\n","\n","  if (!files) {\n","    return {\n","      response: {\n","        action: 'complete',\n","      }\n","    };\n","  }\n","\n","  for (const file of files) {\n","    const li = document.createElement('li');\n","    li.append(span(file.name, {fontWeight: 'bold'}));\n","    li.append(span(\n","        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n","        `last modified: ${\n","            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n","                                    'n/a'} - `));\n","    const percent = span('0% done');\n","    li.appendChild(percent);\n","\n","    outputElement.appendChild(li);\n","\n","    const fileDataPromise = new Promise((resolve) => {\n","      const reader = new FileReader();\n","      reader.onload = (e) => {\n","        resolve(e.target.result);\n","      };\n","      reader.readAsArrayBuffer(file);\n","    });\n","    // Wait for the data to be ready.\n","    let fileData = yield {\n","      promise: fileDataPromise,\n","      response: {\n","        action: 'continue',\n","      }\n","    };\n","\n","    // Use a chunked sending to avoid message size limits. See b/62115660.\n","    let position = 0;\n","    do {\n","      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n","      const chunk = new Uint8Array(fileData, position, length);\n","      position += length;\n","\n","      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n","      yield {\n","        response: {\n","          action: 'append',\n","          file: file.name,\n","          data: base64,\n","        },\n","      };\n","\n","      let percentDone = fileData.byteLength === 0 ?\n","          100 :\n","          Math.round((position / fileData.byteLength) * 100);\n","      percent.textContent = `${percentDone}% done`;\n","\n","    } while (position < fileData.byteLength);\n","  }\n","\n","  // All done.\n","  yield {\n","    response: {\n","      action: 'complete',\n","    }\n","  };\n","}\n","\n","scope.google = scope.google || {};\n","scope.google.colab = scope.google.colab || {};\n","scope.google.colab._files = {\n","  _uploadFiles,\n","  _uploadFilesContinue,\n","};\n","})(self);\n","</script> "]},"metadata":{}},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-4122326006.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    775\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    776\u001b[0m     \u001b[0;31m# Get appropriate paths based on environment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 777\u001b[0;31m     \u001b[0minput_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_folder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_paths\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocal_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    778\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0minput_folder\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mexit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipython-input-4122326006.py\u001b[0m in \u001b[0;36mget_paths\u001b[0;34m(local_input, local_output)\u001b[0m\n\u001b[1;32m    693\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Falling back to ZIP upload.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    694\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nüìÇ Please upload your ZIP file now.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 695\u001b[0;31m         \u001b[0muploaded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    696\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0muploaded\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    697\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"‚ùå No file uploaded. Exiting.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36mupload\u001b[0;34m(target_dir)\u001b[0m\n\u001b[1;32m     70\u001b[0m   \"\"\"\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m   \u001b[0muploaded_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_upload_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmultiple\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m   \u001b[0;31m# Mapping from original filename to filename as saved locally.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m   \u001b[0mlocal_filenames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36m_upload_files\u001b[0;34m(multiple)\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m   \u001b[0;31m# First result is always an indication that the file picker has completed.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m   result = _output.eval_js(\n\u001b[0m\u001b[1;32m    165\u001b[0m       'google.colab._files._uploadFiles(\"{input_id}\", \"{output_id}\")'.format(\n\u001b[1;32m    166\u001b[0m           \u001b[0minput_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/output/_js.py\u001b[0m in \u001b[0;36meval_js\u001b[0;34m(script, ignore_result, timeout_sec)\u001b[0m\n\u001b[1;32m     38\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mignore_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_message\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_read_next_input_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_NOT_READY\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m       \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.025\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m       \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     if (\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["import os\n","import PyPDF2\n","import pdfplumber\n","import fitz  # PyMuPDF\n","from pathlib import Path\n","import pandas as pd\n","from datetime import datetime\n","import re\n","from PIL import Image\n","import pytesseract\n","import io\n","import json\n","import shutil\n","import platform\n","import zipfile\n","import tempfile\n","\n","class PDFIngesterFlat:\n","    def __init__(self, root_folder_path, output_folder_path=None):\n","        self.root_folder_path = Path(root_folder_path)\n","        self.output_folder_path = Path(output_folder_path) if output_folder_path else Path(f\"{root_folder_path}_extracted\")\n","        self.all_pdfs = []  # List to hold info for all PDFs\n","        self.ingestion_log = []\n","\n","        # Define specific section patterns based on your requirements\n","        self.section_patterns = {\n","            'SANCTIONED_INTAKE': [\n","                r'sanctioned.*intake', r'approved.*intake', r'sanctioned.*approved.*intake'\n","            ],\n","            'STUDENT_STRENGTH': [\n","                r'total.*actual.*student.*strength.*program.*offered.*by.*your.*institution',\n","                r'total.*actual.*student.*strength.*program.*offered',\n","                r'total.*actual.*student.*strength.*all.*programs',\n","                r'total.*actual.*student.*strength',\n","                r'student.*strength.*program.*offered',\n","                r'actual.*student.*strength'\n","            ],\n","            'PLACEMENT_STUDIES': [\n","                r'placement.*higher.*studies', r'placement.*studies', r'higher.*studies'\n","            ],\n","            'UG_PLACEMENT': [\n","                r'ug.*\\[.*years?.*program.*\\].*placement.*higher.*studies',\n","                r'ug.*\\[.*years?.*program.*\\].*placement.*studies',\n","                r'ug.*4.*years?.*program.*placement'\n","            ],\n","            'PG_PLACEMENT': [\n","                r'pg.*\\[.*years?.*program.*\\].*placement.*higher.*studies',\n","                r'pg.*\\[.*years?.*program.*\\].*placement.*studies',\n","                r'pg.*2.*years?.*program.*placement'\n","            ],\n","            'UG_PROGRAM': [\n","                r'^ug.*\\[.*years?.*program.*\\](?!.*placement)',  # UG program but NOT placement\n","                r'undergraduate.*program'\n","            ],\n","            'PG_PROGRAM': [\n","                r'^pg.*\\[.*years?.*program.*\\](?!.*placement)',  # PG program but NOT placement\n","                r'postgraduate.*program'\n","            ],\n","            'PHD_DETAILS': [\n","                r'ph\\.?d.*student.*details', r'ph\\.?d.*details', r'doctoral.*program'\n","            ],\n","            'FINANCIAL_RESOURCES': [\n","                r'financial.*resources', r'utilised.*amount', r'capital.*expenditure', r'operational.*expenditure'\n","            ],\n","            'IPR': [\n","                r'^ipr$', r'intellectual.*property', r'patents'\n","            ],\n","            'SPONSORED_RESEARCH': [\n","                r'sponsored.*research.*details', r'sponsored.*research', r'research.*funding'\n","            ],\n","            'CONSULTANCY_PROJECTS': [\n","                r'consultancy.*project.*details', r'consultancy.*projects'\n","            ],\n","            'PCS_FACILITIES': [\n","                r'pcs.*facilities', r'physically.*challenged.*students', r'handicapped.*students'\n","            ],\n","            'FACULTY_DETAILS': [\n","                r'faculty.*details', r'number.*faculty.*members'\n","            ]\n","        }\n","        # Table exclusion patterns\n","        self.table_exclusion_patterns = [\n","            r'^\\d+\\s+\\d+\\s+\\d+',  # Multiple numbers\n","            r'academic.*year.*\\d{4}',  # Academic year data\n","            r'no\\.\\s*of.*students.*\\d+',  # Student count data\n","            r'rs\\.\\s*\\d+',  # Currency amounts\n","            r'within.*state.*outside.*state',  # Geographic data\n","            r'male.*female.*total',  # Demographic headers\n","        ]\n","\n","        # Create output directory structure\n","        self.create_output_structure()\n","\n","    def create_output_structure(self):\n","        \"\"\"Create the output directory structure\"\"\"\n","        print(f\"Creating output directory structure at: {self.output_folder_path}\")\n","        self.output_folder_path.mkdir(parents=True, exist_ok=True)\n","        (self.output_folder_path / \"text_files\").mkdir(exist_ok=True)\n","        (self.output_folder_path / \"metadata\").mkdir(exist_ok=True)\n","        (self.output_folder_path / \"reports\").mkdir(exist_ok=True)\n","        (self.output_folder_path / \"logs\").mkdir(exist_ok=True)\n","        print(f\"‚úì Output structure created at: {self.output_folder_path}\")\n","\n","    def safe_filename(self, filename):\n","        \"\"\"Create a safe filename for output files\"\"\"\n","        safe_name = re.sub(r'[<>:\"/\\\\|?*]', '_', filename)\n","        safe_name = re.sub(r'[^\\w\\s.-]', '_', safe_name)\n","        return safe_name\n","\n","    def extract_pdf_text(self, pdf_path):\n","        \"\"\"Extract text content from PDF file using multiple methods for best results\"\"\"\n","        print(f\"    Extracting text from: {pdf_path.name}\")\n","\n","        # PyMuPDF is prioritized first as it provides better font and color info\n","        text_pymupdf = self._extract_with_pymupdf(pdf_path)\n","        text_pdfplumber = self._extract_with_pdfplumber(pdf_path)\n","        text_pypdf2 = self._extract_with_pypdf2(pdf_path)\n","\n","        text_ocr = None\n","        if not any([text_pymupdf, text_pdfplumber, text_pypdf2]) or \\\n","            all(len(text.strip()) < 100 for text in [text_pymupdf, text_pdfplumber, text_pypdf2] if text):\n","            print(f\"      Performing OCR (document appears to be scanned)...\")\n","            text_ocr = self._extract_with_ocr(pdf_path)\n","\n","        best_text = self._choose_best_text(text_pymupdf, text_pdfplumber, text_pypdf2, text_ocr)\n","\n","        if best_text:\n","            cleaned_text = self._clean_text(best_text)\n","            print(f\"      ‚úì Extracted {len(cleaned_text)} characters\")\n","            return cleaned_text\n","        else:\n","            print(f\"      ‚úó Failed to extract text\")\n","            return None\n","\n","    def _is_table_content(self, text):\n","        \"\"\"Check if text appears to be table content\"\"\"\n","        text_lower = text.lower().strip()\n","        # Skip very short text\n","        if len(text_lower) < 5:\n","            return False\n","\n","        # Strong table indicators (immediate exclusion)\n","        strong_table_indicators = [\n","            r'^\\d+\\s+\\d+\\s+\\d+',  # Multiple numbers at start\n","            r'academic.*year.*\\d{4}-\\d{2}',  # Academic year data\n","            r'no\\.\\s*of.*first.*year.*students',  # Table header patterns\n","            r'no\\.\\s*of.*students.*intake',  # Table header patterns\n","            r'no\\.\\s*of.*students.*admitted',  # Table header patterns\n","            r'no\\.\\s*of.*students.*graduating',  # Table header patterns\n","            r'median.*salary.*placed.*graduates',  # Table header patterns\n","            r'within.*state.*outside.*state.*outside.*country',  # Geographic columns\n","            r'male.*female.*total.*students.*within',  # Demographic table headers\n","            r'utilised.*amount.*utilised.*amount',  # Financial table headers\n","            r'financial.*year.*\\d{4}-\\d{2}.*\\d{4}-\\d{2}',  # Financial year columns\n","            r'\\d+.*lacs?.*crores?',  # Currency with denominations\n","            r'rs\\.\\s*\\d+',  # Currency amounts\n","        ]\n","\n","        for pattern in strong_table_indicators:\n","            if re.search(pattern, text_lower):\n","                return True\n","\n","        # Check for table-like structure patterns\n","        structure_indicators = [\n","            len(re.findall(r'\\b\\d+\\b', text)) >= 4,  # 4 or more numbers\n","            '|' in text,  # Pipe separated\n","            text.count('\\t') >= 3,  # Multiple tabs\n","            len(text.split()) >= 12,  # Very long lines (likely table data)\n","        ]\n","\n","        # If it has 2+ structure indicators, it's likely table content\n","        if sum(structure_indicators) >= 2:\n","            return True\n","\n","        # Additional check: if it contains typical table column headers but is very long\n","        table_column_words = ['no.', 'total', 'male', 'female', 'within', 'outside', 'amount', 'year', 'students']\n","        word_matches = sum(1 for word in table_column_words if word in text_lower)\n","\n","        if word_matches >= 4 and len(text.split()) >= 10:\n","            return True\n","\n","        return False\n","\n","    def _detect_section_type(self, text, line):\n","        \"\"\"Enhanced section detection that treats complete lines as headings\"\"\"\n","        text_lower = text.lower().strip()\n","\n","        # Skip if it looks like table content\n","        if self._is_table_content(text):\n","            return None\n","\n","        # Get font information for additional validation\n","        font_size = line[0].get(\"size\", 12) if line else 12\n","        font_name = line[0].get(\"fontname\", \"\").lower() if line else \"\"\n","\n","        # Check for specific heading patterns first (complete section headers)\n","        complete_heading_patterns = [\n","            r'ug.*\\[.*years?.*program.*\\].*placement.*higher.*studies.*previous.*years?',\n","            r'pg.*\\[.*years?.*program.*\\].*placement.*higher.*studies.*previous.*years?',\n","            r'total.*actual.*student.*strength.*program.*offered.*by.*your.*institution',\n","            r'total.*actual.*student.*strength.*all.*programs',\n","            r'sanctioned.*approved.*intake',\n","            r'ph\\.?d.*student.*details',\n","            r'financial.*resources.*utilised.*amount.*capital.*expenditure',\n","            r'financial.*resources.*utilised.*amount.*operational.*expenditure',\n","            r'consultancy.*project.*details',\n","            r'sponsored.*research.*details',\n","            r'pcs.*facilities.*physically.*challenged.*students',\n","            r'faculty.*details',\n","        ]\n","\n","        # Check if this is a complete heading pattern\n","        is_complete_heading = any(re.search(pattern, text_lower) for pattern in complete_heading_patterns)\n","\n","        # Additional heading indicators\n","        is_likely_heading = (\n","            is_complete_heading or\n","            font_size > 12 or\n","            'bold' in font_name or\n","            (text.isupper() and len(text.split()) <= 8) or\n","            text.endswith(':') or\n","            text.startswith(('Do your', 'Does your')) or\n","            (len(text.split()) <= 8 and any(key in text_lower for key in ['sanctioned', 'placement', 'faculty', 'financial']))\n","        )\n","\n","        # Only proceed if it looks like a heading\n","        if not is_likely_heading:\n","            return None\n","\n","        # Check against each section pattern with priority for complete matches\n","        for section_type, patterns in self.section_patterns.items():\n","            for pattern in patterns:\n","                if re.search(pattern, text_lower, re.IGNORECASE):\n","                    # Additional validation for specific sections\n","                    if self._validate_section_match(section_type, text_lower, text):\n","                        return section_type\n","        return None\n","\n","    def _validate_section_match(self, section_type, text_lower, original_text):\n","        \"\"\"Enhanced validation with original text length consideration\"\"\"\n","        # Allow longer text for specific complete section headers\n","        complete_section_types = ['UG_PLACEMENT', 'PG_PLACEMENT', 'STUDENT_STRENGTH', 'FINANCIAL_RESOURCES']\n","        max_length = 150 if section_type in complete_section_types else 80\n","\n","        # Skip if text is too long (unless it's a complete section header)\n","        if len(original_text) > max_length:\n","            return False\n","\n","        # Enhanced section-specific validation\n","        validations = {\n","            'SANCTIONED_INTAKE': lambda t: ('sanctioned' in t or 'approved' in t) and 'intake' in t,\n","            'STUDENT_STRENGTH': lambda t: 'student' in t and 'strength' in t and 'placement' not in t,\n","            'PLACEMENT_STUDIES': lambda t: 'placement' in t and ('studies' in t or 'higher' in t),\n","            'UG_PLACEMENT': lambda t: ('ug' in t or 'undergraduate' in t) and 'placement' in t and 'years' in t,\n","            'PG_PLACEMENT': lambda t: ('pg' in t or 'postgraduate' in t) and 'placement' in t and 'years' in t,\n","            'UG_PROGRAM': lambda t: ('ug' in t or 'undergraduate' in t) and 'program' in t and 'placement' not in t,\n","            'PG_PROGRAM': lambda t: ('pg' in t or 'postgraduate' in t) and 'program' in t and 'placement' not in t,\n","            'PHD_DETAILS': lambda t: ('ph.d' in t or 'phd' in t or 'doctoral' in t) and 'placement' not in t,\n","            'FINANCIAL_RESOURCES': lambda t: ('financial' in t or 'utilised' in t or 'expenditure' in t) and 'placement' not in t,\n","            'IPR': lambda t: t.strip() == 'ipr' or 'intellectual' in t or 'patent' in t,\n","            'SPONSORED_RESEARCH': lambda t: 'sponsored' in t and 'research' in t,\n","            'CONSULTANCY_PROJECTS': lambda t: 'consultancy' in t and 'project' in t,\n","            'PCS_FACILITIES': lambda t: ('pcs' in t or 'physically' in t or 'challenged' in t) and 'placement' not in t,\n","            'FACULTY_DETAILS': lambda t: 'faculty' in t and 'placement' not in t,\n","        }\n","\n","        validator = validations.get(section_type)\n","        return validator(text_lower) if validator else True\n","\n","    def _extract_with_pdfplumber(self, pdf_path):\n","        \"\"\"Extract text using pdfplumber with enhanced section detection\"\"\"\n","        try:\n","            full_text = []\n","            with pdfplumber.open(pdf_path) as pdf:\n","                for page in pdf.pages:\n","                    words = page.extract_words(x_tolerance=1, y_tolerance=1, extra_attrs=[\"size\", \"fontname\"])\n","                    if not words:\n","                        text = page.extract_text()\n","                        if text:\n","                            full_text.append(text + \"\\n\")\n","                        continue\n","                    # Group words into lines\n","                    lines = self._group_words_into_lines(words)\n","                    # Process each line with table awareness\n","                    for i, line in enumerate(lines):\n","                        if not line:\n","                            continue\n","                        text = \" \".join([w[\"text\"] for w in line]).strip()\n","                        if not text:\n","                            continue\n","                        # Check if this is table content\n","                        if self._is_table_content(text):\n","                            full_text.append(f\"{text}\\n\")\n","                            continue\n","                        # Check for section headers\n","                        section_type = self._detect_section_type(text, line)\n","                        if section_type:\n","                            full_text.append(f\"###SECTION:{section_type}### {text}\\n\")\n","                        else:\n","                            full_text.append(f\"{text}\\n\")\n","                    # Extract tables\n","                    tables = page.extract_tables()\n","                    for table_idx, table in enumerate(tables):\n","                        full_text.append(f\"\\n###TABLE:{table_idx}###\\n\")\n","                        for row in table:\n","                            if row:\n","                                full_text.append(\" | \".join(str(cell) if cell else \"\" for cell in row) + \"\\n\")\n","                        full_text.append(\"###END_TABLE###\\n\")\n","            return \"\".join(full_text).strip() if full_text else None\n","        except Exception as e:\n","            print(f\"      pdfplumber failed: {str(e)}\")\n","            return None\n","\n","    def _extract_with_pymupdf(self, pdf_path):\n","        \"\"\"Extract text using PyMuPDF with enhanced section detection\"\"\"\n","        try:\n","            doc = fitz.open(pdf_path)\n","            full_text = []\n","            for page in doc:\n","                blocks = page.get_text(\"dict\")[\"blocks\"]\n","                for block in blocks:\n","                    if block['type'] == 0 and \"lines\" in block:\n","                        for line in block['lines']:\n","                            line_text = \"\"\n","                            line_info = {'size': 12, 'bold': False, 'color': 0}\n","                            for span in line['spans']:\n","                                text = span['text'].strip()\n","                                if text:\n","                                    line_text += text + \" \"\n","                                    line_info['size'] = max(line_info['size'], span['size'])\n","                                    line_info['bold'] = line_info['bold'] or (span['flags'] & 2) != 0\n","                                    line_info['color'] = span.get('color', 0)\n","                            line_text = line_text.strip()\n","                            if not line_text:\n","                                continue\n","                            # Check if this is table content\n","                            if self._is_table_content(line_text):\n","                                full_text.append(f\"{line_text}\\n\")\n","                                continue\n","                            # Create a mock line object for section detection\n","                            mock_line = [{'size': line_info['size'], 'fontname': 'bold' if line_info['bold'] else ''}]\n","                            section_type = self._detect_section_type(line_text, mock_line)\n","                            if section_type:\n","                                full_text.append(f\"###SECTION:{section_type}### {line_text}\\n\")\n","                            else:\n","                                full_text.append(f\"{line_text}\\n\")\n","            doc.close()\n","            return \"\".join(full_text).strip() if full_text else None\n","        except Exception as e:\n","            print(f\"      PyMuPDF failed: {str(e)}\")\n","            return None\n","\n","    def _group_words_into_lines(self, words):\n","        \"\"\"Group words into lines based on vertical position\"\"\"\n","        if not words:\n","            return []\n","        lines = []\n","        current_line = []\n","        current_top = None\n","        for word in words:\n","            word_top = round(word[\"top\"], 1)\n","            if current_top is None or abs(word_top - current_top) <= 2:\n","                current_line.append(word)\n","                current_top = word_top\n","            else:\n","                if current_line:\n","                    lines.append(current_line)\n","                current_line = [word]\n","                current_top = word_top\n","        if current_line:\n","            lines.append(current_line)\n","        return lines\n","\n","    def _is_blue_color(self, color):\n","        \"\"\"Detect if color is blue (common for headings in your PDF)\"\"\"\n","        if color == 0:  # Black text\n","            return False\n","        r = (color >> 16) & 0xFF\n","        g = (color >> 8) & 0xFF\n","        b = color & 0xFF\n","        return b > max(r, g) * 1.2\n","\n","    def _is_heading_pymupdf(self, spans, text, avg_font_size):\n","        \"\"\"Enhanced heading detection for PyMuPDF extraction\"\"\"\n","        if not text or len(text.strip()) == 0:\n","            return False\n","        has_bold = any(span['bold'] for span in spans)\n","        has_blue = any(span['blue'] for span in spans)\n","        large_font = avg_font_size > 12\n","        criteria = {\n","            'large_font': large_font,\n","            'bold_font': has_bold,\n","            'blue_color': has_blue,\n","            'all_caps': text.isupper() and len(text) > 3,\n","            'pattern_match': any(re.match(pattern, text, re.IGNORECASE) for pattern in self.section_patterns.get('STUDENT_STRENGTH', [])), # Using a specific pattern list here\n","            'section_keywords': self._contains_section_keywords(text),\n","            'short_line': len(text.split()) <= 8 and len(text) > 10,\n","            'colon_ending': text.strip().endswith(':'),\n","            'bracket_pattern': '[' in text and ']' in text,\n","        }\n","        score = 0\n","        if criteria['large_font']: score += 2\n","        if criteria['bold_font']: score += 2\n","        if criteria['blue_color']: score += 3  # Blue color gets high weight\n","        if criteria['all_caps']: score += 2\n","        if criteria['pattern_match']: score += 2\n","        if criteria['section_keywords']: score += 3\n","        if criteria['short_line']: score += 1\n","        if criteria['colon_ending']: score += 2\n","        if criteria['bracket_pattern']: score += 1\n","        return score >= 4\n","\n","    def _contains_section_keywords(self, text):\n","        \"\"\"Check if text contains known section keywords\"\"\"\n","        text_lower = text.lower()\n","        word_set = set(re.findall(r'\\b\\w+\\b', text_lower))\n","        return len(word_set.intersection(self.known_sections)) >= 1\n","\n","    def _extract_with_pypdf2(self, pdf_path):\n","        \"\"\"Extract text using PyPDF2 (fallback method)\"\"\"\n","        try:\n","            with open(pdf_path, 'rb') as file:\n","                pdf_reader = PyPDF2.PdfReader(file)\n","                text = \"\"\n","                for page in pdf_reader.pages:\n","                    page_text = page.extract_text()\n","                    if page_text:\n","                        text += page_text + \"\\n\"\n","                return text.strip() if text.strip() else None\n","        except Exception as e:\n","            print(f\"      PyPDF2 failed: {str(e)}\")\n","            return None\n","\n","    def _extract_with_ocr(self, pdf_path):\n","        \"\"\"Extract text using OCR for scanned PDFs\"\"\"\n","        try:\n","            doc = fitz.open(pdf_path)\n","            text = \"\"\n","            for page_num in range(len(doc)):\n","                page = doc.load_page(page_num)\n","                mat = fitz.Matrix(2, 2)\n","                pix = page.get_pixmap(matrix=mat)\n","                img_data = pix.tobytes(\"png\")\n","                image = Image.open(io.BytesIO(img_data))\n","                page_text = pytesseract.image_to_string(image, lang='eng')\n","                if page_text:\n","                    text += page_text + \"\\n\"\n","            doc.close()\n","            return text.strip() if text.strip() else None\n","        except Exception as e:\n","            print(f\"      OCR failed: {str(e)}\")\n","            return None\n","\n","    def _choose_best_text(self, text_pymupdf, text_pdfplumber, text_pypdf2, text_ocr):\n","        \"\"\"Choose the best text extraction result, prioritizing structured methods\"\"\"\n","        texts = [\n","            (\"PyMuPDF\", text_pymupdf),\n","            (\"pdfplumber\", text_pdfplumber),\n","            (\"PyPDF2\", text_pypdf2),\n","            (\"OCR\", text_ocr)\n","        ]\n","        valid_texts = [(method, text) for method, text in texts if text and text.strip()]\n","        if not valid_texts:\n","            return None\n","        priority_methods = [\"PyMuPDF\", \"pdfplumber\"]\n","        for method in priority_methods:\n","            for m, t in valid_texts:\n","                if m == method:\n","                    return t\n","        best_method, best_text = max(valid_texts, key=lambda x: len(x[1]))\n","        print(f\"      Best method: {best_method}\")\n","        return best_text\n","\n","    def _clean_text(self, text):\n","        \"\"\"Clean and normalize extracted text\"\"\"\n","        if not text:\n","            return \"\"\n","        cleaned_text = re.sub(r'([a-z])([A-Z])', r'\\1 \\2', text)\n","        cleaned_text = re.sub(r'(\\d)([A-Za-z])', r'\\1 \\2', cleaned_text)\n","        cleaned_text = re.sub(r'([A-Za-z])(\\d)', r'\\1 \\2', cleaned_text)\n","        cleaned_text = re.sub(r'\\n\\s*\\n', '\\n\\n', cleaned_text)\n","        return cleaned_text.strip()\n","\n","    def get_pdf_metadata(self, pdf_path):\n","        \"\"\"Extract comprehensive metadata from PDF file\"\"\"\n","        try:\n","            metadata = {}\n","            try:\n","                doc = fitz.open(pdf_path)\n","                pdf_metadata = doc.metadata\n","                metadata.update({\n","                    'title': pdf_metadata.get('title', ''),\n","                    'author': pdf_metadata.get('author', ''),\n","                    'creator': pdf_metadata.get('creator', ''),\n","                    'producer': pdf_metadata.get('producer', ''),\n","                    'subject': pdf_metadata.get('subject', ''),\n","                    'creation_date': pdf_metadata.get('creationDate', ''),\n","                    'modification_date': pdf_metadata.get('modDate', ''),\n","                    'page_count': len(doc),\n","                    'encrypted': doc.is_encrypted,\n","                    'pdf_version': doc.pdf_version()\n","                })\n","                doc.close()\n","            except:\n","                with open(pdf_path, 'rb') as file:\n","                    pdf_reader = PyPDF2.PdfReader(file)\n","                    pdf_metadata = pdf_reader.metadata if pdf_reader.metadata else {}\n","                    metadata.update({\n","                        'title': pdf_metadata.get('/Title', ''),\n","                        'author': pdf_metadata.get('/Author', ''),\n","                        'creator': pdf_metadata.get('/Creator', ''),\n","                        'producer': pdf_metadata.get('/Producer', ''),\n","                        'subject': pdf_metadata.get('/Subject', ''),\n","                        'creation_date': pdf_metadata.get('/CreationDate', ''),\n","                        'modification_date': pdf_metadata.get('/ModDate', ''),\n","                        'page_count': len(pdf_reader.pages),\n","                        'encrypted': pdf_reader.is_encrypted,\n","                        'pdf_version': getattr(pdf_reader, 'pdf_header', '')\n","                    })\n","            return metadata\n","        except Exception as e:\n","            print(f\"Error extracting metadata from {pdf_path}: {str(e)}\")\n","            return {'page_count': 0, 'encrypted': False}\n","\n","    def save_individual_files(self, pdf_info):\n","        \"\"\"Save individual text and metadata files for each PDF in a flat structure\"\"\"\n","        safe_name = self.safe_filename(pdf_info['file_name'])\n","        base_name = safe_name.replace('.pdf', '')\n","        text_output_dir = self.output_folder_path / \"text_files\"\n","        metadata_output_dir = self.output_folder_path / \"metadata\"\n","        text_file_path = None\n","        metadata_file_path = None\n","        if pdf_info.get('text_content'):\n","            text_file_path = text_output_dir / f\"{base_name}.txt\"\n","            with open(text_file_path, 'w', encoding='utf-8') as f:\n","                f.write(pdf_info['text_content'])\n","            print(f\"      ‚úì Text saved to: {text_file_path}\")\n","        else:\n","            print(f\"      ‚ö† No text content to save for: {pdf_info['file_name']}\")\n","        metadata_file_path = metadata_output_dir / f\"{base_name}_metadata.json\"\n","        metadata_to_save = {k: v for k, v in pdf_info.items() if k != 'text_content'}\n","        with open(metadata_file_path, 'w', encoding='utf-8') as f:\n","            json.dump(metadata_to_save, f, indent=2, ensure_ascii=False, default=str)\n","        print(f\"      ‚úì Metadata saved to: {metadata_file_path}\")\n","        return text_file_path, metadata_file_path\n","\n","    def ingest_all(self):\n","        \"\"\"Ingest all PDF files from the root folder and any subfolders\"\"\"\n","        print(f\"Starting PDF ingestion from: {self.root_folder_path}\")\n","        print(f\"Output will be saved to: {self.output_folder_path}\")\n","        print(\"=\"*70)\n","        pdf_count = 0\n","        for dirpath, dirnames, filenames in os.walk(self.root_folder_path):\n","            for filename in filenames:\n","                if filename.lower().endswith('.pdf'):\n","                    file_path = Path(dirpath) / filename\n","                    print(f\"  Processing file: {file_path.relative_to(self.root_folder_path)}\")\n","                    pdf_info = {\n","                        'file_path': str(file_path),\n","                        'file_name': filename,\n","                        'relative_path': str(file_path.relative_to(self.root_folder_path)),\n","                        'file_size': file_path.stat().st_size,\n","                        'ingestion_time': datetime.now().isoformat()\n","                    }\n","                    text_content = self.extract_pdf_text(file_path)\n","                    pdf_info['text_content'] = text_content\n","                    metadata = self.get_pdf_metadata(file_path)\n","                    pdf_info.update(metadata)\n","                    self.save_individual_files(pdf_info)\n","                    self.all_pdfs.append(pdf_info)\n","                    self.ingestion_log.append(f\"Ingested PDF: {pdf_info['relative_path']}\")\n","                    pdf_count += 1\n","        print(\"\\n\" + \"=\"*70)\n","        print(\"Ingestion Summary:\")\n","        print(f\"üìä Total PDFs processed: {pdf_count}\")\n","        print(f\"üíæ Output saved to: {self.output_folder_path}\")\n","\n","    def generate_section_analysis(self):\n","        \"\"\"Generate analysis of detected sections across all PDFs\"\"\"\n","        section_analysis = {\n","            'summary': {\n","                'total_pdfs': len(self.all_pdfs),\n","                'sections_found': {},\n","                'missing_sections': {}\n","            },\n","            'detailed_analysis': {}\n","        }\n","        all_section_types = set(self.section_patterns.keys())\n","        for pdf in self.all_pdfs:\n","            pdf_name = pdf['file_name']\n","            found_sections = []\n","            if pdf.get('text_content'):\n","                section_matches = re.findall(r'###SECTION:(\\w+)### ([^\\n]+)', pdf['text_content'])\n","                found_sections = [(match[0], match[1]) for match in section_matches]\n","            found_types = set([s[0] for s in found_sections])\n","            missing_types = all_section_types - found_types\n","            section_analysis['detailed_analysis'][pdf_name] = {\n","                'found_sections': found_sections,\n","                'missing_sections': list(missing_types),\n","                'section_count': len(found_sections)\n","            }\n","            for section_type in found_types:\n","                if section_type not in section_analysis['summary']['sections_found']:\n","                    section_analysis['summary']['sections_found'][section_type] = 0\n","                section_analysis['summary']['sections_found'][section_type] += 1\n","            for section_type in missing_types:\n","                if section_type not in section_analysis['summary']['missing_sections']:\n","                    section_analysis['summary']['missing_sections'][section_type] = 0\n","                section_analysis['summary']['missing_sections'][section_type] += 1\n","        analysis_path = self.output_folder_path / \"reports\" / \"section_analysis.json\"\n","        with open(analysis_path, 'w', encoding='utf-8') as f:\n","            json.dump(section_analysis, f, indent=2, ensure_ascii=False)\n","        print(f\"‚úì Section analysis saved to: {analysis_path}\")\n","        return section_analysis\n","\n","    def generate_summary_reports(self):\n","        \"\"\"Generate comprehensive summary reports from the flat list of PDFs\"\"\"\n","        print(\"Generating summary reports...\")\n","        if self.all_pdfs:\n","            csv_data = []\n","            for pdf in self.all_pdfs:\n","                csv_row = {k: v for k, v in pdf.items() if k != 'text_content'}\n","                csv_row['text_length'] = len(pdf.get('text_content', '')) if pdf.get('text_content') else 0\n","                csv_data.append(csv_row)\n","            df = pd.DataFrame(csv_data)\n","            csv_path = self.output_folder_path / \"reports\" / \"master_summary.csv\"\n","            df.to_csv(csv_path, index=False)\n","            print(f\"‚úì Master CSV saved to: {csv_path}\")\n","            json_path = self.output_folder_path / \"reports\" / \"detailed_report.json\"\n","            detailed_report = {\n","                'summary': {\n","                    'total_pdfs': len(self.all_pdfs),\n","                    'processing_time': datetime.now().isoformat(),\n","                    'input_folder': str(self.root_folder_path),\n","                    'output_folder': str(self.output_folder_path)\n","                },\n","                'ingested_pdfs': [ {k: v for k, v in pdf.items() if k != 'text_content'} for pdf in self.all_pdfs ],\n","                'ingestion_log': self.ingestion_log\n","            }\n","            with open(json_path, 'w', encoding='utf-8') as f:\n","                json.dump(detailed_report, f, indent=2, ensure_ascii=False, default=str)\n","            print(f\"‚úì Detailed JSON report saved to: {json_path}\")\n","            log_path = self.output_folder_path / \"logs\" / \"processing_log.txt\"\n","            with open(log_path, 'w', encoding='utf-8') as f:\n","                f.write(f\"PDF Ingestion Log - {datetime.now().isoformat()}\\n\")\n","                f.write(\"=\" * 60 + \"\\n\\n\")\n","                f.write(f\"Input Folder: {self.root_folder_path}\\n\")\n","                f.write(f\"Output Folder: {self.output_folder_path}\\n\\n\")\n","                f.write(f\"Total PDFs Processed: {len(self.all_pdfs)}\\n\\n\")\n","                f.write(\"Processing Log:\\n\")\n","                f.write(\"-\" * 40 + \"\\n\")\n","                for log_entry in self.ingestion_log:\n","                    f.write(f\"{log_entry}\\n\")\n","            print(f\"‚úì Processing log saved to: {log_path}\")\n","        self.generate_section_analysis()\n","\n","    def search_content(self, search_term, case_sensitive=False):\n","        \"\"\"Search for specific content across all ingested PDFs\"\"\"\n","        results = []\n","        term = search_term if case_sensitive else search_term.lower()\n","        for pdf in self.all_pdfs:\n","            if pdf.get('text_content'):\n","                content = pdf['text_content'] if case_sensitive else pdf['text_content'].lower()\n","                if term in content:\n","                    results.append({\n","                        'file_name': pdf['file_name'],\n","                        'relative_path': pdf['relative_path'],\n","                        'file_path': pdf['file_path']\n","                    })\n","        return results\n","\n","# --- NEW HYBRID USAGE EXAMPLE ---\n","\n","def is_colab():\n","    try:\n","        import google.colab\n","        return True\n","    except ImportError:\n","        return False\n","\n","def get_paths(local_input, local_output):\n","    if is_colab():\n","        from google.colab import drive, files\n","        print(\"üîπ Running in Google Colab environment.\")\n","        try:\n","            drive.mount('/content/drive', force_remount=True)\n","            gdrive_input_folder = \"/content/drive/MyDrive/\" + os.path.basename(local_input)\n","            if os.path.exists(gdrive_input_folder):\n","                print(\"‚úì Found input folder on Google Drive.\")\n","                return gdrive_input_folder, gdrive_input_folder + \"_extracted\"\n","        except Exception as e:\n","            print(f\"‚ö† Could not mount Google Drive or find folder: {e}\")\n","            print(\"Falling back to ZIP upload.\")\n","        print(\"\\nüìÇ Please upload your ZIP file now.\")\n","        uploaded = files.upload()\n","        if not uploaded:\n","            print(\"‚ùå No file uploaded. Exiting.\")\n","            return None, None\n","        zip_name = next(iter(uploaded))\n","        extract_path = \"/content/\" + os.path.splitext(zip_name)[0]\n","        print(f\"üì¶ Extracting {zip_name} to {extract_path}...\")\n","        with zipfile.ZipFile(zip_name, 'r') as zip_ref:\n","            zip_ref.extractall(extract_path)\n","        print(\"‚úì Extraction complete.\")\n","        input_folder = extract_path\n","        output_folder = extract_path + \"_extracted\"\n","        print(\"üîπ Using ZIP Upload paths:\")\n","        return input_folder, output_folder\n","    else:\n","        print(\"üîπ Running on Local PC.\")\n","        return local_input, local_output\n","\n","def download_results_from_colab(output_folder_path):\n","    \"\"\"Download the complete output folder as a ZIP file in Google Colab\"\"\"\n","    if not is_colab():\n","        print(\"üîπ Running locally - no download needed.\")\n","        return\n","\n","    try:\n","        from google.colab import files\n","        import zipfile\n","        import tempfile\n","\n","        print(\"\\nüì¶ Preparing output files for download...\")\n","\n","        # Create a temporary ZIP file\n","        with tempfile.NamedTemporaryFile(suffix='.zip', delete=False) as temp_zip:\n","            temp_zip_path = temp_zip.name\n","\n","        # Create ZIP of the entire output folder\n","        output_zip_name = f\"{os.path.basename(output_folder_path)}.zip\"\n","\n","        with zipfile.ZipFile(temp_zip_path, 'w', zipfile.ZIP_DEFLATED) as zipf:\n","            for root, dirs, files_to_add in os.walk(output_folder_path):\n","                for file_to_add in files_to_add:\n","                    file_path = os.path.join(root, file_to_add)\n","                    # Get relative path for the ZIP structure\n","                    arcname = os.path.relpath(file_path, output_folder_path)\n","                    zipf.write(file_path, arcname)\n","\n","        # Rename the temp file to the desired output name\n","        final_zip_path = f\"/content/{output_zip_name}\"\n","        shutil.move(temp_zip_path, final_zip_path)\n","\n","        print(f\"‚úì Created ZIP file: {output_zip_name}\")\n","        print(f\"üì¶ ZIP file size: {os.path.getsize(final_zip_path) / (1024*1024):.2f} MB\")\n","\n","        # Download the ZIP file\n","        print(\"‚¨áÔ∏è Starting download...\")\n","        files.download(final_zip_path)\n","\n","        print(\"‚úÖ Download complete! Check your browser's download folder.\")\n","\n","        # Optional: Clean up the ZIP file from Colab storage\n","        try:\n","            os.remove(final_zip_path)\n","            print(\"üßπ Cleaned up temporary ZIP file from Colab.\")\n","        except:\n","            pass\n","\n","    except Exception as e:\n","        print(f\"‚ùå Error during download preparation: {str(e)}\")\n","        print(\"üí° You can manually download files from the Colab file browser on the left.\")\n","\n","# Modify your main execution block (the if __name__ == \"__main__\": section)\n","# Replace the existing main block with this enhanced version:\n","\n","if __name__ == \"__main__\":\n","    print(\"PDF Ingestion Tool - Flat Edition with Auto-Download\")\n","    print(\"=\" * 60)\n","\n","    # Set your local paths here\n","    local_input = r\"C:\\Users\\siddhu\\Desktop\\NIRF(151 to 200)\"\n","    local_output = r\"C:\\Users\\siddhu\\Desktop\\NIRF(151 to 200)_extracted\"\n","\n","    # Get appropriate paths based on environment\n","    input_folder, output_folder = get_paths(local_input, local_output)\n","    if not input_folder:\n","        exit(1)\n","\n","    print(f\"\\nInput folder: {input_folder}\")\n","    print(f\"Output folder: {output_folder}\")\n","    print(\"=\" * 60)\n","\n","    # Create ingester and process files\n","    ingester = PDFIngesterFlat(input_folder, output_folder)\n","    ingester.ingest_all()\n","    ingester.generate_summary_reports()\n","\n","    # Display output structure\n","    print(\"\\n\" + \"=\"*60)\n","    print(\"OUTPUT STRUCTURE:\")\n","    print(\"=\"*60)\n","    print(f\"üìÅ {ingester.output_folder_path}/\")\n","    print(\"‚îú‚îÄ‚îÄ üìÑ text_files/\")\n","    print(\"‚îÇ   ‚îî‚îÄ‚îÄ [all_pdfs_as_txt]\")\n","    print(\"‚îú‚îÄ‚îÄ üìä metadata/\")\n","    print(\"‚îÇ   ‚îî‚îÄ‚îÄ [all_pdfs_as_json]\")\n","    print(\"‚îú‚îÄ‚îÄ üìà reports/\")\n","    print(\"‚îÇ   ‚îú‚îÄ‚îÄ üìÑ master_summary.csv\")\n","    print(\"‚îÇ   ‚îú‚îÄ‚îÄ üìÑ detailed_report.json\")\n","    print(\"‚îÇ   ‚îî‚îÄ‚îÄ üìÑ section_analysis.json\")\n","    print(\"‚îî‚îÄ‚îÄ üìù logs/\")\n","    print(\"    ‚îî‚îÄ‚îÄ üìÑ processing_log.txt\")\n","\n","    print(\"\\n\" + \"=\"*60)\n","    print(\"PROCESSING COMPLETE!\")\n","    print(f\"‚úì All extracted text files saved to: {ingester.output_folder_path}/text_files/\")\n","    print(f\"‚úì All metadata files saved to: {ingester.output_folder_path}/metadata/\")\n","    print(f\"‚úì Summary reports saved to: {ingester.output_folder_path}/reports/\")\n","    print(f\"‚úì Processing logs saved to: {ingester.output_folder_path}/logs/\")\n","    print(\"=\"*60)\n","\n","    # NEW: Auto-download results if running in Colab\n","    if is_colab():\n","        print(\"\\nüîπ Google Colab detected - preparing files for download...\")\n","        download_choice = input(\"üì• Do you want to download the results to your laptop? (y/n): \").strip().lower()\n","        if download_choice in ['y', 'yes', '1']:\n","            download_results_from_colab(ingester.output_folder_path)\n","        else:\n","            print(\"üí° You can manually download files using the file browser on the left.\")\n","            print(f\"üìÅ Output folder location: {ingester.output_folder_path}\")\n","\n","    # Interactive search functionality\n","    print(\"\\n\" + \"=\"*60)\n","    print(\"SEARCH FUNCTIONALITY:\")\n","    print(\"=\"*60)\n","    while True:\n","        search_term = input(\"\\nEnter search term (or 'quit' to exit): \").strip()\n","        if search_term.lower() in ['quit', 'exit', 'q', '']:\n","            break\n","\n","        search_results = ingester.search_content(search_term)\n","        if search_results:\n","            print(f\"\\nüîç Found '{search_term}' in {len(search_results)} files:\")\n","            for result in search_results:\n","                print(f\"  ‚úì {result['file_name']} (Original Path: {result['relative_path']})\")\n","        else:\n","            print(f\"‚ùå No results found for '{search_term}'\")\n","\n","    print(\"\\nüëã Thanks for using PDF Ingestion Tool!\")\n","    if is_colab():\n","        print(\"üìÅ All files are available in your browser's download folder.\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":156539,"status":"ok","timestamp":1762970950232,"user":{"displayName":"Rahul Siddhu","userId":"12007764243202946991"},"user_tz":-330},"id":"AmQ8CXOOlLTk","outputId":"b0da3f39-4f13-48fe-8d57-b431361baf2a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Setting up for Google Colab...\n","Google Colab detected!\n","Do you want to upload files? (y/n): y\n","Please select your NIRF .txt files:\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","     <input type=\"file\" id=\"files-561b4389-97d1-4235-be2f-131efe0f2efe\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-561b4389-97d1-4235-be2f-131efe0f2efe\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script>// Copyright 2017 Google LLC\n","//\n","// Licensed under the Apache License, Version 2.0 (the \"License\");\n","// you may not use this file except in compliance with the License.\n","// You may obtain a copy of the License at\n","//\n","//      http://www.apache.org/licenses/LICENSE-2.0\n","//\n","// Unless required by applicable law or agreed to in writing, software\n","// distributed under the License is distributed on an \"AS IS\" BASIS,\n","// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","// See the License for the specific language governing permissions and\n","// limitations under the License.\n","\n","/**\n"," * @fileoverview Helpers for google.colab Python module.\n"," */\n","(function(scope) {\n","function span(text, styleAttributes = {}) {\n","  const element = document.createElement('span');\n","  element.textContent = text;\n","  for (const key of Object.keys(styleAttributes)) {\n","    element.style[key] = styleAttributes[key];\n","  }\n","  return element;\n","}\n","\n","// Max number of bytes which will be uploaded at a time.\n","const MAX_PAYLOAD_SIZE = 100 * 1024;\n","\n","function _uploadFiles(inputId, outputId) {\n","  const steps = uploadFilesStep(inputId, outputId);\n","  const outputElement = document.getElementById(outputId);\n","  // Cache steps on the outputElement to make it available for the next call\n","  // to uploadFilesContinue from Python.\n","  outputElement.steps = steps;\n","\n","  return _uploadFilesContinue(outputId);\n","}\n","\n","// This is roughly an async generator (not supported in the browser yet),\n","// where there are multiple asynchronous steps and the Python side is going\n","// to poll for completion of each step.\n","// This uses a Promise to block the python side on completion of each step,\n","// then passes the result of the previous step as the input to the next step.\n","function _uploadFilesContinue(outputId) {\n","  const outputElement = document.getElementById(outputId);\n","  const steps = outputElement.steps;\n","\n","  const next = steps.next(outputElement.lastPromiseValue);\n","  return Promise.resolve(next.value.promise).then((value) => {\n","    // Cache the last promise value to make it available to the next\n","    // step of the generator.\n","    outputElement.lastPromiseValue = value;\n","    return next.value.response;\n","  });\n","}\n","\n","/**\n"," * Generator function which is called between each async step of the upload\n"," * process.\n"," * @param {string} inputId Element ID of the input file picker element.\n"," * @param {string} outputId Element ID of the output display.\n"," * @return {!Iterable<!Object>} Iterable of next steps.\n"," */\n","function* uploadFilesStep(inputId, outputId) {\n","  const inputElement = document.getElementById(inputId);\n","  inputElement.disabled = false;\n","\n","  const outputElement = document.getElementById(outputId);\n","  outputElement.innerHTML = '';\n","\n","  const pickedPromise = new Promise((resolve) => {\n","    inputElement.addEventListener('change', (e) => {\n","      resolve(e.target.files);\n","    });\n","  });\n","\n","  const cancel = document.createElement('button');\n","  inputElement.parentElement.appendChild(cancel);\n","  cancel.textContent = 'Cancel upload';\n","  const cancelPromise = new Promise((resolve) => {\n","    cancel.onclick = () => {\n","      resolve(null);\n","    };\n","  });\n","\n","  // Wait for the user to pick the files.\n","  const files = yield {\n","    promise: Promise.race([pickedPromise, cancelPromise]),\n","    response: {\n","      action: 'starting',\n","    }\n","  };\n","\n","  cancel.remove();\n","\n","  // Disable the input element since further picks are not allowed.\n","  inputElement.disabled = true;\n","\n","  if (!files) {\n","    return {\n","      response: {\n","        action: 'complete',\n","      }\n","    };\n","  }\n","\n","  for (const file of files) {\n","    const li = document.createElement('li');\n","    li.append(span(file.name, {fontWeight: 'bold'}));\n","    li.append(span(\n","        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n","        `last modified: ${\n","            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n","                                    'n/a'} - `));\n","    const percent = span('0% done');\n","    li.appendChild(percent);\n","\n","    outputElement.appendChild(li);\n","\n","    const fileDataPromise = new Promise((resolve) => {\n","      const reader = new FileReader();\n","      reader.onload = (e) => {\n","        resolve(e.target.result);\n","      };\n","      reader.readAsArrayBuffer(file);\n","    });\n","    // Wait for the data to be ready.\n","    let fileData = yield {\n","      promise: fileDataPromise,\n","      response: {\n","        action: 'continue',\n","      }\n","    };\n","\n","    // Use a chunked sending to avoid message size limits. See b/62115660.\n","    let position = 0;\n","    do {\n","      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n","      const chunk = new Uint8Array(fileData, position, length);\n","      position += length;\n","\n","      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n","      yield {\n","        response: {\n","          action: 'append',\n","          file: file.name,\n","          data: base64,\n","        },\n","      };\n","\n","      let percentDone = fileData.byteLength === 0 ?\n","          100 :\n","          Math.round((position / fileData.byteLength) * 100);\n","      percent.textContent = `${percentDone}% done`;\n","\n","    } while (position < fileData.byteLength);\n","  }\n","\n","  // All done.\n","  yield {\n","    response: {\n","      action: 'complete',\n","    }\n","  };\n","}\n","\n","scope.google = scope.google || {};\n","scope.google.colab = scope.google.colab || {};\n","scope.google.colab._files = {\n","  _uploadFiles,\n","  _uploadFilesContinue,\n","};\n","})(self);\n","</script> "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n","  Line 2: Ph.D (Student pursuing doctoral program till 2022-23)\n","\n","No PG program indicators found\n","==================================================\n","    Analyzing content length: 235 characters\n","    Sample content preview: Ph.D Student Details\n","Ph.D (Student pursuing doctoral program till 2022-23)\n","Total Students\n","Full Time\n","28\n","Part Time\n","260\n","No. of Ph.D students graduated (including Integrated Ph.D)\n","2022-23\n","2021-22\n","2020-21\n","...\n","    No valid values found for ug_4_years\n","    No valid values found for ug_5_years\n","    No valid values found for pg_2_years\n","    No valid values found for pg_3_years\n","    No valid values found for pg_integrated\n","    Some PG programs not found with primary patterns, trying line-by-line analysis...\n","  Accumulated student data so far: {'ug_4_years': 5050, 'ug_5_years': 0, 'pg_2_years': 466, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 5050, 'ug_5_years': 0, 'pg_2_years': 466, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 5050, 'ug_5_years': 0, 'pg_2_years': 466, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 5050, 'ug_5_years': 0, 'pg_2_years': 466, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 5050, 'ug_5_years': 0, 'pg_2_years': 466, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Found student section: PCS_FACILITIES\n","\n","=== DEBUGGING SECTION: PCS_FACILITIES ===\n","Section length: 430 characters\n","No obvious table structure found\n","\n","First 10 non-empty lines:\n","  1: PCS Facilities: Facilities of Physically Challenged Students\n","  2: 1. Do your institution buildings have Lifts/Ramps?\n","  3: Yes, more than 80% of the buildings\n","  4: 2. Do your institution have provision for walking aids, including wheelchairs and transportation from one building to another for\n","  5: handicapped students?\n","  6: Yes\n","  7: 3. Do your institution buildings have specially designed toilets for handicapped students?\n","  8: Yes, more than 80% of the buildings\n","\n","No PG program indicators found\n","==================================================\n","    Analyzing content length: 430 characters\n","    Sample content preview: PCS Facilities: Facilities of Physically Challenged Students\n","1. Do your institution buildings have Lifts/Ramps?\n","Yes, more than 80% of the buildings\n","2. Do your institution have provision for walking ai...\n","    No valid values found for ug_4_years\n","    No valid values found for ug_5_years\n","    No valid values found for pg_2_years\n","    No valid values found for pg_3_years\n","    No valid values found for pg_integrated\n","    Some PG programs not found with primary patterns, trying line-by-line analysis...\n","  Accumulated student data so far: {'ug_4_years': 5050, 'ug_5_years': 0, 'pg_2_years': 466, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 5050, 'ug_5_years': 0, 'pg_2_years': 466, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 5050, 'ug_5_years': 0, 'pg_2_years': 466, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 5050, 'ug_5_years': 0, 'pg_2_years': 466, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 5050, 'ug_5_years': 0, 'pg_2_years': 466, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Processing faculty section: FACULTY_DETAILS\n","\n","=== DEBUGGING SECTION: FACULTY_DETAILS ===\n","Section length: 37 characters\n","No obvious table structure found\n","\n","First 10 non-empty lines:\n","  1: Number of faculty members entered\n","  2: 362\n","\n","No PG program indicators found\n","==================================================\n","   Looking for pattern: INDEX -> Name...\n","    No valid index->name patterns found\n","  No faculty found in 'FACULTY_DETAILS', processing as normal content.\n","  Creating consolidated student strength point: {'ug_4_years': 5050, 'ug_5_years': 0, 'pg_2_years': 466, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 5516}\n","Created 12 points for R.V. College of Engineering\n","Saved 12 points to R.V. College of Engineering.json (normalized)\n","  Created 12 points\n","\n","Processing file: IIT Varanasi_Banaras Hindu University_.txt\n","Processing: Indian Institute of Technology (Banaras Hindu University) Varanasi (IR-E-U-0701)\n","  Found student section: SANCTIONED_INTAKE\n","\n","=== DEBUGGING SECTION: SANCTIONED_INTAKE ===\n","Section length: 223 characters\n","Relevant lines found:\n","  Line 9: UG [4 Years Program(s)]\n","  Line 16: UG [5 Years Program(s)]\n","  Line 23: PG [2 Year Program(s)]\n","\n","PG Programs (2-Year/3-Year/Integrated/PG-Integrated) analysis:\n","  Line 23: PG [2 Year Program(s)]\n","  Line 24:   -> 555\n","  Line 25:   -> 555\n","==================================================\n","    Analyzing content length: 223 characters\n","    Sample content preview: Sanctioned (Approved) Intake\n","Academic Year\n","2022-23\n","2021-22\n","2020-21\n","2019-20\n","2018-19\n","2017-18\n","UG [4 Years Program(s)]\n","1163\n","1163\n","1163\n","1012\n","-\n","-\n","UG [5 Years Program(s)]\n","400\n","400\n","400\n","334\n","291\n","-\n","PG [2 Year Prog...\n","    Pattern 1 for ug_4_years found TUPLE: Male=1163, Female=1163, Total=1163\n","    Pattern 2 for ug_4_years found TUPLE: Male=1163, Female=1163, Total=1163\n","    Pattern 3 for ug_4_years found TUPLE: Male=1163, Female=1163, Total=1163\n","    Pattern 4 for ug_4_years found SINGLE: 1163\n","    Final ug_4_years: 1163 students (from values: [1163, 1163, 1163, 1163])\n","    Pattern 1 for ug_5_years found TUPLE: Male=400, Female=400, Total=400\n","    Pattern 2 for ug_5_years found TUPLE: Male=400, Female=400, Total=400\n","    Pattern 3 for ug_5_years found TUPLE: Male=400, Female=400, Total=400\n","    Pattern 4 for ug_5_years found SINGLE: 400\n","    Final ug_5_years: 400 students (from values: [400, 400, 400, 400])\n","    Pattern 5 for pg_2_years found SINGLE: 555\n","    Pattern 6 for pg_2_years found SINGLE: 555\n","    Final pg_2_years: 555 students (from values: [555, 555])\n","    No valid values found for pg_3_years\n","    No valid values found for pg_integrated\n","    Some PG programs not found with primary patterns, trying line-by-line analysis...\n","    Calculated total students: 2118\n","  Accumulated student data so far: {'ug_4_years': 1163, 'ug_5_years': 0, 'pg_2_years': 0, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 1163, 'ug_5_years': 400, 'pg_2_years': 0, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 1163, 'ug_5_years': 400, 'pg_2_years': 555, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 1163, 'ug_5_years': 400, 'pg_2_years': 555, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 1163, 'ug_5_years': 400, 'pg_2_years': 555, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Found student section: STUDENT_STRENGTH\n","\n","=== DEBUGGING SECTION: STUDENT_STRENGTH ===\n","Section length: 915 characters\n","Relevant lines found:\n","  Line 1: Total Actual Student Strength (Program(s) Offered by your Institution)\n","  Line 2: (All programs\n","  Line 3: of all years)\n","  Line 52: UG [4 Years\n","  Line 53: Program(s)]\n","  Line 66: UG [5 Years\n","  Line 67: Program(s)]\n","  Line 80: PG [2 Year\n","  Line 81: Program(s)]\n","\n","PG Programs (2-Year/3-Year/Integrated/PG-Integrated) analysis:\n","  Line 80: PG [2 Year\n","  Line 81:   -> Program(s)]\n","  Line 82:   -> 626\n","==================================================\n","    Analyzing content length: 915 characters\n","    Sample content preview: Total Actual Student Strength (Program(s) Offered by your Institution)\n","(All programs\n","of all years)\n","No. of Male\n","Students\n","No. of Female\n","Students\n","Total Students\n","Within State\n","(Including male\n","& female)\n","Out...\n","    Pattern 1 for ug_4_years found TUPLE: Male=3524, Female=835, Total=4359\n","    Pattern 2 for ug_4_years found TUPLE: Male=3524, Female=835, Total=4359\n","    Pattern 3 for ug_4_years found TUPLE: Male=3524, Female=835, Total=4359\n","    Pattern 4 for ug_4_years found SINGLE: 3524\n","    Final ug_4_years: 4359 students (from values: [4359, 4359, 4359, 3524])\n","    Pattern 1 for ug_5_years found TUPLE: Male=1356, Female=318, Total=1674\n","    Pattern 2 for ug_5_years found TUPLE: Male=1356, Female=318, Total=1674\n","    Pattern 3 for ug_5_years found TUPLE: Male=1356, Female=318, Total=1674\n","    Pattern 4 for ug_5_years found SINGLE: 1356\n","    Final ug_5_years: 1674 students (from values: [1674, 1674, 1674, 1356])\n","    Pattern 1 for pg_2_years found TUPLE: Male=626, Female=105, Total=731\n","    Pattern 2 for pg_2_years found TUPLE: Male=626, Female=105, Total=731\n","    Pattern 3 for pg_2_years found TUPLE: Male=626, Female=105, Total=731\n","    Pattern 4 for pg_2_years found TUPLE: Male=626, Female=105, Total=731\n","    Pattern 5 for pg_2_years found SINGLE: 626\n","    Pattern 6 for pg_2_years found SINGLE: 626\n","    Final pg_2_years: 731 students (from values: [731, 731, 731, 731, 626, 626])\n","    No valid values found for pg_3_years\n","    No valid values found for pg_integrated\n","    Some PG programs not found with primary patterns, trying line-by-line analysis...\n","    Calculated total students: 6764\n","  Accumulated student data so far: {'ug_4_years': 4359, 'ug_5_years': 400, 'pg_2_years': 555, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 4359, 'ug_5_years': 1674, 'pg_2_years': 555, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 4359, 'ug_5_years': 1674, 'pg_2_years': 731, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 4359, 'ug_5_years': 1674, 'pg_2_years': 731, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 4359, 'ug_5_years': 1674, 'pg_2_years': 731, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Found student section: PLACEMENT_STUDIES\n","\n","=== DEBUGGING SECTION: PLACEMENT_STUDIES ===\n","Section length: 581 characters\n","Relevant lines found:\n","  Line 1: PG [2 Years Program(s)]: Placement & higher studies for previous 3 years\n","\n","PG Programs (2-Year/3-Year/Integrated/PG-Integrated) analysis:\n","  Line 1: PG [2 Years Program(s)]: Placement & higher studies for previous 3 years\n","  Line 2:   -> Academic Year\n","  Line 3:   -> No. of first year\n","==================================================\n","    Analyzing content length: 581 characters\n","    Sample content preview: PG [2 Years Program(s)]: Placement & higher studies for previous 3 years\n","Academic Year\n","No. of first year\n","students intake in the\n","year\n","No. of first year\n","students admitted in\n","the year\n","Academic Year\n","No. o...\n","    No valid values found for ug_4_years\n","    No valid values found for ug_5_years\n","    Pattern 5 for pg_2_years found SINGLE: 3\n","    Pattern 6 for pg_2_years found SINGLE: 3\n","    Final pg_2_years: 3 students (from values: [3, 3])\n","    No valid values found for pg_3_years\n","    No valid values found for pg_integrated\n","    Some PG programs not found with primary patterns, trying line-by-line analysis...\n","    Calculated total students: 3\n","  Accumulated student data so far: {'ug_4_years': 4359, 'ug_5_years': 1674, 'pg_2_years': 731, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 4359, 'ug_5_years': 1674, 'pg_2_years': 731, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 4359, 'ug_5_years': 1674, 'pg_2_years': 731, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 4359, 'ug_5_years': 1674, 'pg_2_years': 731, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 4359, 'ug_5_years': 1674, 'pg_2_years': 731, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Found student section: PHD_DETAILS\n","\n","=== DEBUGGING SECTION: PHD_DETAILS ===\n","Section length: 236 characters\n","Relevant lines found:\n","  Line 2: Ph.D (Student pursuing doctoral program till 2022-23)\n","\n","No PG program indicators found\n","==================================================\n","    Analyzing content length: 236 characters\n","    Sample content preview: Ph.D Student Details\n","Ph.D (Student pursuing doctoral program till 2022-23)\n","Total Students\n","Full Time\n","969\n","Part Time\n","76\n","No. of Ph.D students graduated (including Integrated Ph.D)\n","2022-23\n","2021-22\n","2020-21\n","...\n","    No valid values found for ug_4_years\n","    No valid values found for ug_5_years\n","    No valid values found for pg_2_years\n","    No valid values found for pg_3_years\n","    No valid values found for pg_integrated\n","    Some PG programs not found with primary patterns, trying line-by-line analysis...\n","  Accumulated student data so far: {'ug_4_years': 4359, 'ug_5_years': 1674, 'pg_2_years': 731, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 4359, 'ug_5_years': 1674, 'pg_2_years': 731, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 4359, 'ug_5_years': 1674, 'pg_2_years': 731, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 4359, 'ug_5_years': 1674, 'pg_2_years': 731, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 4359, 'ug_5_years': 1674, 'pg_2_years': 731, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Found student section: PCS_FACILITIES\n","\n","=== DEBUGGING SECTION: PCS_FACILITIES ===\n","Section length: 430 characters\n","No obvious table structure found\n","\n","First 10 non-empty lines:\n","  1: PCS Facilities: Facilities of Physically Challenged Students\n","  2: 1. Do your institution buildings have Lifts/Ramps?\n","  3: Yes, more than 80% of the buildings\n","  4: 2. Do your institution have provision for walking aids, including wheelchairs and transportation from one building to another for\n","  5: handicapped students?\n","  6: Yes\n","  7: 3. Do your institution buildings have specially designed toilets for handicapped students?\n","  8: Yes, more than 80% of the buildings\n","\n","No PG program indicators found\n","==================================================\n","    Analyzing content length: 430 characters\n","    Sample content preview: PCS Facilities: Facilities of Physically Challenged Students\n","1. Do your institution buildings have Lifts/Ramps?\n","Yes, more than 80% of the buildings\n","2. Do your institution have provision for walking ai...\n","    No valid values found for ug_4_years\n","    No valid values found for ug_5_years\n","    No valid values found for pg_2_years\n","    No valid values found for pg_3_years\n","    No valid values found for pg_integrated\n","    Some PG programs not found with primary patterns, trying line-by-line analysis...\n","  Accumulated student data so far: {'ug_4_years': 4359, 'ug_5_years': 1674, 'pg_2_years': 731, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 4359, 'ug_5_years': 1674, 'pg_2_years': 731, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 4359, 'ug_5_years': 1674, 'pg_2_years': 731, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 4359, 'ug_5_years': 1674, 'pg_2_years': 731, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 4359, 'ug_5_years': 1674, 'pg_2_years': 731, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Processing faculty section: FACULTY_DETAILS\n","\n","=== DEBUGGING SECTION: FACULTY_DETAILS ===\n","Section length: 37 characters\n","No obvious table structure found\n","\n","First 10 non-empty lines:\n","  1: Number of faculty members entered\n","  2: 381\n","\n","No PG program indicators found\n","==================================================\n","   Looking for pattern: INDEX -> Name...\n","    No valid index->name patterns found\n","  No faculty found in 'FACULTY_DETAILS', processing as normal content.\n","  Creating consolidated student strength point: {'ug_4_years': 4359, 'ug_5_years': 1674, 'pg_2_years': 731, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 6764}\n","Created 12 points for Indian Institute of Technology (Banaras Hindu University) Varanasi\n","Saved 12 points to IIT Varanasi_Banaras Hindu University_.json (normalized)\n","  Created 12 points\n","\n","Processing file: IIT Guwahati.txt\n","Processing: Indian Institute of Technology Guwahati (IR-E-U-0053)\n","  Found student section: SANCTIONED_INTAKE\n","\n","=== DEBUGGING SECTION: SANCTIONED_INTAKE ===\n","Section length: 174 characters\n","Relevant lines found:\n","  Line 9: UG [4 Years Program(s)]\n","  Line 16: PG [2 Year Program(s)]\n","\n","PG Programs (2-Year/3-Year/Integrated/PG-Integrated) analysis:\n","  Line 16: PG [2 Year Program(s)]\n","  Line 17:   -> 993\n","  Line 18:   -> 873\n","==================================================\n","    Analyzing content length: 174 characters\n","    Sample content preview: Sanctioned (Approved) Intake\n","Academic Year\n","2022-23\n","2021-22\n","2020-21\n","2019-20\n","2018-19\n","2017-18\n","UG [4 Years Program(s)]\n","1008\n","902\n","978\n","851\n","-\n","-\n","PG [2 Year Program(s)]\n","993\n","873\n","-\n","-\n","-\n","-...\n","    Pattern 1 for ug_4_years found TUPLE: Male=1008, Female=902, Total=978\n","    Pattern 2 for ug_4_years found TUPLE: Male=1008, Female=902, Total=978\n","    Pattern 3 for ug_4_years found TUPLE: Male=1008, Female=902, Total=978\n","    Pattern 4 for ug_4_years found SINGLE: 1008\n","    Final ug_4_years: 1008 students (from values: [978, 978, 978, 1008])\n","    No valid values found for ug_5_years\n","    Pattern 5 for pg_2_years found SINGLE: 993\n","    Pattern 6 for pg_2_years found SINGLE: 993\n","    Final pg_2_years: 993 students (from values: [993, 993])\n","    No valid values found for pg_3_years\n","    No valid values found for pg_integrated\n","    Some PG programs not found with primary patterns, trying line-by-line analysis...\n","    Calculated total students: 2001\n","  Accumulated student data so far: {'ug_4_years': 1008, 'ug_5_years': 0, 'pg_2_years': 0, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 1008, 'ug_5_years': 0, 'pg_2_years': 0, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 1008, 'ug_5_years': 0, 'pg_2_years': 993, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 1008, 'ug_5_years': 0, 'pg_2_years': 993, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 1008, 'ug_5_years': 0, 'pg_2_years': 993, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Found student section: STUDENT_STRENGTH\n","\n","=== DEBUGGING SECTION: STUDENT_STRENGTH ===\n","Section length: 846 characters\n","Relevant lines found:\n","  Line 1: Total Actual Student Strength (Program(s) Offered by your Institution)\n","  Line 2: (All programs\n","  Line 3: of all years)\n","  Line 52: UG [4 Years\n","  Line 53: Program(s)]\n","  Line 66: PG [2 Year\n","  Line 67: Program(s)]\n","\n","PG Programs (2-Year/3-Year/Integrated/PG-Integrated) analysis:\n","  Line 66: PG [2 Year\n","  Line 67:   -> Program(s)]\n","  Line 68:   -> 1452\n","==================================================\n","    Analyzing content length: 846 characters\n","    Sample content preview: Total Actual Student Strength (Program(s) Offered by your Institution)\n","(All programs\n","of all years)\n","No. of Male\n","Students\n","No. of Female\n","Students\n","Total Students\n","Within State\n","(Including male\n","& female)\n","Out...\n","    Pattern 1 for ug_4_years found TUPLE: Male=2985, Female=792, Total=3777\n","    Pattern 2 for ug_4_years found TUPLE: Male=2985, Female=792, Total=3777\n","    Pattern 3 for ug_4_years found TUPLE: Male=2985, Female=792, Total=3777\n","    Pattern 4 for ug_4_years found SINGLE: 2985\n","    Final ug_4_years: 3777 students (from values: [3777, 3777, 3777, 2985])\n","    No valid values found for ug_5_years\n","    Pattern 1 for pg_2_years found TUPLE: Male=1452, Female=301, Total=1753\n","    Pattern 2 for pg_2_years found TUPLE: Male=1452, Female=301, Total=1753\n","    Pattern 3 for pg_2_years found TUPLE: Male=1452, Female=301, Total=1753\n","    Pattern 4 for pg_2_years found TUPLE: Male=1452, Female=301, Total=1753\n","    Pattern 5 for pg_2_years found SINGLE: 1452\n","    Pattern 6 for pg_2_years found SINGLE: 1452\n","    Final pg_2_years: 1753 students (from values: [1753, 1753, 1753, 1753, 1452, 1452])\n","    No valid values found for pg_3_years\n","    No valid values found for pg_integrated\n","    Some PG programs not found with primary patterns, trying line-by-line analysis...\n","    Calculated total students: 5530\n","  Accumulated student data so far: {'ug_4_years': 3777, 'ug_5_years': 0, 'pg_2_years': 993, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 3777, 'ug_5_years': 0, 'pg_2_years': 993, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 3777, 'ug_5_years': 0, 'pg_2_years': 1753, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 3777, 'ug_5_years': 0, 'pg_2_years': 1753, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 3777, 'ug_5_years': 0, 'pg_2_years': 1753, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Found student section: PLACEMENT_STUDIES\n","\n","=== DEBUGGING SECTION: PLACEMENT_STUDIES ===\n","Section length: 591 characters\n","Relevant lines found:\n","  Line 1: PG [2 Years Program(s)]: Placement & higher studies for previous 3 years\n","\n","PG Programs (2-Year/3-Year/Integrated/PG-Integrated) analysis:\n","  Line 1: PG [2 Years Program(s)]: Placement & higher studies for previous 3 years\n","  Line 2:   -> Academic Year\n","  Line 3:   -> No. of first year\n","==================================================\n","    Analyzing content length: 591 characters\n","    Sample content preview: PG [2 Years Program(s)]: Placement & higher studies for previous 3 years\n","Academic Year\n","No. of first year\n","students intake in the\n","year\n","No. of first year\n","students admitted in\n","the year\n","Academic Year\n","No. o...\n","    No valid values found for ug_4_years\n","    No valid values found for ug_5_years\n","    Pattern 5 for pg_2_years found SINGLE: 3\n","    Pattern 6 for pg_2_years found SINGLE: 3\n","    Final pg_2_years: 3 students (from values: [3, 3])\n","    No valid values found for pg_3_years\n","    No valid values found for pg_integrated\n","    Some PG programs not found with primary patterns, trying line-by-line analysis...\n","    Calculated total students: 3\n","  Accumulated student data so far: {'ug_4_years': 3777, 'ug_5_years': 0, 'pg_2_years': 1753, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 3777, 'ug_5_years': 0, 'pg_2_years': 1753, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 3777, 'ug_5_years': 0, 'pg_2_years': 1753, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 3777, 'ug_5_years': 0, 'pg_2_years': 1753, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 3777, 'ug_5_years': 0, 'pg_2_years': 1753, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Found student section: PHD_DETAILS\n","\n","=== DEBUGGING SECTION: PHD_DETAILS ===\n","Section length: 242 characters\n","Relevant lines found:\n","  Line 2: Ph.D (Student pursuing doctoral program till 2022-23)\n","\n","No PG program indicators found\n","==================================================\n","    Analyzing content length: 242 characters\n","    Sample content preview: Ph.D Student Details\n","Ph.D (Student pursuing doctoral program till 2022-23)\n","Total Students\n","Full Time\n","1795\n","Part Time\n","199\n","No. of Ph.D students graduated (including Integrated Ph.D)\n","2022-23\n","2021-22\n","2020-2...\n","    No valid values found for ug_4_years\n","    No valid values found for ug_5_years\n","    No valid values found for pg_2_years\n","    No valid values found for pg_3_years\n","    No valid values found for pg_integrated\n","    Some PG programs not found with primary patterns, trying line-by-line analysis...\n","  Accumulated student data so far: {'ug_4_years': 3777, 'ug_5_years': 0, 'pg_2_years': 1753, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 3777, 'ug_5_years': 0, 'pg_2_years': 1753, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 3777, 'ug_5_years': 0, 'pg_2_years': 1753, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 3777, 'ug_5_years': 0, 'pg_2_years': 1753, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 3777, 'ug_5_years': 0, 'pg_2_years': 1753, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Found student section: PCS_FACILITIES\n","\n","=== DEBUGGING SECTION: PCS_FACILITIES ===\n","Section length: 430 characters\n","No obvious table structure found\n","\n","First 10 non-empty lines:\n","  1: PCS Facilities: Facilities of Physically Challenged Students\n","  2: 1. Do your institution buildings have Lifts/Ramps?\n","  3: Yes, more than 80% of the buildings\n","  4: 2. Do your institution have provision for walking aids, including wheelchairs and transportation from one building to another for\n","  5: handicapped students?\n","  6: Yes\n","  7: 3. Do your institution buildings have specially designed toilets for handicapped students?\n","  8: Yes, more than 80% of the buildings\n","\n","No PG program indicators found\n","==================================================\n","    Analyzing content length: 430 characters\n","    Sample content preview: PCS Facilities: Facilities of Physically Challenged Students\n","1. Do your institution buildings have Lifts/Ramps?\n","Yes, more than 80% of the buildings\n","2. Do your institution have provision for walking ai...\n","    No valid values found for ug_4_years\n","    No valid values found for ug_5_years\n","    No valid values found for pg_2_years\n","    No valid values found for pg_3_years\n","    No valid values found for pg_integrated\n","    Some PG programs not found with primary patterns, trying line-by-line analysis...\n","  Accumulated student data so far: {'ug_4_years': 3777, 'ug_5_years': 0, 'pg_2_years': 1753, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 3777, 'ug_5_years': 0, 'pg_2_years': 1753, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 3777, 'ug_5_years': 0, 'pg_2_years': 1753, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 3777, 'ug_5_years': 0, 'pg_2_years': 1753, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 3777, 'ug_5_years': 0, 'pg_2_years': 1753, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Processing faculty section: FACULTY_DETAILS\n","\n","=== DEBUGGING SECTION: FACULTY_DETAILS ===\n","Section length: 37 characters\n","No obvious table structure found\n","\n","First 10 non-empty lines:\n","  1: Number of faculty members entered\n","  2: 509\n","\n","No PG program indicators found\n","==================================================\n","   Looking for pattern: INDEX -> Name...\n","    No valid index->name patterns found\n","  No faculty found in 'FACULTY_DETAILS', processing as normal content.\n","  Creating consolidated student strength point: {'ug_4_years': 3777, 'ug_5_years': 0, 'pg_2_years': 1753, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 5530}\n","Created 12 points for Indian Institute of Technology Guwahati\n","Saved 12 points to IIT Guwahati.json (normalized)\n","  Created 12 points\n","\n","Processing file: Malaviya National Institute of Technology.txt\n","Processing: Malaviya National Institute of Technology (IR-E-U-0410)\n","  Found student section: SANCTIONED_INTAKE\n","\n","=== DEBUGGING SECTION: SANCTIONED_INTAKE ===\n","Section length: 173 characters\n","Relevant lines found:\n","  Line 9: UG [4 Years Program(s)]\n","  Line 16: PG [2 Year Program(s)]\n","\n","PG Programs (2-Year/3-Year/Integrated/PG-Integrated) analysis:\n","  Line 16: PG [2 Year Program(s)]\n","  Line 17:   -> 511\n","  Line 18:   -> 573\n","==================================================\n","    Analyzing content length: 173 characters\n","    Sample content preview: Sanctioned (Approved) Intake\n","Academic Year\n","2022-23\n","2021-22\n","2020-21\n","2019-20\n","2018-19\n","2017-18\n","UG [4 Years Program(s)]\n","811\n","811\n","832\n","811\n","-\n","-\n","PG [2 Year Program(s)]\n","511\n","573\n","-\n","-\n","-\n","-...\n","    Pattern 1 for ug_4_years found TUPLE: Male=811, Female=811, Total=832\n","    Pattern 2 for ug_4_years found TUPLE: Male=811, Female=811, Total=832\n","    Pattern 3 for ug_4_years found TUPLE: Male=811, Female=811, Total=832\n","    Pattern 4 for ug_4_years found SINGLE: 811\n","    Final ug_4_years: 832 students (from values: [832, 832, 832, 811])\n","    No valid values found for ug_5_years\n","    Pattern 5 for pg_2_years found SINGLE: 511\n","    Pattern 6 for pg_2_years found SINGLE: 511\n","    Final pg_2_years: 511 students (from values: [511, 511])\n","    No valid values found for pg_3_years\n","    No valid values found for pg_integrated\n","    Some PG programs not found with primary patterns, trying line-by-line analysis...\n","    Calculated total students: 1343\n","  Accumulated student data so far: {'ug_4_years': 832, 'ug_5_years': 0, 'pg_2_years': 0, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 832, 'ug_5_years': 0, 'pg_2_years': 0, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 832, 'ug_5_years': 0, 'pg_2_years': 511, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 832, 'ug_5_years': 0, 'pg_2_years': 511, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 832, 'ug_5_years': 0, 'pg_2_years': 511, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Found student section: STUDENT_STRENGTH\n","\n","=== DEBUGGING SECTION: STUDENT_STRENGTH ===\n","Section length: 843 characters\n","Relevant lines found:\n","  Line 1: Total Actual Student Strength (Program(s) Offered by your Institution)\n","  Line 2: (All programs\n","  Line 3: of all years)\n","  Line 52: UG [4 Years\n","  Line 53: Program(s)]\n","  Line 66: PG [2 Year\n","  Line 67: Program(s)]\n","\n","PG Programs (2-Year/3-Year/Integrated/PG-Integrated) analysis:\n","  Line 66: PG [2 Year\n","  Line 67:   -> Program(s)]\n","  Line 68:   -> 570\n","==================================================\n","    Analyzing content length: 843 characters\n","    Sample content preview: Total Actual Student Strength (Program(s) Offered by your Institution)\n","(All programs\n","of all years)\n","No. of Male\n","Students\n","No. of Female\n","Students\n","Total Students\n","Within State\n","(Including male\n","& female)\n","Out...\n","    Pattern 1 for ug_4_years found TUPLE: Male=2562, Female=662, Total=3224\n","    Pattern 2 for ug_4_years found TUPLE: Male=2562, Female=662, Total=3224\n","    Pattern 3 for ug_4_years found TUPLE: Male=2562, Female=662, Total=3224\n","    Pattern 4 for ug_4_years found SINGLE: 2562\n","    Final ug_4_years: 3224 students (from values: [3224, 3224, 3224, 2562])\n","    No valid values found for ug_5_years\n","    Pattern 1 for pg_2_years found TUPLE: Male=570, Female=180, Total=750\n","    Pattern 2 for pg_2_years found TUPLE: Male=570, Female=180, Total=750\n","    Pattern 3 for pg_2_years found TUPLE: Male=570, Female=180, Total=750\n","    Pattern 4 for pg_2_years found TUPLE: Male=570, Female=180, Total=750\n","    Pattern 5 for pg_2_years found SINGLE: 570\n","    Pattern 6 for pg_2_years found SINGLE: 570\n","    Final pg_2_years: 750 students (from values: [750, 750, 750, 750, 570, 570])\n","    No valid values found for pg_3_years\n","    No valid values found for pg_integrated\n","    Some PG programs not found with primary patterns, trying line-by-line analysis...\n","    Calculated total students: 3974\n","  Accumulated student data so far: {'ug_4_years': 3224, 'ug_5_years': 0, 'pg_2_years': 511, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 3224, 'ug_5_years': 0, 'pg_2_years': 511, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 3224, 'ug_5_years': 0, 'pg_2_years': 750, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 3224, 'ug_5_years': 0, 'pg_2_years': 750, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 3224, 'ug_5_years': 0, 'pg_2_years': 750, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Found student section: PLACEMENT_STUDIES\n","\n","=== DEBUGGING SECTION: PLACEMENT_STUDIES ===\n","Section length: 588 characters\n","Relevant lines found:\n","  Line 1: PG [2 Years Program(s)]: Placement & higher studies for previous 3 years\n","\n","PG Programs (2-Year/3-Year/Integrated/PG-Integrated) analysis:\n","  Line 1: PG [2 Years Program(s)]: Placement & higher studies for previous 3 years\n","  Line 2:   -> Academic Year\n","  Line 3:   -> No. of first year\n","==================================================\n","    Analyzing content length: 588 characters\n","    Sample content preview: PG [2 Years Program(s)]: Placement & higher studies for previous 3 years\n","Academic Year\n","No. of first year\n","students intake in the\n","year\n","No. of first year\n","students admitted in\n","the year\n","Academic Year\n","No. o...\n","    No valid values found for ug_4_years\n","    No valid values found for ug_5_years\n","    Pattern 5 for pg_2_years found SINGLE: 3\n","    Pattern 6 for pg_2_years found SINGLE: 3\n","    Final pg_2_years: 3 students (from values: [3, 3])\n","    No valid values found for pg_3_years\n","    No valid values found for pg_integrated\n","    Some PG programs not found with primary patterns, trying line-by-line analysis...\n","    Calculated total students: 3\n","  Accumulated student data so far: {'ug_4_years': 3224, 'ug_5_years': 0, 'pg_2_years': 750, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 3224, 'ug_5_years': 0, 'pg_2_years': 750, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 3224, 'ug_5_years': 0, 'pg_2_years': 750, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 3224, 'ug_5_years': 0, 'pg_2_years': 750, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 3224, 'ug_5_years': 0, 'pg_2_years': 750, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Found student section: PHD_DETAILS\n","\n","=== DEBUGGING SECTION: PHD_DETAILS ===\n","Section length: 238 characters\n","Relevant lines found:\n","  Line 2: Ph.D (Student pursuing doctoral program till 2022-23)\n","\n","No PG program indicators found\n","==================================================\n","    Analyzing content length: 238 characters\n","    Sample content preview: Ph.D Student Details\n","Ph.D (Student pursuing doctoral program till 2022-23)\n","Total Students\n","Full Time\n","576\n","Part Time\n","253\n","No. of Ph.D students graduated (including Integrated Ph.D)\n","2022-23\n","2021-22\n","2020-21...\n","    No valid values found for ug_4_years\n","    No valid values found for ug_5_years\n","    No valid values found for pg_2_years\n","    No valid values found for pg_3_years\n","    No valid values found for pg_integrated\n","    Some PG programs not found with primary patterns, trying line-by-line analysis...\n","  Accumulated student data so far: {'ug_4_years': 3224, 'ug_5_years': 0, 'pg_2_years': 750, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 3224, 'ug_5_years': 0, 'pg_2_years': 750, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 3224, 'ug_5_years': 0, 'pg_2_years': 750, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 3224, 'ug_5_years': 0, 'pg_2_years': 750, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 3224, 'ug_5_years': 0, 'pg_2_years': 750, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Found student section: PCS_FACILITIES\n","\n","=== DEBUGGING SECTION: PCS_FACILITIES ===\n","Section length: 430 characters\n","No obvious table structure found\n","\n","First 10 non-empty lines:\n","  1: PCS Facilities: Facilities of Physically Challenged Students\n","  2: 1. Do your institution buildings have Lifts/Ramps?\n","  3: Yes, more than 80% of the buildings\n","  4: 2. Do your institution have provision for walking aids, including wheelchairs and transportation from one building to another for\n","  5: handicapped students?\n","  6: Yes\n","  7: 3. Do your institution buildings have specially designed toilets for handicapped students?\n","  8: Yes, more than 80% of the buildings\n","\n","No PG program indicators found\n","==================================================\n","    Analyzing content length: 430 characters\n","    Sample content preview: PCS Facilities: Facilities of Physically Challenged Students\n","1. Do your institution buildings have Lifts/Ramps?\n","Yes, more than 80% of the buildings\n","2. Do your institution have provision for walking ai...\n","    No valid values found for ug_4_years\n","    No valid values found for ug_5_years\n","    No valid values found for pg_2_years\n","    No valid values found for pg_3_years\n","    No valid values found for pg_integrated\n","    Some PG programs not found with primary patterns, trying line-by-line analysis...\n","  Accumulated student data so far: {'ug_4_years': 3224, 'ug_5_years': 0, 'pg_2_years': 750, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 3224, 'ug_5_years': 0, 'pg_2_years': 750, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 3224, 'ug_5_years': 0, 'pg_2_years': 750, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 3224, 'ug_5_years': 0, 'pg_2_years': 750, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 3224, 'ug_5_years': 0, 'pg_2_years': 750, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Processing faculty section: FACULTY_DETAILS\n","\n","=== DEBUGGING SECTION: FACULTY_DETAILS ===\n","Section length: 37 characters\n","No obvious table structure found\n","\n","First 10 non-empty lines:\n","  1: Number of faculty members entered\n","  2: 277\n","\n","No PG program indicators found\n","==================================================\n","   Looking for pattern: INDEX -> Name...\n","    No valid index->name patterns found\n","  No faculty found in 'FACULTY_DETAILS', processing as normal content.\n","  Creating consolidated student strength point: {'ug_4_years': 3224, 'ug_5_years': 0, 'pg_2_years': 750, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 3974}\n","Created 12 points for Malaviya National Institute of Technology\n","Saved 12 points to Malaviya National Institute of Technology.json (normalized)\n","  Created 12 points\n","\n","Processing file: Shoolini University of Biotechnology and Management Science.txt\n","Processing: Shoolini University of Biotechnology and Management Sciences (IR-E-U-0190)\n","  Found student section: SANCTIONED_INTAKE\n","\n","=== DEBUGGING SECTION: SANCTIONED_INTAKE ===\n","Section length: 171 characters\n","Relevant lines found:\n","  Line 9: UG [4 Years Program(s)]\n","  Line 16: PG [2 Year Program(s)]\n","\n","PG Programs (2-Year/3-Year/Integrated/PG-Integrated) analysis:\n","  Line 16: PG [2 Year Program(s)]\n","  Line 17:   -> 35\n","  Line 18:   -> 35\n","==================================================\n","    Analyzing content length: 171 characters\n","    Sample content preview: Sanctioned (Approved) Intake\n","Academic Year\n","2022-23\n","2021-22\n","2020-21\n","2019-20\n","2018-19\n","2017-18\n","UG [4 Years Program(s)]\n","240\n","190\n","265\n","240\n","-\n","-\n","PG [2 Year Program(s)]\n","35\n","35\n","-\n","-\n","-\n","-...\n","    Pattern 1 for ug_4_years found TUPLE: Male=240, Female=190, Total=265\n","    Pattern 2 for ug_4_years found TUPLE: Male=240, Female=190, Total=265\n","    Pattern 3 for ug_4_years found TUPLE: Male=240, Female=190, Total=265\n","    Pattern 4 for ug_4_years found SINGLE: 240\n","    Final ug_4_years: 265 students (from values: [265, 265, 265, 240])\n","    No valid values found for ug_5_years\n","    Pattern 5 for pg_2_years found SINGLE: 35\n","    Pattern 6 for pg_2_years found SINGLE: 35\n","    Final pg_2_years: 35 students (from values: [35, 35])\n","    No valid values found for pg_3_years\n","    No valid values found for pg_integrated\n","    Some PG programs not found with primary patterns, trying line-by-line analysis...\n","    Calculated total students: 300\n","  Accumulated student data so far: {'ug_4_years': 265, 'ug_5_years': 0, 'pg_2_years': 0, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 265, 'ug_5_years': 0, 'pg_2_years': 0, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 265, 'ug_5_years': 0, 'pg_2_years': 35, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 265, 'ug_5_years': 0, 'pg_2_years': 35, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 265, 'ug_5_years': 0, 'pg_2_years': 35, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Found student section: STUDENT_STRENGTH\n","\n","=== DEBUGGING SECTION: STUDENT_STRENGTH ===\n","Section length: 826 characters\n","Relevant lines found:\n","  Line 1: Total Actual Student Strength (Program(s) Offered by your Institution)\n","  Line 2: (All programs\n","  Line 3: of all years)\n","  Line 52: UG [4 Years\n","  Line 53: Program(s)]\n","  Line 66: PG [2 Year\n","  Line 67: Program(s)]\n","\n","PG Programs (2-Year/3-Year/Integrated/PG-Integrated) analysis:\n","  Line 66: PG [2 Year\n","  Line 67:   -> Program(s)]\n","  Line 68:   -> 29\n","==================================================\n","    Analyzing content length: 826 characters\n","    Sample content preview: Total Actual Student Strength (Program(s) Offered by your Institution)\n","(All programs\n","of all years)\n","No. of Male\n","Students\n","No. of Female\n","Students\n","Total Students\n","Within State\n","(Including male\n","& female)\n","Out...\n","    Pattern 1 for ug_4_years found TUPLE: Male=399, Female=484, Total=883\n","    Pattern 2 for ug_4_years found TUPLE: Male=399, Female=484, Total=883\n","    Pattern 3 for ug_4_years found TUPLE: Male=399, Female=484, Total=883\n","    Pattern 4 for ug_4_years found SINGLE: 399\n","    Final ug_4_years: 883 students (from values: [883, 883, 883, 399])\n","    No valid values found for ug_5_years\n","    Pattern 1 for pg_2_years found TUPLE: Male=29, Female=32, Total=61\n","    Pattern 2 for pg_2_years found TUPLE: Male=29, Female=32, Total=61\n","    Pattern 3 for pg_2_years found TUPLE: Male=29, Female=32, Total=61\n","    Pattern 4 for pg_2_years found TUPLE: Male=29, Female=32, Total=61\n","    Pattern 5 for pg_2_years found SINGLE: 29\n","    Pattern 6 for pg_2_years found SINGLE: 29\n","    Final pg_2_years: 61 students (from values: [61, 61, 61, 61, 29, 29])\n","    No valid values found for pg_3_years\n","    No valid values found for pg_integrated\n","    Some PG programs not found with primary patterns, trying line-by-line analysis...\n","    Calculated total students: 944\n","  Accumulated student data so far: {'ug_4_years': 883, 'ug_5_years': 0, 'pg_2_years': 35, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 883, 'ug_5_years': 0, 'pg_2_years': 35, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 883, 'ug_5_years': 0, 'pg_2_years': 61, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 883, 'ug_5_years': 0, 'pg_2_years': 61, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 883, 'ug_5_years': 0, 'pg_2_years': 61, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Found student section: PLACEMENT_STUDIES\n","\n","=== DEBUGGING SECTION: PLACEMENT_STUDIES ===\n","Section length: 561 characters\n","Relevant lines found:\n","  Line 1: PG [2 Years Program(s)]: Placement & higher studies for previous 3 years\n","\n","PG Programs (2-Year/3-Year/Integrated/PG-Integrated) analysis:\n","  Line 1: PG [2 Years Program(s)]: Placement & higher studies for previous 3 years\n","  Line 2:   -> Academic Year\n","  Line 3:   -> No. of first year\n","==================================================\n","    Analyzing content length: 561 characters\n","    Sample content preview: PG [2 Years Program(s)]: Placement & higher studies for previous 3 years\n","Academic Year\n","No. of first year\n","students intake in the\n","year\n","No. of first year\n","students admitted in\n","the year\n","Academic Year\n","No. o...\n","    No valid values found for ug_4_years\n","    No valid values found for ug_5_years\n","    Pattern 5 for pg_2_years found SINGLE: 3\n","    Pattern 6 for pg_2_years found SINGLE: 3\n","    Final pg_2_years: 3 students (from values: [3, 3])\n","    No valid values found for pg_3_years\n","    No valid values found for pg_integrated\n","    Some PG programs not found with primary patterns, trying line-by-line analysis...\n","    Calculated total students: 3\n","  Accumulated student data so far: {'ug_4_years': 883, 'ug_5_years': 0, 'pg_2_years': 61, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 883, 'ug_5_years': 0, 'pg_2_years': 61, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 883, 'ug_5_years': 0, 'pg_2_years': 61, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 883, 'ug_5_years': 0, 'pg_2_years': 61, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 883, 'ug_5_years': 0, 'pg_2_years': 61, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Found student section: PHD_DETAILS\n","\n","=== DEBUGGING SECTION: PHD_DETAILS ===\n","Section length: 233 characters\n","Relevant lines found:\n","  Line 2: Ph.D (Student pursuing doctoral program till 2022-23)\n","\n","No PG program indicators found\n","==================================================\n","    Analyzing content length: 233 characters\n","    Sample content preview: Ph.D Student Details\n","Ph.D (Student pursuing doctoral program till 2022-23)\n","Total Students\n","Full Time\n","102\n","Part Time\n","0\n","No. of Ph.D students graduated (including Integrated Ph.D)\n","2022-23\n","2021-22\n","2020-21\n","F...\n","    No valid values found for ug_4_years\n","    No valid values found for ug_5_years\n","    No valid values found for pg_2_years\n","    No valid values found for pg_3_years\n","    No valid values found for pg_integrated\n","    Some PG programs not found with primary patterns, trying line-by-line analysis...\n","  Accumulated student data so far: {'ug_4_years': 883, 'ug_5_years': 0, 'pg_2_years': 61, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 883, 'ug_5_years': 0, 'pg_2_years': 61, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 883, 'ug_5_years': 0, 'pg_2_years': 61, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 883, 'ug_5_years': 0, 'pg_2_years': 61, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 883, 'ug_5_years': 0, 'pg_2_years': 61, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Found student section: PCS_FACILITIES\n","\n","=== DEBUGGING SECTION: PCS_FACILITIES ===\n","Section length: 430 characters\n","No obvious table structure found\n","\n","First 10 non-empty lines:\n","  1: PCS Facilities: Facilities of Physically Challenged Students\n","  2: 1. Do your institution buildings have Lifts/Ramps?\n","  3: Yes, more than 80% of the buildings\n","  4: 2. Do your institution have provision for walking aids, including wheelchairs and transportation from one building to another for\n","  5: handicapped students?\n","  6: Yes\n","  7: 3. Do your institution buildings have specially designed toilets for handicapped students?\n","  8: Yes, more than 80% of the buildings\n","\n","No PG program indicators found\n","==================================================\n","    Analyzing content length: 430 characters\n","    Sample content preview: PCS Facilities: Facilities of Physically Challenged Students\n","1. Do your institution buildings have Lifts/Ramps?\n","Yes, more than 80% of the buildings\n","2. Do your institution have provision for walking ai...\n","    No valid values found for ug_4_years\n","    No valid values found for ug_5_years\n","    No valid values found for pg_2_years\n","    No valid values found for pg_3_years\n","    No valid values found for pg_integrated\n","    Some PG programs not found with primary patterns, trying line-by-line analysis...\n","  Accumulated student data so far: {'ug_4_years': 883, 'ug_5_years': 0, 'pg_2_years': 61, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 883, 'ug_5_years': 0, 'pg_2_years': 61, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 883, 'ug_5_years': 0, 'pg_2_years': 61, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 883, 'ug_5_years': 0, 'pg_2_years': 61, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 883, 'ug_5_years': 0, 'pg_2_years': 61, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Processing faculty section: FACULTY_DETAILS\n","\n","=== DEBUGGING SECTION: FACULTY_DETAILS ===\n","Section length: 36 characters\n","No obvious table structure found\n","\n","First 10 non-empty lines:\n","  1: Number of faculty members entered\n","  2: 68\n","\n","No PG program indicators found\n","==================================================\n","   Looking for pattern: INDEX -> Name...\n","    No valid index->name patterns found\n","  No faculty found in 'FACULTY_DETAILS', processing as normal content.\n","  Creating consolidated student strength point: {'ug_4_years': 883, 'ug_5_years': 0, 'pg_2_years': 61, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 944}\n","Created 11 points for Shoolini University of Biotechnology and Management Sciences\n","Saved 11 points to Shoolini University of Biotechnology and Management Science.json (normalized)\n","  Created 11 points\n","\n","Processing file: IIT Palakkad.txt\n","Processing: Indian Institute of Technology Palakkad (IR-E-U-0878)\n","  Found student section: SANCTIONED_INTAKE\n","\n","=== DEBUGGING SECTION: SANCTIONED_INTAKE ===\n","Section length: 173 characters\n","Relevant lines found:\n","  Line 9: UG [4 Years Program(s)]\n","  Line 16: PG [2 Year Program(s)]\n","\n","PG Programs (2-Year/3-Year/Integrated/PG-Integrated) analysis:\n","  Line 16: PG [2 Year Program(s)]\n","  Line 17:   -> 120\n","  Line 18:   -> 107\n","==================================================\n","    Analyzing content length: 173 characters\n","    Sample content preview: Sanctioned (Approved) Intake\n","Academic Year\n","2022-23\n","2021-22\n","2020-21\n","2019-20\n","2018-19\n","2017-18\n","UG [4 Years Program(s)]\n","180\n","169\n","188\n","181\n","-\n","-\n","PG [2 Year Program(s)]\n","120\n","107\n","-\n","-\n","-\n","-...\n","    Pattern 1 for ug_4_years found TUPLE: Male=180, Female=169, Total=188\n","    Pattern 2 for ug_4_years found TUPLE: Male=180, Female=169, Total=188\n","    Pattern 3 for ug_4_years found TUPLE: Male=180, Female=169, Total=188\n","    Pattern 4 for ug_4_years found SINGLE: 180\n","    Final ug_4_years: 188 students (from values: [188, 188, 188, 180])\n","    No valid values found for ug_5_years\n","    Pattern 5 for pg_2_years found SINGLE: 120\n","    Pattern 6 for pg_2_years found SINGLE: 120\n","    Final pg_2_years: 120 students (from values: [120, 120])\n","    No valid values found for pg_3_years\n","    No valid values found for pg_integrated\n","    Some PG programs not found with primary patterns, trying line-by-line analysis...\n","    Calculated total students: 308\n","  Accumulated student data so far: {'ug_4_years': 188, 'ug_5_years': 0, 'pg_2_years': 0, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 188, 'ug_5_years': 0, 'pg_2_years': 0, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 188, 'ug_5_years': 0, 'pg_2_years': 120, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 188, 'ug_5_years': 0, 'pg_2_years': 120, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 188, 'ug_5_years': 0, 'pg_2_years': 120, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Found student section: STUDENT_STRENGTH\n","\n","=== DEBUGGING SECTION: STUDENT_STRENGTH ===\n","Section length: 831 characters\n","Relevant lines found:\n","  Line 1: Total Actual Student Strength (Program(s) Offered by your Institution)\n","  Line 2: (All programs\n","  Line 3: of all years)\n","  Line 52: UG [4 Years\n","  Line 53: Program(s)]\n","  Line 66: PG [2 Year\n","  Line 67: Program(s)]\n","\n","PG Programs (2-Year/3-Year/Integrated/PG-Integrated) analysis:\n","  Line 66: PG [2 Year\n","  Line 67:   -> Program(s)]\n","  Line 68:   -> 133\n","==================================================\n","    Analyzing content length: 831 characters\n","    Sample content preview: Total Actual Student Strength (Program(s) Offered by your Institution)\n","(All programs\n","of all years)\n","No. of Male\n","Students\n","No. of Female\n","Students\n","Total Students\n","Within State\n","(Including male\n","& female)\n","Out...\n","    Pattern 1 for ug_4_years found TUPLE: Male=500, Female=139, Total=639\n","    Pattern 2 for ug_4_years found TUPLE: Male=500, Female=139, Total=639\n","    Pattern 3 for ug_4_years found TUPLE: Male=500, Female=139, Total=639\n","    Pattern 4 for ug_4_years found SINGLE: 500\n","    Final ug_4_years: 639 students (from values: [639, 639, 639, 500])\n","    No valid values found for ug_5_years\n","    Pattern 1 for pg_2_years found TUPLE: Male=133, Female=43, Total=176\n","    Pattern 2 for pg_2_years found TUPLE: Male=133, Female=43, Total=176\n","    Pattern 3 for pg_2_years found TUPLE: Male=133, Female=43, Total=176\n","    Pattern 4 for pg_2_years found TUPLE: Male=133, Female=43, Total=176\n","    Pattern 5 for pg_2_years found SINGLE: 133\n","    Pattern 6 for pg_2_years found SINGLE: 133\n","    Final pg_2_years: 176 students (from values: [176, 176, 176, 176, 133, 133])\n","    No valid values found for pg_3_years\n","    No valid values found for pg_integrated\n","    Some PG programs not found with primary patterns, trying line-by-line analysis...\n","    Calculated total students: 815\n","  Accumulated student data so far: {'ug_4_years': 639, 'ug_5_years': 0, 'pg_2_years': 120, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 639, 'ug_5_years': 0, 'pg_2_years': 120, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 639, 'ug_5_years': 0, 'pg_2_years': 176, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 639, 'ug_5_years': 0, 'pg_2_years': 176, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 639, 'ug_5_years': 0, 'pg_2_years': 176, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Found student section: PLACEMENT_STUDIES\n","\n","=== DEBUGGING SECTION: PLACEMENT_STUDIES ===\n","Section length: 564 characters\n","Relevant lines found:\n","  Line 1: PG [2 Years Program(s)]: Placement & higher studies for previous 3 years\n","\n","PG Programs (2-Year/3-Year/Integrated/PG-Integrated) analysis:\n","  Line 1: PG [2 Years Program(s)]: Placement & higher studies for previous 3 years\n","  Line 2:   -> Academic Year\n","  Line 3:   -> No. of first year\n","==================================================\n","    Analyzing content length: 564 characters\n","    Sample content preview: PG [2 Years Program(s)]: Placement & higher studies for previous 3 years\n","Academic Year\n","No. of first year\n","students intake in the\n","year\n","No. of first year\n","students admitted in\n","the year\n","Academic Year\n","No. o...\n","    No valid values found for ug_4_years\n","    No valid values found for ug_5_years\n","    Pattern 5 for pg_2_years found SINGLE: 3\n","    Pattern 6 for pg_2_years found SINGLE: 3\n","    Final pg_2_years: 3 students (from values: [3, 3])\n","    No valid values found for pg_3_years\n","    No valid values found for pg_integrated\n","    Some PG programs not found with primary patterns, trying line-by-line analysis...\n","    Calculated total students: 3\n","  Accumulated student data so far: {'ug_4_years': 639, 'ug_5_years': 0, 'pg_2_years': 176, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 639, 'ug_5_years': 0, 'pg_2_years': 176, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 639, 'ug_5_years': 0, 'pg_2_years': 176, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 639, 'ug_5_years': 0, 'pg_2_years': 176, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 639, 'ug_5_years': 0, 'pg_2_years': 176, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Found student section: PHD_DETAILS\n","\n","=== DEBUGGING SECTION: PHD_DETAILS ===\n","Section length: 232 characters\n","Relevant lines found:\n","  Line 2: Ph.D (Student pursuing doctoral program till 2022-23)\n","\n","No PG program indicators found\n","==================================================\n","    Analyzing content length: 232 characters\n","    Sample content preview: Ph.D Student Details\n","Ph.D (Student pursuing doctoral program till 2022-23)\n","Total Students\n","Full Time\n","138\n","Part Time\n","19\n","No. of Ph.D students graduated (including Integrated Ph.D)\n","2022-23\n","2021-22\n","2020-21\n","...\n","    No valid values found for ug_4_years\n","    No valid values found for ug_5_years\n","    No valid values found for pg_2_years\n","    No valid values found for pg_3_years\n","    No valid values found for pg_integrated\n","    Some PG programs not found with primary patterns, trying line-by-line analysis...\n","  Accumulated student data so far: {'ug_4_years': 639, 'ug_5_years': 0, 'pg_2_years': 176, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 639, 'ug_5_years': 0, 'pg_2_years': 176, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 639, 'ug_5_years': 0, 'pg_2_years': 176, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 639, 'ug_5_years': 0, 'pg_2_years': 176, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 639, 'ug_5_years': 0, 'pg_2_years': 176, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Found student section: PCS_FACILITIES\n","\n","=== DEBUGGING SECTION: PCS_FACILITIES ===\n","Section length: 430 characters\n","No obvious table structure found\n","\n","First 10 non-empty lines:\n","  1: PCS Facilities: Facilities of Physically Challenged Students\n","  2: 1. Do your institution buildings have Lifts/Ramps?\n","  3: Yes, more than 80% of the buildings\n","  4: 2. Do your institution have provision for walking aids, including wheelchairs and transportation from one building to another for\n","  5: handicapped students?\n","  6: Yes\n","  7: 3. Do your institution buildings have specially designed toilets for handicapped students?\n","  8: Yes, more than 80% of the buildings\n","\n","No PG program indicators found\n","==================================================\n","    Analyzing content length: 430 characters\n","    Sample content preview: PCS Facilities: Facilities of Physically Challenged Students\n","1. Do your institution buildings have Lifts/Ramps?\n","Yes, more than 80% of the buildings\n","2. Do your institution have provision for walking ai...\n","    No valid values found for ug_4_years\n","    No valid values found for ug_5_years\n","    No valid values found for pg_2_years\n","    No valid values found for pg_3_years\n","    No valid values found for pg_integrated\n","    Some PG programs not found with primary patterns, trying line-by-line analysis...\n","  Accumulated student data so far: {'ug_4_years': 639, 'ug_5_years': 0, 'pg_2_years': 176, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 639, 'ug_5_years': 0, 'pg_2_years': 176, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 639, 'ug_5_years': 0, 'pg_2_years': 176, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 639, 'ug_5_years': 0, 'pg_2_years': 176, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 639, 'ug_5_years': 0, 'pg_2_years': 176, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Processing faculty section: FACULTY_DETAILS\n","\n","=== DEBUGGING SECTION: FACULTY_DETAILS ===\n","Section length: 37 characters\n","No obvious table structure found\n","\n","First 10 non-empty lines:\n","  1: Number of faculty members entered\n","  2: 127\n","\n","No PG program indicators found\n","==================================================\n","   Looking for pattern: INDEX -> Name...\n","    No valid index->name patterns found\n","  No faculty found in 'FACULTY_DETAILS', processing as normal content.\n","  Creating consolidated student strength point: {'ug_4_years': 639, 'ug_5_years': 0, 'pg_2_years': 176, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 815}\n","Created 12 points for Indian Institute of Technology Palakkad\n","Saved 12 points to IIT Palakkad.json (normalized)\n","  Created 12 points\n","\n","Processing file: Motilal Nehru National Institute of Technology.txt\n","Processing: Motilal Nehru National Institute of Technology (IR-E-U-0530)\n","  Found student section: SANCTIONED_INTAKE\n","\n","=== DEBUGGING SECTION: SANCTIONED_INTAKE ===\n","Section length: 177 characters\n","Relevant lines found:\n","  Line 9: UG [4 Years Program(s)]\n","  Line 16: PG [2 Year Program(s)]\n","\n","PG Programs (2-Year/3-Year/Integrated/PG-Integrated) analysis:\n","  Line 16: PG [2 Year Program(s)]\n","  Line 17:   -> 595\n","  Line 18:   -> 595\n","==================================================\n","    Analyzing content length: 177 characters\n","    Sample content preview: Sanctioned (Approved) Intake\n","Academic Year\n","2022-23\n","2021-22\n","2020-21\n","2019-20\n","2018-19\n","2017-18\n","UG [4 Years Program(s)]\n","1074\n","1074\n","1074\n","1006\n","-\n","-\n","PG [2 Year Program(s)]\n","595\n","595\n","-\n","-\n","-\n","-...\n","    Pattern 1 for ug_4_years found TUPLE: Male=1074, Female=1074, Total=1074\n","    Pattern 2 for ug_4_years found TUPLE: Male=1074, Female=1074, Total=1074\n","    Pattern 3 for ug_4_years found TUPLE: Male=1074, Female=1074, Total=1074\n","    Pattern 4 for ug_4_years found SINGLE: 1074\n","    Final ug_4_years: 1074 students (from values: [1074, 1074, 1074, 1074])\n","    No valid values found for ug_5_years\n","    Pattern 5 for pg_2_years found SINGLE: 595\n","    Pattern 6 for pg_2_years found SINGLE: 595\n","    Final pg_2_years: 595 students (from values: [595, 595])\n","    No valid values found for pg_3_years\n","    No valid values found for pg_integrated\n","    Some PG programs not found with primary patterns, trying line-by-line analysis...\n","    Calculated total students: 1669\n","  Accumulated student data so far: {'ug_4_years': 1074, 'ug_5_years': 0, 'pg_2_years': 0, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 1074, 'ug_5_years': 0, 'pg_2_years': 0, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 1074, 'ug_5_years': 0, 'pg_2_years': 595, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 1074, 'ug_5_years': 0, 'pg_2_years': 595, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 1074, 'ug_5_years': 0, 'pg_2_years': 595, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Found student section: STUDENT_STRENGTH\n","\n","=== DEBUGGING SECTION: STUDENT_STRENGTH ===\n","Section length: 846 characters\n","Relevant lines found:\n","  Line 1: Total Actual Student Strength (Program(s) Offered by your Institution)\n","  Line 2: (All programs\n","  Line 3: of all years)\n","  Line 52: UG [4 Years\n","  Line 53: Program(s)]\n","  Line 66: PG [2 Year\n","  Line 67: Program(s)]\n","\n","PG Programs (2-Year/3-Year/Integrated/PG-Integrated) analysis:\n","  Line 66: PG [2 Year\n","  Line 67:   -> Program(s)]\n","  Line 68:   -> 683\n","==================================================\n","    Analyzing content length: 846 characters\n","    Sample content preview: Total Actual Student Strength (Program(s) Offered by your Institution)\n","(All programs\n","of all years)\n","No. of Male\n","Students\n","No. of Female\n","Students\n","Total Students\n","Within State\n","(Including male\n","& female)\n","Out...\n","    Pattern 1 for ug_4_years found TUPLE: Male=3543, Female=841, Total=4384\n","    Pattern 2 for ug_4_years found TUPLE: Male=3543, Female=841, Total=4384\n","    Pattern 3 for ug_4_years found TUPLE: Male=3543, Female=841, Total=4384\n","    Pattern 4 for ug_4_years found SINGLE: 3543\n","    Final ug_4_years: 4384 students (from values: [4384, 4384, 4384, 3543])\n","    No valid values found for ug_5_years\n","    Pattern 1 for pg_2_years found TUPLE: Male=683, Female=156, Total=839\n","    Pattern 2 for pg_2_years found TUPLE: Male=683, Female=156, Total=839\n","    Pattern 3 for pg_2_years found TUPLE: Male=683, Female=156, Total=839\n","    Pattern 4 for pg_2_years found TUPLE: Male=683, Female=156, Total=839\n","    Pattern 5 for pg_2_years found SINGLE: 683\n","    Pattern 6 for pg_2_years found SINGLE: 683\n","    Final pg_2_years: 839 students (from values: [839, 839, 839, 839, 683, 683])\n","    No valid values found for pg_3_years\n","    No valid values found for pg_integrated\n","    Some PG programs not found with primary patterns, trying line-by-line analysis...\n","    Calculated total students: 5223\n","  Accumulated student data so far: {'ug_4_years': 4384, 'ug_5_years': 0, 'pg_2_years': 595, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 4384, 'ug_5_years': 0, 'pg_2_years': 595, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 4384, 'ug_5_years': 0, 'pg_2_years': 839, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 4384, 'ug_5_years': 0, 'pg_2_years': 839, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 4384, 'ug_5_years': 0, 'pg_2_years': 839, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Found student section: PLACEMENT_STUDIES\n","\n","=== DEBUGGING SECTION: PLACEMENT_STUDIES ===\n","Section length: 587 characters\n","Relevant lines found:\n","  Line 1: PG [2 Years Program(s)]: Placement & higher studies for previous 3 years\n","\n","PG Programs (2-Year/3-Year/Integrated/PG-Integrated) analysis:\n","  Line 1: PG [2 Years Program(s)]: Placement & higher studies for previous 3 years\n","  Line 2:   -> Academic Year\n","  Line 3:   -> No. of first year\n","==================================================\n","    Analyzing content length: 587 characters\n","    Sample content preview: PG [2 Years Program(s)]: Placement & higher studies for previous 3 years\n","Academic Year\n","No. of first year\n","students intake in the\n","year\n","No. of first year\n","students admitted in\n","the year\n","Academic Year\n","No. o...\n","    No valid values found for ug_4_years\n","    No valid values found for ug_5_years\n","    Pattern 5 for pg_2_years found SINGLE: 3\n","    Pattern 6 for pg_2_years found SINGLE: 3\n","    Final pg_2_years: 3 students (from values: [3, 3])\n","    No valid values found for pg_3_years\n","    No valid values found for pg_integrated\n","    Some PG programs not found with primary patterns, trying line-by-line analysis...\n","    Calculated total students: 3\n","  Accumulated student data so far: {'ug_4_years': 4384, 'ug_5_years': 0, 'pg_2_years': 839, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 4384, 'ug_5_years': 0, 'pg_2_years': 839, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 4384, 'ug_5_years': 0, 'pg_2_years': 839, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 4384, 'ug_5_years': 0, 'pg_2_years': 839, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 4384, 'ug_5_years': 0, 'pg_2_years': 839, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Found student section: PHD_DETAILS\n","\n","=== DEBUGGING SECTION: PHD_DETAILS ===\n","Section length: 238 characters\n","Relevant lines found:\n","  Line 2: Ph.D (Student pursuing doctoral program till 2022-23)\n","\n","No PG program indicators found\n","==================================================\n","    Analyzing content length: 238 characters\n","    Sample content preview: Ph.D Student Details\n","Ph.D (Student pursuing doctoral program till 2022-23)\n","Total Students\n","Full Time\n","469\n","Part Time\n","150\n","No. of Ph.D students graduated (including Integrated Ph.D)\n","2022-23\n","2021-22\n","2020-21...\n","    No valid values found for ug_4_years\n","    No valid values found for ug_5_years\n","    No valid values found for pg_2_years\n","    No valid values found for pg_3_years\n","    No valid values found for pg_integrated\n","    Some PG programs not found with primary patterns, trying line-by-line analysis...\n","  Accumulated student data so far: {'ug_4_years': 4384, 'ug_5_years': 0, 'pg_2_years': 839, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 4384, 'ug_5_years': 0, 'pg_2_years': 839, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 4384, 'ug_5_years': 0, 'pg_2_years': 839, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 4384, 'ug_5_years': 0, 'pg_2_years': 839, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 4384, 'ug_5_years': 0, 'pg_2_years': 839, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Found student section: PCS_FACILITIES\n","\n","=== DEBUGGING SECTION: PCS_FACILITIES ===\n","Section length: 430 characters\n","No obvious table structure found\n","\n","First 10 non-empty lines:\n","  1: PCS Facilities: Facilities of Physically Challenged Students\n","  2: 1. Do your institution buildings have Lifts/Ramps?\n","  3: Yes, more than 80% of the buildings\n","  4: 2. Do your institution have provision for walking aids, including wheelchairs and transportation from one building to another for\n","  5: handicapped students?\n","  6: Yes\n","  7: 3. Do your institution buildings have specially designed toilets for handicapped students?\n","  8: Yes, more than 80% of the buildings\n","\n","No PG program indicators found\n","==================================================\n","    Analyzing content length: 430 characters\n","    Sample content preview: PCS Facilities: Facilities of Physically Challenged Students\n","1. Do your institution buildings have Lifts/Ramps?\n","Yes, more than 80% of the buildings\n","2. Do your institution have provision for walking ai...\n","    No valid values found for ug_4_years\n","    No valid values found for ug_5_years\n","    No valid values found for pg_2_years\n","    No valid values found for pg_3_years\n","    No valid values found for pg_integrated\n","    Some PG programs not found with primary patterns, trying line-by-line analysis...\n","  Accumulated student data so far: {'ug_4_years': 4384, 'ug_5_years': 0, 'pg_2_years': 839, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 4384, 'ug_5_years': 0, 'pg_2_years': 839, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 4384, 'ug_5_years': 0, 'pg_2_years': 839, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 4384, 'ug_5_years': 0, 'pg_2_years': 839, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 4384, 'ug_5_years': 0, 'pg_2_years': 839, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Processing faculty section: FACULTY_DETAILS\n","\n","=== DEBUGGING SECTION: FACULTY_DETAILS ===\n","Section length: 37 characters\n","No obvious table structure found\n","\n","First 10 non-empty lines:\n","  1: Number of faculty members entered\n","  2: 280\n","\n","No PG program indicators found\n","==================================================\n","   Looking for pattern: INDEX -> Name...\n","    No valid index->name patterns found\n","  No faculty found in 'FACULTY_DETAILS', processing as normal content.\n","  Creating consolidated student strength point: {'ug_4_years': 4384, 'ug_5_years': 0, 'pg_2_years': 839, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 5223}\n","Created 12 points for Motilal Nehru National Institute of Technology\n","Saved 12 points to Motilal Nehru National Institute of Technology.json (normalized)\n","  Created 12 points\n","\n","Processing file: NIT Tiruchirappalli.txt\n","Processing: National Institute of Technology Tiruchirappalli (IR-E-U-0467)\n","  Found student section: SANCTIONED_INTAKE\n","\n","=== DEBUGGING SECTION: SANCTIONED_INTAKE ===\n","Section length: 173 characters\n","Relevant lines found:\n","  Line 9: UG [4 Years Program(s)]\n","  Line 16: PG [2 Year Program(s)]\n","\n","PG Programs (2-Year/3-Year/Integrated/PG-Integrated) analysis:\n","  Line 16: PG [2 Year Program(s)]\n","  Line 17:   -> 658\n","  Line 18:   -> 688\n","==================================================\n","    Analyzing content length: 173 characters\n","    Sample content preview: Sanctioned (Approved) Intake\n","Academic Year\n","2022-23\n","2021-22\n","2020-21\n","2019-20\n","2018-19\n","2017-18\n","UG [4 Years Program(s)]\n","964\n","964\n","964\n","964\n","-\n","-\n","PG [2 Year Program(s)]\n","658\n","688\n","-\n","-\n","-\n","-...\n","    Pattern 1 for ug_4_years found TUPLE: Male=964, Female=964, Total=964\n","    Pattern 2 for ug_4_years found TUPLE: Male=964, Female=964, Total=964\n","    Pattern 3 for ug_4_years found TUPLE: Male=964, Female=964, Total=964\n","    Pattern 4 for ug_4_years found SINGLE: 964\n","    Final ug_4_years: 964 students (from values: [964, 964, 964, 964])\n","    No valid values found for ug_5_years\n","    Pattern 5 for pg_2_years found SINGLE: 658\n","    Pattern 6 for pg_2_years found SINGLE: 658\n","    Final pg_2_years: 658 students (from values: [658, 658])\n","    No valid values found for pg_3_years\n","    No valid values found for pg_integrated\n","    Some PG programs not found with primary patterns, trying line-by-line analysis...\n","    Calculated total students: 1622\n","  Accumulated student data so far: {'ug_4_years': 964, 'ug_5_years': 0, 'pg_2_years': 0, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 964, 'ug_5_years': 0, 'pg_2_years': 0, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 964, 'ug_5_years': 0, 'pg_2_years': 658, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 964, 'ug_5_years': 0, 'pg_2_years': 658, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 964, 'ug_5_years': 0, 'pg_2_years': 658, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Found student section: STUDENT_STRENGTH\n","\n","=== DEBUGGING SECTION: STUDENT_STRENGTH ===\n","Section length: 848 characters\n","Relevant lines found:\n","  Line 1: Total Actual Student Strength (Program(s) Offered by your Institution)\n","  Line 2: (All programs\n","  Line 3: of all years)\n","  Line 52: UG [4 Years\n","  Line 53: Program(s)]\n","  Line 66: PG [2 Year\n","  Line 67: Program(s)]\n","\n","PG Programs (2-Year/3-Year/Integrated/PG-Integrated) analysis:\n","  Line 66: PG [2 Year\n","  Line 67:   -> Program(s)]\n","  Line 68:   -> 948\n","==================================================\n","    Analyzing content length: 848 characters\n","    Sample content preview: Total Actual Student Strength (Program(s) Offered by your Institution)\n","(All programs\n","of all years)\n","No. of Male\n","Students\n","No. of Female\n","Students\n","Total Students\n","Within State\n","(Including male\n","& female)\n","Out...\n","    Pattern 1 for ug_4_years found TUPLE: Male=3399, Female=905, Total=4304\n","    Pattern 2 for ug_4_years found TUPLE: Male=3399, Female=905, Total=4304\n","    Pattern 3 for ug_4_years found TUPLE: Male=3399, Female=905, Total=4304\n","    Pattern 4 for ug_4_years found SINGLE: 3399\n","    Final ug_4_years: 4304 students (from values: [4304, 4304, 4304, 3399])\n","    No valid values found for ug_5_years\n","    Pattern 1 for pg_2_years found TUPLE: Male=948, Female=159, Total=1107\n","    Pattern 2 for pg_2_years found TUPLE: Male=948, Female=159, Total=1107\n","    Pattern 3 for pg_2_years found TUPLE: Male=948, Female=159, Total=1107\n","    Pattern 4 for pg_2_years found TUPLE: Male=948, Female=159, Total=1107\n","    Pattern 5 for pg_2_years found SINGLE: 948\n","    Pattern 6 for pg_2_years found SINGLE: 948\n","    Final pg_2_years: 1107 students (from values: [1107, 1107, 1107, 1107, 948, 948])\n","    No valid values found for pg_3_years\n","    No valid values found for pg_integrated\n","    Some PG programs not found with primary patterns, trying line-by-line analysis...\n","    Calculated total students: 5411\n","  Accumulated student data so far: {'ug_4_years': 4304, 'ug_5_years': 0, 'pg_2_years': 658, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 4304, 'ug_5_years': 0, 'pg_2_years': 658, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 4304, 'ug_5_years': 0, 'pg_2_years': 1107, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 4304, 'ug_5_years': 0, 'pg_2_years': 1107, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 4304, 'ug_5_years': 0, 'pg_2_years': 1107, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Found student section: PLACEMENT_STUDIES\n","\n","=== DEBUGGING SECTION: PLACEMENT_STUDIES ===\n","Section length: 591 characters\n","Relevant lines found:\n","  Line 1: PG [2 Years Program(s)]: Placement & higher studies for previous 3 years\n","\n","PG Programs (2-Year/3-Year/Integrated/PG-Integrated) analysis:\n","  Line 1: PG [2 Years Program(s)]: Placement & higher studies for previous 3 years\n","  Line 2:   -> Academic Year\n","  Line 3:   -> No. of first year\n","==================================================\n","    Analyzing content length: 591 characters\n","    Sample content preview: PG [2 Years Program(s)]: Placement & higher studies for previous 3 years\n","Academic Year\n","No. of first year\n","students intake in the\n","year\n","No. of first year\n","students admitted in\n","the year\n","Academic Year\n","No. o...\n","    No valid values found for ug_4_years\n","    No valid values found for ug_5_years\n","    Pattern 5 for pg_2_years found SINGLE: 3\n","    Pattern 6 for pg_2_years found SINGLE: 3\n","    Final pg_2_years: 3 students (from values: [3, 3])\n","    No valid values found for pg_3_years\n","    No valid values found for pg_integrated\n","    Some PG programs not found with primary patterns, trying line-by-line analysis...\n","    Calculated total students: 3\n","  Accumulated student data so far: {'ug_4_years': 4304, 'ug_5_years': 0, 'pg_2_years': 1107, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 4304, 'ug_5_years': 0, 'pg_2_years': 1107, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 4304, 'ug_5_years': 0, 'pg_2_years': 1107, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 4304, 'ug_5_years': 0, 'pg_2_years': 1107, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 4304, 'ug_5_years': 0, 'pg_2_years': 1107, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Found student section: PHD_DETAILS\n","\n","=== DEBUGGING SECTION: PHD_DETAILS ===\n","Section length: 240 characters\n","Relevant lines found:\n","  Line 2: Ph.D (Student pursuing doctoral program till 2022-23)\n","\n","No PG program indicators found\n","==================================================\n","    Analyzing content length: 240 characters\n","    Sample content preview: Ph.D Student Details\n","Ph.D (Student pursuing doctoral program till 2022-23)\n","Total Students\n","Full Time\n","720\n","Part Time\n","236\n","No. of Ph.D students graduated (including Integrated Ph.D)\n","2022-23\n","2021-22\n","2020-21...\n","    No valid values found for ug_4_years\n","    No valid values found for ug_5_years\n","    No valid values found for pg_2_years\n","    No valid values found for pg_3_years\n","    No valid values found for pg_integrated\n","    Some PG programs not found with primary patterns, trying line-by-line analysis...\n","  Accumulated student data so far: {'ug_4_years': 4304, 'ug_5_years': 0, 'pg_2_years': 1107, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 4304, 'ug_5_years': 0, 'pg_2_years': 1107, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 4304, 'ug_5_years': 0, 'pg_2_years': 1107, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 4304, 'ug_5_years': 0, 'pg_2_years': 1107, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 4304, 'ug_5_years': 0, 'pg_2_years': 1107, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Found student section: PCS_FACILITIES\n","\n","=== DEBUGGING SECTION: PCS_FACILITIES ===\n","Section length: 430 characters\n","No obvious table structure found\n","\n","First 10 non-empty lines:\n","  1: PCS Facilities: Facilities of Physically Challenged Students\n","  2: 1. Do your institution buildings have Lifts/Ramps?\n","  3: Yes, more than 80% of the buildings\n","  4: 2. Do your institution have provision for walking aids, including wheelchairs and transportation from one building to another for\n","  5: handicapped students?\n","  6: Yes\n","  7: 3. Do your institution buildings have specially designed toilets for handicapped students?\n","  8: Yes, more than 80% of the buildings\n","\n","No PG program indicators found\n","==================================================\n","    Analyzing content length: 430 characters\n","    Sample content preview: PCS Facilities: Facilities of Physically Challenged Students\n","1. Do your institution buildings have Lifts/Ramps?\n","Yes, more than 80% of the buildings\n","2. Do your institution have provision for walking ai...\n","    No valid values found for ug_4_years\n","    No valid values found for ug_5_years\n","    No valid values found for pg_2_years\n","    No valid values found for pg_3_years\n","    No valid values found for pg_integrated\n","    Some PG programs not found with primary patterns, trying line-by-line analysis...\n","  Accumulated student data so far: {'ug_4_years': 4304, 'ug_5_years': 0, 'pg_2_years': 1107, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 4304, 'ug_5_years': 0, 'pg_2_years': 1107, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 4304, 'ug_5_years': 0, 'pg_2_years': 1107, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 4304, 'ug_5_years': 0, 'pg_2_years': 1107, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 4304, 'ug_5_years': 0, 'pg_2_years': 1107, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Processing faculty section: FACULTY_DETAILS\n","\n","=== DEBUGGING SECTION: FACULTY_DETAILS ===\n","Section length: 37 characters\n","No obvious table structure found\n","\n","First 10 non-empty lines:\n","  1: Number of faculty members entered\n","  2: 305\n","\n","No PG program indicators found\n","==================================================\n","   Looking for pattern: INDEX -> Name...\n","    No valid index->name patterns found\n","  No faculty found in 'FACULTY_DETAILS', processing as normal content.\n","  Creating consolidated student strength point: {'ug_4_years': 4304, 'ug_5_years': 0, 'pg_2_years': 1107, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 5411}\n","Created 12 points for National Institute of Technology Tiruchirappalli\n","Saved 12 points to NIT Tiruchirappalli.json (normalized)\n","  Created 12 points\n","\n","Processing file: University of Hyderabad.txt\n","Processing: University of Hyderabad (IR-E-U-0042)\n","  Found student section: SANCTIONED_INTAKE\n","\n","=== DEBUGGING SECTION: SANCTIONED_INTAKE ===\n","Section length: 160 characters\n","Relevant lines found:\n","  Line 9: PG [2 Year Program(s)]\n","\n","PG Programs (2-Year/3-Year/Integrated/PG-Integrated) analysis:\n","  Line 9: PG [2 Year Program(s)]\n","  Line 10:   -> 274\n","  Line 11:   -> 256\n","  Line 16: PG-Integrated\n","  Line 17:   -> 38\n","  Line 18:   -> 29\n","==================================================\n","    Analyzing content length: 160 characters\n","    Sample content preview: Sanctioned (Approved) Intake\n","Academic Year\n","2022-23\n","2021-22\n","2020-21\n","2019-20\n","2018-19\n","2017-18\n","PG [2 Year Program(s)]\n","274\n","256\n","-\n","-\n","-\n","-\n","PG-Integrated\n","38\n","29\n","30\n","21\n","21\n","-...\n","    No valid values found for ug_4_years\n","    No valid values found for ug_5_years\n","    Pattern 5 for pg_2_years found SINGLE: 274\n","    Pattern 6 for pg_2_years found SINGLE: 274\n","    Final pg_2_years: 274 students (from values: [274, 274])\n","    No valid values found for pg_3_years\n","    Pattern 4 for pg_integrated found TUPLE: Male=38, Female=29, Total=30\n","    Pattern 5 for pg_integrated found TUPLE: Male=38, Female=29, Total=30\n","    Pattern 6 for pg_integrated found TUPLE: Male=38, Female=29, Total=30\n","    Final pg_integrated: 30 students (from values: [30, 30, 30])\n","    Some PG programs not found with primary patterns, trying line-by-line analysis...\n","    Found PG Integrated line 15: PG-Integrated\n","    Calculated total students: 304\n","  Accumulated student data so far: {'ug_4_years': 0, 'ug_5_years': 0, 'pg_2_years': 0, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 0, 'ug_5_years': 0, 'pg_2_years': 0, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 0, 'ug_5_years': 0, 'pg_2_years': 274, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 0, 'ug_5_years': 0, 'pg_2_years': 274, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 0, 'ug_5_years': 0, 'pg_2_years': 274, 'pg_3_years': 0, 'pg_integrated': 30, 'total_students': 0}\n","  Found student section: STUDENT_STRENGTH\n","\n","=== DEBUGGING SECTION: STUDENT_STRENGTH ===\n","Section length: 814 characters\n","Relevant lines found:\n","  Line 1: Total Actual Student Strength (Program(s) Offered by your Institution)\n","  Line 2: (All programs\n","  Line 3: of all years)\n","  Line 52: PG [2 Year\n","  Line 53: Program(s)]\n","\n","PG Programs (2-Year/3-Year/Integrated/PG-Integrated) analysis:\n","  Line 52: PG [2 Year\n","  Line 53:   -> Program(s)]\n","  Line 54:   -> 103\n","  Line 66: PG-Integrated\n","  Line 67:   -> 112\n","  Line 68:   -> 28\n","==================================================\n","    Analyzing content length: 814 characters\n","    Sample content preview: Total Actual Student Strength (Program(s) Offered by your Institution)\n","(All programs\n","of all years)\n","No. of Male\n","Students\n","No. of Female\n","Students\n","Total Students\n","Within State\n","(Including male\n","& female)\n","Out...\n","    No valid values found for ug_4_years\n","    No valid values found for ug_5_years\n","    Pattern 1 for pg_2_years found TUPLE: Male=103, Female=80, Total=183\n","    Pattern 2 for pg_2_years found TUPLE: Male=103, Female=80, Total=183\n","    Pattern 3 for pg_2_years found TUPLE: Male=103, Female=80, Total=183\n","    Pattern 4 for pg_2_years found TUPLE: Male=103, Female=80, Total=183\n","    Pattern 5 for pg_2_years found SINGLE: 103\n","    Pattern 6 for pg_2_years found SINGLE: 103\n","    Final pg_2_years: 183 students (from values: [183, 183, 183, 183, 103, 103])\n","    No valid values found for pg_3_years\n","    Pattern 4 for pg_integrated found TUPLE: Male=112, Female=28, Total=140\n","    Pattern 5 for pg_integrated found TUPLE: Male=112, Female=28, Total=140\n","    Pattern 6 for pg_integrated found TUPLE: Male=112, Female=28, Total=140\n","    Final pg_integrated: 140 students (from values: [140, 140, 140])\n","    Some PG programs not found with primary patterns, trying line-by-line analysis...\n","    Found PG Integrated line 65: PG-Integrated\n","    Calculated total students: 323\n","  Accumulated student data so far: {'ug_4_years': 0, 'ug_5_years': 0, 'pg_2_years': 274, 'pg_3_years': 0, 'pg_integrated': 30, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 0, 'ug_5_years': 0, 'pg_2_years': 274, 'pg_3_years': 0, 'pg_integrated': 30, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 0, 'ug_5_years': 0, 'pg_2_years': 274, 'pg_3_years': 0, 'pg_integrated': 30, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 0, 'ug_5_years': 0, 'pg_2_years': 274, 'pg_3_years': 0, 'pg_integrated': 30, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 0, 'ug_5_years': 0, 'pg_2_years': 274, 'pg_3_years': 0, 'pg_integrated': 140, 'total_students': 0}\n","  Found student section: PLACEMENT_STUDIES\n","\n","=== DEBUGGING SECTION: PLACEMENT_STUDIES ===\n","Section length: 589 characters\n","Relevant lines found:\n","  Line 1: PG [2 Years Program(s)]: Placement & higher studies for previous 3 years\n","\n","PG Programs (2-Year/3-Year/Integrated/PG-Integrated) analysis:\n","  Line 1: PG [2 Years Program(s)]: Placement & higher studies for previous 3 years\n","  Line 2:   -> Academic Year\n","  Line 3:   -> No. of first year\n","==================================================\n","    Analyzing content length: 589 characters\n","    Sample content preview: PG [2 Years Program(s)]: Placement & higher studies for previous 3 years\n","Academic Year\n","No. of first year\n","students intake in the\n","year\n","No. of first year\n","students admitted in\n","the year\n","Academic Year\n","No. o...\n","    No valid values found for ug_4_years\n","    No valid values found for ug_5_years\n","    Pattern 5 for pg_2_years found SINGLE: 3\n","    Pattern 6 for pg_2_years found SINGLE: 3\n","    Final pg_2_years: 3 students (from values: [3, 3])\n","    No valid values found for pg_3_years\n","    No valid values found for pg_integrated\n","    Some PG programs not found with primary patterns, trying line-by-line analysis...\n","    Calculated total students: 3\n","  Accumulated student data so far: {'ug_4_years': 0, 'ug_5_years': 0, 'pg_2_years': 274, 'pg_3_years': 0, 'pg_integrated': 140, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 0, 'ug_5_years': 0, 'pg_2_years': 274, 'pg_3_years': 0, 'pg_integrated': 140, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 0, 'ug_5_years': 0, 'pg_2_years': 274, 'pg_3_years': 0, 'pg_integrated': 140, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 0, 'ug_5_years': 0, 'pg_2_years': 274, 'pg_3_years': 0, 'pg_integrated': 140, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 0, 'ug_5_years': 0, 'pg_2_years': 274, 'pg_3_years': 0, 'pg_integrated': 140, 'total_students': 0}\n","  Found student section: PG_PLACEMENT\n","\n","=== DEBUGGING SECTION: PG_PLACEMENT ===\n","Section length: 582 characters\n","Relevant lines found:\n","  Line 1: PG-Integrated [5 Years Program(s)]: Placement & higher studies for previous 3 years\n","\n","PG Programs (2-Year/3-Year/Integrated/PG-Integrated) analysis:\n","  Line 1: PG-Integrated [5 Years Program(s)]: Placement & higher studies for previous 3 years\n","  Line 2:   -> Academic Year\n","  Line 3:   -> No. of first year\n","==================================================\n","    Analyzing content length: 582 characters\n","    Sample content preview: PG-Integrated [5 Years Program(s)]: Placement & higher studies for previous 3 years\n","Academic Year\n","No. of first year\n","students intake in the\n","year\n","No. of first year\n","students admitted in\n","the year\n","Academic...\n","    No valid values found for ug_4_years\n","    No valid values found for ug_5_years\n","    No valid values found for pg_2_years\n","    No valid values found for pg_3_years\n","    No valid values found for pg_integrated\n","    Some PG programs not found with primary patterns, trying line-by-line analysis...\n","    Found PG Integrated line 0: PG-Integrated [5 Years Program(s)]: Placement & higher studies for previous 3 years\n","  Accumulated student data so far: {'ug_4_years': 0, 'ug_5_years': 0, 'pg_2_years': 274, 'pg_3_years': 0, 'pg_integrated': 140, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 0, 'ug_5_years': 0, 'pg_2_years': 274, 'pg_3_years': 0, 'pg_integrated': 140, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 0, 'ug_5_years': 0, 'pg_2_years': 274, 'pg_3_years': 0, 'pg_integrated': 140, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 0, 'ug_5_years': 0, 'pg_2_years': 274, 'pg_3_years': 0, 'pg_integrated': 140, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 0, 'ug_5_years': 0, 'pg_2_years': 274, 'pg_3_years': 0, 'pg_integrated': 140, 'total_students': 0}\n","  Found student section: PHD_DETAILS\n","\n","=== DEBUGGING SECTION: PHD_DETAILS ===\n","Section length: 234 characters\n","Relevant lines found:\n","  Line 2: Ph.D (Student pursuing doctoral program till 2022-23)\n","\n","No PG program indicators found\n","==================================================\n","    Analyzing content length: 234 characters\n","    Sample content preview: Ph.D Student Details\n","Ph.D (Student pursuing doctoral program till 2022-23)\n","Total Students\n","Full Time\n","190\n","Part Time\n","11\n","No. of Ph.D students graduated (including Integrated Ph.D)\n","2022-23\n","2021-22\n","2020-21\n","...\n","    No valid values found for ug_4_years\n","    No valid values found for ug_5_years\n","    No valid values found for pg_2_years\n","    No valid values found for pg_3_years\n","    No valid values found for pg_integrated\n","    Some PG programs not found with primary patterns, trying line-by-line analysis...\n","  Accumulated student data so far: {'ug_4_years': 0, 'ug_5_years': 0, 'pg_2_years': 274, 'pg_3_years': 0, 'pg_integrated': 140, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 0, 'ug_5_years': 0, 'pg_2_years': 274, 'pg_3_years': 0, 'pg_integrated': 140, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 0, 'ug_5_years': 0, 'pg_2_years': 274, 'pg_3_years': 0, 'pg_integrated': 140, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 0, 'ug_5_years': 0, 'pg_2_years': 274, 'pg_3_years': 0, 'pg_integrated': 140, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 0, 'ug_5_years': 0, 'pg_2_years': 274, 'pg_3_years': 0, 'pg_integrated': 140, 'total_students': 0}\n","  Found student section: PCS_FACILITIES\n","\n","=== DEBUGGING SECTION: PCS_FACILITIES ===\n","Section length: 430 characters\n","No obvious table structure found\n","\n","First 10 non-empty lines:\n","  1: PCS Facilities: Facilities of Physically Challenged Students\n","  2: 1. Do your institution buildings have Lifts/Ramps?\n","  3: Yes, more than 80% of the buildings\n","  4: 2. Do your institution have provision for walking aids, including wheelchairs and transportation from one building to another for\n","  5: handicapped students?\n","  6: Yes\n","  7: 3. Do your institution buildings have specially designed toilets for handicapped students?\n","  8: Yes, more than 80% of the buildings\n","\n","No PG program indicators found\n","==================================================\n","    Analyzing content length: 430 characters\n","    Sample content preview: PCS Facilities: Facilities of Physically Challenged Students\n","1. Do your institution buildings have Lifts/Ramps?\n","Yes, more than 80% of the buildings\n","2. Do your institution have provision for walking ai...\n","    No valid values found for ug_4_years\n","    No valid values found for ug_5_years\n","    No valid values found for pg_2_years\n","    No valid values found for pg_3_years\n","    No valid values found for pg_integrated\n","    Some PG programs not found with primary patterns, trying line-by-line analysis...\n","  Accumulated student data so far: {'ug_4_years': 0, 'ug_5_years': 0, 'pg_2_years': 274, 'pg_3_years': 0, 'pg_integrated': 140, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 0, 'ug_5_years': 0, 'pg_2_years': 274, 'pg_3_years': 0, 'pg_integrated': 140, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 0, 'ug_5_years': 0, 'pg_2_years': 274, 'pg_3_years': 0, 'pg_integrated': 140, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 0, 'ug_5_years': 0, 'pg_2_years': 274, 'pg_3_years': 0, 'pg_integrated': 140, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 0, 'ug_5_years': 0, 'pg_2_years': 274, 'pg_3_years': 0, 'pg_integrated': 140, 'total_students': 0}\n","  Processing faculty section: FACULTY_DETAILS\n","\n","=== DEBUGGING SECTION: FACULTY_DETAILS ===\n","Section length: 36 characters\n","No obvious table structure found\n","\n","First 10 non-empty lines:\n","  1: Number of faculty members entered\n","  2: 55\n","\n","No PG program indicators found\n","==================================================\n","   Looking for pattern: INDEX -> Name...\n","    No valid index->name patterns found\n","  No faculty found in 'FACULTY_DETAILS', processing as normal content.\n","  Creating consolidated student strength point: {'ug_4_years': 0, 'ug_5_years': 0, 'pg_2_years': 274, 'pg_3_years': 0, 'pg_integrated': 140, 'total_students': 414}\n","Created 12 points for University of Hyderabad\n","Saved 12 points to University of Hyderabad.json (normalized)\n","  Created 12 points\n","\n","Processing file: C.V. Raman Global University_ Odisha.txt\n","Processing: C.V. Raman Global University, Odisha (IR-E-C-30045)\n","  Found student section: SANCTIONED_INTAKE\n","\n","=== DEBUGGING SECTION: SANCTIONED_INTAKE ===\n","Section length: 177 characters\n","Relevant lines found:\n","  Line 9: UG [4 Years Program(s)]\n","  Line 16: PG [2 Year Program(s)]\n","\n","PG Programs (2-Year/3-Year/Integrated/PG-Integrated) analysis:\n","  Line 16: PG [2 Year Program(s)]\n","  Line 17:   -> 132\n","  Line 18:   -> 114\n","==================================================\n","    Analyzing content length: 177 characters\n","    Sample content preview: Sanctioned (Approved) Intake\n","Academic Year\n","2022-23\n","2021-22\n","2020-21\n","2019-20\n","2018-19\n","2017-18\n","UG [4 Years Program(s)]\n","1050\n","1440\n","1320\n","1080\n","-\n","-\n","PG [2 Year Program(s)]\n","132\n","114\n","-\n","-\n","-\n","-...\n","    Pattern 1 for ug_4_years found TUPLE: Male=1050, Female=1440, Total=1320\n","    Pattern 2 for ug_4_years found TUPLE: Male=1050, Female=1440, Total=1320\n","    Pattern 3 for ug_4_years found TUPLE: Male=1050, Female=1440, Total=1320\n","    Pattern 4 for ug_4_years found SINGLE: 1050\n","    Final ug_4_years: 1320 students (from values: [1320, 1320, 1320, 1050])\n","    No valid values found for ug_5_years\n","    Pattern 5 for pg_2_years found SINGLE: 132\n","    Pattern 6 for pg_2_years found SINGLE: 132\n","    Final pg_2_years: 132 students (from values: [132, 132])\n","    No valid values found for pg_3_years\n","    No valid values found for pg_integrated\n","    Some PG programs not found with primary patterns, trying line-by-line analysis...\n","    Calculated total students: 1452\n","  Accumulated student data so far: {'ug_4_years': 1320, 'ug_5_years': 0, 'pg_2_years': 0, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 1320, 'ug_5_years': 0, 'pg_2_years': 0, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 1320, 'ug_5_years': 0, 'pg_2_years': 132, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 1320, 'ug_5_years': 0, 'pg_2_years': 132, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 1320, 'ug_5_years': 0, 'pg_2_years': 132, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Found student section: STUDENT_STRENGTH\n","\n","=== DEBUGGING SECTION: STUDENT_STRENGTH ===\n","Section length: 850 characters\n","Relevant lines found:\n","  Line 1: Total Actual Student Strength (Program(s) Offered by your Institution)\n","  Line 2: (All programs\n","  Line 3: of all years)\n","  Line 52: UG [4 Years\n","  Line 53: Program(s)]\n","  Line 66: PG [2 Year\n","  Line 67: Program(s)]\n","\n","PG Programs (2-Year/3-Year/Integrated/PG-Integrated) analysis:\n","  Line 66: PG [2 Year\n","  Line 67:   -> Program(s)]\n","  Line 68:   -> 118\n","==================================================\n","    Analyzing content length: 850 characters\n","    Sample content preview: Total Actual Student Strength (Program(s) Offered by your Institution)\n","(All programs\n","of all years)\n","No. of Male\n","Students\n","No. of Female\n","Students\n","Total Students\n","Within State\n","(Including male\n","& female)\n","Out...\n","    Pattern 1 for ug_4_years found TUPLE: Male=2183, Female=2662, Total=4845\n","    Pattern 2 for ug_4_years found TUPLE: Male=2183, Female=2662, Total=4845\n","    Pattern 3 for ug_4_years found TUPLE: Male=2183, Female=2662, Total=4845\n","    Pattern 4 for ug_4_years found SINGLE: 2183\n","    Final ug_4_years: 4845 students (from values: [4845, 4845, 4845, 2183])\n","    No valid values found for ug_5_years\n","    Pattern 1 for pg_2_years found TUPLE: Male=118, Female=128, Total=246\n","    Pattern 2 for pg_2_years found TUPLE: Male=118, Female=128, Total=246\n","    Pattern 3 for pg_2_years found TUPLE: Male=118, Female=128, Total=246\n","    Pattern 4 for pg_2_years found TUPLE: Male=118, Female=128, Total=246\n","    Pattern 5 for pg_2_years found SINGLE: 118\n","    Pattern 6 for pg_2_years found SINGLE: 118\n","    Final pg_2_years: 246 students (from values: [246, 246, 246, 246, 118, 118])\n","    No valid values found for pg_3_years\n","    No valid values found for pg_integrated\n","    Some PG programs not found with primary patterns, trying line-by-line analysis...\n","    Calculated total students: 5091\n","  Accumulated student data so far: {'ug_4_years': 4845, 'ug_5_years': 0, 'pg_2_years': 132, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 4845, 'ug_5_years': 0, 'pg_2_years': 132, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 4845, 'ug_5_years': 0, 'pg_2_years': 246, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 4845, 'ug_5_years': 0, 'pg_2_years': 246, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 4845, 'ug_5_years': 0, 'pg_2_years': 246, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Found student section: PLACEMENT_STUDIES\n","\n","=== DEBUGGING SECTION: PLACEMENT_STUDIES ===\n","Section length: 600 characters\n","Relevant lines found:\n","  Line 1: PG [2 Years Program(s)]: Placement & higher studies for previous 3 years\n","\n","PG Programs (2-Year/3-Year/Integrated/PG-Integrated) analysis:\n","  Line 1: PG [2 Years Program(s)]: Placement & higher studies for previous 3 years\n","  Line 2:   -> Academic Year\n","  Line 3:   -> No. of first year\n","==================================================\n","    Analyzing content length: 600 characters\n","    Sample content preview: PG [2 Years Program(s)]: Placement & higher studies for previous 3 years\n","Academic Year\n","No. of first year\n","students intake in the\n","year\n","No. of first year\n","students admitted in\n","the year\n","Academic Year\n","No. o...\n","    No valid values found for ug_4_years\n","    No valid values found for ug_5_years\n","    Pattern 5 for pg_2_years found SINGLE: 3\n","    Pattern 6 for pg_2_years found SINGLE: 3\n","    Final pg_2_years: 3 students (from values: [3, 3])\n","    No valid values found for pg_3_years\n","    No valid values found for pg_integrated\n","    Some PG programs not found with primary patterns, trying line-by-line analysis...\n","    Calculated total students: 3\n","  Accumulated student data so far: {'ug_4_years': 4845, 'ug_5_years': 0, 'pg_2_years': 246, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 4845, 'ug_5_years': 0, 'pg_2_years': 246, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 4845, 'ug_5_years': 0, 'pg_2_years': 246, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 4845, 'ug_5_years': 0, 'pg_2_years': 246, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 4845, 'ug_5_years': 0, 'pg_2_years': 246, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Found student section: PHD_DETAILS\n","\n","=== DEBUGGING SECTION: PHD_DETAILS ===\n","Section length: 231 characters\n","Relevant lines found:\n","  Line 2: Ph.D (Student pursuing doctoral program till 2022-23)\n","\n","No PG program indicators found\n","==================================================\n","    Analyzing content length: 231 characters\n","    Sample content preview: Ph.D Student Details\n","Ph.D (Student pursuing doctoral program till 2022-23)\n","Total Students\n","Full Time\n","221\n","Part Time\n","34\n","No. of Ph.D students graduated (including Integrated Ph.D)\n","2022-23\n","2021-22\n","2020-21\n","...\n","    No valid values found for ug_4_years\n","    No valid values found for ug_5_years\n","    No valid values found for pg_2_years\n","    No valid values found for pg_3_years\n","    No valid values found for pg_integrated\n","    Some PG programs not found with primary patterns, trying line-by-line analysis...\n","  Accumulated student data so far: {'ug_4_years': 4845, 'ug_5_years': 0, 'pg_2_years': 246, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 4845, 'ug_5_years': 0, 'pg_2_years': 246, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 4845, 'ug_5_years': 0, 'pg_2_years': 246, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 4845, 'ug_5_years': 0, 'pg_2_years': 246, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 4845, 'ug_5_years': 0, 'pg_2_years': 246, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Found student section: PCS_FACILITIES\n","\n","=== DEBUGGING SECTION: PCS_FACILITIES ===\n","Section length: 430 characters\n","No obvious table structure found\n","\n","First 10 non-empty lines:\n","  1: PCS Facilities: Facilities of Physically Challenged Students\n","  2: 1. Do your institution buildings have Lifts/Ramps?\n","  3: Yes, more than 80% of the buildings\n","  4: 2. Do your institution have provision for walking aids, including wheelchairs and transportation from one building to another for\n","  5: handicapped students?\n","  6: Yes\n","  7: 3. Do your institution buildings have specially designed toilets for handicapped students?\n","  8: Yes, more than 80% of the buildings\n","\n","No PG program indicators found\n","==================================================\n","    Analyzing content length: 430 characters\n","    Sample content preview: PCS Facilities: Facilities of Physically Challenged Students\n","1. Do your institution buildings have Lifts/Ramps?\n","Yes, more than 80% of the buildings\n","2. Do your institution have provision for walking ai...\n","    No valid values found for ug_4_years\n","    No valid values found for ug_5_years\n","    No valid values found for pg_2_years\n","    No valid values found for pg_3_years\n","    No valid values found for pg_integrated\n","    Some PG programs not found with primary patterns, trying line-by-line analysis...\n","  Accumulated student data so far: {'ug_4_years': 4845, 'ug_5_years': 0, 'pg_2_years': 246, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 4845, 'ug_5_years': 0, 'pg_2_years': 246, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 4845, 'ug_5_years': 0, 'pg_2_years': 246, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 4845, 'ug_5_years': 0, 'pg_2_years': 246, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 4845, 'ug_5_years': 0, 'pg_2_years': 246, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Processing faculty section: FACULTY_DETAILS\n","\n","=== DEBUGGING SECTION: FACULTY_DETAILS ===\n","Section length: 37 characters\n","No obvious table structure found\n","\n","First 10 non-empty lines:\n","  1: Number of faculty members entered\n","  2: 452\n","\n","No PG program indicators found\n","==================================================\n","   Looking for pattern: INDEX -> Name...\n","    No valid index->name patterns found\n","  No faculty found in 'FACULTY_DETAILS', processing as normal content.\n","  Creating consolidated student strength point: {'ug_4_years': 4845, 'ug_5_years': 0, 'pg_2_years': 246, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 5091}\n","Created 12 points for C.V. Raman Global University, Odisha\n","Saved 12 points to C.V. Raman Global University_ Odisha.json (normalized)\n","  Created 12 points\n","\n","Processing file: Kalasalingam Academy of Research and Education.txt\n","Processing: Kalasalingam Academy of Research and Education (IR-E-U-0458)\n","  Found student section: SANCTIONED_INTAKE\n","\n","=== DEBUGGING SECTION: SANCTIONED_INTAKE ===\n","Section length: 177 characters\n","Relevant lines found:\n","  Line 9: UG [4 Years Program(s)]\n","  Line 16: PG [2 Year Program(s)]\n","\n","PG Programs (2-Year/3-Year/Integrated/PG-Integrated) analysis:\n","  Line 16: PG [2 Year Program(s)]\n","  Line 17:   -> 108\n","  Line 18:   -> 108\n","==================================================\n","    Analyzing content length: 177 characters\n","    Sample content preview: Sanctioned (Approved) Intake\n","Academic Year\n","2022-23\n","2021-22\n","2020-21\n","2019-20\n","2018-19\n","2017-18\n","UG [4 Years Program(s)]\n","1719\n","1590\n","1470\n","1290\n","-\n","-\n","PG [2 Year Program(s)]\n","108\n","108\n","-\n","-\n","-\n","-...\n","    Pattern 1 for ug_4_years found TUPLE: Male=1719, Female=1590, Total=1470\n","    Pattern 2 for ug_4_years found TUPLE: Male=1719, Female=1590, Total=1470\n","    Pattern 3 for ug_4_years found TUPLE: Male=1719, Female=1590, Total=1470\n","    Pattern 4 for ug_4_years found SINGLE: 1719\n","    Final ug_4_years: 1719 students (from values: [1470, 1470, 1470, 1719])\n","    No valid values found for ug_5_years\n","    Pattern 5 for pg_2_years found SINGLE: 108\n","    Pattern 6 for pg_2_years found SINGLE: 108\n","    Final pg_2_years: 108 students (from values: [108, 108])\n","    No valid values found for pg_3_years\n","    No valid values found for pg_integrated\n","    Some PG programs not found with primary patterns, trying line-by-line analysis...\n","    Calculated total students: 1827\n","  Accumulated student data so far: {'ug_4_years': 1719, 'ug_5_years': 0, 'pg_2_years': 0, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 1719, 'ug_5_years': 0, 'pg_2_years': 0, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 1719, 'ug_5_years': 0, 'pg_2_years': 108, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 1719, 'ug_5_years': 0, 'pg_2_years': 108, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 1719, 'ug_5_years': 0, 'pg_2_years': 108, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Found student section: STUDENT_STRENGTH\n","\n","=== DEBUGGING SECTION: STUDENT_STRENGTH ===\n","Section length: 851 characters\n","Relevant lines found:\n","  Line 1: Total Actual Student Strength (Program(s) Offered by your Institution)\n","  Line 2: (All programs\n","  Line 3: of all years)\n","  Line 52: UG [4 Years\n","  Line 53: Program(s)]\n","  Line 66: PG [2 Year\n","  Line 67: Program(s)]\n","\n","PG Programs (2-Year/3-Year/Integrated/PG-Integrated) analysis:\n","  Line 66: PG [2 Year\n","  Line 67:   -> Program(s)]\n","  Line 68:   -> 81\n","==================================================\n","    Analyzing content length: 851 characters\n","    Sample content preview: Total Actual Student Strength (Program(s) Offered by your Institution)\n","(All programs\n","of all years)\n","No. of Male\n","Students\n","No. of Female\n","Students\n","Total Students\n","Within State\n","(Including male\n","& female)\n","Out...\n","    Pattern 1 for ug_4_years found TUPLE: Male=2955, Female=3107, Total=6062\n","    Pattern 2 for ug_4_years found TUPLE: Male=2955, Female=3107, Total=6062\n","    Pattern 3 for ug_4_years found TUPLE: Male=2955, Female=3107, Total=6062\n","    Pattern 4 for ug_4_years found SINGLE: 2955\n","    Final ug_4_years: 6062 students (from values: [6062, 6062, 6062, 2955])\n","    No valid values found for ug_5_years\n","    Pattern 1 for pg_2_years found TUPLE: Male=81, Female=133, Total=214\n","    Pattern 2 for pg_2_years found TUPLE: Male=81, Female=133, Total=214\n","    Pattern 3 for pg_2_years found TUPLE: Male=81, Female=133, Total=214\n","    Pattern 4 for pg_2_years found TUPLE: Male=81, Female=133, Total=214\n","    Pattern 5 for pg_2_years found SINGLE: 81\n","    Pattern 6 for pg_2_years found SINGLE: 81\n","    Final pg_2_years: 214 students (from values: [214, 214, 214, 214, 81, 81])\n","    No valid values found for pg_3_years\n","    No valid values found for pg_integrated\n","    Some PG programs not found with primary patterns, trying line-by-line analysis...\n","    Calculated total students: 6276\n","  Accumulated student data so far: {'ug_4_years': 6062, 'ug_5_years': 0, 'pg_2_years': 108, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 6062, 'ug_5_years': 0, 'pg_2_years': 108, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 6062, 'ug_5_years': 0, 'pg_2_years': 214, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 6062, 'ug_5_years': 0, 'pg_2_years': 214, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 6062, 'ug_5_years': 0, 'pg_2_years': 214, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Found student section: PLACEMENT_STUDIES\n","\n","=== DEBUGGING SECTION: PLACEMENT_STUDIES ===\n","Section length: 584 characters\n","Relevant lines found:\n","  Line 1: PG [2 Years Program(s)]: Placement & higher studies for previous 3 years\n","\n","PG Programs (2-Year/3-Year/Integrated/PG-Integrated) analysis:\n","  Line 1: PG [2 Years Program(s)]: Placement & higher studies for previous 3 years\n","  Line 2:   -> Academic Year\n","  Line 3:   -> No. of first year\n","==================================================\n","    Analyzing content length: 584 characters\n","    Sample content preview: PG [2 Years Program(s)]: Placement & higher studies for previous 3 years\n","Academic Year\n","No. of first year\n","students intake in the\n","year\n","No. of first year\n","students admitted in\n","the year\n","Academic Year\n","No. o...\n","    No valid values found for ug_4_years\n","    No valid values found for ug_5_years\n","    Pattern 5 for pg_2_years found SINGLE: 3\n","    Pattern 6 for pg_2_years found SINGLE: 3\n","    Final pg_2_years: 3 students (from values: [3, 3])\n","    No valid values found for pg_3_years\n","    No valid values found for pg_integrated\n","    Some PG programs not found with primary patterns, trying line-by-line analysis...\n","    Calculated total students: 3\n","  Accumulated student data so far: {'ug_4_years': 6062, 'ug_5_years': 0, 'pg_2_years': 214, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 6062, 'ug_5_years': 0, 'pg_2_years': 214, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 6062, 'ug_5_years': 0, 'pg_2_years': 214, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 6062, 'ug_5_years': 0, 'pg_2_years': 214, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 6062, 'ug_5_years': 0, 'pg_2_years': 214, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Found student section: PHD_DETAILS\n","\n","=== DEBUGGING SECTION: PHD_DETAILS ===\n","Section length: 238 characters\n","Relevant lines found:\n","  Line 2: Ph.D (Student pursuing doctoral program till 2022-23)\n","\n","No PG program indicators found\n","==================================================\n","    Analyzing content length: 238 characters\n","    Sample content preview: Ph.D Student Details\n","Ph.D (Student pursuing doctoral program till 2022-23)\n","Total Students\n","Full Time\n","407\n","Part Time\n","106\n","No. of Ph.D students graduated (including Integrated Ph.D)\n","2022-23\n","2021-22\n","2020-21...\n","    No valid values found for ug_4_years\n","    No valid values found for ug_5_years\n","    No valid values found for pg_2_years\n","    No valid values found for pg_3_years\n","    No valid values found for pg_integrated\n","    Some PG programs not found with primary patterns, trying line-by-line analysis...\n","  Accumulated student data so far: {'ug_4_years': 6062, 'ug_5_years': 0, 'pg_2_years': 214, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 6062, 'ug_5_years': 0, 'pg_2_years': 214, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 6062, 'ug_5_years': 0, 'pg_2_years': 214, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 6062, 'ug_5_years': 0, 'pg_2_years': 214, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 6062, 'ug_5_years': 0, 'pg_2_years': 214, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Found student section: PCS_FACILITIES\n","\n","=== DEBUGGING SECTION: PCS_FACILITIES ===\n","Section length: 430 characters\n","No obvious table structure found\n","\n","First 10 non-empty lines:\n","  1: PCS Facilities: Facilities of Physically Challenged Students\n","  2: 1. Do your institution buildings have Lifts/Ramps?\n","  3: Yes, more than 80% of the buildings\n","  4: 2. Do your institution have provision for walking aids, including wheelchairs and transportation from one building to another for\n","  5: handicapped students?\n","  6: Yes\n","  7: 3. Do your institution buildings have specially designed toilets for handicapped students?\n","  8: Yes, more than 80% of the buildings\n","\n","No PG program indicators found\n","==================================================\n","    Analyzing content length: 430 characters\n","    Sample content preview: PCS Facilities: Facilities of Physically Challenged Students\n","1. Do your institution buildings have Lifts/Ramps?\n","Yes, more than 80% of the buildings\n","2. Do your institution have provision for walking ai...\n","    No valid values found for ug_4_years\n","    No valid values found for ug_5_years\n","    No valid values found for pg_2_years\n","    No valid values found for pg_3_years\n","    No valid values found for pg_integrated\n","    Some PG programs not found with primary patterns, trying line-by-line analysis...\n","  Accumulated student data so far: {'ug_4_years': 6062, 'ug_5_years': 0, 'pg_2_years': 214, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 6062, 'ug_5_years': 0, 'pg_2_years': 214, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 6062, 'ug_5_years': 0, 'pg_2_years': 214, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 6062, 'ug_5_years': 0, 'pg_2_years': 214, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 6062, 'ug_5_years': 0, 'pg_2_years': 214, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Processing faculty section: FACULTY_DETAILS\n","\n","=== DEBUGGING SECTION: FACULTY_DETAILS ===\n","Section length: 37 characters\n","No obvious table structure found\n","\n","First 10 non-empty lines:\n","  1: Number of faculty members entered\n","  2: 455\n","\n","No PG program indicators found\n","==================================================\n","   Looking for pattern: INDEX -> Name...\n","    No valid index->name patterns found\n","  No faculty found in 'FACULTY_DETAILS', processing as normal content.\n","  Creating consolidated student strength point: {'ug_4_years': 6062, 'ug_5_years': 0, 'pg_2_years': 214, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 6276}\n","Created 12 points for Kalasalingam Academy of Research and Education\n","Saved 12 points to Kalasalingam Academy of Research and Education.json (normalized)\n","  Created 12 points\n","\n","Processing file: IIT Gandhinagar.txt\n","Processing: Indian Institute of Technology Gandhinagar (IR-E-U-0139)\n","  Found student section: SANCTIONED_INTAKE\n","\n","=== DEBUGGING SECTION: SANCTIONED_INTAKE ===\n","Section length: 209 characters\n","Relevant lines found:\n","  Line 9: UG [4 Years Program(s)]\n","  Line 16: UG [5 Years Program(s)]\n","  Line 23: PG [2 Year Program(s)]\n","\n","PG Programs (2-Year/3-Year/Integrated/PG-Integrated) analysis:\n","  Line 23: PG [2 Year Program(s)]\n","  Line 24:   -> 100\n","  Line 25:   -> 72\n","==================================================\n","    Analyzing content length: 209 characters\n","    Sample content preview: Sanctioned (Approved) Intake\n","Academic Year\n","2022-23\n","2021-22\n","2020-21\n","2019-20\n","2018-19\n","2017-18\n","UG [4 Years Program(s)]\n","225\n","225\n","225\n","193\n","-\n","-\n","UG [5 Years Program(s)]\n","40\n","0\n","0\n","0\n","0\n","-\n","PG [2 Year Program(s)]\n","100\n","7...\n","    Pattern 1 for ug_4_years found TUPLE: Male=225, Female=225, Total=225\n","    Pattern 2 for ug_4_years found TUPLE: Male=225, Female=225, Total=225\n","    Pattern 3 for ug_4_years found TUPLE: Male=225, Female=225, Total=225\n","    Pattern 4 for ug_4_years found SINGLE: 225\n","    Final ug_4_years: 225 students (from values: [225, 225, 225, 225])\n","    Pattern 1 for ug_5_years found TUPLE: Male=40, Female=0, Total=0\n","    Rejected unreasonable value: 0\n","    Pattern 2 for ug_5_years found TUPLE: Male=40, Female=0, Total=0\n","    Rejected unreasonable value: 0\n","    Pattern 3 for ug_5_years found TUPLE: Male=40, Female=0, Total=0\n","    Rejected unreasonable value: 0\n","    Pattern 4 for ug_5_years found SINGLE: 40\n","    Final ug_5_years: 40 students (from values: [40])\n","    Pattern 5 for pg_2_years found SINGLE: 100\n","    Pattern 6 for pg_2_years found SINGLE: 100\n","    Final pg_2_years: 100 students (from values: [100, 100])\n","    No valid values found for pg_3_years\n","    No valid values found for pg_integrated\n","    Some PG programs not found with primary patterns, trying line-by-line analysis...\n","    Calculated total students: 365\n","  Accumulated student data so far: {'ug_4_years': 225, 'ug_5_years': 0, 'pg_2_years': 0, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 225, 'ug_5_years': 40, 'pg_2_years': 0, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 225, 'ug_5_years': 40, 'pg_2_years': 100, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 225, 'ug_5_years': 40, 'pg_2_years': 100, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 225, 'ug_5_years': 40, 'pg_2_years': 100, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Found student section: STUDENT_STRENGTH\n","\n","=== DEBUGGING SECTION: STUDENT_STRENGTH ===\n","Section length: 887 characters\n","Relevant lines found:\n","  Line 1: Total Actual Student Strength (Program(s) Offered by your Institution)\n","  Line 2: (All programs\n","  Line 3: of all years)\n","  Line 52: UG [4 Years\n","  Line 53: Program(s)]\n","  Line 66: UG [5 Years\n","  Line 67: Program(s)]\n","  Line 80: PG [2 Year\n","  Line 81: Program(s)]\n","\n","PG Programs (2-Year/3-Year/Integrated/PG-Integrated) analysis:\n","  Line 80: PG [2 Year\n","  Line 81:   -> Program(s)]\n","  Line 82:   -> 100\n","==================================================\n","    Analyzing content length: 887 characters\n","    Sample content preview: Total Actual Student Strength (Program(s) Offered by your Institution)\n","(All programs\n","of all years)\n","No. of Male\n","Students\n","No. of Female\n","Students\n","Total Students\n","Within State\n","(Including male\n","& female)\n","Out...\n","    Pattern 1 for ug_4_years found TUPLE: Male=750, Female=183, Total=933\n","    Pattern 2 for ug_4_years found TUPLE: Male=750, Female=183, Total=933\n","    Pattern 3 for ug_4_years found TUPLE: Male=750, Female=183, Total=933\n","    Pattern 4 for ug_4_years found SINGLE: 750\n","    Final ug_4_years: 933 students (from values: [933, 933, 933, 750])\n","    Pattern 1 for ug_5_years found TUPLE: Male=30, Female=9, Total=39\n","    Pattern 2 for ug_5_years found TUPLE: Male=30, Female=9, Total=39\n","    Pattern 3 for ug_5_years found TUPLE: Male=30, Female=9, Total=39\n","    Pattern 4 for ug_5_years found SINGLE: 30\n","    Final ug_5_years: 39 students (from values: [39, 39, 39, 30])\n","    Pattern 1 for pg_2_years found TUPLE: Male=100, Female=49, Total=149\n","    Pattern 2 for pg_2_years found TUPLE: Male=100, Female=49, Total=149\n","    Pattern 3 for pg_2_years found TUPLE: Male=100, Female=49, Total=149\n","    Pattern 4 for pg_2_years found TUPLE: Male=100, Female=49, Total=149\n","    Pattern 5 for pg_2_years found SINGLE: 100\n","    Pattern 6 for pg_2_years found SINGLE: 100\n","    Final pg_2_years: 149 students (from values: [149, 149, 149, 149, 100, 100])\n","    No valid values found for pg_3_years\n","    No valid values found for pg_integrated\n","    Some PG programs not found with primary patterns, trying line-by-line analysis...\n","    Calculated total students: 1121\n","  Accumulated student data so far: {'ug_4_years': 933, 'ug_5_years': 40, 'pg_2_years': 100, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 933, 'ug_5_years': 40, 'pg_2_years': 100, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 933, 'ug_5_years': 40, 'pg_2_years': 149, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 933, 'ug_5_years': 40, 'pg_2_years': 149, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 933, 'ug_5_years': 40, 'pg_2_years': 149, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Found student section: PLACEMENT_STUDIES\n","\n","=== DEBUGGING SECTION: PLACEMENT_STUDIES ===\n","Section length: 584 characters\n","Relevant lines found:\n","  Line 1: PG [2 Years Program(s)]: Placement & higher studies for previous 3 years\n","\n","PG Programs (2-Year/3-Year/Integrated/PG-Integrated) analysis:\n","  Line 1: PG [2 Years Program(s)]: Placement & higher studies for previous 3 years\n","  Line 2:   -> Academic Year\n","  Line 3:   -> No. of first year\n","==================================================\n","    Analyzing content length: 584 characters\n","    Sample content preview: PG [2 Years Program(s)]: Placement & higher studies for previous 3 years\n","Academic Year\n","No. of first year\n","students intake in the\n","year\n","No. of first year\n","students admitted in\n","the year\n","Academic Year\n","No. o...\n","    No valid values found for ug_4_years\n","    No valid values found for ug_5_years\n","    Pattern 5 for pg_2_years found SINGLE: 3\n","    Pattern 6 for pg_2_years found SINGLE: 3\n","    Final pg_2_years: 3 students (from values: [3, 3])\n","    No valid values found for pg_3_years\n","    No valid values found for pg_integrated\n","    Some PG programs not found with primary patterns, trying line-by-line analysis...\n","    Calculated total students: 3\n","  Accumulated student data so far: {'ug_4_years': 933, 'ug_5_years': 40, 'pg_2_years': 149, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 933, 'ug_5_years': 40, 'pg_2_years': 149, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 933, 'ug_5_years': 40, 'pg_2_years': 149, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 933, 'ug_5_years': 40, 'pg_2_years': 149, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 933, 'ug_5_years': 40, 'pg_2_years': 149, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Found student section: PHD_DETAILS\n","\n","=== DEBUGGING SECTION: PHD_DETAILS ===\n","Section length: 233 characters\n","Relevant lines found:\n","  Line 2: Ph.D (Student pursuing doctoral program till 2022-23)\n","\n","No PG program indicators found\n","==================================================\n","    Analyzing content length: 233 characters\n","    Sample content preview: Ph.D Student Details\n","Ph.D (Student pursuing doctoral program till 2022-23)\n","Total Students\n","Full Time\n","560\n","Part Time\n","2\n","No. of Ph.D students graduated (including Integrated Ph.D)\n","2022-23\n","2021-22\n","2020-21\n","F...\n","    No valid values found for ug_4_years\n","    No valid values found for ug_5_years\n","    No valid values found for pg_2_years\n","    No valid values found for pg_3_years\n","    No valid values found for pg_integrated\n","    Some PG programs not found with primary patterns, trying line-by-line analysis...\n","  Accumulated student data so far: {'ug_4_years': 933, 'ug_5_years': 40, 'pg_2_years': 149, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 933, 'ug_5_years': 40, 'pg_2_years': 149, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 933, 'ug_5_years': 40, 'pg_2_years': 149, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 933, 'ug_5_years': 40, 'pg_2_years': 149, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 933, 'ug_5_years': 40, 'pg_2_years': 149, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Found student section: PCS_FACILITIES\n","\n","=== DEBUGGING SECTION: PCS_FACILITIES ===\n","Section length: 430 characters\n","No obvious table structure found\n","\n","First 10 non-empty lines:\n","  1: PCS Facilities: Facilities of Physically Challenged Students\n","  2: 1. Do your institution buildings have Lifts/Ramps?\n","  3: Yes, more than 80% of the buildings\n","  4: 2. Do your institution have provision for walking aids, including wheelchairs and transportation from one building to another for\n","  5: handicapped students?\n","  6: Yes\n","  7: 3. Do your institution buildings have specially designed toilets for handicapped students?\n","  8: Yes, more than 80% of the buildings\n","\n","No PG program indicators found\n","==================================================\n","    Analyzing content length: 430 characters\n","    Sample content preview: PCS Facilities: Facilities of Physically Challenged Students\n","1. Do your institution buildings have Lifts/Ramps?\n","Yes, more than 80% of the buildings\n","2. Do your institution have provision for walking ai...\n","    No valid values found for ug_4_years\n","    No valid values found for ug_5_years\n","    No valid values found for pg_2_years\n","    No valid values found for pg_3_years\n","    No valid values found for pg_integrated\n","    Some PG programs not found with primary patterns, trying line-by-line analysis...\n","  Accumulated student data so far: {'ug_4_years': 933, 'ug_5_years': 40, 'pg_2_years': 149, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 933, 'ug_5_years': 40, 'pg_2_years': 149, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 933, 'ug_5_years': 40, 'pg_2_years': 149, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 933, 'ug_5_years': 40, 'pg_2_years': 149, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 933, 'ug_5_years': 40, 'pg_2_years': 149, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Processing faculty section: FACULTY_DETAILS\n","\n","=== DEBUGGING SECTION: FACULTY_DETAILS ===\n","Section length: 37 characters\n","No obvious table structure found\n","\n","First 10 non-empty lines:\n","  1: Number of faculty members entered\n","  2: 125\n","\n","No PG program indicators found\n","==================================================\n","   Looking for pattern: INDEX -> Name...\n","    No valid index->name patterns found\n","  No faculty found in 'FACULTY_DETAILS', processing as normal content.\n","  Creating consolidated student strength point: {'ug_4_years': 933, 'ug_5_years': 40, 'pg_2_years': 149, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 1122}\n","Created 12 points for Indian Institute of Technology Gandhinagar\n","Saved 12 points to IIT Gandhinagar.json (normalized)\n","  Created 12 points\n","\n","Processing file: AU College of Enginnering.txt\n","Processing: AU College of Engineering (A) (IR-E-C-24004)\n","  Found student section: SANCTIONED_INTAKE\n","\n","=== DEBUGGING SECTION: SANCTIONED_INTAKE ===\n","Section length: 173 characters\n","Relevant lines found:\n","  Line 9: UG [4 Years Program(s)]\n","  Line 16: PG [2 Year Program(s)]\n","\n","PG Programs (2-Year/3-Year/Integrated/PG-Integrated) analysis:\n","  Line 16: PG [2 Year Program(s)]\n","  Line 17:   -> 510\n","  Line 18:   -> 510\n","==================================================\n","    Analyzing content length: 173 characters\n","    Sample content preview: Sanctioned (Approved) Intake\n","Academic Year\n","2022-23\n","2021-22\n","2020-21\n","2019-20\n","2018-19\n","2017-18\n","UG [4 Years Program(s)]\n","530\n","530\n","530\n","754\n","-\n","-\n","PG [2 Year Program(s)]\n","510\n","510\n","-\n","-\n","-\n","-...\n","    Pattern 1 for ug_4_years found TUPLE: Male=530, Female=530, Total=530\n","    Pattern 2 for ug_4_years found TUPLE: Male=530, Female=530, Total=530\n","    Pattern 3 for ug_4_years found TUPLE: Male=530, Female=530, Total=530\n","    Pattern 4 for ug_4_years found SINGLE: 530\n","    Final ug_4_years: 530 students (from values: [530, 530, 530, 530])\n","    No valid values found for ug_5_years\n","    Pattern 5 for pg_2_years found SINGLE: 510\n","    Pattern 6 for pg_2_years found SINGLE: 510\n","    Final pg_2_years: 510 students (from values: [510, 510])\n","    No valid values found for pg_3_years\n","    No valid values found for pg_integrated\n","    Some PG programs not found with primary patterns, trying line-by-line analysis...\n","    Calculated total students: 1040\n","  Accumulated student data so far: {'ug_4_years': 530, 'ug_5_years': 0, 'pg_2_years': 0, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 530, 'ug_5_years': 0, 'pg_2_years': 0, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 530, 'ug_5_years': 0, 'pg_2_years': 510, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 530, 'ug_5_years': 0, 'pg_2_years': 510, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 530, 'ug_5_years': 0, 'pg_2_years': 510, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Found student section: STUDENT_STRENGTH\n","\n","=== DEBUGGING SECTION: STUDENT_STRENGTH ===\n","Section length: 852 characters\n","Relevant lines found:\n","  Line 1: Total Actual Student Strength (Program(s) Offered by your Institution)\n","  Line 2: (All programs\n","  Line 3: of all years)\n","  Line 52: UG [4 Years\n","  Line 53: Program(s)]\n","  Line 66: PG [2 Year\n","  Line 67: Program(s)]\n","\n","PG Programs (2-Year/3-Year/Integrated/PG-Integrated) analysis:\n","  Line 66: PG [2 Year\n","  Line 67:   -> Program(s)]\n","  Line 68:   -> 477\n","==================================================\n","    Analyzing content length: 852 characters\n","    Sample content preview: Total Actual Student Strength (Program(s) Offered by your Institution)\n","(All programs\n","of all years)\n","No. of Male\n","Students\n","No. of Female\n","Students\n","Total Students\n","Within State\n","(Including male\n","& female)\n","Out...\n","    Pattern 1 for ug_4_years found TUPLE: Male=1168, Female=1175, Total=2343\n","    Pattern 2 for ug_4_years found TUPLE: Male=1168, Female=1175, Total=2343\n","    Pattern 3 for ug_4_years found TUPLE: Male=1168, Female=1175, Total=2343\n","    Pattern 4 for ug_4_years found SINGLE: 1168\n","    Final ug_4_years: 2343 students (from values: [2343, 2343, 2343, 1168])\n","    No valid values found for ug_5_years\n","    Pattern 1 for pg_2_years found TUPLE: Male=477, Female=541, Total=1018\n","    Pattern 2 for pg_2_years found TUPLE: Male=477, Female=541, Total=1018\n","    Pattern 3 for pg_2_years found TUPLE: Male=477, Female=541, Total=1018\n","    Pattern 4 for pg_2_years found TUPLE: Male=477, Female=541, Total=1018\n","    Pattern 5 for pg_2_years found SINGLE: 477\n","    Pattern 6 for pg_2_years found SINGLE: 477\n","    Final pg_2_years: 1018 students (from values: [1018, 1018, 1018, 1018, 477, 477])\n","    No valid values found for pg_3_years\n","    No valid values found for pg_integrated\n","    Some PG programs not found with primary patterns, trying line-by-line analysis...\n","    Calculated total students: 3361\n","  Accumulated student data so far: {'ug_4_years': 2343, 'ug_5_years': 0, 'pg_2_years': 510, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 2343, 'ug_5_years': 0, 'pg_2_years': 510, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 2343, 'ug_5_years': 0, 'pg_2_years': 1018, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 2343, 'ug_5_years': 0, 'pg_2_years': 1018, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 2343, 'ug_5_years': 0, 'pg_2_years': 1018, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Found student section: PLACEMENT_STUDIES\n","\n","=== DEBUGGING SECTION: PLACEMENT_STUDIES ===\n","Section length: 587 characters\n","Relevant lines found:\n","  Line 1: PG [2 Years Program(s)]: Placement & higher studies for previous 3 years\n","\n","PG Programs (2-Year/3-Year/Integrated/PG-Integrated) analysis:\n","  Line 1: PG [2 Years Program(s)]: Placement & higher studies for previous 3 years\n","  Line 2:   -> Academic Year\n","  Line 3:   -> No. of first year\n","==================================================\n","    Analyzing content length: 587 characters\n","    Sample content preview: PG [2 Years Program(s)]: Placement & higher studies for previous 3 years\n","Academic Year\n","No. of first year\n","students intake in the\n","year\n","No. of first year\n","students admitted in\n","the year\n","Academic Year\n","No. o...\n","    No valid values found for ug_4_years\n","    No valid values found for ug_5_years\n","    Pattern 5 for pg_2_years found SINGLE: 3\n","    Pattern 6 for pg_2_years found SINGLE: 3\n","    Final pg_2_years: 3 students (from values: [3, 3])\n","    No valid values found for pg_3_years\n","    No valid values found for pg_integrated\n","    Some PG programs not found with primary patterns, trying line-by-line analysis...\n","    Calculated total students: 3\n","  Accumulated student data so far: {'ug_4_years': 2343, 'ug_5_years': 0, 'pg_2_years': 1018, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 2343, 'ug_5_years': 0, 'pg_2_years': 1018, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 2343, 'ug_5_years': 0, 'pg_2_years': 1018, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 2343, 'ug_5_years': 0, 'pg_2_years': 1018, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 2343, 'ug_5_years': 0, 'pg_2_years': 1018, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Found student section: PHD_DETAILS\n","\n","=== DEBUGGING SECTION: PHD_DETAILS ===\n","Section length: 237 characters\n","Relevant lines found:\n","  Line 2: Ph.D (Student pursuing doctoral program till 2022-23)\n","\n","No PG program indicators found\n","==================================================\n","    Analyzing content length: 237 characters\n","    Sample content preview: Ph.D Student Details\n","Ph.D (Student pursuing doctoral program till 2022-23)\n","Total Students\n","Full Time\n","68\n","Part Time\n","35\n","No. of Ph.D students graduated (including Integrated Ph.D)\n","2022-23\n","2021-22\n","2020-21\n","F...\n","    No valid values found for ug_4_years\n","    No valid values found for ug_5_years\n","    No valid values found for pg_2_years\n","    No valid values found for pg_3_years\n","    No valid values found for pg_integrated\n","    Some PG programs not found with primary patterns, trying line-by-line analysis...\n","  Accumulated student data so far: {'ug_4_years': 2343, 'ug_5_years': 0, 'pg_2_years': 1018, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 2343, 'ug_5_years': 0, 'pg_2_years': 1018, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 2343, 'ug_5_years': 0, 'pg_2_years': 1018, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 2343, 'ug_5_years': 0, 'pg_2_years': 1018, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 2343, 'ug_5_years': 0, 'pg_2_years': 1018, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Found student section: PCS_FACILITIES\n","\n","=== DEBUGGING SECTION: PCS_FACILITIES ===\n","Section length: 430 characters\n","No obvious table structure found\n","\n","First 10 non-empty lines:\n","  1: PCS Facilities: Facilities of Physically Challenged Students\n","  2: 1. Do your institution buildings have Lifts/Ramps?\n","  3: Yes, more than 80% of the buildings\n","  4: 2. Do your institution have provision for walking aids, including wheelchairs and transportation from one building to another for\n","  5: handicapped students?\n","  6: Yes\n","  7: 3. Do your institution buildings have specially designed toilets for handicapped students?\n","  8: Yes, more than 80% of the buildings\n","\n","No PG program indicators found\n","==================================================\n","    Analyzing content length: 430 characters\n","    Sample content preview: PCS Facilities: Facilities of Physically Challenged Students\n","1. Do your institution buildings have Lifts/Ramps?\n","Yes, more than 80% of the buildings\n","2. Do your institution have provision for walking ai...\n","    No valid values found for ug_4_years\n","    No valid values found for ug_5_years\n","    No valid values found for pg_2_years\n","    No valid values found for pg_3_years\n","    No valid values found for pg_integrated\n","    Some PG programs not found with primary patterns, trying line-by-line analysis...\n","  Accumulated student data so far: {'ug_4_years': 2343, 'ug_5_years': 0, 'pg_2_years': 1018, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 2343, 'ug_5_years': 0, 'pg_2_years': 1018, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 2343, 'ug_5_years': 0, 'pg_2_years': 1018, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 2343, 'ug_5_years': 0, 'pg_2_years': 1018, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 2343, 'ug_5_years': 0, 'pg_2_years': 1018, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Processing faculty section: FACULTY_DETAILS\n","\n","=== DEBUGGING SECTION: FACULTY_DETAILS ===\n","Section length: 37 characters\n","No obvious table structure found\n","\n","First 10 non-empty lines:\n","  1: Number of faculty members entered\n","  2: 246\n","\n","No PG program indicators found\n","==================================================\n","   Looking for pattern: INDEX -> Name...\n","    No valid index->name patterns found\n","  No faculty found in 'FACULTY_DETAILS', processing as normal content.\n","  Creating consolidated student strength point: {'ug_4_years': 2343, 'ug_5_years': 0, 'pg_2_years': 1018, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 3361}\n","Created 12 points for AU College of Engineering (A)\n","Saved 12 points to AU College of Enginnering.json (normalized)\n","  Created 12 points\n","\n","Processing file: Manipal University_ Jaipur.txt\n","Processing: Manipal University, Jaipur (IR-E-U-0749)\n","  Found student section: SANCTIONED_INTAKE\n","\n","=== DEBUGGING SECTION: SANCTIONED_INTAKE ===\n","Section length: 176 characters\n","Relevant lines found:\n","  Line 9: UG [4 Years Program(s)]\n","  Line 16: PG [2 Year Program(s)]\n","\n","PG Programs (2-Year/3-Year/Integrated/PG-Integrated) analysis:\n","  Line 16: PG [2 Year Program(s)]\n","  Line 17:   -> 84\n","  Line 18:   -> 144\n","==================================================\n","    Analyzing content length: 176 characters\n","    Sample content preview: Sanctioned (Approved) Intake\n","Academic Year\n","2022-23\n","2021-22\n","2020-21\n","2019-20\n","2018-19\n","2017-18\n","UG [4 Years Program(s)]\n","2460\n","2130\n","1410\n","1350\n","-\n","-\n","PG [2 Year Program(s)]\n","84\n","144\n","-\n","-\n","-\n","-...\n","    Pattern 1 for ug_4_years found TUPLE: Male=2460, Female=2130, Total=1410\n","    Pattern 2 for ug_4_years found TUPLE: Male=2460, Female=2130, Total=1410\n","    Pattern 3 for ug_4_years found TUPLE: Male=2460, Female=2130, Total=1410\n","    Pattern 4 for ug_4_years found SINGLE: 2460\n","    Final ug_4_years: 2460 students (from values: [1410, 1410, 1410, 2460])\n","    No valid values found for ug_5_years\n","    Pattern 5 for pg_2_years found SINGLE: 84\n","    Pattern 6 for pg_2_years found SINGLE: 84\n","    Final pg_2_years: 84 students (from values: [84, 84])\n","    No valid values found for pg_3_years\n","    No valid values found for pg_integrated\n","    Some PG programs not found with primary patterns, trying line-by-line analysis...\n","    Calculated total students: 2544\n","  Accumulated student data so far: {'ug_4_years': 2460, 'ug_5_years': 0, 'pg_2_years': 0, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 2460, 'ug_5_years': 0, 'pg_2_years': 0, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 2460, 'ug_5_years': 0, 'pg_2_years': 84, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 2460, 'ug_5_years': 0, 'pg_2_years': 84, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 2460, 'ug_5_years': 0, 'pg_2_years': 84, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Found student section: STUDENT_STRENGTH\n","\n","=== DEBUGGING SECTION: STUDENT_STRENGTH ===\n","Section length: 831 characters\n","Relevant lines found:\n","  Line 1: Total Actual Student Strength (Program(s) Offered by your Institution)\n","  Line 2: (All programs\n","  Line 3: of all years)\n","  Line 52: UG [4 Years\n","  Line 53: Program(s)]\n","  Line 66: PG [2 Year\n","  Line 67: Program(s)]\n","\n","PG Programs (2-Year/3-Year/Integrated/PG-Integrated) analysis:\n","  Line 66: PG [2 Year\n","  Line 67:   -> Program(s)]\n","  Line 68:   -> 28\n","==================================================\n","    Analyzing content length: 831 characters\n","    Sample content preview: Total Actual Student Strength (Program(s) Offered by your Institution)\n","(All programs\n","of all years)\n","No. of Male\n","Students\n","No. of Female\n","Students\n","Total Students\n","Within State\n","(Including male\n","& female)\n","Out...\n","    Pattern 1 for ug_4_years found TUPLE: Male=4265, Female=2808, Total=7073\n","    Pattern 2 for ug_4_years found TUPLE: Male=4265, Female=2808, Total=7073\n","    Pattern 3 for ug_4_years found TUPLE: Male=4265, Female=2808, Total=7073\n","    Pattern 4 for ug_4_years found SINGLE: 4265\n","    Final ug_4_years: 7073 students (from values: [7073, 7073, 7073, 4265])\n","    No valid values found for ug_5_years\n","    Pattern 1 for pg_2_years found TUPLE: Male=28, Female=10, Total=38\n","    Pattern 2 for pg_2_years found TUPLE: Male=28, Female=10, Total=38\n","    Pattern 3 for pg_2_years found TUPLE: Male=28, Female=10, Total=38\n","    Pattern 4 for pg_2_years found TUPLE: Male=28, Female=10, Total=38\n","    Pattern 5 for pg_2_years found SINGLE: 28\n","    Pattern 6 for pg_2_years found SINGLE: 28\n","    Final pg_2_years: 38 students (from values: [38, 38, 38, 38, 28, 28])\n","    No valid values found for pg_3_years\n","    No valid values found for pg_integrated\n","    Some PG programs not found with primary patterns, trying line-by-line analysis...\n","    Calculated total students: 7111\n","  Accumulated student data so far: {'ug_4_years': 7073, 'ug_5_years': 0, 'pg_2_years': 84, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 7073, 'ug_5_years': 0, 'pg_2_years': 84, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 7073, 'ug_5_years': 0, 'pg_2_years': 84, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 7073, 'ug_5_years': 0, 'pg_2_years': 84, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 7073, 'ug_5_years': 0, 'pg_2_years': 84, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Found student section: PLACEMENT_STUDIES\n","\n","=== DEBUGGING SECTION: PLACEMENT_STUDIES ===\n","Section length: 518 characters\n","Relevant lines found:\n","  Line 1: PG [2 Years Program(s)]: Placement & higher studies for previous 3 years\n","\n","PG Programs (2-Year/3-Year/Integrated/PG-Integrated) analysis:\n","  Line 1: PG [2 Years Program(s)]: Placement & higher studies for previous 3 years\n","  Line 2:   -> Academic Year\n","  Line 3:   -> No. of first year\n","==================================================\n","    Analyzing content length: 518 characters\n","    Sample content preview: PG [2 Years Program(s)]: Placement & higher studies for previous 3 years\n","Academic Year\n","No. of first year\n","students intake in the\n","year\n","No. of first year\n","students admitted in\n","the year\n","Academic Year\n","No. o...\n","    No valid values found for ug_4_years\n","    No valid values found for ug_5_years\n","    Pattern 5 for pg_2_years found SINGLE: 3\n","    Pattern 6 for pg_2_years found SINGLE: 3\n","    Final pg_2_years: 3 students (from values: [3, 3])\n","    No valid values found for pg_3_years\n","    No valid values found for pg_integrated\n","    Some PG programs not found with primary patterns, trying line-by-line analysis...\n","    Calculated total students: 3\n","  Accumulated student data so far: {'ug_4_years': 7073, 'ug_5_years': 0, 'pg_2_years': 84, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 7073, 'ug_5_years': 0, 'pg_2_years': 84, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 7073, 'ug_5_years': 0, 'pg_2_years': 84, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 7073, 'ug_5_years': 0, 'pg_2_years': 84, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 7073, 'ug_5_years': 0, 'pg_2_years': 84, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Found student section: PHD_DETAILS\n","\n","=== DEBUGGING SECTION: PHD_DETAILS ===\n","Section length: 235 characters\n","Relevant lines found:\n","  Line 2: Ph.D (Student pursuing doctoral program till 2022-23)\n","\n","No PG program indicators found\n","==================================================\n","    Analyzing content length: 235 characters\n","    Sample content preview: Ph.D Student Details\n","Ph.D (Student pursuing doctoral program till 2022-23)\n","Total Students\n","Full Time\n","186\n","Part Time\n","132\n","No. of Ph.D students graduated (including Integrated Ph.D)\n","2022-23\n","2021-22\n","2020-21...\n","    No valid values found for ug_4_years\n","    No valid values found for ug_5_years\n","    No valid values found for pg_2_years\n","    No valid values found for pg_3_years\n","    No valid values found for pg_integrated\n","    Some PG programs not found with primary patterns, trying line-by-line analysis...\n","  Accumulated student data so far: {'ug_4_years': 7073, 'ug_5_years': 0, 'pg_2_years': 84, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 7073, 'ug_5_years': 0, 'pg_2_years': 84, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 7073, 'ug_5_years': 0, 'pg_2_years': 84, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 7073, 'ug_5_years': 0, 'pg_2_years': 84, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 7073, 'ug_5_years': 0, 'pg_2_years': 84, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Found student section: PCS_FACILITIES\n","\n","=== DEBUGGING SECTION: PCS_FACILITIES ===\n","Section length: 430 characters\n","No obvious table structure found\n","\n","First 10 non-empty lines:\n","  1: PCS Facilities: Facilities of Physically Challenged Students\n","  2: 1. Do your institution buildings have Lifts/Ramps?\n","  3: Yes, more than 80% of the buildings\n","  4: 2. Do your institution have provision for walking aids, including wheelchairs and transportation from one building to another for\n","  5: handicapped students?\n","  6: Yes\n","  7: 3. Do your institution buildings have specially designed toilets for handicapped students?\n","  8: Yes, more than 80% of the buildings\n","\n","No PG program indicators found\n","==================================================\n","    Analyzing content length: 430 characters\n","    Sample content preview: PCS Facilities: Facilities of Physically Challenged Students\n","1. Do your institution buildings have Lifts/Ramps?\n","Yes, more than 80% of the buildings\n","2. Do your institution have provision for walking ai...\n","    No valid values found for ug_4_years\n","    No valid values found for ug_5_years\n","    No valid values found for pg_2_years\n","    No valid values found for pg_3_years\n","    No valid values found for pg_integrated\n","    Some PG programs not found with primary patterns, trying line-by-line analysis...\n","  Accumulated student data so far: {'ug_4_years': 7073, 'ug_5_years': 0, 'pg_2_years': 84, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 7073, 'ug_5_years': 0, 'pg_2_years': 84, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 7073, 'ug_5_years': 0, 'pg_2_years': 84, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 7073, 'ug_5_years': 0, 'pg_2_years': 84, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 7073, 'ug_5_years': 0, 'pg_2_years': 84, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Processing faculty section: FACULTY_DETAILS\n","\n","=== DEBUGGING SECTION: FACULTY_DETAILS ===\n","Section length: 37 characters\n","No obvious table structure found\n","\n","First 10 non-empty lines:\n","  1: Number of faculty members entered\n","  2: 591\n","\n","No PG program indicators found\n","==================================================\n","   Looking for pattern: INDEX -> Name...\n","    No valid index->name patterns found\n","  No faculty found in 'FACULTY_DETAILS', processing as normal content.\n","  Creating consolidated student strength point: {'ug_4_years': 7073, 'ug_5_years': 0, 'pg_2_years': 84, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 7157}\n","Created 12 points for Manipal University, Jaipur\n","Saved 12 points to Manipal University_ Jaipur.json (normalized)\n","  Created 12 points\n","\n","Processing file: Indian Institute of Technology _Indian School of Mines_ Dhanbad.txt\n","Processing: Indian Institute of Technology (Indian School of Mines) Dhanbad (IR-E-U-0205)\n","  Found student section: SANCTIONED_INTAKE\n","\n","=== DEBUGGING SECTION: SANCTIONED_INTAKE ===\n","Section length: 217 characters\n","Relevant lines found:\n","  Line 9: UG [4 Years Program(s)]\n","  Line 16: UG [5 Years Program(s)]\n","  Line 23: PG [2 Year Program(s)]\n","\n","PG Programs (2-Year/3-Year/Integrated/PG-Integrated) analysis:\n","  Line 23: PG [2 Year Program(s)]\n","  Line 24:   -> 596\n","  Line 25:   -> 680\n","==================================================\n","    Analyzing content length: 217 characters\n","    Sample content preview: Sanctioned (Approved) Intake\n","Academic Year\n","2022-23\n","2021-22\n","2020-21\n","2019-20\n","2018-19\n","2017-18\n","UG [4 Years Program(s)]\n","1028\n","1028\n","1028\n","869\n","-\n","-\n","UG [5 Years Program(s)]\n","97\n","97\n","97\n","83\n","96\n","-\n","PG [2 Year Program(s)...\n","    Pattern 1 for ug_4_years found TUPLE: Male=1028, Female=1028, Total=1028\n","    Pattern 2 for ug_4_years found TUPLE: Male=1028, Female=1028, Total=1028\n","    Pattern 3 for ug_4_years found TUPLE: Male=1028, Female=1028, Total=1028\n","    Pattern 4 for ug_4_years found SINGLE: 1028\n","    Final ug_4_years: 1028 students (from values: [1028, 1028, 1028, 1028])\n","    Pattern 1 for ug_5_years found TUPLE: Male=97, Female=97, Total=97\n","    Pattern 2 for ug_5_years found TUPLE: Male=97, Female=97, Total=97\n","    Pattern 3 for ug_5_years found TUPLE: Male=97, Female=97, Total=97\n","    Pattern 4 for ug_5_years found SINGLE: 97\n","    Final ug_5_years: 97 students (from values: [97, 97, 97, 97])\n","    Pattern 5 for pg_2_years found SINGLE: 596\n","    Pattern 6 for pg_2_years found SINGLE: 596\n","    Final pg_2_years: 596 students (from values: [596, 596])\n","    No valid values found for pg_3_years\n","    No valid values found for pg_integrated\n","    Some PG programs not found with primary patterns, trying line-by-line analysis...\n","    Calculated total students: 1721\n","  Accumulated student data so far: {'ug_4_years': 1028, 'ug_5_years': 0, 'pg_2_years': 0, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 1028, 'ug_5_years': 97, 'pg_2_years': 0, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 1028, 'ug_5_years': 97, 'pg_2_years': 596, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 1028, 'ug_5_years': 97, 'pg_2_years': 596, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 1028, 'ug_5_years': 97, 'pg_2_years': 596, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Found student section: STUDENT_STRENGTH\n","\n","=== DEBUGGING SECTION: STUDENT_STRENGTH ===\n","Section length: 901 characters\n","Relevant lines found:\n","  Line 1: Total Actual Student Strength (Program(s) Offered by your Institution)\n","  Line 2: (All programs\n","  Line 3: of all years)\n","  Line 52: UG [4 Years\n","  Line 53: Program(s)]\n","  Line 66: UG [5 Years\n","  Line 67: Program(s)]\n","  Line 80: PG [2 Year\n","  Line 81: Program(s)]\n","\n","PG Programs (2-Year/3-Year/Integrated/PG-Integrated) analysis:\n","  Line 80: PG [2 Year\n","  Line 81:   -> Program(s)]\n","  Line 82:   -> 566\n","==================================================\n","    Analyzing content length: 901 characters\n","    Sample content preview: Total Actual Student Strength (Program(s) Offered by your Institution)\n","(All programs\n","of all years)\n","No. of Male\n","Students\n","No. of Female\n","Students\n","Total Students\n","Within State\n","(Including male\n","& female)\n","Out...\n","    Pattern 1 for ug_4_years found TUPLE: Male=3003, Female=721, Total=3724\n","    Pattern 2 for ug_4_years found TUPLE: Male=3003, Female=721, Total=3724\n","    Pattern 3 for ug_4_years found TUPLE: Male=3003, Female=721, Total=3724\n","    Pattern 4 for ug_4_years found SINGLE: 3003\n","    Final ug_4_years: 3724 students (from values: [3724, 3724, 3724, 3003])\n","    Pattern 1 for ug_5_years found TUPLE: Male=357, Female=77, Total=434\n","    Pattern 2 for ug_5_years found TUPLE: Male=357, Female=77, Total=434\n","    Pattern 3 for ug_5_years found TUPLE: Male=357, Female=77, Total=434\n","    Pattern 4 for ug_5_years found SINGLE: 357\n","    Final ug_5_years: 434 students (from values: [434, 434, 434, 357])\n","    Pattern 1 for pg_2_years found TUPLE: Male=566, Female=102, Total=668\n","    Pattern 2 for pg_2_years found TUPLE: Male=566, Female=102, Total=668\n","    Pattern 3 for pg_2_years found TUPLE: Male=566, Female=102, Total=668\n","    Pattern 4 for pg_2_years found TUPLE: Male=566, Female=102, Total=668\n","    Pattern 5 for pg_2_years found SINGLE: 566\n","    Pattern 6 for pg_2_years found SINGLE: 566\n","    Final pg_2_years: 668 students (from values: [668, 668, 668, 668, 566, 566])\n","    No valid values found for pg_3_years\n","    No valid values found for pg_integrated\n","    Some PG programs not found with primary patterns, trying line-by-line analysis...\n","    Calculated total students: 4826\n","  Accumulated student data so far: {'ug_4_years': 3724, 'ug_5_years': 97, 'pg_2_years': 596, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 3724, 'ug_5_years': 434, 'pg_2_years': 596, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 3724, 'ug_5_years': 434, 'pg_2_years': 668, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 3724, 'ug_5_years': 434, 'pg_2_years': 668, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 3724, 'ug_5_years': 434, 'pg_2_years': 668, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Found student section: PLACEMENT_STUDIES\n","\n","=== DEBUGGING SECTION: PLACEMENT_STUDIES ===\n","Section length: 573 characters\n","Relevant lines found:\n","  Line 1: PG [2 Years Program(s)]: Placement & higher studies for previous 3 years\n","\n","PG Programs (2-Year/3-Year/Integrated/PG-Integrated) analysis:\n","  Line 1: PG [2 Years Program(s)]: Placement & higher studies for previous 3 years\n","  Line 2:   -> Academic Year\n","  Line 3:   -> No. of first year\n","==================================================\n","    Analyzing content length: 573 characters\n","    Sample content preview: PG [2 Years Program(s)]: Placement & higher studies for previous 3 years\n","Academic Year\n","No. of first year\n","students intake in the\n","year\n","No. of first year\n","students admitted in\n","the year\n","Academic Year\n","No. o...\n","    No valid values found for ug_4_years\n","    No valid values found for ug_5_years\n","    Pattern 5 for pg_2_years found SINGLE: 3\n","    Pattern 6 for pg_2_years found SINGLE: 3\n","    Final pg_2_years: 3 students (from values: [3, 3])\n","    No valid values found for pg_3_years\n","    No valid values found for pg_integrated\n","    Some PG programs not found with primary patterns, trying line-by-line analysis...\n","    Calculated total students: 3\n","  Accumulated student data so far: {'ug_4_years': 3724, 'ug_5_years': 434, 'pg_2_years': 668, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 3724, 'ug_5_years': 434, 'pg_2_years': 668, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 3724, 'ug_5_years': 434, 'pg_2_years': 668, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 3724, 'ug_5_years': 434, 'pg_2_years': 668, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 3724, 'ug_5_years': 434, 'pg_2_years': 668, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Found student section: PHD_DETAILS\n","\n","=== DEBUGGING SECTION: PHD_DETAILS ===\n","Section length: 241 characters\n","Relevant lines found:\n","  Line 2: Ph.D (Student pursuing doctoral program till 2022-23)\n","\n","No PG program indicators found\n","==================================================\n","    Analyzing content length: 241 characters\n","    Sample content preview: Ph.D Student Details\n","Ph.D (Student pursuing doctoral program till 2022-23)\n","Total Students\n","Full Time\n","834\n","Part Time\n","268\n","No. of Ph.D students graduated (including Integrated Ph.D)\n","2022-23\n","2021-22\n","2020-21...\n","    No valid values found for ug_4_years\n","    No valid values found for ug_5_years\n","    No valid values found for pg_2_years\n","    No valid values found for pg_3_years\n","    No valid values found for pg_integrated\n","    Some PG programs not found with primary patterns, trying line-by-line analysis...\n","  Accumulated student data so far: {'ug_4_years': 3724, 'ug_5_years': 434, 'pg_2_years': 668, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 3724, 'ug_5_years': 434, 'pg_2_years': 668, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 3724, 'ug_5_years': 434, 'pg_2_years': 668, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 3724, 'ug_5_years': 434, 'pg_2_years': 668, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 3724, 'ug_5_years': 434, 'pg_2_years': 668, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Found student section: PCS_FACILITIES\n","\n","=== DEBUGGING SECTION: PCS_FACILITIES ===\n","Section length: 430 characters\n","No obvious table structure found\n","\n","First 10 non-empty lines:\n","  1: PCS Facilities: Facilities of Physically Challenged Students\n","  2: 1. Do your institution buildings have Lifts/Ramps?\n","  3: Yes, more than 80% of the buildings\n","  4: 2. Do your institution have provision for walking aids, including wheelchairs and transportation from one building to another for\n","  5: handicapped students?\n","  6: Yes\n","  7: 3. Do your institution buildings have specially designed toilets for handicapped students?\n","  8: Yes, more than 80% of the buildings\n","\n","No PG program indicators found\n","==================================================\n","    Analyzing content length: 430 characters\n","    Sample content preview: PCS Facilities: Facilities of Physically Challenged Students\n","1. Do your institution buildings have Lifts/Ramps?\n","Yes, more than 80% of the buildings\n","2. Do your institution have provision for walking ai...\n","    No valid values found for ug_4_years\n","    No valid values found for ug_5_years\n","    No valid values found for pg_2_years\n","    No valid values found for pg_3_years\n","    No valid values found for pg_integrated\n","    Some PG programs not found with primary patterns, trying line-by-line analysis...\n","  Accumulated student data so far: {'ug_4_years': 3724, 'ug_5_years': 434, 'pg_2_years': 668, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 3724, 'ug_5_years': 434, 'pg_2_years': 668, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 3724, 'ug_5_years': 434, 'pg_2_years': 668, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 3724, 'ug_5_years': 434, 'pg_2_years': 668, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 3724, 'ug_5_years': 434, 'pg_2_years': 668, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Processing faculty section: FACULTY_DETAILS\n","\n","=== DEBUGGING SECTION: FACULTY_DETAILS ===\n","Section length: 37 characters\n","No obvious table structure found\n","\n","First 10 non-empty lines:\n","  1: Number of faculty members entered\n","  2: 414\n","\n","No PG program indicators found\n","==================================================\n","   Looking for pattern: INDEX -> Name...\n","    No valid index->name patterns found\n","  No faculty found in 'FACULTY_DETAILS', processing as normal content.\n","  Creating consolidated student strength point: {'ug_4_years': 3724, 'ug_5_years': 434, 'pg_2_years': 668, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 4826}\n","Created 12 points for Indian Institute of Technology (Indian School of Mines) Dhanbad\n","Saved 12 points to Indian Institute of Technology _Indian School of Mines_ Dhanbad.json (normalized)\n","  Created 12 points\n","\n","Processing file: Rajiv Gandhi Institute of Petroleum Technology.txt\n","Processing: Rajiv Gandhi Institute of Petroleum Technology (IR-E-U-0535)\n","  Found student section: SANCTIONED_INTAKE\n","\n","=== DEBUGGING SECTION: SANCTIONED_INTAKE ===\n","Section length: 170 characters\n","Relevant lines found:\n","  Line 9: UG [4 Years Program(s)]\n","  Line 16: PG [2 Year Program(s)]\n","\n","PG Programs (2-Year/3-Year/Integrated/PG-Integrated) analysis:\n","  Line 16: PG [2 Year Program(s)]\n","  Line 17:   -> 7\n","  Line 18:   -> 44\n","==================================================\n","    Analyzing content length: 170 characters\n","    Sample content preview: Sanctioned (Approved) Intake\n","Academic Year\n","2022-23\n","2021-22\n","2020-21\n","2019-20\n","2018-19\n","2017-18\n","UG [4 Years Program(s)]\n","409\n","207\n","182\n","128\n","-\n","-\n","PG [2 Year Program(s)]\n","7\n","44\n","-\n","-\n","-\n","-...\n","    Pattern 1 for ug_4_years found TUPLE: Male=409, Female=207, Total=182\n","    Pattern 2 for ug_4_years found TUPLE: Male=409, Female=207, Total=182\n","    Pattern 3 for ug_4_years found TUPLE: Male=409, Female=207, Total=182\n","    Pattern 4 for ug_4_years found SINGLE: 409\n","    Final ug_4_years: 409 students (from values: [182, 182, 182, 409])\n","    No valid values found for ug_5_years\n","    Pattern 5 for pg_2_years found SINGLE: 7\n","    Pattern 6 for pg_2_years found SINGLE: 7\n","    Final pg_2_years: 7 students (from values: [7, 7])\n","    No valid values found for pg_3_years\n","    No valid values found for pg_integrated\n","    Some PG programs not found with primary patterns, trying line-by-line analysis...\n","    Calculated total students: 416\n","  Accumulated student data so far: {'ug_4_years': 409, 'ug_5_years': 0, 'pg_2_years': 0, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 409, 'ug_5_years': 0, 'pg_2_years': 0, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 409, 'ug_5_years': 0, 'pg_2_years': 7, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 409, 'ug_5_years': 0, 'pg_2_years': 7, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 409, 'ug_5_years': 0, 'pg_2_years': 7, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Found student section: STUDENT_STRENGTH\n","\n","=== DEBUGGING SECTION: STUDENT_STRENGTH ===\n","Section length: 828 characters\n","Relevant lines found:\n","  Line 1: Total Actual Student Strength (Program(s) Offered by your Institution)\n","  Line 2: (All programs\n","  Line 3: of all years)\n","  Line 52: UG [4 Years\n","  Line 53: Program(s)]\n","  Line 66: PG [2 Year\n","  Line 67: Program(s)]\n","\n","PG Programs (2-Year/3-Year/Integrated/PG-Integrated) analysis:\n","  Line 66: PG [2 Year\n","  Line 67:   -> Program(s)]\n","  Line 68:   -> 40\n","==================================================\n","    Analyzing content length: 828 characters\n","    Sample content preview: Total Actual Student Strength (Program(s) Offered by your Institution)\n","(All programs\n","of all years)\n","No. of Male\n","Students\n","No. of Female\n","Students\n","Total Students\n","Within State\n","(Including male\n","& female)\n","Out...\n","    Pattern 1 for ug_4_years found TUPLE: Male=827, Female=99, Total=926\n","    Pattern 2 for ug_4_years found TUPLE: Male=827, Female=99, Total=926\n","    Pattern 3 for ug_4_years found TUPLE: Male=827, Female=99, Total=926\n","    Pattern 4 for ug_4_years found SINGLE: 827\n","    Final ug_4_years: 926 students (from values: [926, 926, 926, 827])\n","    No valid values found for ug_5_years\n","    Pattern 1 for pg_2_years found TUPLE: Male=40, Female=11, Total=51\n","    Pattern 2 for pg_2_years found TUPLE: Male=40, Female=11, Total=51\n","    Pattern 3 for pg_2_years found TUPLE: Male=40, Female=11, Total=51\n","    Pattern 4 for pg_2_years found TUPLE: Male=40, Female=11, Total=51\n","    Pattern 5 for pg_2_years found SINGLE: 40\n","    Pattern 6 for pg_2_years found SINGLE: 40\n","    Final pg_2_years: 51 students (from values: [51, 51, 51, 51, 40, 40])\n","    No valid values found for pg_3_years\n","    No valid values found for pg_integrated\n","    Some PG programs not found with primary patterns, trying line-by-line analysis...\n","    Calculated total students: 977\n","  Accumulated student data so far: {'ug_4_years': 926, 'ug_5_years': 0, 'pg_2_years': 7, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 926, 'ug_5_years': 0, 'pg_2_years': 7, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 926, 'ug_5_years': 0, 'pg_2_years': 51, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 926, 'ug_5_years': 0, 'pg_2_years': 51, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 926, 'ug_5_years': 0, 'pg_2_years': 51, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Found student section: PLACEMENT_STUDIES\n","\n","=== DEBUGGING SECTION: PLACEMENT_STUDIES ===\n","Section length: 553 characters\n","Relevant lines found:\n","  Line 1: PG [2 Years Program(s)]: Placement & higher studies for previous 3 years\n","\n","PG Programs (2-Year/3-Year/Integrated/PG-Integrated) analysis:\n","  Line 1: PG [2 Years Program(s)]: Placement & higher studies for previous 3 years\n","  Line 2:   -> Academic Year\n","  Line 3:   -> No. of first year\n","==================================================\n","    Analyzing content length: 553 characters\n","    Sample content preview: PG [2 Years Program(s)]: Placement & higher studies for previous 3 years\n","Academic Year\n","No. of first year\n","students intake in the\n","year\n","No. of first year\n","students admitted in\n","the year\n","Academic Year\n","No. o...\n","    No valid values found for ug_4_years\n","    No valid values found for ug_5_years\n","    Pattern 5 for pg_2_years found SINGLE: 3\n","    Pattern 6 for pg_2_years found SINGLE: 3\n","    Final pg_2_years: 3 students (from values: [3, 3])\n","    No valid values found for pg_3_years\n","    No valid values found for pg_integrated\n","    Some PG programs not found with primary patterns, trying line-by-line analysis...\n","    Calculated total students: 3\n","  Accumulated student data so far: {'ug_4_years': 926, 'ug_5_years': 0, 'pg_2_years': 51, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 926, 'ug_5_years': 0, 'pg_2_years': 51, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 926, 'ug_5_years': 0, 'pg_2_years': 51, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 926, 'ug_5_years': 0, 'pg_2_years': 51, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 926, 'ug_5_years': 0, 'pg_2_years': 51, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Found student section: PHD_DETAILS\n","\n","=== DEBUGGING SECTION: PHD_DETAILS ===\n","Section length: 234 characters\n","Relevant lines found:\n","  Line 2: Ph.D (Student pursuing doctoral program till 2022-23)\n","\n","No PG program indicators found\n","==================================================\n","    Analyzing content length: 234 characters\n","    Sample content preview: Ph.D Student Details\n","Ph.D (Student pursuing doctoral program till 2022-23)\n","Total Students\n","Full Time\n","130\n","Part Time\n","53\n","No. of Ph.D students graduated (including Integrated Ph.D)\n","2022-23\n","2021-22\n","2020-21\n","...\n","    No valid values found for ug_4_years\n","    No valid values found for ug_5_years\n","    No valid values found for pg_2_years\n","    No valid values found for pg_3_years\n","    No valid values found for pg_integrated\n","    Some PG programs not found with primary patterns, trying line-by-line analysis...\n","  Accumulated student data so far: {'ug_4_years': 926, 'ug_5_years': 0, 'pg_2_years': 51, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 926, 'ug_5_years': 0, 'pg_2_years': 51, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 926, 'ug_5_years': 0, 'pg_2_years': 51, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 926, 'ug_5_years': 0, 'pg_2_years': 51, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 926, 'ug_5_years': 0, 'pg_2_years': 51, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Found student section: PCS_FACILITIES\n","\n","=== DEBUGGING SECTION: PCS_FACILITIES ===\n","Section length: 430 characters\n","No obvious table structure found\n","\n","First 10 non-empty lines:\n","  1: PCS Facilities: Facilities of Physically Challenged Students\n","  2: 1. Do your institution buildings have Lifts/Ramps?\n","  3: Yes, more than 80% of the buildings\n","  4: 2. Do your institution have provision for walking aids, including wheelchairs and transportation from one building to another for\n","  5: handicapped students?\n","  6: Yes\n","  7: 3. Do your institution buildings have specially designed toilets for handicapped students?\n","  8: Yes, more than 80% of the buildings\n","\n","No PG program indicators found\n","==================================================\n","    Analyzing content length: 430 characters\n","    Sample content preview: PCS Facilities: Facilities of Physically Challenged Students\n","1. Do your institution buildings have Lifts/Ramps?\n","Yes, more than 80% of the buildings\n","2. Do your institution have provision for walking ai...\n","    No valid values found for ug_4_years\n","    No valid values found for ug_5_years\n","    No valid values found for pg_2_years\n","    No valid values found for pg_3_years\n","    No valid values found for pg_integrated\n","    Some PG programs not found with primary patterns, trying line-by-line analysis...\n","  Accumulated student data so far: {'ug_4_years': 926, 'ug_5_years': 0, 'pg_2_years': 51, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 926, 'ug_5_years': 0, 'pg_2_years': 51, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 926, 'ug_5_years': 0, 'pg_2_years': 51, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 926, 'ug_5_years': 0, 'pg_2_years': 51, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 926, 'ug_5_years': 0, 'pg_2_years': 51, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Processing faculty section: FACULTY_DETAILS\n","\n","=== DEBUGGING SECTION: FACULTY_DETAILS ===\n","Section length: 37 characters\n","No obvious table structure found\n","\n","First 10 non-empty lines:\n","  1: Number of faculty members entered\n","  2: 118\n","\n","No PG program indicators found\n","==================================================\n","   Looking for pattern: INDEX -> Name...\n","    No valid index->name patterns found\n","  No faculty found in 'FACULTY_DETAILS', processing as normal content.\n","  Creating consolidated student strength point: {'ug_4_years': 926, 'ug_5_years': 0, 'pg_2_years': 51, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 977}\n","Created 12 points for Rajiv Gandhi Institute of Petroleum Technology\n","Saved 12 points to Rajiv Gandhi Institute of Petroleum Technology.json (normalized)\n","  Created 12 points\n","\n","Processing file: IIT Madras.txt\n","Processing: Indian Institute of Technology Madras (IR-E-U-0456)\n","  Found student section: SANCTIONED_INTAKE\n","\n","=== DEBUGGING SECTION: SANCTIONED_INTAKE ===\n","Section length: 260 characters\n","Relevant lines found:\n","  Line 9: UG [4 Years Program(s)]\n","  Line 16: UG [5 Years Program(s)]\n","  Line 23: PG [2 Year Program(s)]\n","  Line 30: PG [3 Year Program(s)]\n","\n","PG Programs (2-Year/3-Year/Integrated/PG-Integrated) analysis:\n","  Line 23: PG [2 Year Program(s)]\n","  Line 24:   -> 670\n","  Line 25:   -> 511\n","  Line 30: PG [3 Year Program(s)]\n","  Line 31:   -> 245\n","  Line 32:   -> 245\n","==================================================\n","    Analyzing content length: 260 characters\n","    Sample content preview: Sanctioned (Approved) Intake\n","Academic Year\n","2022-23\n","2021-22\n","2020-21\n","2019-20\n","2018-19\n","2017-18\n","UG [4 Years Program(s)]\n","877\n","877\n","877\n","762\n","-\n","-\n","UG [5 Years Program(s)]\n","177\n","177\n","177\n","157\n","358\n","-\n","PG [2 Year Program(...\n","    Pattern 1 for ug_4_years found TUPLE: Male=877, Female=877, Total=877\n","    Pattern 2 for ug_4_years found TUPLE: Male=877, Female=877, Total=877\n","    Pattern 3 for ug_4_years found TUPLE: Male=877, Female=877, Total=877\n","    Pattern 4 for ug_4_years found SINGLE: 877\n","    Final ug_4_years: 877 students (from values: [877, 877, 877, 877])\n","    Pattern 1 for ug_5_years found TUPLE: Male=177, Female=177, Total=177\n","    Pattern 2 for ug_5_years found TUPLE: Male=177, Female=177, Total=177\n","    Pattern 3 for ug_5_years found TUPLE: Male=177, Female=177, Total=177\n","    Pattern 4 for ug_5_years found SINGLE: 177\n","    Final ug_5_years: 177 students (from values: [177, 177, 177, 177])\n","    Pattern 5 for pg_2_years found SINGLE: 670\n","    Pattern 6 for pg_2_years found SINGLE: 670\n","    Final pg_2_years: 670 students (from values: [670, 670])\n","    Pattern 1 for pg_3_years found TUPLE: Male=245, Female=245, Total=245\n","    Pattern 2 for pg_3_years found TUPLE: Male=245, Female=245, Total=245\n","    Pattern 3 for pg_3_years found TUPLE: Male=245, Female=245, Total=245\n","    Pattern 4 for pg_3_years found SINGLE: 245\n","    Final pg_3_years: 245 students (from values: [245, 245, 245, 245])\n","    No valid values found for pg_integrated\n","    Some PG programs not found with primary patterns, trying line-by-line analysis...\n","    Calculated total students: 1969\n","  Accumulated student data so far: {'ug_4_years': 877, 'ug_5_years': 0, 'pg_2_years': 0, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 877, 'ug_5_years': 177, 'pg_2_years': 0, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 877, 'ug_5_years': 177, 'pg_2_years': 670, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 877, 'ug_5_years': 177, 'pg_2_years': 670, 'pg_3_years': 245, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 877, 'ug_5_years': 177, 'pg_2_years': 670, 'pg_3_years': 245, 'pg_integrated': 0, 'total_students': 0}\n","  Found student section: STUDENT_STRENGTH\n","\n","=== DEBUGGING SECTION: STUDENT_STRENGTH ===\n","Section length: 981 characters\n","Relevant lines found:\n","  Line 1: Total Actual Student Strength (Program(s) Offered by your Institution)\n","  Line 2: (All programs\n","  Line 3: of all years)\n","  Line 52: UG [4 Years\n","  Line 53: Program(s)]\n","  Line 66: UG [5 Years\n","  Line 67: Program(s)]\n","  Line 80: PG [2 Year\n","  Line 81: Program(s)]\n","  Line 94: PG [3 Year\n","  Line 95: Program(s)]\n","\n","PG Programs (2-Year/3-Year/Integrated/PG-Integrated) analysis:\n","  Line 80: PG [2 Year\n","  Line 81:   -> Program(s)]\n","  Line 82:   -> 1026\n","  Line 94: PG [3 Year\n","  Line 95:   -> Program(s)]\n","  Line 96:   -> 416\n","==================================================\n","    Analyzing content length: 981 characters\n","    Sample content preview: Total Actual Student Strength (Program(s) Offered by your Institution)\n","(All programs\n","of all years)\n","No. of Male\n","Students\n","No. of Female\n","Students\n","Total Students\n","Within State\n","(Including male\n","& female)\n","Out...\n","    Pattern 1 for ug_4_years found TUPLE: Male=2739, Female=701, Total=3440\n","    Pattern 2 for ug_4_years found TUPLE: Male=2739, Female=701, Total=3440\n","    Pattern 3 for ug_4_years found TUPLE: Male=2739, Female=701, Total=3440\n","    Pattern 4 for ug_4_years found SINGLE: 2739\n","    Final ug_4_years: 3440 students (from values: [3440, 3440, 3440, 2739])\n","    Pattern 1 for ug_5_years found TUPLE: Male=1201, Female=268, Total=1469\n","    Pattern 2 for ug_5_years found TUPLE: Male=1201, Female=268, Total=1469\n","    Pattern 3 for ug_5_years found TUPLE: Male=1201, Female=268, Total=1469\n","    Pattern 4 for ug_5_years found SINGLE: 1201\n","    Final ug_5_years: 1469 students (from values: [1469, 1469, 1469, 1201])\n","    Pattern 1 for pg_2_years found TUPLE: Male=1026, Female=179, Total=1205\n","    Pattern 2 for pg_2_years found TUPLE: Male=1026, Female=179, Total=1205\n","    Pattern 3 for pg_2_years found TUPLE: Male=1026, Female=179, Total=1205\n","    Pattern 4 for pg_2_years found TUPLE: Male=1026, Female=179, Total=1205\n","    Pattern 5 for pg_2_years found SINGLE: 1026\n","    Pattern 6 for pg_2_years found SINGLE: 1026\n","    Final pg_2_years: 1205 students (from values: [1205, 1205, 1205, 1205, 1026, 1026])\n","    Pattern 1 for pg_3_years found TUPLE: Male=416, Female=82, Total=498\n","    Pattern 2 for pg_3_years found TUPLE: Male=416, Female=82, Total=498\n","    Pattern 3 for pg_3_years found TUPLE: Male=416, Female=82, Total=498\n","    Pattern 4 for pg_3_years found SINGLE: 416\n","    Final pg_3_years: 498 students (from values: [498, 498, 498, 416])\n","    No valid values found for pg_integrated\n","    Some PG programs not found with primary patterns, trying line-by-line analysis...\n","    Calculated total students: 6612\n","  Accumulated student data so far: {'ug_4_years': 3440, 'ug_5_years': 177, 'pg_2_years': 670, 'pg_3_years': 245, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 3440, 'ug_5_years': 1469, 'pg_2_years': 670, 'pg_3_years': 245, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 3440, 'ug_5_years': 1469, 'pg_2_years': 1205, 'pg_3_years': 245, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 3440, 'ug_5_years': 1469, 'pg_2_years': 1205, 'pg_3_years': 498, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 3440, 'ug_5_years': 1469, 'pg_2_years': 1205, 'pg_3_years': 498, 'pg_integrated': 0, 'total_students': 0}\n","  Found student section: PLACEMENT_STUDIES\n","\n","=== DEBUGGING SECTION: PLACEMENT_STUDIES ===\n","Section length: 659 characters\n","Relevant lines found:\n","  Line 1: PG [3 Years Program(s)]: Placement & higher studies for previous 3 years\n","\n","PG Programs (2-Year/3-Year/Integrated/PG-Integrated) analysis:\n","  Line 1: PG [3 Years Program(s)]: Placement & higher studies for previous 3 years\n","  Line 2:   -> Academic Year\n","  Line 3:   -> No. of first year\n","==================================================\n","    Analyzing content length: 659 characters\n","    Sample content preview: PG [3 Years Program(s)]: Placement & higher studies for previous 3 years\n","Academic Year\n","No. of first year\n","students intake in the\n","year\n","No. of first year\n","students admitted in\n","the year\n","Academic Year\n","No. o...\n","    No valid values found for ug_4_years\n","    No valid values found for ug_5_years\n","    No valid values found for pg_2_years\n","    Pattern 4 for pg_3_years found SINGLE: 3\n","    Final pg_3_years: 3 students (from values: [3])\n","    No valid values found for pg_integrated\n","    Some PG programs not found with primary patterns, trying line-by-line analysis...\n","    Calculated total students: 3\n","  Accumulated student data so far: {'ug_4_years': 3440, 'ug_5_years': 1469, 'pg_2_years': 1205, 'pg_3_years': 498, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 3440, 'ug_5_years': 1469, 'pg_2_years': 1205, 'pg_3_years': 498, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 3440, 'ug_5_years': 1469, 'pg_2_years': 1205, 'pg_3_years': 498, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 3440, 'ug_5_years': 1469, 'pg_2_years': 1205, 'pg_3_years': 498, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 3440, 'ug_5_years': 1469, 'pg_2_years': 1205, 'pg_3_years': 498, 'pg_integrated': 0, 'total_students': 0}\n","  Found student section: PHD_DETAILS\n","\n","=== DEBUGGING SECTION: PHD_DETAILS ===\n","Section length: 238 characters\n","Relevant lines found:\n","  Line 2: Ph.D (Student pursuing doctoral program till 2022-23)\n","\n","No PG program indicators found\n","==================================================\n","    Analyzing content length: 238 characters\n","    Sample content preview: Ph.D Student Details\n","Ph.D (Student pursuing doctoral program till 2022-23)\n","Total Students\n","Full Time\n","2529\n","Part Time\n","45\n","No. of Ph.D students graduated (including Integrated Ph.D)\n","2022-23\n","2021-22\n","2020-21...\n","    No valid values found for ug_4_years\n","    No valid values found for ug_5_years\n","    No valid values found for pg_2_years\n","    No valid values found for pg_3_years\n","    No valid values found for pg_integrated\n","    Some PG programs not found with primary patterns, trying line-by-line analysis...\n","  Accumulated student data so far: {'ug_4_years': 3440, 'ug_5_years': 1469, 'pg_2_years': 1205, 'pg_3_years': 498, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 3440, 'ug_5_years': 1469, 'pg_2_years': 1205, 'pg_3_years': 498, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 3440, 'ug_5_years': 1469, 'pg_2_years': 1205, 'pg_3_years': 498, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 3440, 'ug_5_years': 1469, 'pg_2_years': 1205, 'pg_3_years': 498, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 3440, 'ug_5_years': 1469, 'pg_2_years': 1205, 'pg_3_years': 498, 'pg_integrated': 0, 'total_students': 0}\n","  Found student section: PCS_FACILITIES\n","\n","=== DEBUGGING SECTION: PCS_FACILITIES ===\n","Section length: 430 characters\n","No obvious table structure found\n","\n","First 10 non-empty lines:\n","  1: PCS Facilities: Facilities of Physically Challenged Students\n","  2: 1. Do your institution buildings have Lifts/Ramps?\n","  3: Yes, more than 80% of the buildings\n","  4: 2. Do your institution have provision for walking aids, including wheelchairs and transportation from one building to another for\n","  5: handicapped students?\n","  6: Yes\n","  7: 3. Do your institution buildings have specially designed toilets for handicapped students?\n","  8: Yes, more than 80% of the buildings\n","\n","No PG program indicators found\n","==================================================\n","    Analyzing content length: 430 characters\n","    Sample content preview: PCS Facilities: Facilities of Physically Challenged Students\n","1. Do your institution buildings have Lifts/Ramps?\n","Yes, more than 80% of the buildings\n","2. Do your institution have provision for walking ai...\n","    No valid values found for ug_4_years\n","    No valid values found for ug_5_years\n","    No valid values found for pg_2_years\n","    No valid values found for pg_3_years\n","    No valid values found for pg_integrated\n","    Some PG programs not found with primary patterns, trying line-by-line analysis...\n","  Accumulated student data so far: {'ug_4_years': 3440, 'ug_5_years': 1469, 'pg_2_years': 1205, 'pg_3_years': 498, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 3440, 'ug_5_years': 1469, 'pg_2_years': 1205, 'pg_3_years': 498, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 3440, 'ug_5_years': 1469, 'pg_2_years': 1205, 'pg_3_years': 498, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 3440, 'ug_5_years': 1469, 'pg_2_years': 1205, 'pg_3_years': 498, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 3440, 'ug_5_years': 1469, 'pg_2_years': 1205, 'pg_3_years': 498, 'pg_integrated': 0, 'total_students': 0}\n","  Processing faculty section: FACULTY_DETAILS\n","\n","=== DEBUGGING SECTION: FACULTY_DETAILS ===\n","Section length: 37 characters\n","No obvious table structure found\n","\n","First 10 non-empty lines:\n","  1: Number of faculty members entered\n","  2: 674\n","\n","No PG program indicators found\n","==================================================\n","   Looking for pattern: INDEX -> Name...\n","    No valid index->name patterns found\n","  No faculty found in 'FACULTY_DETAILS', processing as normal content.\n","  Creating consolidated student strength point: {'ug_4_years': 3440, 'ug_5_years': 1469, 'pg_2_years': 1205, 'pg_3_years': 498, 'pg_integrated': 0, 'total_students': 6612}\n","Created 12 points for Indian Institute of Technology Madras\n","Saved 12 points to IIT Madras.json (normalized)\n","  Created 12 points\n","\n","Processing file: Sri Krishna College of Engineering and Technology.txt\n","Processing: Sri Krishna College of Engineering and Technology (IR-E-C-36995)\n","  Found student section: SANCTIONED_INTAKE\n","\n","=== DEBUGGING SECTION: SANCTIONED_INTAKE ===\n","Section length: 215 characters\n","Relevant lines found:\n","  Line 9: UG [4 Years Program(s)]\n","  Line 16: UG [5 Years Program(s)]\n","  Line 23: PG [2 Year Program(s)]\n","\n","PG Programs (2-Year/3-Year/Integrated/PG-Integrated) analysis:\n","  Line 23: PG [2 Year Program(s)]\n","  Line 24:   -> 60\n","  Line 25:   -> 78\n","==================================================\n","    Analyzing content length: 215 characters\n","    Sample content preview: Sanctioned (Approved) Intake\n","Academic Year\n","2022-23\n","2021-22\n","2020-21\n","2019-20\n","2018-19\n","2017-18\n","UG [4 Years Program(s)]\n","1362\n","1080\n","1140\n","1140\n","-\n","-\n","UG [5 Years Program(s)]\n","60\n","60\n","60\n","60\n","0\n","-\n","PG [2 Year Program(s)...\n","    Pattern 1 for ug_4_years found TUPLE: Male=1362, Female=1080, Total=1140\n","    Pattern 2 for ug_4_years found TUPLE: Male=1362, Female=1080, Total=1140\n","    Pattern 3 for ug_4_years found TUPLE: Male=1362, Female=1080, Total=1140\n","    Pattern 4 for ug_4_years found SINGLE: 1362\n","    Final ug_4_years: 1362 students (from values: [1140, 1140, 1140, 1362])\n","    Pattern 1 for ug_5_years found TUPLE: Male=60, Female=60, Total=60\n","    Pattern 2 for ug_5_years found TUPLE: Male=60, Female=60, Total=60\n","    Pattern 3 for ug_5_years found TUPLE: Male=60, Female=60, Total=60\n","    Pattern 4 for ug_5_years found SINGLE: 60\n","    Final ug_5_years: 60 students (from values: [60, 60, 60, 60])\n","    Pattern 5 for pg_2_years found SINGLE: 60\n","    Pattern 6 for pg_2_years found SINGLE: 60\n","    Final pg_2_years: 60 students (from values: [60, 60])\n","    No valid values found for pg_3_years\n","    No valid values found for pg_integrated\n","    Some PG programs not found with primary patterns, trying line-by-line analysis...\n","    Calculated total students: 1482\n","  Accumulated student data so far: {'ug_4_years': 1362, 'ug_5_years': 0, 'pg_2_years': 0, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 1362, 'ug_5_years': 60, 'pg_2_years': 0, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 1362, 'ug_5_years': 60, 'pg_2_years': 60, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 1362, 'ug_5_years': 60, 'pg_2_years': 60, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 1362, 'ug_5_years': 60, 'pg_2_years': 60, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Found student section: STUDENT_STRENGTH\n","\n","=== DEBUGGING SECTION: STUDENT_STRENGTH ===\n","Section length: 895 characters\n","Relevant lines found:\n","  Line 1: Total Actual Student Strength (Program(s) Offered by your Institution)\n","  Line 2: (All programs\n","  Line 3: of all years)\n","  Line 52: UG [4 Years\n","  Line 53: Program(s)]\n","  Line 66: UG [5 Years\n","  Line 67: Program(s)]\n","  Line 80: PG [2 Year\n","  Line 81: Program(s)]\n","\n","PG Programs (2-Year/3-Year/Integrated/PG-Integrated) analysis:\n","  Line 80: PG [2 Year\n","  Line 81:   -> Program(s)]\n","  Line 82:   -> 34\n","==================================================\n","    Analyzing content length: 895 characters\n","    Sample content preview: Total Actual Student Strength (Program(s) Offered by your Institution)\n","(All programs\n","of all years)\n","No. of Male\n","Students\n","No. of Female\n","Students\n","Total Students\n","Within State\n","(Including male\n","& female)\n","Out...\n","    Pattern 1 for ug_4_years found TUPLE: Male=3593, Female=1220, Total=4813\n","    Pattern 2 for ug_4_years found TUPLE: Male=3593, Female=1220, Total=4813\n","    Pattern 3 for ug_4_years found TUPLE: Male=3593, Female=1220, Total=4813\n","    Pattern 4 for ug_4_years found SINGLE: 3593\n","    Final ug_4_years: 4813 students (from values: [4813, 4813, 4813, 3593])\n","    Pattern 1 for ug_5_years found TUPLE: Male=134, Female=62, Total=196\n","    Pattern 2 for ug_5_years found TUPLE: Male=134, Female=62, Total=196\n","    Pattern 3 for ug_5_years found TUPLE: Male=134, Female=62, Total=196\n","    Pattern 4 for ug_5_years found SINGLE: 134\n","    Final ug_5_years: 196 students (from values: [196, 196, 196, 134])\n","    Pattern 1 for pg_2_years found TUPLE: Male=34, Female=58, Total=92\n","    Pattern 2 for pg_2_years found TUPLE: Male=34, Female=58, Total=92\n","    Pattern 3 for pg_2_years found TUPLE: Male=34, Female=58, Total=92\n","    Pattern 4 for pg_2_years found TUPLE: Male=34, Female=58, Total=92\n","    Pattern 5 for pg_2_years found SINGLE: 34\n","    Pattern 6 for pg_2_years found SINGLE: 34\n","    Final pg_2_years: 92 students (from values: [92, 92, 92, 92, 34, 34])\n","    No valid values found for pg_3_years\n","    No valid values found for pg_integrated\n","    Some PG programs not found with primary patterns, trying line-by-line analysis...\n","    Calculated total students: 5101\n","  Accumulated student data so far: {'ug_4_years': 4813, 'ug_5_years': 60, 'pg_2_years': 60, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 4813, 'ug_5_years': 196, 'pg_2_years': 60, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 4813, 'ug_5_years': 196, 'pg_2_years': 92, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 4813, 'ug_5_years': 196, 'pg_2_years': 92, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 4813, 'ug_5_years': 196, 'pg_2_years': 92, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Found student section: PLACEMENT_STUDIES\n","\n","=== DEBUGGING SECTION: PLACEMENT_STUDIES ===\n","Section length: 533 characters\n","Relevant lines found:\n","  Line 1: PG [2 Years Program(s)]: Placement & higher studies for previous 3 years\n","\n","PG Programs (2-Year/3-Year/Integrated/PG-Integrated) analysis:\n","  Line 1: PG [2 Years Program(s)]: Placement & higher studies for previous 3 years\n","  Line 2:   -> Academic Year\n","  Line 3:   -> No. of first year\n","==================================================\n","    Analyzing content length: 533 characters\n","    Sample content preview: PG [2 Years Program(s)]: Placement & higher studies for previous 3 years\n","Academic Year\n","No. of first year\n","students intake in the\n","year\n","No. of first year\n","students admitted in\n","the year\n","Academic Year\n","No. o...\n","    No valid values found for ug_4_years\n","    No valid values found for ug_5_years\n","    Pattern 5 for pg_2_years found SINGLE: 3\n","    Pattern 6 for pg_2_years found SINGLE: 3\n","    Final pg_2_years: 3 students (from values: [3, 3])\n","    No valid values found for pg_3_years\n","    No valid values found for pg_integrated\n","    Some PG programs not found with primary patterns, trying line-by-line analysis...\n","    Calculated total students: 3\n","  Accumulated student data so far: {'ug_4_years': 4813, 'ug_5_years': 196, 'pg_2_years': 92, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 4813, 'ug_5_years': 196, 'pg_2_years': 92, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 4813, 'ug_5_years': 196, 'pg_2_years': 92, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 4813, 'ug_5_years': 196, 'pg_2_years': 92, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 4813, 'ug_5_years': 196, 'pg_2_years': 92, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Found student section: PHD_DETAILS\n","\n","=== DEBUGGING SECTION: PHD_DETAILS ===\n","Section length: 233 characters\n","Relevant lines found:\n","  Line 2: Ph.D (Student pursuing doctoral program till 2022-23)\n","\n","No PG program indicators found\n","==================================================\n","    Analyzing content length: 233 characters\n","    Sample content preview: Ph.D Student Details\n","Ph.D (Student pursuing doctoral program till 2022-23)\n","Total Students\n","Full Time\n","18\n","Part Time\n","155\n","No. of Ph.D students graduated (including Integrated Ph.D)\n","2022-23\n","2021-22\n","2020-21\n","...\n","    No valid values found for ug_4_years\n","    No valid values found for ug_5_years\n","    No valid values found for pg_2_years\n","    No valid values found for pg_3_years\n","    No valid values found for pg_integrated\n","    Some PG programs not found with primary patterns, trying line-by-line analysis...\n","  Accumulated student data so far: {'ug_4_years': 4813, 'ug_5_years': 196, 'pg_2_years': 92, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 4813, 'ug_5_years': 196, 'pg_2_years': 92, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 4813, 'ug_5_years': 196, 'pg_2_years': 92, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 4813, 'ug_5_years': 196, 'pg_2_years': 92, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 4813, 'ug_5_years': 196, 'pg_2_years': 92, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Found student section: PCS_FACILITIES\n","\n","=== DEBUGGING SECTION: PCS_FACILITIES ===\n","Section length: 430 characters\n","No obvious table structure found\n","\n","First 10 non-empty lines:\n","  1: PCS Facilities: Facilities of Physically Challenged Students\n","  2: 1. Do your institution buildings have Lifts/Ramps?\n","  3: Yes, more than 80% of the buildings\n","  4: 2. Do your institution have provision for walking aids, including wheelchairs and transportation from one building to another for\n","  5: handicapped students?\n","  6: Yes\n","  7: 3. Do your institution buildings have specially designed toilets for handicapped students?\n","  8: Yes, more than 80% of the buildings\n","\n","No PG program indicators found\n","==================================================\n","    Analyzing content length: 430 characters\n","    Sample content preview: PCS Facilities: Facilities of Physically Challenged Students\n","1. Do your institution buildings have Lifts/Ramps?\n","Yes, more than 80% of the buildings\n","2. Do your institution have provision for walking ai...\n","    No valid values found for ug_4_years\n","    No valid values found for ug_5_years\n","    No valid values found for pg_2_years\n","    No valid values found for pg_3_years\n","    No valid values found for pg_integrated\n","    Some PG programs not found with primary patterns, trying line-by-line analysis...\n","  Accumulated student data so far: {'ug_4_years': 4813, 'ug_5_years': 196, 'pg_2_years': 92, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 4813, 'ug_5_years': 196, 'pg_2_years': 92, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 4813, 'ug_5_years': 196, 'pg_2_years': 92, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 4813, 'ug_5_years': 196, 'pg_2_years': 92, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 4813, 'ug_5_years': 196, 'pg_2_years': 92, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Processing faculty section: FACULTY_DETAILS\n","\n","=== DEBUGGING SECTION: FACULTY_DETAILS ===\n","Section length: 37 characters\n","No obvious table structure found\n","\n","First 10 non-empty lines:\n","  1: Number of faculty members entered\n","  2: 346\n","\n","No PG program indicators found\n","==================================================\n","   Looking for pattern: INDEX -> Name...\n","    No valid index->name patterns found\n","  No faculty found in 'FACULTY_DETAILS', processing as normal content.\n","  Creating consolidated student strength point: {'ug_4_years': 4813, 'ug_5_years': 196, 'pg_2_years': 92, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 5101}\n","Created 12 points for Sri Krishna College of Engineering and Technology\n","Saved 12 points to Sri Krishna College of Engineering and Technology.json (normalized)\n","  Created 12 points\n","\n","Processing file: IIT Jodhpur.txt\n","Processing: Indian Institute of Technology Jodhpur (IR-E-U-0395)\n","  Found student section: SANCTIONED_INTAKE\n","\n","=== DEBUGGING SECTION: SANCTIONED_INTAKE ===\n","Section length: 173 characters\n","Relevant lines found:\n","  Line 9: UG [4 Years Program(s)]\n","  Line 16: PG [2 Year Program(s)]\n","\n","PG Programs (2-Year/3-Year/Integrated/PG-Integrated) analysis:\n","  Line 16: PG [2 Year Program(s)]\n","  Line 17:   -> 229\n","  Line 18:   -> 199\n","==================================================\n","    Analyzing content length: 173 characters\n","    Sample content preview: Sanctioned (Approved) Intake\n","Academic Year\n","2022-23\n","2021-22\n","2020-21\n","2019-20\n","2018-19\n","2017-18\n","UG [4 Years Program(s)]\n","530\n","490\n","490\n","352\n","-\n","-\n","PG [2 Year Program(s)]\n","229\n","199\n","-\n","-\n","-\n","-...\n","    Pattern 1 for ug_4_years found TUPLE: Male=530, Female=490, Total=490\n","    Pattern 2 for ug_4_years found TUPLE: Male=530, Female=490, Total=490\n","    Pattern 3 for ug_4_years found TUPLE: Male=530, Female=490, Total=490\n","    Pattern 4 for ug_4_years found SINGLE: 530\n","    Final ug_4_years: 530 students (from values: [490, 490, 490, 530])\n","    No valid values found for ug_5_years\n","    Pattern 5 for pg_2_years found SINGLE: 229\n","    Pattern 6 for pg_2_years found SINGLE: 229\n","    Final pg_2_years: 229 students (from values: [229, 229])\n","    No valid values found for pg_3_years\n","    No valid values found for pg_integrated\n","    Some PG programs not found with primary patterns, trying line-by-line analysis...\n","    Calculated total students: 759\n","  Accumulated student data so far: {'ug_4_years': 530, 'ug_5_years': 0, 'pg_2_years': 0, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 530, 'ug_5_years': 0, 'pg_2_years': 0, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 530, 'ug_5_years': 0, 'pg_2_years': 229, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 530, 'ug_5_years': 0, 'pg_2_years': 229, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 530, 'ug_5_years': 0, 'pg_2_years': 229, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Found student section: STUDENT_STRENGTH\n","\n","=== DEBUGGING SECTION: STUDENT_STRENGTH ===\n","Section length: 841 characters\n","Relevant lines found:\n","  Line 1: Total Actual Student Strength (Program(s) Offered by your Institution)\n","  Line 2: (All programs\n","  Line 3: of all years)\n","  Line 52: UG [4 Years\n","  Line 53: Program(s)]\n","  Line 66: PG [2 Year\n","  Line 67: Program(s)]\n","\n","PG Programs (2-Year/3-Year/Integrated/PG-Integrated) analysis:\n","  Line 66: PG [2 Year\n","  Line 67:   -> Program(s)]\n","  Line 68:   -> 330\n","==================================================\n","    Analyzing content length: 841 characters\n","    Sample content preview: Total Actual Student Strength (Program(s) Offered by your Institution)\n","(All programs\n","of all years)\n","No. of Male\n","Students\n","No. of Female\n","Students\n","Total Students\n","Within State\n","(Including male\n","& female)\n","Out...\n","    Pattern 1 for ug_4_years found TUPLE: Male=1424, Female=318, Total=1742\n","    Pattern 2 for ug_4_years found TUPLE: Male=1424, Female=318, Total=1742\n","    Pattern 3 for ug_4_years found TUPLE: Male=1424, Female=318, Total=1742\n","    Pattern 4 for ug_4_years found SINGLE: 1424\n","    Final ug_4_years: 1742 students (from values: [1742, 1742, 1742, 1424])\n","    No valid values found for ug_5_years\n","    Pattern 1 for pg_2_years found TUPLE: Male=330, Female=98, Total=428\n","    Pattern 2 for pg_2_years found TUPLE: Male=330, Female=98, Total=428\n","    Pattern 3 for pg_2_years found TUPLE: Male=330, Female=98, Total=428\n","    Pattern 4 for pg_2_years found TUPLE: Male=330, Female=98, Total=428\n","    Pattern 5 for pg_2_years found SINGLE: 330\n","    Pattern 6 for pg_2_years found SINGLE: 330\n","    Final pg_2_years: 428 students (from values: [428, 428, 428, 428, 330, 330])\n","    No valid values found for pg_3_years\n","    No valid values found for pg_integrated\n","    Some PG programs not found with primary patterns, trying line-by-line analysis...\n","    Calculated total students: 2170\n","  Accumulated student data so far: {'ug_4_years': 1742, 'ug_5_years': 0, 'pg_2_years': 229, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 1742, 'ug_5_years': 0, 'pg_2_years': 229, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 1742, 'ug_5_years': 0, 'pg_2_years': 428, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 1742, 'ug_5_years': 0, 'pg_2_years': 428, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 1742, 'ug_5_years': 0, 'pg_2_years': 428, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Found student section: PLACEMENT_STUDIES\n","\n","=== DEBUGGING SECTION: PLACEMENT_STUDIES ===\n","Section length: 550 characters\n","Relevant lines found:\n","  Line 1: PG [2 Years Program(s)]: Placement & higher studies for previous 3 years\n","\n","PG Programs (2-Year/3-Year/Integrated/PG-Integrated) analysis:\n","  Line 1: PG [2 Years Program(s)]: Placement & higher studies for previous 3 years\n","  Line 2:   -> Academic Year\n","  Line 3:   -> No. of first year\n","==================================================\n","    Analyzing content length: 550 characters\n","    Sample content preview: PG [2 Years Program(s)]: Placement & higher studies for previous 3 years\n","Academic Year\n","No. of first year\n","students intake in the\n","year\n","No. of first year\n","students admitted in\n","the year\n","Academic Year\n","No. o...\n","    No valid values found for ug_4_years\n","    No valid values found for ug_5_years\n","    Pattern 5 for pg_2_years found SINGLE: 3\n","    Pattern 6 for pg_2_years found SINGLE: 3\n","    Final pg_2_years: 3 students (from values: [3, 3])\n","    No valid values found for pg_3_years\n","    No valid values found for pg_integrated\n","    Some PG programs not found with primary patterns, trying line-by-line analysis...\n","    Calculated total students: 3\n","  Accumulated student data so far: {'ug_4_years': 1742, 'ug_5_years': 0, 'pg_2_years': 428, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 1742, 'ug_5_years': 0, 'pg_2_years': 428, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 1742, 'ug_5_years': 0, 'pg_2_years': 428, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 1742, 'ug_5_years': 0, 'pg_2_years': 428, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 1742, 'ug_5_years': 0, 'pg_2_years': 428, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Found student section: PHD_DETAILS\n","\n","=== DEBUGGING SECTION: PHD_DETAILS ===\n","Section length: 234 characters\n","Relevant lines found:\n","  Line 2: Ph.D (Student pursuing doctoral program till 2022-23)\n","\n","No PG program indicators found\n","==================================================\n","    Analyzing content length: 234 characters\n","    Sample content preview: Ph.D Student Details\n","Ph.D (Student pursuing doctoral program till 2022-23)\n","Total Students\n","Full Time\n","652\n","Part Time\n","82\n","No. of Ph.D students graduated (including Integrated Ph.D)\n","2022-23\n","2021-22\n","2020-21\n","...\n","    No valid values found for ug_4_years\n","    No valid values found for ug_5_years\n","    No valid values found for pg_2_years\n","    No valid values found for pg_3_years\n","    No valid values found for pg_integrated\n","    Some PG programs not found with primary patterns, trying line-by-line analysis...\n","  Accumulated student data so far: {'ug_4_years': 1742, 'ug_5_years': 0, 'pg_2_years': 428, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 1742, 'ug_5_years': 0, 'pg_2_years': 428, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 1742, 'ug_5_years': 0, 'pg_2_years': 428, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 1742, 'ug_5_years': 0, 'pg_2_years': 428, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 1742, 'ug_5_years': 0, 'pg_2_years': 428, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Found student section: PCS_FACILITIES\n","\n","=== DEBUGGING SECTION: PCS_FACILITIES ===\n","Section length: 430 characters\n","No obvious table structure found\n","\n","First 10 non-empty lines:\n","  1: PCS Facilities: Facilities of Physically Challenged Students\n","  2: 1. Do your institution buildings have Lifts/Ramps?\n","  3: Yes, more than 80% of the buildings\n","  4: 2. Do your institution have provision for walking aids, including wheelchairs and transportation from one building to another for\n","  5: handicapped students?\n","  6: Yes\n","  7: 3. Do your institution buildings have specially designed toilets for handicapped students?\n","  8: Yes, more than 80% of the buildings\n","\n","No PG program indicators found\n","==================================================\n","    Analyzing content length: 430 characters\n","    Sample content preview: PCS Facilities: Facilities of Physically Challenged Students\n","1. Do your institution buildings have Lifts/Ramps?\n","Yes, more than 80% of the buildings\n","2. Do your institution have provision for walking ai...\n","    No valid values found for ug_4_years\n","    No valid values found for ug_5_years\n","    No valid values found for pg_2_years\n","    No valid values found for pg_3_years\n","    No valid values found for pg_integrated\n","    Some PG programs not found with primary patterns, trying line-by-line analysis...\n","  Accumulated student data so far: {'ug_4_years': 1742, 'ug_5_years': 0, 'pg_2_years': 428, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 1742, 'ug_5_years': 0, 'pg_2_years': 428, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 1742, 'ug_5_years': 0, 'pg_2_years': 428, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 1742, 'ug_5_years': 0, 'pg_2_years': 428, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 1742, 'ug_5_years': 0, 'pg_2_years': 428, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Processing faculty section: FACULTY_DETAILS\n","\n","=== DEBUGGING SECTION: FACULTY_DETAILS ===\n","Section length: 37 characters\n","No obvious table structure found\n","\n","First 10 non-empty lines:\n","  1: Number of faculty members entered\n","  2: 238\n","\n","No PG program indicators found\n","==================================================\n","   Looking for pattern: INDEX -> Name...\n","    No valid index->name patterns found\n","  No faculty found in 'FACULTY_DETAILS', processing as normal content.\n","  Creating consolidated student strength point: {'ug_4_years': 1742, 'ug_5_years': 0, 'pg_2_years': 428, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 2170}\n","Created 12 points for Indian Institute of Technology Jodhpur\n","Saved 12 points to IIT Jodhpur.json (normalized)\n","  Created 12 points\n","\n","Processing file: Amity University.txt\n","Processing: Amity University (IR-E-U-0497)\n","  Found student section: SANCTIONED_INTAKE\n","\n","=== DEBUGGING SECTION: SANCTIONED_INTAKE ===\n","Section length: 208 characters\n","Relevant lines found:\n","  Line 9: UG [4 Years Program(s)]\n","  Line 16: PG [2 Year Program(s)]\n","\n","PG Programs (2-Year/3-Year/Integrated/PG-Integrated) analysis:\n","  Line 16: PG [2 Year Program(s)]\n","  Line 17:   -> 150\n","  Line 18:   -> 150\n","  Line 23: PG-Integrated\n","  Line 24:   -> 45\n","  Line 25:   -> 45\n","==================================================\n","    Analyzing content length: 208 characters\n","    Sample content preview: Sanctioned (Approved) Intake\n","Academic Year\n","2022-23\n","2021-22\n","2020-21\n","2019-20\n","2018-19\n","2017-18\n","UG [4 Years Program(s)]\n","1140\n","1140\n","1140\n","1710\n","-\n","-\n","PG [2 Year Program(s)]\n","150\n","150\n","-\n","-\n","-\n","-\n","PG-Integrated\n","45\n","45\n","45...\n","    Pattern 1 for ug_4_years found TUPLE: Male=1140, Female=1140, Total=1140\n","    Pattern 2 for ug_4_years found TUPLE: Male=1140, Female=1140, Total=1140\n","    Pattern 3 for ug_4_years found TUPLE: Male=1140, Female=1140, Total=1140\n","    Pattern 4 for ug_4_years found SINGLE: 1140\n","    Final ug_4_years: 1140 students (from values: [1140, 1140, 1140, 1140])\n","    No valid values found for ug_5_years\n","    Pattern 5 for pg_2_years found SINGLE: 150\n","    Pattern 6 for pg_2_years found SINGLE: 150\n","    Final pg_2_years: 150 students (from values: [150, 150])\n","    No valid values found for pg_3_years\n","    Pattern 4 for pg_integrated found TUPLE: Male=45, Female=45, Total=45\n","    Pattern 5 for pg_integrated found TUPLE: Male=45, Female=45, Total=45\n","    Pattern 6 for pg_integrated found TUPLE: Male=45, Female=45, Total=45\n","    Final pg_integrated: 45 students (from values: [45, 45, 45])\n","    Some PG programs not found with primary patterns, trying line-by-line analysis...\n","    Found PG Integrated line 22: PG-Integrated\n","    Calculated total students: 1335\n","  Accumulated student data so far: {'ug_4_years': 1140, 'ug_5_years': 0, 'pg_2_years': 0, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 1140, 'ug_5_years': 0, 'pg_2_years': 0, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 1140, 'ug_5_years': 0, 'pg_2_years': 150, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 1140, 'ug_5_years': 0, 'pg_2_years': 150, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 1140, 'ug_5_years': 0, 'pg_2_years': 150, 'pg_3_years': 0, 'pg_integrated': 45, 'total_students': 0}\n","  Found student section: STUDENT_STRENGTH\n","\n","=== DEBUGGING SECTION: STUDENT_STRENGTH ===\n","Section length: 887 characters\n","Relevant lines found:\n","  Line 1: Total Actual Student Strength (Program(s) Offered by your Institution)\n","  Line 2: (All programs\n","  Line 3: of all years)\n","  Line 52: UG [4 Years\n","  Line 53: Program(s)]\n","  Line 66: PG [2 Year\n","  Line 67: Program(s)]\n","\n","PG Programs (2-Year/3-Year/Integrated/PG-Integrated) analysis:\n","  Line 66: PG [2 Year\n","  Line 67:   -> Program(s)]\n","  Line 68:   -> 187\n","  Line 80: PG-Integrated\n","  Line 81:   -> 148\n","  Line 82:   -> 128\n","==================================================\n","    Analyzing content length: 887 characters\n","    Sample content preview: Total Actual Student Strength (Program(s) Offered by your Institution)\n","(All programs\n","of all years)\n","No. of Male\n","Students\n","No. of Female\n","Students\n","Total Students\n","Within State\n","(Including male\n","& female)\n","Out...\n","    Pattern 1 for ug_4_years found TUPLE: Male=3469, Female=1661, Total=5130\n","    Pattern 2 for ug_4_years found TUPLE: Male=3469, Female=1661, Total=5130\n","    Pattern 3 for ug_4_years found TUPLE: Male=3469, Female=1661, Total=5130\n","    Pattern 4 for ug_4_years found SINGLE: 3469\n","    Final ug_4_years: 5130 students (from values: [5130, 5130, 5130, 3469])\n","    No valid values found for ug_5_years\n","    Pattern 1 for pg_2_years found TUPLE: Male=187, Female=109, Total=296\n","    Pattern 2 for pg_2_years found TUPLE: Male=187, Female=109, Total=296\n","    Pattern 3 for pg_2_years found TUPLE: Male=187, Female=109, Total=296\n","    Pattern 4 for pg_2_years found TUPLE: Male=187, Female=109, Total=296\n","    Pattern 5 for pg_2_years found SINGLE: 187\n","    Pattern 6 for pg_2_years found SINGLE: 187\n","    Final pg_2_years: 296 students (from values: [296, 296, 296, 296, 187, 187])\n","    No valid values found for pg_3_years\n","    Pattern 4 for pg_integrated found TUPLE: Male=148, Female=128, Total=276\n","    Pattern 5 for pg_integrated found TUPLE: Male=148, Female=128, Total=276\n","    Pattern 6 for pg_integrated found TUPLE: Male=148, Female=128, Total=276\n","    Final pg_integrated: 276 students (from values: [276, 276, 276])\n","    Some PG programs not found with primary patterns, trying line-by-line analysis...\n","    Found PG Integrated line 79: PG-Integrated\n","    Calculated total students: 5702\n","  Accumulated student data so far: {'ug_4_years': 5130, 'ug_5_years': 0, 'pg_2_years': 150, 'pg_3_years': 0, 'pg_integrated': 45, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 5130, 'ug_5_years': 0, 'pg_2_years': 150, 'pg_3_years': 0, 'pg_integrated': 45, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 5130, 'ug_5_years': 0, 'pg_2_years': 296, 'pg_3_years': 0, 'pg_integrated': 45, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 5130, 'ug_5_years': 0, 'pg_2_years': 296, 'pg_3_years': 0, 'pg_integrated': 45, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 5130, 'ug_5_years': 0, 'pg_2_years': 296, 'pg_3_years': 0, 'pg_integrated': 276, 'total_students': 0}\n","  Found student section: PLACEMENT_STUDIES\n","\n","=== DEBUGGING SECTION: PLACEMENT_STUDIES ===\n","Section length: 554 characters\n","Relevant lines found:\n","  Line 1: PG [2 Years Program(s)]: Placement & higher studies for previous 3 years\n","\n","PG Programs (2-Year/3-Year/Integrated/PG-Integrated) analysis:\n","  Line 1: PG [2 Years Program(s)]: Placement & higher studies for previous 3 years\n","  Line 2:   -> Academic Year\n","  Line 3:   -> No. of first year\n","==================================================\n","    Analyzing content length: 554 characters\n","    Sample content preview: PG [2 Years Program(s)]: Placement & higher studies for previous 3 years\n","Academic Year\n","No. of first year\n","students intake in the\n","year\n","No. of first year\n","students admitted in\n","the year\n","Academic Year\n","No. o...\n","    No valid values found for ug_4_years\n","    No valid values found for ug_5_years\n","    Pattern 5 for pg_2_years found SINGLE: 3\n","    Pattern 6 for pg_2_years found SINGLE: 3\n","    Final pg_2_years: 3 students (from values: [3, 3])\n","    No valid values found for pg_3_years\n","    No valid values found for pg_integrated\n","    Some PG programs not found with primary patterns, trying line-by-line analysis...\n","    Calculated total students: 3\n","  Accumulated student data so far: {'ug_4_years': 5130, 'ug_5_years': 0, 'pg_2_years': 296, 'pg_3_years': 0, 'pg_integrated': 276, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 5130, 'ug_5_years': 0, 'pg_2_years': 296, 'pg_3_years': 0, 'pg_integrated': 276, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 5130, 'ug_5_years': 0, 'pg_2_years': 296, 'pg_3_years': 0, 'pg_integrated': 276, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 5130, 'ug_5_years': 0, 'pg_2_years': 296, 'pg_3_years': 0, 'pg_integrated': 276, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 5130, 'ug_5_years': 0, 'pg_2_years': 296, 'pg_3_years': 0, 'pg_integrated': 276, 'total_students': 0}\n","  Found student section: PG_PLACEMENT\n","\n","=== DEBUGGING SECTION: PG_PLACEMENT ===\n","Section length: 573 characters\n","Relevant lines found:\n","  Line 1: PG-Integrated [5 Years Program(s)]: Placement & higher studies for previous 3 years\n","\n","PG Programs (2-Year/3-Year/Integrated/PG-Integrated) analysis:\n","  Line 1: PG-Integrated [5 Years Program(s)]: Placement & higher studies for previous 3 years\n","  Line 2:   -> Academic Year\n","  Line 3:   -> No. of first year\n","==================================================\n","    Analyzing content length: 573 characters\n","    Sample content preview: PG-Integrated [5 Years Program(s)]: Placement & higher studies for previous 3 years\n","Academic Year\n","No. of first year\n","students intake in the\n","year\n","No. of first year\n","students admitted in\n","the year\n","Academic...\n","    No valid values found for ug_4_years\n","    No valid values found for ug_5_years\n","    No valid values found for pg_2_years\n","    No valid values found for pg_3_years\n","    No valid values found for pg_integrated\n","    Some PG programs not found with primary patterns, trying line-by-line analysis...\n","    Found PG Integrated line 0: PG-Integrated [5 Years Program(s)]: Placement & higher studies for previous 3 years\n","  Accumulated student data so far: {'ug_4_years': 5130, 'ug_5_years': 0, 'pg_2_years': 296, 'pg_3_years': 0, 'pg_integrated': 276, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 5130, 'ug_5_years': 0, 'pg_2_years': 296, 'pg_3_years': 0, 'pg_integrated': 276, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 5130, 'ug_5_years': 0, 'pg_2_years': 296, 'pg_3_years': 0, 'pg_integrated': 276, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 5130, 'ug_5_years': 0, 'pg_2_years': 296, 'pg_3_years': 0, 'pg_integrated': 276, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 5130, 'ug_5_years': 0, 'pg_2_years': 296, 'pg_3_years': 0, 'pg_integrated': 276, 'total_students': 0}\n","  Found student section: PHD_DETAILS\n","\n","=== DEBUGGING SECTION: PHD_DETAILS ===\n","Section length: 239 characters\n","Relevant lines found:\n","  Line 2: Ph.D (Student pursuing doctoral program till 2022-23)\n","\n","No PG program indicators found\n","==================================================\n","    Analyzing content length: 239 characters\n","    Sample content preview: Ph.D Student Details\n","Ph.D (Student pursuing doctoral program till 2022-23)\n","Total Students\n","Full Time\n","325\n","Part Time\n","668\n","No. of Ph.D students graduated (including Integrated Ph.D)\n","2022-23\n","2021-22\n","2020-21...\n","    No valid values found for ug_4_years\n","    No valid values found for ug_5_years\n","    No valid values found for pg_2_years\n","    No valid values found for pg_3_years\n","    No valid values found for pg_integrated\n","    Some PG programs not found with primary patterns, trying line-by-line analysis...\n","  Accumulated student data so far: {'ug_4_years': 5130, 'ug_5_years': 0, 'pg_2_years': 296, 'pg_3_years': 0, 'pg_integrated': 276, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 5130, 'ug_5_years': 0, 'pg_2_years': 296, 'pg_3_years': 0, 'pg_integrated': 276, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 5130, 'ug_5_years': 0, 'pg_2_years': 296, 'pg_3_years': 0, 'pg_integrated': 276, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 5130, 'ug_5_years': 0, 'pg_2_years': 296, 'pg_3_years': 0, 'pg_integrated': 276, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 5130, 'ug_5_years': 0, 'pg_2_years': 296, 'pg_3_years': 0, 'pg_integrated': 276, 'total_students': 0}\n","  Found student section: PCS_FACILITIES\n","\n","=== DEBUGGING SECTION: PCS_FACILITIES ===\n","Section length: 430 characters\n","No obvious table structure found\n","\n","First 10 non-empty lines:\n","  1: PCS Facilities: Facilities of Physically Challenged Students\n","  2: 1. Do your institution buildings have Lifts/Ramps?\n","  3: Yes, more than 80% of the buildings\n","  4: 2. Do your institution have provision for walking aids, including wheelchairs and transportation from one building to another for\n","  5: handicapped students?\n","  6: Yes\n","  7: 3. Do your institution buildings have specially designed toilets for handicapped students?\n","  8: Yes, more than 80% of the buildings\n","\n","No PG program indicators found\n","==================================================\n","    Analyzing content length: 430 characters\n","    Sample content preview: PCS Facilities: Facilities of Physically Challenged Students\n","1. Do your institution buildings have Lifts/Ramps?\n","Yes, more than 80% of the buildings\n","2. Do your institution have provision for walking ai...\n","    No valid values found for ug_4_years\n","    No valid values found for ug_5_years\n","    No valid values found for pg_2_years\n","    No valid values found for pg_3_years\n","    No valid values found for pg_integrated\n","    Some PG programs not found with primary patterns, trying line-by-line analysis...\n","  Accumulated student data so far: {'ug_4_years': 5130, 'ug_5_years': 0, 'pg_2_years': 296, 'pg_3_years': 0, 'pg_integrated': 276, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 5130, 'ug_5_years': 0, 'pg_2_years': 296, 'pg_3_years': 0, 'pg_integrated': 276, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 5130, 'ug_5_years': 0, 'pg_2_years': 296, 'pg_3_years': 0, 'pg_integrated': 276, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 5130, 'ug_5_years': 0, 'pg_2_years': 296, 'pg_3_years': 0, 'pg_integrated': 276, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 5130, 'ug_5_years': 0, 'pg_2_years': 296, 'pg_3_years': 0, 'pg_integrated': 276, 'total_students': 0}\n","  Processing faculty section: FACULTY_DETAILS\n","\n","=== DEBUGGING SECTION: FACULTY_DETAILS ===\n","Section length: 37 characters\n","No obvious table structure found\n","\n","First 10 non-empty lines:\n","  1: Number of faculty members entered\n","  2: 449\n","\n","No PG program indicators found\n","==================================================\n","   Looking for pattern: INDEX -> Name...\n","    No valid index->name patterns found\n","  No faculty found in 'FACULTY_DETAILS', processing as normal content.\n","  Creating consolidated student strength point: {'ug_4_years': 5130, 'ug_5_years': 0, 'pg_2_years': 296, 'pg_3_years': 0, 'pg_integrated': 276, 'total_students': 5702}\n","Created 13 points for Amity University\n","Saved 13 points to Amity University.json (normalized)\n","  Created 13 points\n","\n","Processing file: K L College of Engineering_Vaddeswaram_.txt\n","Processing: Koneru Lakshmaiah Education Foundation University (K L College of Engineering) (IR-E-U-0020)\n","  Found student section: SANCTIONED_INTAKE\n","\n","=== DEBUGGING SECTION: SANCTIONED_INTAKE ===\n","Section length: 177 characters\n","Relevant lines found:\n","  Line 9: UG [4 Years Program(s)]\n","  Line 16: PG [2 Year Program(s)]\n","\n","PG Programs (2-Year/3-Year/Integrated/PG-Integrated) analysis:\n","  Line 16: PG [2 Year Program(s)]\n","  Line 17:   -> 252\n","  Line 18:   -> 342\n","==================================================\n","    Analyzing content length: 177 characters\n","    Sample content preview: Sanctioned (Approved) Intake\n","Academic Year\n","2022-23\n","2021-22\n","2020-21\n","2019-20\n","2018-19\n","2017-18\n","UG [4 Years Program(s)]\n","3420\n","3060\n","3180\n","3480\n","-\n","-\n","PG [2 Year Program(s)]\n","252\n","342\n","-\n","-\n","-\n","-...\n","    Pattern 1 for ug_4_years found TUPLE: Male=3420, Female=3060, Total=3180\n","    Pattern 2 for ug_4_years found TUPLE: Male=3420, Female=3060, Total=3180\n","    Pattern 3 for ug_4_years found TUPLE: Male=3420, Female=3060, Total=3180\n","    Pattern 4 for ug_4_years found SINGLE: 3420\n","    Final ug_4_years: 3420 students (from values: [3180, 3180, 3180, 3420])\n","    No valid values found for ug_5_years\n","    Pattern 5 for pg_2_years found SINGLE: 252\n","    Pattern 6 for pg_2_years found SINGLE: 252\n","    Final pg_2_years: 252 students (from values: [252, 252])\n","    No valid values found for pg_3_years\n","    No valid values found for pg_integrated\n","    Some PG programs not found with primary patterns, trying line-by-line analysis...\n","    Calculated total students: 3672\n","  Accumulated student data so far: {'ug_4_years': 3420, 'ug_5_years': 0, 'pg_2_years': 0, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 3420, 'ug_5_years': 0, 'pg_2_years': 0, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 3420, 'ug_5_years': 0, 'pg_2_years': 252, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 3420, 'ug_5_years': 0, 'pg_2_years': 252, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 3420, 'ug_5_years': 0, 'pg_2_years': 252, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Found student section: STUDENT_STRENGTH\n","\n","=== DEBUGGING SECTION: STUDENT_STRENGTH ===\n","Section length: 846 characters\n","Relevant lines found:\n","  Line 1: Total Actual Student Strength (Program(s) Offered by your Institution)\n","  Line 2: (All programs\n","  Line 3: of all years)\n","  Line 52: UG [4 Years\n","  Line 53: Program(s)]\n","  Line 66: PG [2 Year\n","  Line 67: Program(s)]\n","\n","PG Programs (2-Year/3-Year/Integrated/PG-Integrated) analysis:\n","  Line 66: PG [2 Year\n","  Line 67:   -> Program(s)]\n","  Line 68:   -> 270\n","==================================================\n","    Analyzing content length: 846 characters\n","    Sample content preview: Total Actual Student Strength (Program(s) Offered by your Institution)\n","(All programs\n","of all years)\n","No. of Male\n","Students\n","No. of Female\n","Students\n","Total Students\n","Within State\n","(Including male\n","& female)\n","Out...\n","    Pattern 1 for ug_4_years found TUPLE: Male=6261, Female=6482, Total=12743\n","    Pattern 2 for ug_4_years found TUPLE: Male=6261, Female=6482, Total=12743\n","    Pattern 3 for ug_4_years found TUPLE: Male=6261, Female=6482, Total=12743\n","    Pattern 4 for ug_4_years found SINGLE: 6261\n","    Final ug_4_years: 12743 students (from values: [12743, 12743, 12743, 6261])\n","    No valid values found for ug_5_years\n","    Pattern 1 for pg_2_years found TUPLE: Male=270, Female=235, Total=505\n","    Pattern 2 for pg_2_years found TUPLE: Male=270, Female=235, Total=505\n","    Pattern 3 for pg_2_years found TUPLE: Male=270, Female=235, Total=505\n","    Pattern 4 for pg_2_years found TUPLE: Male=270, Female=235, Total=505\n","    Pattern 5 for pg_2_years found SINGLE: 270\n","    Pattern 6 for pg_2_years found SINGLE: 270\n","    Final pg_2_years: 505 students (from values: [505, 505, 505, 505, 270, 270])\n","    No valid values found for pg_3_years\n","    No valid values found for pg_integrated\n","    Some PG programs not found with primary patterns, trying line-by-line analysis...\n","    Calculated total students: 13248\n","  Accumulated student data so far: {'ug_4_years': 12743, 'ug_5_years': 0, 'pg_2_years': 252, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 12743, 'ug_5_years': 0, 'pg_2_years': 252, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 12743, 'ug_5_years': 0, 'pg_2_years': 505, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 12743, 'ug_5_years': 0, 'pg_2_years': 505, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 12743, 'ug_5_years': 0, 'pg_2_years': 505, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Found student section: PLACEMENT_STUDIES\n","\n","=== DEBUGGING SECTION: PLACEMENT_STUDIES ===\n","Section length: 587 characters\n","Relevant lines found:\n","  Line 1: PG [2 Years Program(s)]: Placement & higher studies for previous 3 years\n","\n","PG Programs (2-Year/3-Year/Integrated/PG-Integrated) analysis:\n","  Line 1: PG [2 Years Program(s)]: Placement & higher studies for previous 3 years\n","  Line 2:   -> Academic Year\n","  Line 3:   -> No. of first year\n","==================================================\n","    Analyzing content length: 587 characters\n","    Sample content preview: PG [2 Years Program(s)]: Placement & higher studies for previous 3 years\n","Academic Year\n","No. of first year\n","students intake in the\n","year\n","No. of first year\n","students admitted in\n","the year\n","Academic Year\n","No. o...\n","    No valid values found for ug_4_years\n","    No valid values found for ug_5_years\n","    Pattern 5 for pg_2_years found SINGLE: 3\n","    Pattern 6 for pg_2_years found SINGLE: 3\n","    Final pg_2_years: 3 students (from values: [3, 3])\n","    No valid values found for pg_3_years\n","    No valid values found for pg_integrated\n","    Some PG programs not found with primary patterns, trying line-by-line analysis...\n","    Calculated total students: 3\n","  Accumulated student data so far: {'ug_4_years': 12743, 'ug_5_years': 0, 'pg_2_years': 505, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 12743, 'ug_5_years': 0, 'pg_2_years': 505, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 12743, 'ug_5_years': 0, 'pg_2_years': 505, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 12743, 'ug_5_years': 0, 'pg_2_years': 505, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 12743, 'ug_5_years': 0, 'pg_2_years': 505, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Found student section: PHD_DETAILS\n","\n","=== DEBUGGING SECTION: PHD_DETAILS ===\n","Section length: 238 characters\n","Relevant lines found:\n","  Line 2: Ph.D (Student pursuing doctoral program till 2022-23)\n","\n","No PG program indicators found\n","==================================================\n","    Analyzing content length: 238 characters\n","    Sample content preview: Ph.D Student Details\n","Ph.D (Student pursuing doctoral program till 2022-23)\n","Total Students\n","Full Time\n","406\n","Part Time\n","411\n","No. of Ph.D students graduated (including Integrated Ph.D)\n","2022-23\n","2021-22\n","2020-21...\n","    No valid values found for ug_4_years\n","    No valid values found for ug_5_years\n","    No valid values found for pg_2_years\n","    No valid values found for pg_3_years\n","    No valid values found for pg_integrated\n","    Some PG programs not found with primary patterns, trying line-by-line analysis...\n","  Accumulated student data so far: {'ug_4_years': 12743, 'ug_5_years': 0, 'pg_2_years': 505, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 12743, 'ug_5_years': 0, 'pg_2_years': 505, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 12743, 'ug_5_years': 0, 'pg_2_years': 505, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 12743, 'ug_5_years': 0, 'pg_2_years': 505, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 12743, 'ug_5_years': 0, 'pg_2_years': 505, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Found student section: PCS_FACILITIES\n","\n","=== DEBUGGING SECTION: PCS_FACILITIES ===\n","Section length: 430 characters\n","No obvious table structure found\n","\n","First 10 non-empty lines:\n","  1: PCS Facilities: Facilities of Physically Challenged Students\n","  2: 1. Do your institution buildings have Lifts/Ramps?\n","  3: Yes, more than 80% of the buildings\n","  4: 2. Do your institution have provision for walking aids, including wheelchairs and transportation from one building to another for\n","  5: handicapped students?\n","  6: Yes\n","  7: 3. Do your institution buildings have specially designed toilets for handicapped students?\n","  8: Yes, more than 80% of the buildings\n","\n","No PG program indicators found\n","==================================================\n","    Analyzing content length: 430 characters\n","    Sample content preview: PCS Facilities: Facilities of Physically Challenged Students\n","1. Do your institution buildings have Lifts/Ramps?\n","Yes, more than 80% of the buildings\n","2. Do your institution have provision for walking ai...\n","    No valid values found for ug_4_years\n","    No valid values found for ug_5_years\n","    No valid values found for pg_2_years\n","    No valid values found for pg_3_years\n","    No valid values found for pg_integrated\n","    Some PG programs not found with primary patterns, trying line-by-line analysis...\n","  Accumulated student data so far: {'ug_4_years': 12743, 'ug_5_years': 0, 'pg_2_years': 505, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 12743, 'ug_5_years': 0, 'pg_2_years': 505, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 12743, 'ug_5_years': 0, 'pg_2_years': 505, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 12743, 'ug_5_years': 0, 'pg_2_years': 505, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Accumulated student data so far: {'ug_4_years': 12743, 'ug_5_years': 0, 'pg_2_years': 505, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 0}\n","  Processing faculty section: FACULTY_DETAILS\n","\n","=== DEBUGGING SECTION: FACULTY_DETAILS ===\n","Section length: 37 characters\n","No obvious table structure found\n","\n","First 10 non-empty lines:\n","  1: Number of faculty members entered\n","  2: 945\n","\n","No PG program indicators found\n","==================================================\n","   Looking for pattern: INDEX -> Name...\n","    No valid index->name patterns found\n","  No faculty found in 'FACULTY_DETAILS', processing as normal content.\n","  Creating consolidated student strength point: {'ug_4_years': 12743, 'ug_5_years': 0, 'pg_2_years': 505, 'pg_3_years': 0, 'pg_integrated': 0, 'total_students': 13248}\n","Created 12 points for Koneru Lakshmaiah Education Foundation University (K L College of Engineering)\n","Saved 12 points to K L College of Engineering_Vaddeswaram_.json (normalized)\n","  Created 12 points\n","Added to ZIP: IIT Mandi.json\n","Added to ZIP: NIT  Agartala.json\n","Added to ZIP: Engineering  2024.json\n","Added to ZIP: Amrita Vishwa Vidyapeetham.json\n","Added to ZIP: Shoolini University of Biotechnology and Management Science.json\n","Added to ZIP: IIT Kharagpur.json\n","Added to ZIP: International Institute of Information Technology Bangalore.json\n","Added to ZIP: NIT calicut.json\n","Added to ZIP: Saveetha Institute of Medical and Technical Sciences.json\n","Added to ZIP: Jain University_ Bangalore.json\n","Added to ZIP: NIT Patna.json\n","Added to ZIP: IIT Gandhinagar.json\n","Added to ZIP: Jamia Millia Islamia.json\n","Added to ZIP: IIEST Shibpur.json\n","Added to ZIP: Vignan_s Foundation for Science_ Technology and Research.json\n","Added to ZIP: Birla Institute of Technology Ranchi.json\n","Added to ZIP: Banasthali Vidyapith.json\n","Added to ZIP: IIT Bhilai.json\n","Added to ZIP: K L College of Engineering_Vaddeswaram_.json\n","Added to ZIP: Sri Krishna College of Engineering and Technology.json\n","Added to ZIP: IIIT Allahabad.json\n","Added to ZIP: Chithara University.json\n","Added to ZIP: NIT Surathkal.json\n","Added to ZIP: IIT Bhuvaneswar.json\n","Added to ZIP: Thapar Institute of Engineering and Technology _Deemed-to-be-university.json\n","Added to ZIP: University of Hyderabad.json\n","Added to ZIP: IIT Jodhpur.json\n","Added to ZIP: IIIT Hyderabad .json\n","Added to ZIP: NIT Silchar.json\n","Added to ZIP: Motilal Nehru National Institute of Technology.json\n","Added to ZIP: NIT Rourkela.json\n","Added to ZIP: IIT Roorkee 2024.json\n","Added to ZIP: Institute of Chemical Technology.json\n","Added to ZIP: NIT Durgapur.json\n","Added to ZIP: COEP Technological University.json\n","Added to ZIP: IIT Guwahati.json\n","Added to ZIP: IIT Jammu.json\n","Added to ZIP: Indraprastha Institute of Information Technology.json\n","Added to ZIP: IIT Patna.json\n","Added to ZIP: R.V. College of Engineering.json\n","Added to ZIP: Maulana Azad National Institute of Technology.json\n","Added to ZIP: Malaviya National Institute of Technology.json\n","Added to ZIP: Sri Sivasubramaniya Nadar College of Engineering.json\n","Added to ZIP: NIT Tiruchirappalli.json\n","Added to ZIP: IIT Tirupati.json\n","Added to ZIP: IIT Delhi.json\n","Added to ZIP: SR University Warangal.json\n","Added to ZIP: Aligarh Muslim University.json\n","Added to ZIP: Netaji Subhas University of Technology _NSUT_.json\n","Added to ZIP: Madan Mohan Malaviya University of Technology.json\n","Added to ZIP: M. S. Ramaiah Institute of Technology.json\n","Added to ZIP: IIT Kanpur.json\n","Added to ZIP: Jadavpur University.json\n","Added to ZIP: Defence Institute of Adavanced Technology.json\n","Added to ZIP: Shanmugha Arts Science Technology and Research Academy.json\n","Added to ZIP: Manipal Institute of Technology.json\n","Added to ZIP: Sardar Vallabhbhai National Institute of Technology.json\n","Added to ZIP: Indian Institute of Technology _Indian School of Mines_ Dhanbad.json\n","Added to ZIP: Delhi Technological University.json\n","Added to ZIP: Chandigarh University.json\n","Added to ZIP: IIT Ropar.json\n","Added to ZIP: Guru Gobind Singh Indraprastha University.json\n","Added to ZIP: Visvesvaraya National Institute of Technology Nagpur.json\n","Added to ZIP: Visvesvaraya Technological University.json\n","Added to ZIP: Lovely Professional University.json\n","Added to ZIP: Kalinga Institute of Industrial Technology.json\n","Added to ZIP: VIT Vellore.json\n","Added to ZIP: IIT Hyderabad.json\n","Added to ZIP: IIT Bombay.json\n","Added to ZIP: NIT Kurukshetra.json\n","Added to ZIP: NIT Raipur.json\n","Added to ZIP: Birla Institute of Technology  and Science_ Pilani.json\n","Added to ZIP: C.V. Raman Global University_ Odisha.json\n","Added to ZIP: IIT Varanasi_Banaras Hindu University_.json\n","Added to ZIP: Dr. B R Ambedkar National Institute of Technology Jalandhar.json\n","Added to ZIP: NIT Srinagar.json\n","Added to ZIP: Kalasalingam Academy of Research and Education.json\n","Added to ZIP: Amity University.json\n","Added to ZIP: Rajiv Gandhi Institute of Petroleum Technology.json\n","Added to ZIP: AU College of Enginnering.json\n","Added to ZIP: Sant Longowal Institute of Engineering and Technology.json\n","Added to ZIP: IIT Madras.json\n","Added to ZIP: NIT Delhi.json\n","Added to ZIP: SRM Chennai.json\n","Added to ZIP: Indian Institute of Space Science and Technology.json\n","Added to ZIP: Siddaganga Institute of Technology.json\n","Added to ZIP: Anna University.json\n","Added to ZIP: Vel Tech Rangarajan Dr. Sagunthala R _ D Institute of Science and Technology.json\n","Added to ZIP: NIT Warangal.json\n","Added to ZIP: Manipal University_ Jaipur.json\n","Added to ZIP: NIT Meghalaya.json\n","Added to ZIP: Sathyabama Institute of Science and Technology Chennai.json\n","Added to ZIP: IIT Palakkad.json\n","Added to ZIP: IIT Indore.json\n","Added to ZIP: Jawaharlal Nehru Technological University.json\n","Added to ZIP: PSG College of Technology.json\n","Added to ZIP: NIT  Puducherry.json\n","Added to ZIP: UPES.json\n","Created ZIP file: nirf_processed_data_20251112_180912.zip\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["download(\"download_72630600-71db-4dd2-ae9d-b14c44e79560\", \"nirf_processed_data_20251112_180912.zip\", 933871)"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Cleaned up: IIT Mandi.json\n","Cleaned up: NIT  Agartala.json\n","Cleaned up: Engineering  2024.json\n","Cleaned up: Amrita Vishwa Vidyapeetham.json\n","Cleaned up: Shoolini University of Biotechnology and Management Science.json\n","Cleaned up: IIT Kharagpur.json\n","Cleaned up: International Institute of Information Technology Bangalore.json\n","Cleaned up: NIT calicut.json\n","Cleaned up: Saveetha Institute of Medical and Technical Sciences.json\n","Cleaned up: Jain University_ Bangalore.json\n","Cleaned up: NIT Patna.json\n","Cleaned up: IIT Gandhinagar.json\n","Cleaned up: Jamia Millia Islamia.json\n","Cleaned up: IIEST Shibpur.json\n","Cleaned up: Vignan_s Foundation for Science_ Technology and Research.json\n","Cleaned up: Birla Institute of Technology Ranchi.json\n","Cleaned up: Banasthali Vidyapith.json\n","Cleaned up: IIT Bhilai.json\n","Cleaned up: K L College of Engineering_Vaddeswaram_.json\n","Cleaned up: Sri Krishna College of Engineering and Technology.json\n","Cleaned up: IIIT Allahabad.json\n","Cleaned up: Chithara University.json\n","Cleaned up: NIT Surathkal.json\n","Cleaned up: IIT Bhuvaneswar.json\n","Cleaned up: Thapar Institute of Engineering and Technology _Deemed-to-be-university.json\n","Cleaned up: University of Hyderabad.json\n","Cleaned up: IIT Jodhpur.json\n","Cleaned up: IIIT Hyderabad .json\n","Cleaned up: NIT Silchar.json\n","Cleaned up: Motilal Nehru National Institute of Technology.json\n","Cleaned up: NIT Rourkela.json\n","Cleaned up: IIT Roorkee 2024.json\n","Cleaned up: Institute of Chemical Technology.json\n","Cleaned up: NIT Durgapur.json\n","Cleaned up: COEP Technological University.json\n","Cleaned up: IIT Guwahati.json\n","Cleaned up: IIT Jammu.json\n","Cleaned up: Indraprastha Institute of Information Technology.json\n","Cleaned up: IIT Patna.json\n","Cleaned up: R.V. College of Engineering.json\n","Cleaned up: Maulana Azad National Institute of Technology.json\n","Cleaned up: Malaviya National Institute of Technology.json\n","Cleaned up: Sri Sivasubramaniya Nadar College of Engineering.json\n","Cleaned up: NIT Tiruchirappalli.json\n","Cleaned up: IIT Tirupati.json\n","Cleaned up: IIT Delhi.json\n","Cleaned up: SR University Warangal.json\n","Cleaned up: Aligarh Muslim University.json\n","Cleaned up: Netaji Subhas University of Technology _NSUT_.json\n","Cleaned up: Madan Mohan Malaviya University of Technology.json\n","Cleaned up: M. S. Ramaiah Institute of Technology.json\n","Cleaned up: IIT Kanpur.json\n","Cleaned up: Jadavpur University.json\n","Cleaned up: Defence Institute of Adavanced Technology.json\n","Cleaned up: Shanmugha Arts Science Technology and Research Academy.json\n","Cleaned up: Manipal Institute of Technology.json\n","Cleaned up: Sardar Vallabhbhai National Institute of Technology.json\n","Cleaned up: Indian Institute of Technology _Indian School of Mines_ Dhanbad.json\n","Cleaned up: Delhi Technological University.json\n","Cleaned up: Chandigarh University.json\n","Cleaned up: IIT Ropar.json\n","Cleaned up: Guru Gobind Singh Indraprastha University.json\n","Cleaned up: Visvesvaraya National Institute of Technology Nagpur.json\n","Cleaned up: Visvesvaraya Technological University.json\n","Cleaned up: Lovely Professional University.json\n","Cleaned up: Kalinga Institute of Industrial Technology.json\n","Cleaned up: VIT Vellore.json\n","Cleaned up: IIT Hyderabad.json\n","Cleaned up: IIT Bombay.json\n","Cleaned up: NIT Kurukshetra.json\n","Cleaned up: NIT Raipur.json\n","Cleaned up: Birla Institute of Technology  and Science_ Pilani.json\n","Cleaned up: C.V. Raman Global University_ Odisha.json\n","Cleaned up: IIT Varanasi_Banaras Hindu University_.json\n","Cleaned up: Dr. B R Ambedkar National Institute of Technology Jalandhar.json\n","Cleaned up: NIT Srinagar.json\n","Cleaned up: Kalasalingam Academy of Research and Education.json\n","Cleaned up: Amity University.json\n","Cleaned up: Rajiv Gandhi Institute of Petroleum Technology.json\n","Cleaned up: AU College of Enginnering.json\n","Cleaned up: Sant Longowal Institute of Engineering and Technology.json\n","Cleaned up: IIT Madras.json\n","Cleaned up: NIT Delhi.json\n","Cleaned up: SRM Chennai.json\n","Cleaned up: Indian Institute of Space Science and Technology.json\n","Cleaned up: Siddaganga Institute of Technology.json\n","Cleaned up: Anna University.json\n","Cleaned up: Vel Tech Rangarajan Dr. Sagunthala R _ D Institute of Science and Technology.json\n","Cleaned up: NIT Warangal.json\n","Cleaned up: Manipal University_ Jaipur.json\n","Cleaned up: NIT Meghalaya.json\n","Cleaned up: Sathyabama Institute of Science and Technology Chennai.json\n","Cleaned up: IIT Palakkad.json\n","Cleaned up: IIT Indore.json\n","Cleaned up: Jawaharlal Nehru Technological University.json\n","Cleaned up: PSG College of Technology.json\n","Cleaned up: NIT  Puducherry.json\n","Cleaned up: UPES.json\n"]}],"source":["import os\n","import json\n","import re\n","import uuid\n","from typing import Dict, List, Any, Tuple\n","from pathlib import Path\n","import hashlib\n","from datetime import datetime\n","import shutil\n","import zipfile\n","\n","class NIRFDataConverter:\n","    def __init__(self, max_chunk_size: int = 1000):\n","        \"\"\"\n","        Initialize the NIRF Data Converter\n","\n","        Args:\n","            max_chunk_size: Maximum number of characters per chunk\n","        \"\"\"\n","        self.max_chunk_size = max_chunk_size\n","        self.processed_data = []\n","\n","        self.faculty_patterns = {\n","            'basic_entry': r'(\\d+)\\s+([A-Z\\s]+?)\\s+(\\d+)\\s+(Assistant Professor|Associate Professor|Professor|Lecturer)\\s+(Male|Female)\\s+(Ph\\.?\\s?D\\.?|M\\.?\\s?Tech|B\\.?\\s?Tech|M\\.?\\s?Sc|B\\.?\\s?Sc|LLM|MBA|MCA)\\s+(\\d+)\\s+(Yes|No)\\s+(\\d{2}-\\d{2}-\\d{4})',\n","            'pipe_separated': r'(\\d+)\\s*\\|\\s*([A-Z\\s]+?)\\s*\\|\\s*(\\d+)\\s*\\|\\s*(Assistant Professor|Associate Professor|Professor|Lecturer)\\s*\\|\\s*(Male|Female)\\s*\\|\\s*(Ph\\.?\\s?D\\.?|M\\.?\\s?Tech|B\\.?\\s?Tech|M\\.?\\s?Sc|B\\.?\\s?Sc|LLM|MBA|MCA)\\s*\\|\\s*(\\d+)\\s*\\|\\s*(Yes|No)\\s*\\|\\s*(\\d{2}-\\d{2}-\\d{4})',\n","            'structured_with_name': r'Name:\\s*([A-Za-z\\s]+?)\\s*\\|\\s*Designation:\\s*([^|]+)\\s*\\|\\s*Gender:\\s*([^|]+)\\s*\\|\\s*Qualification:\\s*([^|]+)'\n","        }\n","        self.qualification_mappings = {\n","            'ph d': 'Ph.D', 'phd': 'Ph.D', 'ph.d': 'Ph.D', 'ph.d.': 'Ph.D',\n","            'm tech': 'M.Tech', 'm.tech': 'M.Tech', 'mtech': 'M.Tech',\n","            'b tech': 'B.Tech', 'b.tech': 'B.Tech', 'btech': 'B.Tech',\n","            'm sc': 'M.Sc', 'm.sc': 'M.Sc', 'msc': 'M.Sc',\n","            'b sc': 'B.Sc', 'b.sc': 'B.Sc', 'bsc': 'B.Sc',\n","            'llm': 'LLM', 'l.l.m': 'LLM', 'l.l.m.': 'LLM'\n","        }\n","        self.designation_mappings = {\n","            'assistant': 'Assistant Professor',\n","            'associate': 'Associate Professor',\n","            'professor': 'Professor',\n","            'lecturer': 'Lecturer'\n","        }\n","\n","    def extract_institute_name(self, content: str) -> str:\n","        \"\"\"Extract institute name from the content\"\"\"\n","        pattern = r'Institute Name:\\s*([^\\[]+)\\s*\\[([^\\]]+)\\]'\n","        match = re.search(pattern, content)\n","        if match:\n","            return match.group(1).strip()\n","        return \"Unknown Institute\"\n","\n","    def extract_institute_code(self, content: str) -> str:\n","        \"\"\"Extract institute code from the content\"\"\"\n","        pattern = r'Institute Name:.*?\\[([^\\]]+)\\]'\n","        match = re.search(pattern, content)\n","        if match:\n","            return match.group(1).strip()\n","        return \"Unknown Code\"\n","\n","    def parse_sections(self, content: str) -> Dict[str, str]:\n","        \"\"\"Parse content into sections based on ###SECTION:...### markers\"\"\"\n","        sections = {}\n","        section_pattern = r'###SECTION:([^#]+)###'\n","        parts = re.split(section_pattern, content)\n","        if parts[0].strip():\n","            sections['HEADER'] = parts[0].strip()\n","        for i in range(1, len(parts), 2):\n","            if i + 1 < len(parts):\n","                section_name = parts[i].strip()\n","                section_content = parts[i + 1].strip()\n","                if section_content:\n","                    sections[section_name] = section_content\n","        return sections\n","\n","    def chunk_text(self, text: str, section_name: str) -> List[str]:\n","        \"\"\"Split text into chunks if it exceeds max_chunk_size\"\"\"\n","        if len(text) <= self.max_chunk_size:\n","            return [text]\n","        chunks = []\n","        delimiters = ['\\n\\n', '\\n', '. ', ', ', ' ']\n","        def split_by_delimiter(text: str, delimiter: str) -> List[str]:\n","            parts = text.split(delimiter)\n","            result = []\n","            current_chunk = \"\"\n","            for part in parts:\n","                if len(current_chunk) + len(delimiter) + len(part) <= self.max_chunk_size:\n","                    if current_chunk:\n","                        current_chunk += delimiter + part\n","                    else:\n","                        current_chunk = part\n","                else:\n","                    if current_chunk:\n","                        result.append(current_chunk)\n","                    current_chunk = part\n","            if current_chunk:\n","                result.append(current_chunk)\n","            return result\n","        for delimiter in delimiters:\n","            if delimiter in text:\n","                chunks = split_by_delimiter(text, delimiter)\n","                if all(len(chunk) <= self.max_chunk_size for chunk in chunks):\n","                    break\n","        if not chunks or any(len(chunk) > self.max_chunk_size for chunk in chunks):\n","            chunks = [text[i:i + self.max_chunk_size] for i in range(0, len(text), self.max_chunk_size)]\n","        return chunks\n","\n","    def _is_faculty_section(self, section_name: str, content: str) -> bool:\n","        \"\"\"Check if section contains faculty data\"\"\"\n","        faculty_indicators = ['faculty', 'professor', 'lecturer', 'designation', 'qualification']\n","        section_lower = section_name.lower()\n","        content_lower = content.lower()\n","        return (any(indicator in section_lower for indicator in faculty_indicators) or\n","                any(indicator in content_lower for indicator in faculty_indicators[:3]))\n","\n","    def _is_student_section(self, section_name: str, content: str) -> bool:\n","        \"\"\"Check if section contains student enrollment data\"\"\"\n","        student_indicators = ['student', 'enrollment', 'strength', 'admitted', 'ug', 'pg', 'undergraduate', 'postgraduate']\n","        section_lower = section_name.lower()\n","        content_lower = content.lower()\n","        return (any(indicator in section_lower for indicator in student_indicators) or\n","                any(indicator in content_lower for indicator in student_indicators[:6]))\n","\n","    def parse_faculty_data(self, content: str, metadata: Dict[str, Any]) -> int:\n","        \"\"\"\n","        Simple algorithm: INDEX always comes before NAME\n","        Pattern: Employment_Type -> INDEX -> Name -> ...\n","        \"\"\"\n","        print(f\"   Looking for pattern: INDEX -> Name...\")\n","        lines = content.split('\\n')\n","        faculty_indices = []\n","        for i in range(len(lines) - 1):\n","            current_line = lines[i].strip()\n","            next_line = lines[i + 1].strip() if i + 1 < len(lines) else \"\"\n","            if current_line.isdigit():\n","                index = int(current_line)\n","                if (next_line and\n","                    re.match(r'^[A-Za-z\\s\\.]+$', next_line) and\n","                    3 <= len(next_line) <= 50 and\n","                    1 <= index <= 50000):\n","                    faculty_indices.append(index)\n","                    print(f\"    Found: {index} -> {next_line}\")\n","        if faculty_indices:\n","            max_index = max(faculty_indices)\n","            min_index = min(faculty_indices)\n","            total_found = len(faculty_indices)\n","            print(f\"    Summary:\")\n","            print(f\"      Total indices found: {total_found}\")\n","            print(f\"      Index range: {min_index} to {max_index}\")\n","            print(f\"      Sample indices: {sorted(faculty_indices)[:10]}...\")\n","            print(f\"    FINAL FACULTY COUNT: {max_index}\")\n","            return max_index\n","        else:\n","            print(f\"    No valid index->name patterns found\")\n","            return 0\n","\n","    def test_index_before_name(self, content: str, show_samples: int = 10):\n","        \"\"\"Quick test to show index->name patterns found\"\"\"\n","        lines = content.split('\\n')\n","        patterns_found = []\n","        for i in range(len(lines) - 1):\n","            current_line = lines[i].strip()\n","            next_line = lines[i + 1].strip() if i + 1 < len(lines) else \"\"\n","            if (current_line.isdigit() and\n","                next_line and\n","                re.match(r'^[A-Za-z\\s\\.]+$', next_line) and\n","                3 <= len(next_line) <= 50):\n","                index = int(current_line)\n","                if 1 <= index <= 50000:\n","                    patterns_found.append((index, next_line, i+1))\n","        print(f\"Index->Name patterns found: {len(patterns_found)}\")\n","        print(f\"Showing first {show_samples} and last {show_samples}:\")\n","        for i, (idx, name, line_num) in enumerate(patterns_found[:show_samples]):\n","            print(f\"  {idx:3d} -> {name} (line {line_num})\")\n","        if len(patterns_found) > show_samples * 2:\n","            print(f\"  ... ({len(patterns_found) - show_samples * 2} more) ...\")\n","        for i, (idx, name, line_num) in enumerate(patterns_found[-show_samples:]):\n","            print(f\"  {idx:3d} -> {name} (line {line_num})\")\n","        if patterns_found:\n","            max_idx = max(pattern[0] for pattern in patterns_found)\n","            print(f\"\\nHighest index found: {max_idx}\")\n","            return max_idx\n","        return 0\n","\n","    def parse_student_data(self, content: str, metadata: Dict[str, Any]) -> Dict[str, int]:\n","        \"\"\"Enhanced student enrollment data extraction with better table parsing\"\"\"\n","        student_counts = {\n","            'ug_4_years': 0,\n","            'ug_5_years': 0,\n","            'pg_2_years': 0,\n","            'pg_3_years': 0,  # Already defined\n","            'pg_integrated': 0,\n","            'total_students': 0\n","        }\n","\n","        # Enhanced patterns specifically for table-based data\n","        enhanced_patterns = {\n","            'ug_4_years': [\n","                r'UG\\s*\\[\\s*4\\s+Years?\\s+Program\\(s\\)\\s*\\]\\s*(\\d+)\\s+(\\d+)\\s+(\\d+)',\n","                r'UG\\s*\\[\\s*4\\s*Years?[^\\]]*?\\]\\s*(\\d+)\\s+(\\d+)\\s+(\\d+)',\n","                r'UG\\s*\\[\\s*4\\s*Years?[^\\]]*?\\]\\s*[^\\d]*?(\\d+)\\s+(\\d+)\\s+(\\d+)',\n","                r'UG\\s*\\[4\\s*Years?[^\\]]*?\\][^\\d]*(\\d+)',\n","                r'UG.*?4.*?Years.*?Total[^\\d]*(\\d+)',\n","            ],\n","            'ug_5_years': [\n","                r'UG\\s*\\[\\s*5\\s+Years?\\s+Program\\(s\\)\\s*\\]\\s*(\\d+)\\s+(\\d+)\\s+(\\d+)',\n","                r'UG\\s*\\[\\s*5\\s*Years?[^\\]]*?\\]\\s*(\\d+)\\s+(\\d+)\\s+(\\d+)',\n","                r'UG\\s*\\[\\s*5\\s*Years?[^\\]]*?\\]\\s*[^\\d]*?(\\d+)\\s+(\\d+)\\s+(\\d+)',\n","                r'UG\\s*\\[5\\s*Years?[^\\]]*?\\][^\\d]*(\\d+)',\n","                r'UG.*?5.*?Years.*?Total[^\\d]*(\\d+)',\n","            ],\n","            'pg_2_years': [\n","                r'PG\\s*\\[\\s*2\\s+Years?\\s+Program\\(s\\)\\s*\\]\\s*(\\d+)\\s+(\\d+)\\s+(\\d+)',\n","                r'PG\\s*\\[\\s*2\\s*Years?\\s+Program\\(s\\)\\s*\\]\\s*(\\d+)\\s+(\\d+)\\s+(\\d+)',\n","                r'PG\\s*\\[\\s*2\\s*Years?[^\\]]*?\\]\\s*(\\d+)\\s+(\\d+)\\s+(\\d+)',\n","                r'PG\\s*\\[\\s*2\\s*Years?[^\\]]*?\\]\\s*[^\\d]*?(\\d+)\\s+(\\d+)\\s+(\\d+)',\n","                r'PG\\s*\\[\\s*2\\s*Years?[^\\]]*?\\][^\\d]*?(\\d+)',\n","                r'PG.*?2.*?Years?.*?Program[^\\d]*(\\d+)',\n","                r'PG.*?2.*?Years?[^\\d]*Total[^\\d]*(\\d+)',\n","                r'M\\.?Tech.*?Total[^\\d]*(\\d+)',\n","            ],\n","            'pg_3_years': [ # ADD THIS NEW SECTION\n","                r'PG\\s*\\[\\s*3\\s+Years?\\s+Program\\(s\\)\\s*\\]\\s*(\\d+)\\s+(\\d+)\\s+(\\d+)',\n","                r'PG\\s*\\[\\s*3\\s*Years?[^\\]]*?\\]\\s*(\\d+)\\s+(\\d+)\\s+(\\d+)',\n","                r'PG\\s*\\[\\s*3\\s*Years?[^\\]]*?\\]\\s*[^\\d]*?(\\d+)\\s+(\\d+)\\s+(\\d+)',\n","                r'PG\\s*\\[3\\s*Years?[^\\]]*?\\][^\\d]*(\\d+)',\n","                r'PG.*?3.*?Years.*?Total[^\\d]*(\\d+)',\n","            ],\n","            'pg_integrated': [\n","                r'PG\\s*\\[\\s*.*?Integrated[^\\]]*?\\]\\s*(\\d+)\\s+(\\d+)\\s+(\\d+)',\n","                r'PG\\s*\\[.*?Integrated[^\\]]*?\\][^\\d]*(\\d+)',\n","                r'Integrated.*?PG[^\\d]*(\\d+)',\n","                r'PG-Integrated\\s*(\\d+)\\s+(\\d+)\\s+(\\d+)',\n","                r'PG-Integrated[^\\d]*(\\d+)\\s+(\\d+)\\s+(\\d+)',\n","                r'PG\\s*-\\s*Integrated\\s*(\\d+)\\s+(\\d+)\\s+(\\d+)',\n","            ]\n","        }\n","\n","        print(f\"    Analyzing content length: {len(content)} characters\")\n","        print(f\"    Sample content preview: {content[:200]}...\")\n","\n","        for category, patterns in enhanced_patterns.items():\n","            found_values = []\n","            for i, pattern in enumerate(patterns):\n","                matches = re.findall(pattern, content, re.IGNORECASE | re.MULTILINE | re.DOTALL)\n","                if matches:\n","                    for match in matches:\n","                        try:\n","                            if isinstance(match, tuple):\n","                                if len(match) >= 3:\n","                                    value = int(match[2])\n","                                    print(f\"    Pattern {i+1} for {category} found TUPLE: Male={match[0]}, Female={match[1]}, Total={match[2]}\")\n","                                else:\n","                                    value = int(match[-1])\n","                                    print(f\"    Pattern {i+1} for {category} found TUPLE (fallback): {match} -> {value}\")\n","                            else:\n","                                value = int(match)\n","                                print(f\"    Pattern {i+1} for {category} found SINGLE: {value}\")\n","\n","                            if 0 < value < 50000:\n","                                found_values.append(value)\n","                            else:\n","                                print(f\"    Rejected unreasonable value: {value}\")\n","\n","                        except (ValueError, IndexError) as e:\n","                            print(f\"    Error parsing match {match} for {category}: {e}\")\n","                            continue\n","\n","            if found_values:\n","                max_value = max(found_values)\n","                student_counts[category] = max_value\n","                print(f\"    Final {category}: {max_value} students (from values: {found_values})\")\n","            else:\n","                print(f\"    No valid values found for {category}\")\n","\n","        if student_counts['pg_2_years'] == 0 or student_counts['pg_integrated'] == 0 or student_counts['pg_3_years'] == 0:\n","            print(\"    Some PG programs not found with primary patterns, trying line-by-line analysis...\")\n","            lines = content.split('\\n')\n","            for i, line in enumerate(lines):\n","                line_clean = line.strip()\n","                if student_counts['pg_2_years'] == 0 and ('PG [2 Year' in line_clean or 'PG [2 Years' in line_clean):\n","                    print(f\"    Found PG 2 Year line {i}: {line_clean}\")\n","                    for j in range(1, 4):\n","                        if i + j < len(lines):\n","                            next_line = lines[i + j].strip()\n","                            number_match = re.findall(r'\\b(\\d+)\\s+(\\d+)\\s+(\\d+)\\b', next_line)\n","                            if number_match:\n","                                male, female, total = map(int, number_match[0])\n","                                print(f\"    Found PG 2 Years numbers in line {i+j}: Male={male}, Female={female}, Total={total}\")\n","                                if total == male + female and total > 0:\n","                                    student_counts['pg_2_years'] = total\n","                                    print(f\"    Successfully extracted PG 2 Years: {total}\")\n","                                    break\n","                # ADD THIS NEW SECTION FOR PG 3 YEARS\n","                if student_counts['pg_3_years'] == 0 and ('PG [3 Year' in line_clean or 'PG [3 Years' in line_clean):\n","                    print(f\"    Found PG 3 Year line {i}: {line_clean}\")\n","                    for j in range(1, 4):\n","                        if i + j < len(lines):\n","                            next_line = lines[i + j].strip()\n","                            number_match = re.findall(r'\\b(\\d+)\\s+(\\d+)\\s+(\\d+)\\b', next_line)\n","                            if number_match:\n","                                male, female, total = map(int, number_match[0])\n","                                print(f\"    Found PG 3 Years numbers in line {i+j}: Male={male}, Female={female}, Total={total}\")\n","                                if total == male + female and total > 0:\n","                                    student_counts['pg_3_years'] = total\n","                                    print(f\"    Successfully extracted PG 3 Years: {total}\")\n","                                    break\n","                if (('PG [' in line_clean and ('Integrated' in line_clean or '5 Years' in line_clean or 'Dual' in line_clean)) or\n","                    'PG-Integrated' in line_clean or 'PG - Integrated' in line_clean):\n","                    print(f\"    Found PG Integrated line {i}: {line_clean}\")\n","                    for j in range(1, 4):\n","                        if i + j < len(lines):\n","                            next_line = lines[i + j].strip()\n","                            number_match = re.findall(r'\\b(\\d+)\\s+(\\d+)\\s+(\\d+)\\b', next_line)\n","                            if number_match:\n","                                male, female, total = map(int, number_match[0])\n","                                print(f\"    Found PG Integrated numbers in line {i+j}: Male={male}, Female={female}, Total={total}\")\n","                                if total == male + female and total > 0:\n","                                    student_counts['pg_integrated'] += total\n","                                    print(f\"    Successfully added to PG Integrated: +{total} (total now: {student_counts['pg_integrated']})\")\n","                                    break\n","\n","        calculated_total = (student_counts['ug_4_years'] +\n","                            student_counts['ug_5_years'] +\n","                            student_counts['pg_2_years'] +\n","                            student_counts['pg_3_years'] +\n","                            student_counts['pg_integrated'])\n","\n","        if calculated_total > 0:\n","            student_counts['total_students'] = calculated_total\n","            print(f\"    Calculated total students: {calculated_total}\")\n","\n","        return student_counts\n","\n","    def debug_section_content(self, section_name: str, content: str) -> None:\n","        \"\"\"Enhanced debug method to analyze section content for pattern matching\"\"\"\n","        print(f\"\\n=== DEBUGGING SECTION: {section_name} ===\")\n","        print(f\"Section length: {len(content)} characters\")\n","        lines = content.split('\\n')\n","        relevant_lines = []\n","        for i, line in enumerate(lines):\n","            line_clean = line.strip()\n","            if any(keyword in line_clean.upper() for keyword in ['UG [', 'PG [', 'PROGRAM', 'YEARS']):\n","                relevant_lines.append((i, line_clean))\n","            numbers = re.findall(r'\\b\\d+\\b', line_clean)\n","            if len(numbers) >= 3:\n","                relevant_lines.append((i, line_clean))\n","        if relevant_lines:\n","            print(\"Relevant lines found:\")\n","            for line_num, line_content in relevant_lines[:15]:\n","                print(f\"  Line {line_num+1}: {line_content}\")\n","        else:\n","            print(\"No obvious table structure found\")\n","            print(\"\\nFirst 10 non-empty lines:\")\n","            non_empty_lines = [line.strip() for line in lines if line.strip()]\n","            for i, line in enumerate(non_empty_lines[:10]):\n","                print(f\"  {i+1}: {line}\")\n","        pg_analysis = []\n","        for i, line in enumerate(lines):\n","            line_upper = line.upper()\n","            if ('PG' in line_upper and\n","                ('2' in line or '3' in line or 'INTEGRATED' in line_upper or  # '3' is already here\n","                 '5 YEARS' in line_upper or 'DUAL' in line_upper)) or 'PG-INTEGRATED' in line_upper:\n","                pg_analysis.append((i, line.strip()))\n","                if i+1 < len(lines):\n","                    pg_analysis.append((i+1, f\"  -> {lines[i+1].strip()}\"))\n","                if i+2 < len(lines):\n","                    pg_analysis.append((i+2, f\"  -> {lines[i+2].strip()}\"))\n","        if pg_analysis:\n","            print(\"\\nPG Programs (2-Year/3-Year/Integrated/PG-Integrated) analysis:\") # Already mentions 3-Year\n","            for line_info in pg_analysis[:20]:\n","                print(f\"  Line {line_info[0]+1}: {line_info[1]}\")\n","        else:\n","            print(\"\\nNo PG program indicators found\")\n","        print(\"=\" * 50)\n","\n","    def create_qdrant_point(self, chunk: str, institute_name: str, institute_code: str,\n","                            section_name: str, chunk_index: int = 0, total_chunks: int = 1) -> Dict[str, Any]:\n","        \"\"\"Create a Qdrant-compatible point with enhanced faculty support\"\"\"\n","        content_hash = hashlib.md5(f\"{institute_code}_{section_name}_{chunk_index}_{chunk}\".encode()).hexdigest()\n","        point_id = str(uuid.uuid5(uuid.NAMESPACE_DNS, content_hash))\n","        payload = {\n","            \"institute_name\": institute_name,\n","            \"institute_code\": institute_code,\n","            \"content_type\": section_name,\n","            \"chunk_index\": chunk_index,\n","            \"total_chunks\": total_chunks,\n","            \"content\": chunk,\n","            \"content_length\": len(chunk)\n","        }\n","        point = {\n","            \"id\": point_id,\n","            \"payload\": payload,\n","            \"vector\": None\n","        }\n","        return point\n","\n","    def normalize_json_content(self, data: Any) -> Any:\n","        \"\"\"\n","        Recursively normalize JSON by replacing all newlines in content fields with single space\n","        Only modifies 'content' fields, leaves all other fields unchanged\n","        \"\"\"\n","        if isinstance(data, dict):\n","            normalized_data = {}\n","            for key, value in data.items():\n","                if key == 'content' and isinstance(value, str):\n","                    # Replace all variations of newlines with single space\n","                    normalized_value = value.replace('\\\\n', ' ').replace('\\n', ' ')\n","                    # Clean up multiple spaces\n","                    normalized_value = ' '.join(normalized_value.split())\n","                    normalized_data[key] = normalized_value\n","                else:\n","                    normalized_data[key] = self.normalize_json_content(value)\n","            return normalized_data\n","        elif isinstance(data, list):\n","            return [self.normalize_json_content(item) for item in data]\n","        else:\n","            return data\n","\n","    def process_file(self, file_path: str) -> List[Dict[str, Any]]:\n","        \"\"\"Process a single NIRF data file\"\"\"\n","        try:\n","            with open(file_path, 'r', encoding='utf-8') as file:\n","                content = file.read()\n","        except UnicodeDecodeError:\n","            with open(file_path, 'r', encoding='latin-1') as file:\n","                content = file.read()\n","        institute_name = self.extract_institute_name(content)\n","        institute_code = self.extract_institute_code(content)\n","        print(f\"Processing: {institute_name} ({institute_code})\")\n","        sections = self.parse_sections(content)\n","        points = []\n","        all_student_data = {\n","            'ug_4_years': 0,\n","            'ug_5_years': 0,\n","            'pg_2_years': 0,\n","            'pg_3_years': 0,\n","            'pg_integrated': 0,\n","            'total_students': 0\n","        }\n","        for section_name, section_content in sections.items():\n","            if self._is_faculty_section(section_name, section_content):\n","                print(f\"  Processing faculty section: {section_name}\")\n","                self.debug_section_content(section_name, section_content)\n","                faculty_count = self.parse_faculty_data(section_content, {\n","                    'institute_name': institute_name,\n","                    'institute_code': institute_code,\n","                    'section_name': section_name\n","                })\n","                if faculty_count > 0:\n","                    print(f\"  Found {faculty_count} faculty members\")\n","                    faculty_content = f\"Faculty Total Strength: {faculty_count}\"\n","                    point = self.create_qdrant_point(\n","                        chunk=faculty_content,\n","                        institute_name=institute_name,\n","                        institute_code=institute_code,\n","                        section_name=section_name,\n","                        chunk_index=0,\n","                        total_chunks=1\n","                    )\n","                    points.append(point)\n","                else:\n","                    print(f\"  No faculty found in '{section_name}', processing as normal content.\")\n","                    chunks = self.chunk_text(section_content, section_name)\n","                    for i, chunk in enumerate(chunks):\n","                        point = self.create_qdrant_point(\n","                            chunk=chunk,\n","                            institute_name=institute_name,\n","                            institute_code=institute_code,\n","                            section_name=section_name,\n","                            chunk_index=i,\n","                            total_chunks=len(chunks)\n","                        )\n","                        points.append(point)\n","            elif self._is_student_section(section_name, section_content):\n","                print(f\"  Found student section: {section_name}\")\n","                self.debug_section_content(section_name, section_content)\n","                student_data = self.parse_student_data(section_content, {\n","                    'institute_name': institute_name,\n","                    'institute_code': institute_code,\n","                    'section_name': section_name\n","                })\n","                for key in all_student_data.keys():\n","                    if key != 'total_students':\n","                        all_student_data[key] = max(all_student_data[key], student_data.get(key, 0))\n","                        print(f\"  Accumulated student data so far: {all_student_data}\")\n","                chunks = self.chunk_text(section_content, section_name)\n","                for i, chunk in enumerate(chunks):\n","                    point = self.create_qdrant_point(\n","                        chunk=chunk,\n","                        institute_name=institute_name,\n","                        institute_code=institute_code,\n","                        section_name=section_name,\n","                        chunk_index=i,\n","                        total_chunks=len(chunks)\n","                    )\n","                    points.append(point)\n","            else:\n","                chunks = self.chunk_text(section_content, section_name)\n","                for i, chunk in enumerate(chunks):\n","                    point = self.create_qdrant_point(\n","                        chunk=chunk,\n","                        institute_name=institute_name,\n","                        institute_code=institute_code,\n","                        section_name=section_name,\n","                        chunk_index=i,\n","                        total_chunks=len(chunks)\n","                    )\n","                    points.append(point)\n","        if any(count > 0 for count in all_student_data.values() if count != all_student_data['total_students']):\n","            total_calculated = (all_student_data['ug_4_years'] +\n","                                all_student_data['ug_5_years'] +\n","                                all_student_data['pg_2_years'] +\n","                                all_student_data['pg_3_years'] +\n","                                all_student_data['pg_integrated'])\n","            all_student_data['total_students'] = total_calculated\n","            print(f\"  Creating consolidated student strength point: {all_student_data}\")\n","            student_content_parts = []\n","            if all_student_data['ug_4_years'] > 0:\n","                student_content_parts.append(f\"UG 4 Years: {all_student_data['ug_4_years']}\")\n","            if all_student_data['ug_5_years'] > 0:\n","                student_content_parts.append(f\"UG 5 Years: {all_student_data['ug_5_years']}\")\n","            if all_student_data['pg_2_years'] > 0:\n","                student_content_parts.append(f\"PG 2 Years: {all_student_data['pg_2_years']}\")\n","            if all_student_data['pg_3_years'] > 0:\n","                student_content_parts.append(f\"PG 3 Years: {all_student_data['pg_3_years']}\")\n","            if all_student_data['pg_integrated'] > 0:\n","                student_content_parts.append(f\"PG Integrated: {all_student_data['pg_integrated']}\")\n","            if total_calculated > 0:\n","                student_content_parts.append(f\"Total Students: {total_calculated}\")\n","            student_content = \"Students Strength - \" + \", \".join(student_content_parts)\n","            point = self.create_qdrant_point(\n","                chunk=student_content,\n","                institute_name=institute_name,\n","                institute_code=institute_code,\n","                section_name=\"students_strength\",\n","                chunk_index=0,\n","                total_chunks=1\n","            )\n","            points.append(point)\n","        print(f\"Created {len(points)} points for {institute_name}\")\n","        return points\n","\n","    def process_directory(self, directory_path: str) -> None:\n","        \"\"\"Process all .txt files in a directory and save each individually\"\"\"\n","        directory = Path(directory_path)\n","        txt_files = list(directory.glob(\"*.txt\"))\n","        if not txt_files:\n","            print(f\"No .txt files found in {directory_path}\")\n","            return\n","        print(f\"Found {len(txt_files)} files to process\")\n","        for file_path in txt_files:\n","            print(f\"\\nProcessing file: {file_path.name}\")\n","            try:\n","                points = self.process_file(str(file_path))\n","                input_name = file_path.stem\n","                output_file = f\"{input_name}.json\"\n","                self.save_to_json(points, output_file)\n","                stats = self.get_statistics(points)\n","                print(f\"  Created {stats['total_points']} points\")\n","            except Exception as e:\n","                print(f\"Error processing {file_path.name}: {str(e)}\")\n","                continue\n","\n","    def save_to_json(self, points: List[Dict[str, Any]], output_file: str):\n","        \"\"\"Save points to JSON file with normalization\"\"\"\n","        output_data = {\n","            \"total_points\": len(points),\n","            \"points\": points\n","        }\n","\n","        # Apply normalization\n","        output_data = self.normalize_json_content(output_data)\n","\n","        with open(output_file, 'w', encoding='utf-8') as f:\n","            json.dump(output_data, f, indent=2, ensure_ascii=False)\n","        print(f\"Saved {len(points)} points to {output_file} (normalized)\")\n","\n","    def get_statistics(self, points: List[Dict[str, Any]]) -> Dict[str, Any]:\n","        \"\"\"Get statistics about the processed data\"\"\"\n","        if not points:\n","            return {\"error\": \"No points processed\"}\n","        institutes = set()\n","        sections = set()\n","        total_content_length = 0\n","        chunks_per_section = {}\n","        for point in points:\n","            payload = point[\"payload\"]\n","            institutes.add(payload[\"institute_name\"])\n","            sections.add(payload[\"content_type\"])\n","            total_content_length += payload[\"content_length\"]\n","            section = payload[\"content_type\"]\n","            if section not in chunks_per_section:\n","                chunks_per_section[section] = 0\n","            chunks_per_section[section] += 1\n","        return {\n","            \"total_points\": len(points),\n","            \"unique_institutes\": len(institutes),\n","            \"unique_sections\": len(sections),\n","            \"institutes\": list(institutes),\n","            \"sections\": list(sections),\n","            \"total_content_length\": total_content_length,\n","            \"avg_content_length\": total_content_length / len(points),\n","            \"chunks_per_section\": chunks_per_section\n","        }\n","\n","    def quick_faculty_test(self, file_path: str):\n","        \"\"\"Quick test method to verify faculty counting on a specific file\"\"\"\n","        try:\n","            with open(file_path, 'r', encoding='utf-8') as file:\n","                content = file.read()\n","        except UnicodeDecodeError:\n","            with open(file_path, 'r', encoding='latin-1') as file:\n","                content = file.read()\n","        print(f\"Testing faculty counting on: {file_path}\")\n","        print(\"=\" * 60)\n","        institute_name = self.extract_institute_name(content)\n","        print(f\"Institute: {institute_name}\")\n","        sections = self.parse_sections(content)\n","        total_faculty = 0\n","        for section_name, section_content in sections.items():\n","            if self._is_faculty_section(section_name, section_content):\n","                print(f\"\\n--- FACULTY SECTION: {section_name} ---\")\n","                first_lines = section_content.split('\\n')[:10]\n","                print(\"Sample content:\")\n","                for i, line in enumerate(first_lines):\n","                    if line.strip():\n","                        print(f\"  {line.strip()}\")\n","                    if i >= 5:\n","                        break\n","                print(f\"\\nRunning faculty analysis...\")\n","                faculty_count = self.parse_faculty_data(section_content, {})\n","                total_faculty += faculty_count\n","                print(f\"\\nFaculty count in '{section_name}': {faculty_count}\")\n","        print(f\"\\n{'='*60}\")\n","        print(f\"TOTAL FACULTY COUNT: {total_faculty}\")\n","        print(f\"{'='*60}\")\n","        return total_faculty\n","\n","    def find_last_faculty_index(self, content: str) -> int:\n","        \"\"\"Quick method to just find the last faculty index\"\"\"\n","        lines = content.split('\\n')\n","        last_100_lines = lines[-100:] if len(lines) > 100 else lines\n","        max_number = 0\n","        for line in last_100_lines:\n","            line = line.strip()\n","            if line.isdigit():\n","                num = int(line)\n","                if 1 <= num <= 50000:\n","                    max_number = max(max_number, num)\n","        if max_number == 0:\n","            for line in last_100_lines:\n","                line = line.strip()\n","                match = re.match(r'^\\d+', line)\n","                if match:\n","                    num = int(match.group(1))\n","                    if 1 <= num <= 50000:\n","                        max_number = max(max_number, num)\n","        return max_number\n","\n","def test_student_parsing(test_cases: List[Dict[str, Any]]):\n","    \"\"\"Test method to verify student data parsing with various formats\"\"\"\n","    converter = NIRFDataConverter()\n","    print(\"=\" * 60)\n","    print(\"TESTING STUDENT DATA PARSING\")\n","    print(\"=\" * 60)\n","    for i, test_case in enumerate(test_cases, 1):\n","        print(f\"\\n--- TEST CASE {i}: {test_case.get('description', 'No description')} ---\")\n","        content = test_case['content']\n","        expected = test_case.get('expected', {})\n","        print(f\"Input content preview: {content[:200]}...\")\n","        result = converter.parse_student_data(content, {'test_case': i})\n","        print(f\"\\nResults:\")\n","        for program_type, count in result.items():\n","            expected_count = expected.get(program_type, 'Not specified')\n","            status = \"‚úì\" if count == expected.get(program_type, count) else \"‚úó\"\n","            print(f\"  {status} {program_type}: {count} (expected: {expected_count})\")\n","        print(\"-\" * 40)\n","\n","def main():\n","    \"\"\"Main function to run the converter\"\"\"\n","    print(\"NIRF Data to Qdrant JSON Converter\")\n","    print(\"=\" * 40)\n","    input_dir = input(\"Enter the path to directory containing NIRF .txt files: \").strip()\n","    if not os.path.exists(input_dir):\n","        print(f\"Error: Directory '{input_dir}' does not exist!\")\n","        return\n","    chunk_size_input = input(\"Enter max chunk size in characters (default: 1000): \").strip()\n","    try:\n","        chunk_size = int(chunk_size_input) if chunk_size_input else 1000\n","    except ValueError:\n","        chunk_size = 1000\n","        print(\"Invalid chunk size, using default: 1000\")\n","    converter = NIRFDataConverter(max_chunk_size=chunk_size)\n","    print(f\"\\nProcessing files in: {input_dir}\")\n","    print(f\"Max chunk size: {chunk_size}\")\n","    print(\"Each file will be saved as: [filename].json\")\n","    print(\"-\" * 40)\n","    converter.process_directory(input_dir)\n","    print(\"\\nAll files processed successfully!\")\n","\n","def setup_colab():\n","    \"\"\"Setup function for Google Colab\"\"\"\n","    print(\"Setting up for Google Colab...\")\n","    try:\n","        import google.colab\n","        from google.colab import files\n","        print(\"Google Colab detected!\")\n","        upload_files = input(\"Do you want to upload files? (y/n): \").lower().strip()\n","        if upload_files == 'y':\n","            print(\"Please select your NIRF .txt files:\")\n","            uploaded = files.upload()\n","            os.makedirs('uploaded_files', exist_ok=True)\n","            for filename in uploaded.keys():\n","                os.rename(filename, f'uploaded_files/{filename}')\n","            return 'uploaded_files'\n","        else:\n","            return input(\"Enter the path to directory containing NIRF .txt files: \").strip()\n","    except ImportError:\n","        return None\n","\n","if __name__ == \"__main__\":\n","    colab_dir = setup_colab()\n","    if colab_dir:\n","        print(f\"Using directory: {colab_dir}\")\n","        converter = NIRFDataConverter(max_chunk_size=1000)\n","        converter.process_directory(colab_dir)\n","        try:\n","            from google.colab import files\n","            json_files = list(Path('.').glob('*.json'))\n","            if json_files:\n","                timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n","                zip_filename = f'nirf_processed_data_{timestamp}.zip'\n","                with zipfile.ZipFile(zip_filename, 'w') as zipf:\n","                    for json_file in json_files:\n","                        zipf.write(str(json_file), json_file.name)\n","                        print(f\"Added to ZIP: {json_file}\")\n","                print(f\"Created ZIP file: {zip_filename}\")\n","                files.download(zip_filename)\n","                for json_file in json_files:\n","                    os.remove(str(json_file))\n","                    print(f\"Cleaned up: {json_file}\")\n","            else:\n","                print(\"No JSON files found to download\")\n","        except ImportError:\n","            pass\n","    else:\n","        test_cases = [\n","            {\n","                'description': 'Multiple PG-Integrated Programs Format',\n","                'content': '''###SECTION:STUDENT_STRENGTH###\n","Student Enrollment Data\n","\n","UG [4 Years Program(s)]\n","1000      500       1500\n","\n","PG [2 Year Program(s)]\n","600       200       800\n","\n","PG [5 Years Integrated Program(s)]\n","100       50        150\n","\n","PG [Dual Degree Program(s)]\n","80        40        120\n","\n","PG-Integrated Programs\n","200       100       300\n","\n","PG - Integrated Master\n","150       75        225''',\n","                'expected': {\n","                    'ug_4_years': 1500,\n","                    'pg_2_years': 800,\n","                    'pg_integrated': 795,\n","                    'total_students': 3095\n","                }\n","            },\n","            {\n","                'description': 'Standard NIRF Table Format',\n","                'content': '''###SECTION:STUDENT_STRENGTH###\n","Total Actual Student Strength (Program(s) Offered by Your Institution)\n","\n","UG [4 Years Program(s)]\n","4170      994       5164      1443    3684    37    947       2668    1227    539       419       1430\n","\n","UG [5 Years Program(s)]\n","901       208       1109      400     707     2     174       564     253     346       61        78\n","\n","PG [2 Year Program(s)]\n","2144      409       2553      596     1957    0     275       1247    469     648       0         405\n","\n","PG [5 Years Integrated Program(s)]\n","150       75        225       100     125     0     50        100     25      30        10        60''',\n","                'expected': {\n","                    'ug_4_years': 5164,\n","                    'ug_5_years': 1109,\n","                    'pg_2_years': 2553,\n","                    'pg_integrated': 225,\n","                    'total_students': 9051\n","                }\n","            },\n","            {\n","                'description': 'Alternative Integrated Program Format',\n","                'content': '''###SECTION:STUDENT_STRENGTH###\n","Student Enrollment Data\n","\n","UG [4 Years Program(s)]\n","1500      300       1800\n","\n","PG [2 Year Program(s)]\n","800       200       1000\n","\n","PG [Dual Degree Program(s)]\n","100       50        150\n","\n","PG [Integrated Master Program(s)]\n","200       100       300''',\n","                'expected': {\n","                    'ug_4_years': 1800,\n","                    'pg_2_years': 1000,\n","                    'pg_integrated': 450,\n","                    'total_students': 3250\n","                }\n","            },\n","            {\n","                'description': 'Mixed Format with PG 3 Years and Different Spacing',\n","                'content': '''Student Strength Details\n","\n","UG [ 4 Years Program(s) ]\n","Male: 2000, Female: 500, Total: 2500\n","\n","PG [ 2 Years Program(s) ]\n","Male: 1000, Female: 200, Total: 1200\n","\n","PG [ 3 Years Program(s) ]\n","Male: 600, Female: 150, Total: 750\n","\n","PG [ 5 Years Integrated Program(s) ]\n","Male: 80, Female: 20, Total: 100''',\n","                'expected': {\n","                    'ug_4_years': 2500,\n","                    'pg_2_years': 1200,\n","                    'pg_3_years': 750,\n","                    'pg_integrated': 100,\n","                    'total_students': 4550\n","                }\n","            }\n","        ]\n","        test_student_parsing(test_cases)"]},{"cell_type":"code","source":["import os\n","import json\n","import gspread\n","from google.oauth2.service_account import Credentials\n","from pathlib import Path\n","from datetime import datetime\n","import time\n","\n","class StudentDataSheetUploader:\n","    def __init__(self, credentials_path=None, spreadsheet_url=None):\n","        \"\"\"\n","        Initialize the Google Sheets uploader\n","\n","        Args:\n","            credentials_path: Path to Google service account JSON file\n","            spreadsheet_url: URL or ID of the Google Sheet\n","        \"\"\"\n","        self.credentials_path = credentials_path\n","        self.spreadsheet_url = spreadsheet_url\n","        self.client = None\n","        self.worksheet = None\n","\n","        # Define all possible student categories\n","        self.student_categories = [\n","            'ug_2_years',\n","            'ug_3_years',\n","            'ug_4_years',\n","            'ug_5_years',\n","            'pg_2_years',\n","            'pg_3_years',\n","            'pg_integrated',\n","            'total_students'\n","        ]\n","\n","    def authenticate(self):\n","        \"\"\"Authenticate with Google Sheets API\"\"\"\n","        try:\n","            # Define the required scopes\n","            scopes = [\n","                'https://www.googleapis.com/auth/spreadsheets',\n","                'https://www.googleapis.com/auth/drive'\n","            ]\n","\n","            # Load credentials\n","            if not self.credentials_path or not os.path.exists(self.credentials_path):\n","                print(\"‚ùå Credentials file not found!\")\n","                print(\"üí° Please provide a valid Google service account JSON file\")\n","                return False\n","\n","            creds = Credentials.from_service_account_file(\n","                self.credentials_path,\n","                scopes=scopes\n","            )\n","\n","            # Authorize the client\n","            self.client = gspread.authorize(creds)\n","            print(\"‚úì Successfully authenticated with Google Sheets\")\n","            return True\n","\n","        except Exception as e:\n","            print(f\"‚ùå Authentication failed: {str(e)}\")\n","            return False\n","\n","    def open_spreadsheet(self):\n","        \"\"\"Open the Google Spreadsheet\"\"\"\n","        try:\n","            # Try to open by URL or ID\n","            if 'docs.google.com' in self.spreadsheet_url:\n","                # Extract spreadsheet ID from URL\n","                import re\n","                match = re.search(r'/d/([a-zA-Z0-9-_]+)', self.spreadsheet_url)\n","                if match:\n","                    spreadsheet_id = match.group(1)\n","                    spreadsheet = self.client.open_by_key(spreadsheet_id)\n","                else:\n","                    print(\"‚ùå Invalid Google Sheets URL\")\n","                    return False\n","            else:\n","                # Assume it's a spreadsheet ID\n","                spreadsheet = self.client.open_by_key(self.spreadsheet_url)\n","\n","            # Get the first worksheet or create one\n","            try:\n","                self.worksheet = spreadsheet.sheet1\n","            except:\n","                self.worksheet = spreadsheet.add_worksheet(title=\"Student Data\", rows=\"1000\", cols=\"20\")\n","\n","            print(f\"‚úì Opened spreadsheet: {spreadsheet.title}\")\n","            print(f\"‚úì Using worksheet: {self.worksheet.title}\")\n","            return True\n","\n","        except Exception as e:\n","            print(f\"‚ùå Failed to open spreadsheet: {str(e)}\")\n","            print(\"üí° Make sure you've shared the spreadsheet with the service account email\")\n","            return False\n","\n","    def initialize_headers(self):\n","        \"\"\"Initialize headers if sheet is empty or has no proper headers\"\"\"\n","        try:\n","            # Check if sheet is empty\n","            all_values = self.worksheet.get_all_values()\n","\n","            if not all_values or len(all_values) == 0:\n","                # Sheet is completely empty - create headers\n","                headers = ['Institute Name', 'Institute Code'] + [\n","                    cat.replace('_', ' ').title() for cat in self.student_categories\n","                ] + ['Last Updated']\n","\n","                self.worksheet.update('A1:M1', [headers])\n","\n","                # Format headers (bold)\n","                self.worksheet.format('A1:M1', {\n","                    'textFormat': {'bold': True},\n","                    'backgroundColor': {'red': 0.9, 'green': 0.9, 'blue': 0.9}\n","                })\n","\n","                print(\"‚úì Created new headers in empty sheet\")\n","                return True\n","\n","            # Check if first row has proper headers\n","            first_row = all_values[0]\n","            expected_headers = ['Institute Name', 'Institute Code']\n","\n","            if len(first_row) < 2 or first_row[0] != 'Institute Name':\n","                # Headers missing or incorrect - add them\n","                headers = ['Institute Name', 'Institute Code'] + [\n","                    cat.replace('_', ' ').title() for cat in self.student_categories\n","                ] + ['Last Updated']\n","\n","                # Insert new row at top\n","                self.worksheet.insert_row(headers, 1)\n","\n","                # Format headers\n","                self.worksheet.format('A1:M1', {\n","                    'textFormat': {'bold': True},\n","                    'backgroundColor': {'red': 0.9, 'green': 0.9, 'blue': 0.9}\n","                })\n","\n","                print(\"‚úì Added headers to existing sheet\")\n","                return True\n","\n","            print(\"‚úì Headers already exist\")\n","            return True\n","\n","        except Exception as e:\n","            print(f\"‚ùå Failed to initialize headers: {str(e)}\")\n","            return False\n","\n","    def get_existing_institutes(self):\n","        \"\"\"Get list of existing institute codes in the sheet\"\"\"\n","        try:\n","            # Get all values from column B (Institute Code)\n","            col_values = self.worksheet.col_values(2)  # Column B\n","\n","            # Skip header and get institute codes\n","            existing_codes = set()\n","            for i, value in enumerate(col_values):\n","                if i == 0:  # Skip header\n","                    continue\n","                if value and value.strip():\n","                    existing_codes.add(value.strip())\n","\n","            print(f\"‚úì Found {len(existing_codes)} existing institutes in sheet\")\n","            return existing_codes\n","\n","        except Exception as e:\n","            print(f\"‚ùå Failed to get existing institutes: {str(e)}\")\n","            return set()\n","\n","    def extract_student_data_from_json(self, json_file_path):\n","        \"\"\"Extract student data from the converter output JSON file\"\"\"\n","        try:\n","            with open(json_file_path, 'r', encoding='utf-8') as f:\n","                data = json.load(f)\n","\n","            # Initialize data structure\n","            student_data = {\n","                'institute_name': '',\n","                'institute_code': '',\n","                'student_counts': {cat: 0 for cat in self.student_categories}\n","            }\n","\n","            # Extract from points\n","            points = data.get('points', [])\n","\n","            if not points:\n","                print(f\"‚ö† No points found in {json_file_path}\")\n","                return None\n","\n","            # Get institute info from first point\n","            first_point = points[0]\n","            payload = first_point.get('payload', {})\n","            student_data['institute_name'] = payload.get('institute_name', 'Unknown')\n","            student_data['institute_code'] = payload.get('institute_code', 'Unknown')\n","\n","            # Search for student strength data\n","            for point in points:\n","                payload = point.get('payload', {})\n","                content = payload.get('content', '')\n","                content_type = payload.get('content_type', '')\n","\n","                # Check if this is a student strength point\n","                if 'student' in content_type.lower() or 'Students Strength' in content:\n","                    # Parse the content\n","                    if 'UG 2 Years:' in content or 'Ug 2 Years:' in content:\n","                        import re\n","                        match = re.search(r'UG 2 Years:\\s*(\\d+)', content, re.IGNORECASE)\n","                        if match:\n","                            student_data['student_counts']['ug_2_years'] = int(match.group(1))\n","\n","                    if 'UG 3 Years:' in content or 'Ug 3 Years:' in content:\n","                        import re\n","                        match = re.search(r'UG 3 Years:\\s*(\\d+)', content, re.IGNORECASE)\n","                        if match:\n","                            student_data['student_counts']['ug_3_years'] = int(match.group(1))\n","\n","                    if 'UG 4 Years:' in content or 'Ug 4 Years:' in content:\n","                        import re\n","                        match = re.search(r'UG 4 Years:\\s*(\\d+)', content, re.IGNORECASE)\n","                        if match:\n","                            student_data['student_counts']['ug_4_years'] = int(match.group(1))\n","\n","                    if 'UG 5 Years:' in content or 'Ug 5 Years:' in content:\n","                        import re\n","                        match = re.search(r'UG 5 Years:\\s*(\\d+)', content, re.IGNORECASE)\n","                        if match:\n","                            student_data['student_counts']['ug_5_years'] = int(match.group(1))\n","\n","                    if 'PG 2 Years:' in content or 'Pg 2 Years:' in content:\n","                        import re\n","                        match = re.search(r'PG 2 Years:\\s*(\\d+)', content, re.IGNORECASE)\n","                        if match:\n","                            student_data['student_counts']['pg_2_years'] = int(match.group(1))\n","\n","                    if 'PG 3 Years:' in content or 'Pg 3 Years:' in content:\n","                        import re\n","                        match = re.search(r'PG 3 Years:\\s*(\\d+)', content, re.IGNORECASE)\n","                        if match:\n","                            student_data['student_counts']['pg_3_years'] = int(match.group(1))\n","\n","                    if 'PG Integrated:' in content or 'Pg Integrated:' in content:\n","                        import re\n","                        match = re.search(r'PG Integrated:\\s*(\\d+)', content, re.IGNORECASE)\n","                        if match:\n","                            student_data['student_counts']['pg_integrated'] = int(match.group(1))\n","\n","                    if 'Total Students:' in content or 'Total students:' in content:\n","                        import re\n","                        match = re.search(r'Total Students:\\s*(\\d+)', content, re.IGNORECASE)\n","                        if match:\n","                            student_data['student_counts']['total_students'] = int(match.group(1))\n","\n","            # If no student data found, return None\n","            if all(count == 0 for count in student_data['student_counts'].values()):\n","                print(f\"‚ö† No student data found in {json_file_path}\")\n","                return None\n","\n","            return student_data\n","\n","        except Exception as e:\n","            print(f\"‚ùå Failed to extract data from {json_file_path}: {str(e)}\")\n","            return None\n","\n","    def insert_student_data(self, student_data):\n","        \"\"\"Insert student data into Google Sheet\"\"\"\n","        try:\n","            institute_code = student_data['institute_code']\n","            institute_name = student_data['institute_name']\n","\n","            # Prepare row data\n","            row_data = [\n","                institute_name,\n","                institute_code\n","            ]\n","\n","            # Add student counts for each category\n","            for category in self.student_categories:\n","                count = student_data['student_counts'].get(category, 0)\n","                row_data.append(count if count > 0 else '')  # Empty cell if 0\n","\n","            # Add timestamp\n","            row_data.append(datetime.now().strftime('%Y-%m-%d %H:%M:%S'))\n","\n","            # Append row to sheet\n","            self.worksheet.append_row(row_data)\n","\n","            print(f\"‚úì Inserted data for: {institute_name} ({institute_code})\")\n","\n","            # Show what was inserted\n","            counts = student_data['student_counts']\n","            print(f\"  Student counts:\", end=\" \")\n","            inserted_categories = []\n","            for cat in self.student_categories:\n","                if counts.get(cat, 0) > 0:\n","                    inserted_categories.append(f\"{cat.replace('_', ' ').title()}: {counts[cat]}\")\n","            print(\", \".join(inserted_categories) if inserted_categories else \"No data\")\n","\n","            return True\n","\n","        except Exception as e:\n","            print(f\"‚ùå Failed to insert data: {str(e)}\")\n","            return False\n","\n","    def process_json_files(self, json_directory):\n","        \"\"\"Process all JSON files in a directory\"\"\"\n","        try:\n","            directory = Path(json_directory)\n","            json_files = list(directory.glob('*.json'))\n","\n","            if not json_files:\n","                print(f\"‚ùå No JSON files found in {json_directory}\")\n","                return\n","\n","            print(f\"\\nüìÇ Found {len(json_files)} JSON files to process\")\n","            print(\"=\" * 60)\n","\n","            # Get existing institutes\n","            existing_institutes = self.get_existing_institutes()\n","\n","            # Statistics\n","            stats = {\n","                'total': len(json_files),\n","                'inserted': 0,\n","                'skipped_existing': 0,\n","                'skipped_no_data': 0,\n","                'failed': 0\n","            }\n","\n","            # Process each file\n","            for i, json_file in enumerate(json_files, 1):\n","                print(f\"\\n[{i}/{len(json_files)}] Processing: {json_file.name}\")\n","\n","                try:\n","                    # Extract student data\n","                    student_data = self.extract_student_data_from_json(str(json_file))\n","\n","                    if not student_data:\n","                        print(f\"‚ö† Skipping - no student data found\")\n","                        stats['skipped_no_data'] += 1\n","                        continue\n","\n","                    institute_code = student_data['institute_code']\n","\n","                    # Check if already exists\n","                    if institute_code in existing_institutes:\n","                        print(f\"‚ö† Skipping - institute already exists: {student_data['institute_name']}\")\n","                        stats['skipped_existing'] += 1\n","                        continue\n","\n","                    # Insert data\n","                    if self.insert_student_data(student_data):\n","                        stats['inserted'] += 1\n","                        existing_institutes.add(institute_code)  # Update local cache\n","                        time.sleep(1)  # Rate limiting to avoid API quota issues\n","                    else:\n","                        stats['failed'] += 1\n","\n","                except Exception as e:\n","                    print(f\"‚ùå Error processing {json_file.name}: {str(e)}\")\n","                    stats['failed'] += 1\n","                    continue\n","\n","            # Print summary\n","            print(\"\\n\" + \"=\" * 60)\n","            print(\"PROCESSING SUMMARY\")\n","            print(\"=\" * 60)\n","            print(f\"üìä Total files: {stats['total']}\")\n","            print(f\"‚úì Successfully inserted: {stats['inserted']}\")\n","            print(f\"‚ö† Skipped (already exists): {stats['skipped_existing']}\")\n","            print(f\"‚ö† Skipped (no data): {stats['skipped_no_data']}\")\n","            print(f\"‚ùå Failed: {stats['failed']}\")\n","            print(\"=\" * 60)\n","\n","        except Exception as e:\n","            print(f\"‚ùå Error processing directory: {str(e)}\")\n","\n","\n","def is_colab():\n","    \"\"\"Check if running in Google Colab\"\"\"\n","    try:\n","        import google.colab\n","        return True\n","    except ImportError:\n","        return False\n","\n","\n","def main():\n","    \"\"\"Main function\"\"\"\n","    print(\"=\" * 60)\n","    print(\"Google Sheets Student Data Uploader\")\n","    print(\"=\" * 60)\n","\n","    # Step 1: Get credentials file\n","    print(\"\\nüìã Step 1: Google Service Account Credentials\")\n","    print(\"-\" * 60)\n","\n","    if is_colab():\n","        from google.colab import files\n","        print(\"Running in Google Colab\")\n","        print(\"Please upload your Google service account JSON file:\")\n","        uploaded = files.upload()\n","\n","        if not uploaded:\n","            print(\"‚ùå No credentials file uploaded!\")\n","            return\n","\n","        credentials_path = list(uploaded.keys())[0]\n","        print(f\"‚úì Using credentials: {credentials_path}\")\n","    else:\n","        credentials_path = input(\"Enter path to Google service account JSON file: \").strip()\n","        if not os.path.exists(credentials_path):\n","            print(f\"‚ùå File not found: {credentials_path}\")\n","            return\n","\n","    # Step 2: Get spreadsheet URL\n","    print(\"\\nüìä Step 2: Google Spreadsheet\")\n","    print(\"-\" * 60)\n","    spreadsheet_url = input(\"Enter Google Spreadsheet URL or ID: \").strip()\n","\n","    if not spreadsheet_url:\n","        print(\"‚ùå Spreadsheet URL/ID is required!\")\n","        return\n","\n","    # Step 3: Get JSON directory\n","    print(\"\\nüìÇ Step 3: JSON Files Directory\")\n","    print(\"-\" * 60)\n","\n","    if is_colab():\n","        from google.colab import files\n","        upload_choice = input(\"Upload JSON files now? (y/n): \").strip().lower()\n","\n","        if upload_choice == 'y':\n","            print(\"Please upload your JSON files:\")\n","            uploaded_jsons = files.upload()\n","\n","            # Create temporary directory\n","            os.makedirs('temp_json_files', exist_ok=True)\n","            for filename in uploaded_jsons.keys():\n","                os.rename(filename, f'temp_json_files/{filename}')\n","\n","            json_directory = 'temp_json_files'\n","            print(f\"‚úì Using directory: {json_directory}\")\n","        else:\n","            json_directory = input(\"Enter path to JSON files directory: \").strip()\n","    else:\n","        json_directory = input(\"Enter path to JSON files directory: \").strip()\n","\n","    if not os.path.exists(json_directory):\n","        print(f\"‚ùå Directory not found: {json_directory}\")\n","        return\n","\n","    # Step 4: Initialize uploader\n","    print(\"\\nüöÄ Step 4: Initializing Uploader\")\n","    print(\"-\" * 60)\n","\n","    uploader = StudentDataSheetUploader(\n","        credentials_path=credentials_path,\n","        spreadsheet_url=spreadsheet_url\n","    )\n","\n","    # Authenticate\n","    if not uploader.authenticate():\n","        return\n","\n","    # Open spreadsheet\n","    if not uploader.open_spreadsheet():\n","        return\n","\n","    # Initialize headers\n","    if not uploader.initialize_headers():\n","        return\n","\n","    # Step 5: Process files\n","    print(\"\\nüì§ Step 5: Processing and Uploading Data\")\n","    print(\"-\" * 60)\n","\n","    confirm = input(\"Ready to process JSON files and upload to Google Sheets? (y/n): \").strip().lower()\n","\n","    if confirm != 'y':\n","        print(\"Operation cancelled by user.\")\n","        return\n","\n","    uploader.process_json_files(json_directory)\n","\n","    print(\"\\n‚úÖ All done!\")\n","    print(f\"üìä Check your Google Sheet: {spreadsheet_url}\")\n","\n","\n","if __name__ == \"__main__\":\n","    main()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"f7h6u-kST_8B","executionInfo":{"status":"ok","timestamp":1762972997913,"user_tz":-330,"elapsed":330736,"user":{"displayName":"Rahul Siddhu","userId":"12007764243202946991"}},"outputId":"fb910510-aca7-4798-e756-67b6776c5aa4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["============================================================\n","Google Sheets Student Data Uploader\n","============================================================\n","\n","üìã Step 1: Google Service Account Credentials\n","------------------------------------------------------------\n","Running in Google Colab\n","Please upload your Google service account JSON file:\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","     <input type=\"file\" id=\"files-a445a64c-438b-43e0-a0c4-3742cc69c21d\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-a445a64c-438b-43e0-a0c4-3742cc69c21d\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script>// Copyright 2017 Google LLC\n","//\n","// Licensed under the Apache License, Version 2.0 (the \"License\");\n","// you may not use this file except in compliance with the License.\n","// You may obtain a copy of the License at\n","//\n","//      http://www.apache.org/licenses/LICENSE-2.0\n","//\n","// Unless required by applicable law or agreed to in writing, software\n","// distributed under the License is distributed on an \"AS IS\" BASIS,\n","// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","// See the License for the specific language governing permissions and\n","// limitations under the License.\n","\n","/**\n"," * @fileoverview Helpers for google.colab Python module.\n"," */\n","(function(scope) {\n","function span(text, styleAttributes = {}) {\n","  const element = document.createElement('span');\n","  element.textContent = text;\n","  for (const key of Object.keys(styleAttributes)) {\n","    element.style[key] = styleAttributes[key];\n","  }\n","  return element;\n","}\n","\n","// Max number of bytes which will be uploaded at a time.\n","const MAX_PAYLOAD_SIZE = 100 * 1024;\n","\n","function _uploadFiles(inputId, outputId) {\n","  const steps = uploadFilesStep(inputId, outputId);\n","  const outputElement = document.getElementById(outputId);\n","  // Cache steps on the outputElement to make it available for the next call\n","  // to uploadFilesContinue from Python.\n","  outputElement.steps = steps;\n","\n","  return _uploadFilesContinue(outputId);\n","}\n","\n","// This is roughly an async generator (not supported in the browser yet),\n","// where there are multiple asynchronous steps and the Python side is going\n","// to poll for completion of each step.\n","// This uses a Promise to block the python side on completion of each step,\n","// then passes the result of the previous step as the input to the next step.\n","function _uploadFilesContinue(outputId) {\n","  const outputElement = document.getElementById(outputId);\n","  const steps = outputElement.steps;\n","\n","  const next = steps.next(outputElement.lastPromiseValue);\n","  return Promise.resolve(next.value.promise).then((value) => {\n","    // Cache the last promise value to make it available to the next\n","    // step of the generator.\n","    outputElement.lastPromiseValue = value;\n","    return next.value.response;\n","  });\n","}\n","\n","/**\n"," * Generator function which is called between each async step of the upload\n"," * process.\n"," * @param {string} inputId Element ID of the input file picker element.\n"," * @param {string} outputId Element ID of the output display.\n"," * @return {!Iterable<!Object>} Iterable of next steps.\n"," */\n","function* uploadFilesStep(inputId, outputId) {\n","  const inputElement = document.getElementById(inputId);\n","  inputElement.disabled = false;\n","\n","  const outputElement = document.getElementById(outputId);\n","  outputElement.innerHTML = '';\n","\n","  const pickedPromise = new Promise((resolve) => {\n","    inputElement.addEventListener('change', (e) => {\n","      resolve(e.target.files);\n","    });\n","  });\n","\n","  const cancel = document.createElement('button');\n","  inputElement.parentElement.appendChild(cancel);\n","  cancel.textContent = 'Cancel upload';\n","  const cancelPromise = new Promise((resolve) => {\n","    cancel.onclick = () => {\n","      resolve(null);\n","    };\n","  });\n","\n","  // Wait for the user to pick the files.\n","  const files = yield {\n","    promise: Promise.race([pickedPromise, cancelPromise]),\n","    response: {\n","      action: 'starting',\n","    }\n","  };\n","\n","  cancel.remove();\n","\n","  // Disable the input element since further picks are not allowed.\n","  inputElement.disabled = true;\n","\n","  if (!files) {\n","    return {\n","      response: {\n","        action: 'complete',\n","      }\n","    };\n","  }\n","\n","  for (const file of files) {\n","    const li = document.createElement('li');\n","    li.append(span(file.name, {fontWeight: 'bold'}));\n","    li.append(span(\n","        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n","        `last modified: ${\n","            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n","                                    'n/a'} - `));\n","    const percent = span('0% done');\n","    li.appendChild(percent);\n","\n","    outputElement.appendChild(li);\n","\n","    const fileDataPromise = new Promise((resolve) => {\n","      const reader = new FileReader();\n","      reader.onload = (e) => {\n","        resolve(e.target.result);\n","      };\n","      reader.readAsArrayBuffer(file);\n","    });\n","    // Wait for the data to be ready.\n","    let fileData = yield {\n","      promise: fileDataPromise,\n","      response: {\n","        action: 'continue',\n","      }\n","    };\n","\n","    // Use a chunked sending to avoid message size limits. See b/62115660.\n","    let position = 0;\n","    do {\n","      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n","      const chunk = new Uint8Array(fileData, position, length);\n","      position += length;\n","\n","      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n","      yield {\n","        response: {\n","          action: 'append',\n","          file: file.name,\n","          data: base64,\n","        },\n","      };\n","\n","      let percentDone = fileData.byteLength === 0 ?\n","          100 :\n","          Math.round((position / fileData.byteLength) * 100);\n","      percent.textContent = `${percentDone}% done`;\n","\n","    } while (position < fileData.byteLength);\n","  }\n","\n","  // All done.\n","  yield {\n","    response: {\n","      action: 'complete',\n","    }\n","  };\n","}\n","\n","scope.google = scope.google || {};\n","scope.google.colab = scope.google.colab || {};\n","scope.google.colab._files = {\n","  _uploadFiles,\n","  _uploadFilesContinue,\n","};\n","})(self);\n","</script> "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Saving luminous-byway-468905-r1-d5b2959372cb.json to luminous-byway-468905-r1-d5b2959372cb.json\n","‚úì Using credentials: luminous-byway-468905-r1-d5b2959372cb.json\n","\n","üìä Step 2: Google Spreadsheet\n","------------------------------------------------------------\n","Enter Google Spreadsheet URL or ID: https://docs.google.com/spreadsheets/d/1AdMNjPdfv_YLknr3xVodq6KZHLvGyNHTNO1Sqbzt1wM/edit?usp=sharing\n","\n","üìÇ Step 3: JSON Files Directory\n","------------------------------------------------------------\n","Upload JSON files now? (y/n): y\n","Please upload your JSON files:\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","     <input type=\"file\" id=\"files-e5b77ca4-5efb-4c69-82b0-a6f2558e12e1\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-e5b77ca4-5efb-4c69-82b0-a6f2558e12e1\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script>// Copyright 2017 Google LLC\n","//\n","// Licensed under the Apache License, Version 2.0 (the \"License\");\n","// you may not use this file except in compliance with the License.\n","// You may obtain a copy of the License at\n","//\n","//      http://www.apache.org/licenses/LICENSE-2.0\n","//\n","// Unless required by applicable law or agreed to in writing, software\n","// distributed under the License is distributed on an \"AS IS\" BASIS,\n","// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","// See the License for the specific language governing permissions and\n","// limitations under the License.\n","\n","/**\n"," * @fileoverview Helpers for google.colab Python module.\n"," */\n","(function(scope) {\n","function span(text, styleAttributes = {}) {\n","  const element = document.createElement('span');\n","  element.textContent = text;\n","  for (const key of Object.keys(styleAttributes)) {\n","    element.style[key] = styleAttributes[key];\n","  }\n","  return element;\n","}\n","\n","// Max number of bytes which will be uploaded at a time.\n","const MAX_PAYLOAD_SIZE = 100 * 1024;\n","\n","function _uploadFiles(inputId, outputId) {\n","  const steps = uploadFilesStep(inputId, outputId);\n","  const outputElement = document.getElementById(outputId);\n","  // Cache steps on the outputElement to make it available for the next call\n","  // to uploadFilesContinue from Python.\n","  outputElement.steps = steps;\n","\n","  return _uploadFilesContinue(outputId);\n","}\n","\n","// This is roughly an async generator (not supported in the browser yet),\n","// where there are multiple asynchronous steps and the Python side is going\n","// to poll for completion of each step.\n","// This uses a Promise to block the python side on completion of each step,\n","// then passes the result of the previous step as the input to the next step.\n","function _uploadFilesContinue(outputId) {\n","  const outputElement = document.getElementById(outputId);\n","  const steps = outputElement.steps;\n","\n","  const next = steps.next(outputElement.lastPromiseValue);\n","  return Promise.resolve(next.value.promise).then((value) => {\n","    // Cache the last promise value to make it available to the next\n","    // step of the generator.\n","    outputElement.lastPromiseValue = value;\n","    return next.value.response;\n","  });\n","}\n","\n","/**\n"," * Generator function which is called between each async step of the upload\n"," * process.\n"," * @param {string} inputId Element ID of the input file picker element.\n"," * @param {string} outputId Element ID of the output display.\n"," * @return {!Iterable<!Object>} Iterable of next steps.\n"," */\n","function* uploadFilesStep(inputId, outputId) {\n","  const inputElement = document.getElementById(inputId);\n","  inputElement.disabled = false;\n","\n","  const outputElement = document.getElementById(outputId);\n","  outputElement.innerHTML = '';\n","\n","  const pickedPromise = new Promise((resolve) => {\n","    inputElement.addEventListener('change', (e) => {\n","      resolve(e.target.files);\n","    });\n","  });\n","\n","  const cancel = document.createElement('button');\n","  inputElement.parentElement.appendChild(cancel);\n","  cancel.textContent = 'Cancel upload';\n","  const cancelPromise = new Promise((resolve) => {\n","    cancel.onclick = () => {\n","      resolve(null);\n","    };\n","  });\n","\n","  // Wait for the user to pick the files.\n","  const files = yield {\n","    promise: Promise.race([pickedPromise, cancelPromise]),\n","    response: {\n","      action: 'starting',\n","    }\n","  };\n","\n","  cancel.remove();\n","\n","  // Disable the input element since further picks are not allowed.\n","  inputElement.disabled = true;\n","\n","  if (!files) {\n","    return {\n","      response: {\n","        action: 'complete',\n","      }\n","    };\n","  }\n","\n","  for (const file of files) {\n","    const li = document.createElement('li');\n","    li.append(span(file.name, {fontWeight: 'bold'}));\n","    li.append(span(\n","        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n","        `last modified: ${\n","            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n","                                    'n/a'} - `));\n","    const percent = span('0% done');\n","    li.appendChild(percent);\n","\n","    outputElement.appendChild(li);\n","\n","    const fileDataPromise = new Promise((resolve) => {\n","      const reader = new FileReader();\n","      reader.onload = (e) => {\n","        resolve(e.target.result);\n","      };\n","      reader.readAsArrayBuffer(file);\n","    });\n","    // Wait for the data to be ready.\n","    let fileData = yield {\n","      promise: fileDataPromise,\n","      response: {\n","        action: 'continue',\n","      }\n","    };\n","\n","    // Use a chunked sending to avoid message size limits. See b/62115660.\n","    let position = 0;\n","    do {\n","      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n","      const chunk = new Uint8Array(fileData, position, length);\n","      position += length;\n","\n","      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n","      yield {\n","        response: {\n","          action: 'append',\n","          file: file.name,\n","          data: base64,\n","        },\n","      };\n","\n","      let percentDone = fileData.byteLength === 0 ?\n","          100 :\n","          Math.round((position / fileData.byteLength) * 100);\n","      percent.textContent = `${percentDone}% done`;\n","\n","    } while (position < fileData.byteLength);\n","  }\n","\n","  // All done.\n","  yield {\n","    response: {\n","      action: 'complete',\n","    }\n","  };\n","}\n","\n","scope.google = scope.google || {};\n","scope.google.colab = scope.google.colab || {};\n","scope.google.colab._files = {\n","  _uploadFiles,\n","  _uploadFilesContinue,\n","};\n","})(self);\n","</script> "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Saving Aligarh Muslim University.json to Aligarh Muslim University (1).json\n","Saving Amity University.json to Amity University (1).json\n","Saving Amrita Vishwa Vidyapeetham.json to Amrita Vishwa Vidyapeetham (1).json\n","Saving Anna University.json to Anna University (1).json\n","Saving AU College of Enginnering.json to AU College of Enginnering (1).json\n","Saving Banasthali Vidyapith.json to Banasthali Vidyapith (1).json\n","Saving Birla Institute of Technology  and Science_ Pilani.json to Birla Institute of Technology  and Science_ Pilani (1).json\n","Saving Birla Institute of Technology Ranchi.json to Birla Institute of Technology Ranchi (1).json\n","Saving C.V. Raman Global University_ Odisha.json to C.V. Raman Global University_ Odisha (1).json\n","Saving Chandigarh University.json to Chandigarh University (1).json\n","Saving Chithara University.json to Chithara University (1).json\n","Saving COEP Technological University.json to COEP Technological University (1).json\n","Saving Defence Institute of Adavanced Technology.json to Defence Institute of Adavanced Technology (1).json\n","Saving Delhi Technological University.json to Delhi Technological University (1).json\n","Saving Dr. B R Ambedkar National Institute of Technology Jalandhar.json to Dr. B R Ambedkar National Institute of Technology Jalandhar (1).json\n","Saving Engineering  2024.json to Engineering  2024 (1).json\n","Saving Guru Gobind Singh Indraprastha University.json to Guru Gobind Singh Indraprastha University (1).json\n","Saving IIEST Shibpur.json to IIEST Shibpur (1).json\n","Saving IIIT Allahabad.json to IIIT Allahabad (1).json\n","Saving IIIT Hyderabad .json to IIIT Hyderabad  (1).json\n","Saving IIT Bhilai.json to IIT Bhilai (1).json\n","Saving IIT Bhuvaneswar.json to IIT Bhuvaneswar (1).json\n","Saving IIT Bombay.json to IIT Bombay (1).json\n","Saving IIT Delhi.json to IIT Delhi (1).json\n","Saving IIT Gandhinagar.json to IIT Gandhinagar (1).json\n","Saving IIT Guwahati.json to IIT Guwahati (1).json\n","Saving IIT Hyderabad.json to IIT Hyderabad (1).json\n","Saving IIT Indore.json to IIT Indore (1).json\n","Saving IIT Jammu.json to IIT Jammu (1).json\n","Saving IIT Jodhpur.json to IIT Jodhpur (1).json\n","Saving IIT Kanpur.json to IIT Kanpur (1).json\n","Saving IIT Kharagpur.json to IIT Kharagpur (1).json\n","Saving IIT Madras.json to IIT Madras (1).json\n","Saving IIT Mandi.json to IIT Mandi (1).json\n","Saving IIT Palakkad.json to IIT Palakkad (1).json\n","Saving IIT Patna.json to IIT Patna (1).json\n","Saving IIT Roorkee 2024.json to IIT Roorkee 2024 (1).json\n","Saving IIT Ropar.json to IIT Ropar (1).json\n","Saving IIT Tirupati.json to IIT Tirupati (1).json\n","Saving IIT Varanasi_Banaras Hindu University_.json to IIT Varanasi_Banaras Hindu University_ (1).json\n","Saving Indian Institute of Space Science and Technology.json to Indian Institute of Space Science and Technology (1).json\n","Saving Indian Institute of Technology _Indian School of Mines_ Dhanbad.json to Indian Institute of Technology _Indian School of Mines_ Dhanbad (1).json\n","Saving Indraprastha Institute of Information Technology.json to Indraprastha Institute of Information Technology (1).json\n","Saving Institute of Chemical Technology.json to Institute of Chemical Technology (1).json\n","Saving International Institute of Information Technology Bangalore.json to International Institute of Information Technology Bangalore (1).json\n","Saving Jadavpur University.json to Jadavpur University (1).json\n","Saving Jain University_ Bangalore.json to Jain University_ Bangalore (1).json\n","Saving Jamia Millia Islamia.json to Jamia Millia Islamia (1).json\n","Saving Jawaharlal Nehru Technological University.json to Jawaharlal Nehru Technological University (1).json\n","Saving K L College of Engineering_Vaddeswaram_.json to K L College of Engineering_Vaddeswaram_ (1).json\n","Saving Kalasalingam Academy of Research and Education.json to Kalasalingam Academy of Research and Education (1).json\n","Saving Kalinga Institute of Industrial Technology.json to Kalinga Institute of Industrial Technology (1).json\n","Saving Lovely Professional University.json to Lovely Professional University (1).json\n","Saving M. S. Ramaiah Institute of Technology.json to M. S. Ramaiah Institute of Technology (1).json\n","Saving Madan Mohan Malaviya University of Technology.json to Madan Mohan Malaviya University of Technology (1).json\n","Saving Malaviya National Institute of Technology.json to Malaviya National Institute of Technology (1).json\n","Saving Manipal Institute of Technology.json to Manipal Institute of Technology (1).json\n","Saving Manipal University_ Jaipur.json to Manipal University_ Jaipur (1).json\n","Saving Maulana Azad National Institute of Technology.json to Maulana Azad National Institute of Technology (1).json\n","Saving Motilal Nehru National Institute of Technology.json to Motilal Nehru National Institute of Technology (1).json\n","Saving Netaji Subhas University of Technology _NSUT_.json to Netaji Subhas University of Technology _NSUT_ (1).json\n","Saving NIT  Agartala.json to NIT  Agartala (1).json\n","Saving NIT  Puducherry.json to NIT  Puducherry (1).json\n","Saving NIT calicut.json to NIT calicut (1).json\n","Saving NIT Delhi.json to NIT Delhi (1).json\n","Saving NIT Durgapur.json to NIT Durgapur (1).json\n","Saving NIT Kurukshetra.json to NIT Kurukshetra (1).json\n","Saving NIT Meghalaya.json to NIT Meghalaya (1).json\n","Saving NIT Patna.json to NIT Patna (1).json\n","Saving NIT Raipur.json to NIT Raipur (1).json\n","Saving NIT Rourkela.json to NIT Rourkela (1).json\n","Saving NIT Silchar.json to NIT Silchar (1).json\n","Saving NIT Srinagar.json to NIT Srinagar (1).json\n","Saving NIT Surathkal.json to NIT Surathkal (1).json\n","Saving NIT Tiruchirappalli.json to NIT Tiruchirappalli (1).json\n","Saving NIT Warangal.json to NIT Warangal (1).json\n","Saving PSG College of Technology.json to PSG College of Technology (1).json\n","Saving R.V. College of Engineering.json to R.V. College of Engineering (1).json\n","Saving Rajiv Gandhi Institute of Petroleum Technology.json to Rajiv Gandhi Institute of Petroleum Technology (1).json\n","Saving Sant Longowal Institute of Engineering and Technology.json to Sant Longowal Institute of Engineering and Technology (1).json\n","Saving Sardar Vallabhbhai National Institute of Technology.json to Sardar Vallabhbhai National Institute of Technology (1).json\n","Saving Sathyabama Institute of Science and Technology Chennai.json to Sathyabama Institute of Science and Technology Chennai (1).json\n","Saving Saveetha Institute of Medical and Technical Sciences.json to Saveetha Institute of Medical and Technical Sciences (1).json\n","Saving Shanmugha Arts Science Technology and Research Academy.json to Shanmugha Arts Science Technology and Research Academy (1).json\n","Saving Shoolini University of Biotechnology and Management Science.json to Shoolini University of Biotechnology and Management Science (1).json\n","Saving Siddaganga Institute of Technology.json to Siddaganga Institute of Technology (1).json\n","Saving SR University Warangal.json to SR University Warangal (1).json\n","Saving Sri Krishna College of Engineering and Technology.json to Sri Krishna College of Engineering and Technology (1).json\n","Saving Sri Sivasubramaniya Nadar College of Engineering.json to Sri Sivasubramaniya Nadar College of Engineering (1).json\n","Saving SRM Chennai.json to SRM Chennai (1).json\n","Saving Thapar Institute of Engineering and Technology _Deemed-to-be-university.json to Thapar Institute of Engineering and Technology _Deemed-to-be-university (1).json\n","Saving University of Hyderabad.json to University of Hyderabad (1).json\n","Saving UPES.json to UPES (1).json\n","Saving Vel Tech Rangarajan Dr. Sagunthala R _ D Institute of Science and Technology.json to Vel Tech Rangarajan Dr. Sagunthala R _ D Institute of Science and Technology (1).json\n","Saving Vignan_s Foundation for Science_ Technology and Research.json to Vignan_s Foundation for Science_ Technology and Research (1).json\n","Saving Visvesvaraya National Institute of Technology Nagpur.json to Visvesvaraya National Institute of Technology Nagpur (1).json\n","Saving Visvesvaraya Technological University.json to Visvesvaraya Technological University (1).json\n","Saving VIT Vellore.json to VIT Vellore (1).json\n","‚úì Using directory: temp_json_files\n","\n","üöÄ Step 4: Initializing Uploader\n","------------------------------------------------------------\n","‚úì Successfully authenticated with Google Sheets\n","‚úì Opened spreadsheet: Untitled spreadsheet\n","‚úì Using worksheet: Sheet1\n","‚úì Added headers to existing sheet\n","\n","üì§ Step 5: Processing and Uploading Data\n","------------------------------------------------------------\n","Ready to process JSON files and upload to Google Sheets? (y/n): y\n","\n","üìÇ Found 98 JSON files to process\n","============================================================\n","‚úì Found 0 existing institutes in sheet\n","\n","[1/98] Processing: SR University Warangal (1).json\n","‚úì Inserted data for: SR University (IR-E-C-19754)\n","  Student counts: Ug 4 Years: 3960, Pg 2 Years: 180, Total Students: 4140\n","\n","[2/98] Processing: Sathyabama Institute of Science and Technology Chennai (1).json\n","‚úì Inserted data for: Sathyabama Institute of Science and Technology (IR-E-U-0474)\n","  Student counts: Ug 4 Years: 10611, Pg 2 Years: 283, Total Students: 10894\n","\n","[3/98] Processing: IIT Bombay (1).json\n","‚úì Inserted data for: Indian Institute of Technology Bombay (IR-E-U-0306)\n","  Student counts: Ug 4 Years: 4791, Ug 5 Years: 1172, Pg 2 Years: 2568, Total Students: 8531\n","\n","[4/98] Processing: SRM Chennai (1).json\n","‚úì Inserted data for: S.R.M. Institute of Science and Technology (IR-E-U-0473)\n","  Student counts: Ug 4 Years: 20229, Pg 2 Years: 862, Pg Integrated: 384, Total Students: 21475\n","\n","[5/98] Processing: M. S. Ramaiah Institute of Technology (1).json\n","‚úì Inserted data for: M. S. Ramaiah Institute of Technology (IR-E-C-1331)\n","  Student counts: Ug 4 Years: 4480, Pg 2 Years: 303, Total Students: 4783\n","\n","[6/98] Processing: IIT Gandhinagar (1).json\n","‚úì Inserted data for: Indian Institute of Technology Gandhinagar (IR-E-U-0139)\n","  Student counts: Ug 4 Years: 933, Ug 5 Years: 40, Pg 2 Years: 149, Total Students: 1122\n","\n","[7/98] Processing: IIT Patna (1).json\n","‚úì Inserted data for: Indian Institute of Technology Patna (IR-E-U-0064)\n","  Student counts: Ug 4 Years: 1797, Pg 2 Years: 291, Total Students: 2088\n","\n","[8/98] Processing: Indian Institute of Technology _Indian School of Mines_ Dhanbad (1).json\n","‚úì Inserted data for: Indian Institute of Technology (Indian School of Mines) Dhanbad (IR-E-U-0205)\n","  Student counts: Ug 4 Years: 3724, Ug 5 Years: 434, Pg 2 Years: 668, Total Students: 4826\n","\n","[9/98] Processing: IIT Varanasi_Banaras Hindu University_ (1).json\n","‚úì Inserted data for: Indian Institute of Technology (Banaras Hindu University) Varanasi (IR-E-U-0701)\n","  Student counts: Ug 4 Years: 4359, Ug 5 Years: 1674, Pg 2 Years: 731, Total Students: 6764\n","\n","[10/98] Processing: UPES (1).json\n","‚úì Inserted data for: UPES (IR-E-U-0564)\n","  Student counts: Ug 4 Years: 5285, Pg 2 Years: 413, Total Students: 5698\n","\n","[11/98] Processing: IIT Bhilai (1).json\n","‚úì Inserted data for: Indian Institute of Technology Bhilai (IR-E-U-0946)\n","  Student counts: Ug 4 Years: 652, Pg 2 Years: 69, Total Students: 721\n","\n","[12/98] Processing: Jain University_ Bangalore (1).json\n","‚úì Inserted data for: Jain University, Bangalore (IR-E-U-0223)\n","  Student counts: Ug 4 Years: 4606, Pg 2 Years: 183, Total Students: 4789\n","\n","[13/98] Processing: IIT Jammu (1).json\n","‚úì Inserted data for: Indian Institute of Technology Jammu (IR-E-U-0906)\n","  Student counts: Ug 4 Years: 784, Pg 2 Years: 119, Pg 3 Years: 48, Total Students: 951\n","\n","[14/98] Processing: Sri Krishna College of Engineering and Technology (1).json\n","‚úì Inserted data for: Sri Krishna College of Engineering and Technology (IR-E-C-36995)\n","  Student counts: Ug 4 Years: 4813, Ug 5 Years: 196, Pg 2 Years: 92, Total Students: 5101\n","\n","[15/98] Processing: Thapar Institute of Engineering and Technology _Deemed-to-be-university (1).json\n","‚úì Inserted data for: Thapar Institute of Engineering and Technology (Deemed-to-be-university) (IR-E-I-1480)\n","  Student counts: Ug 4 Years: 9329, Pg 2 Years: 401, Total Students: 9730\n","\n","[16/98] Processing: IIT Delhi (1).json\n","‚úì Inserted data for: Indian Institute of Technology Delhi (IR-E-I-1074)\n","  Student counts: Ug 4 Years: 4312, Ug 5 Years: 659, Pg 2 Years: 3325, Total Students: 8296\n","\n","[17/98] Processing: Chithara University (1).json\n","‚úì Inserted data for: Chitkara University (IR-E-U-0373)\n","  Student counts: Ug 4 Years: 7710, Pg 2 Years: 15, Pg 3 Years: 18, Total Students: 7743\n","\n","[18/98] Processing: IIT Ropar (1).json\n","‚úì Inserted data for: Indian Institute of Technology Ropar (IR-E-U-0378)\n","  Student counts: Ug 4 Years: 1408, Pg 2 Years: 464, Pg Integrated: 25, Total Students: 1897\n","\n","[19/98] Processing: Kalinga Institute of Industrial Technology (1).json\n","‚úì Inserted data for: Kalinga Institute of Industrial Technology (IR-E-U-0356)\n","  Student counts: Ug 4 Years: 13957, Pg 2 Years: 224, Total Students: 14181\n","\n","[20/98] Processing: IIT Jodhpur (1).json\n","‚úì Inserted data for: Indian Institute of Technology Jodhpur (IR-E-U-0395)\n","  Student counts: Ug 4 Years: 1742, Pg 2 Years: 428, Total Students: 2170\n","\n","[21/98] Processing: Kalasalingam Academy of Research and Education (1).json\n","‚úì Inserted data for: Kalasalingam Academy of Research and Education (IR-E-U-0458)\n","  Student counts: Ug 4 Years: 6062, Pg 2 Years: 214, Total Students: 6276\n","\n","[22/98] Processing: Dr. B R Ambedkar National Institute of Technology Jalandhar (1).json\n","‚úì Inserted data for: Dr. B R Ambedkar National Institute of Technology Jalandhar (IR-E-U-0374)\n","  Student counts: Ug 4 Years: 4269, Pg 2 Years: 634, Total Students: 4903\n","\n","[23/98] Processing: IIT Kanpur (1).json\n","‚úì Inserted data for: Indian Institute of Technology Kanpur (IR-E-I-1075)\n","  Student counts: Ug 4 Years: 4410, Pg 2 Years: 1713, Total Students: 6123\n","\n","[24/98] Processing: IIT Roorkee 2024 (1).json\n","‚úì Inserted data for: Indian Institute of Technology Roorkee (IR-E-U-0560)\n","  Student counts: Ug 4 Years: 4334, Pg 2 Years: 1372, Pg Integrated: 759, Total Students: 6465\n","\n","[25/98] Processing: Manipal University_ Jaipur (1).json\n","‚úì Inserted data for: Manipal University, Jaipur (IR-E-U-0749)\n","  Student counts: Ug 4 Years: 7073, Pg 2 Years: 84, Total Students: 7157\n","\n","[26/98] Processing: IIT Bhuvaneswar (1).json\n","‚úì Inserted data for: Indian Institute of Technology Bhubaneswar (IR-E-U-0355)\n","  Student counts: Ug 4 Years: 1314, Ug 5 Years: 518, Pg 2 Years: 366, Total Students: 2198\n","\n","[27/98] Processing: IIT Guwahati (1).json\n","‚úì Inserted data for: Indian Institute of Technology Guwahati (IR-E-U-0053)\n","  Student counts: Ug 4 Years: 3777, Pg 2 Years: 1753, Total Students: 5530\n","\n","[28/98] Processing: NIT Delhi (1).json\n","‚úì Inserted data for: National Institute of Technology Delhi (IR-E-U-0622)\n","  Student counts: Ug 4 Years: 758, Pg 2 Years: 144, Total Students: 902\n","\n","[29/98] Processing: IIT Palakkad (1).json\n","‚úì Inserted data for: Indian Institute of Technology Palakkad (IR-E-U-0878)\n","  Student counts: Ug 4 Years: 639, Pg 2 Years: 176, Total Students: 815\n","\n","[30/98] Processing: Delhi Technological University (1).json\n","‚úì Inserted data for: Delhi Technological University (IR-E-U-0098)\n","  Student counts: Ug 4 Years: 10175, Pg 2 Years: 583, Total Students: 10758\n","\n","[31/98] Processing: PSG College of Technology (1).json\n","‚úì Inserted data for: PSG College of Technology (IR-E-C-37013)\n","  Student counts: Ug 4 Years: 4927, Ug 5 Years: 817, Pg 2 Years: 421, Total Students: 6165\n","\n","[32/98] Processing: Saveetha Institute of Medical and Technical Sciences (1).json\n","‚úì Inserted data for: Saveetha Institute of Medical and Technical Sciences (IR-E-I-1441)\n","  Student counts: Ug 4 Years: 5405, Pg 2 Years: 90, Total Students: 5495\n","\n","[33/98] Processing: C.V. Raman Global University_ Odisha (1).json\n","‚úì Inserted data for: C.V. Raman Global University, Odisha (IR-E-C-30045)\n","  Student counts: Ug 4 Years: 4845, Pg 2 Years: 246, Total Students: 5091\n","\n","[34/98] Processing: Engineering  2024 (1).json\n","‚úì Inserted data for: Graphic Era University (IR-E-U-0555)\n","  Student counts: Ug 4 Years: 4528, Pg 2 Years: 90, Total Students: 4618\n","\n","[35/98] Processing: IIIT Hyderabad  (1).json\n","‚úì Inserted data for: International Institute of Information Technology Hyderabad (IR-E-U-0014)\n","  Student counts: Ug 4 Years: 736, Ug 5 Years: 614, Pg 2 Years: 391, Total Students: 1741\n","\n","[36/98] Processing: NIT Surathkal (1).json\n","‚úì Inserted data for: National Institute of Technology Karnataka, Surathkal (IR-E-U-0237)\n","  Student counts: Ug 4 Years: 3927, Pg 2 Years: 1626, Total Students: 5553\n","\n","[37/98] Processing: IIT Indore (1).json\n","‚úì Inserted data for: Indian Institute of Technology Indore (IR-E-U-0273)\n","  Student counts: Ug 4 Years: 1343, Pg 2 Years: 370, Total Students: 1713\n","\n","[38/98] Processing: Sri Sivasubramaniya Nadar College of Engineering (1).json\n","‚úì Inserted data for: Sri Sivasubramaniya Nadar College of Engineering (IR-E-C-16604)\n","  Student counts: Ug 4 Years: 3543, Pg 2 Years: 180, Total Students: 3723\n","\n","[39/98] Processing: Maulana Azad National Institute of Technology (1).json\n","‚úì Inserted data for: Maulana Azad National Institute of Technology (IR-E-U-0284)\n","  Student counts: Ug 4 Years: 3994, Pg 2 Years: 642, Pg Integrated: 59, Total Students: 4695\n","\n","[40/98] Processing: Rajiv Gandhi Institute of Petroleum Technology (1).json\n","‚úì Inserted data for: Rajiv Gandhi Institute of Petroleum Technology (IR-E-U-0535)\n","  Student counts: Ug 4 Years: 926, Pg 2 Years: 51, Total Students: 977\n","\n","[41/98] Processing: Vel Tech Rangarajan Dr. Sagunthala R _ D Institute of Science and Technology (1).json\n","‚úì Inserted data for: Vel Tech Rangarajan Dr. Sagunthala R & D Institute of Science and Technology (IR-E-U-0489)\n","  Student counts: Ug 4 Years: 9172, Pg 2 Years: 216, Total Students: 9388\n","\n","[42/98] Processing: International Institute of Information Technology Bangalore (1).json\n","‚úì Inserted data for: International Institute of Information Technology Bangalore (IR-E-U-0221)\n","  Student counts: Pg 2 Years: 357, Pg Integrated: 653, Total Students: 1010\n","\n","[43/98] Processing: COEP Technological University (1).json\n","‚úì Inserted data for: COEP Technological University (IR-E-C-41593)\n","  Student counts: Ug 4 Years: 3134, Pg 2 Years: 534, Total Students: 3668\n","\n","[44/98] Processing: Visvesvaraya Technological University (1).json\n","‚úì Inserted data for: Visvesvaraya Technological University (IR-E-U-0249)\n","  Student counts: Ug 4 Years: 526, Pg 2 Years: 945, Total Students: 1471\n","\n","[45/98] Processing: Sant Longowal Institute of Engineering and Technology (1).json\n","‚úì Inserted data for: Sant Longowal Institute of Engineering and Technology (IR-E-U-0384)\n","  Student counts: Ug 4 Years: 2018, Pg 2 Years: 110, Total Students: 2128\n","\n","[46/98] Processing: Netaji Subhas University of Technology _NSUT_ (1).json\n","‚úì Inserted data for: Netaji Subhas University of Technology (NSUT) (IR-E-C-6379)\n","  Student counts: Ug 4 Years: 6862, Pg 2 Years: 296, Total Students: 7158\n","\n","[47/98] Processing: Jadavpur University (1).json\n","‚úì Inserted data for: Jadavpur University (IR-E-U-0575)\n","  Student counts: Ug 4 Years: 4983, Pg 2 Years: 781, Total Students: 5764\n","\n","[48/98] Processing: NIT Patna (1).json\n","‚úì Inserted data for: National Institute of Technology Patna (IR-E-U-0072)\n","  Student counts: Ug 4 Years: 2764, Pg 2 Years: 333, Total Students: 3097\n","\n","[49/98] Processing: IIT Kharagpur (1).json\n","‚úì Inserted data for: Indian Institute of Technology Kharagpur (IR-E-U-0573)\n","  Student counts: Ug 4 Years: 3859, Ug 5 Years: 4113, Pg 2 Years: 3033, Pg 3 Years: 46, Total Students: 11051\n","\n","[50/98] Processing: NIT Durgapur (1).json\n","‚úì Inserted data for: National Institute of Technology Durgapur (IR-E-U-0577)\n","  Student counts: Ug 4 Years: 3348, Ug 5 Years: 50, Pg 2 Years: 452, Total Students: 3850\n","\n","[51/98] Processing: IIT Hyderabad (1).json\n","‚úì Inserted data for: Indian Institute of Technology Hyderabad (IR-E-U-0013)\n","  Student counts: Ug 4 Years: 1690, Pg 2 Years: 629, Pg 3 Years: 125, Total Students: 2444\n","\n","[52/98] Processing: Shoolini University of Biotechnology and Management Science (1).json\n","‚úì Inserted data for: Shoolini University of Biotechnology and Management Sciences (IR-E-U-0190)\n","  Student counts: Ug 4 Years: 883, Pg 2 Years: 61, Total Students: 944\n","\n","[53/98] Processing: IIT Tirupati (1).json\n","‚úì Inserted data for: Indian Institute of Technology Tirupati (IR-E-U-0844)\n","  Student counts: Ug 4 Years: 852, Pg 2 Years: 165, Pg Integrated: 2, Total Students: 1019\n","\n","[54/98] Processing: Amrita Vishwa Vidyapeetham (1).json\n","‚úì Inserted data for: Amrita Vishwa Vidyapeetham (IR-E-U-0436)\n","  Student counts: Ug 4 Years: 11071, Pg 2 Years: 865, Total Students: 11936\n","\n","[55/98] Processing: Jamia Millia Islamia (1).json\n","‚úì Inserted data for: Jamia Millia Islamia (IR-E-U-0108)\n","  Student counts: Ug 4 Years: 1409, Pg 2 Years: 334, Total Students: 1743\n","\n","[56/98] Processing: NIT Tiruchirappalli (1).json\n","‚úì Inserted data for: National Institute of Technology Tiruchirappalli (IR-E-U-0467)\n","  Student counts: Ug 4 Years: 4304, Pg 2 Years: 1107, Total Students: 5411\n","\n","[57/98] Processing: Institute of Chemical Technology (1).json\n","‚úì Inserted data for: Institute of Chemical Technology (IR-E-U-0308)\n","  Student counts: Ug 4 Years: 944, Pg 2 Years: 578, Pg Integrated: 537, Total Students: 2059\n","\n","[58/98] Processing: Aligarh Muslim University (1).json\n","‚úì Inserted data for: Aligarh Muslim University (IR-E-U-0496)\n","  Student counts: Ug 4 Years: 1832, Pg 2 Years: 599, Total Students: 2431\n","\n","[59/98] Processing: VIT Vellore (1).json\n","‚úì Inserted data for: Vellore Institute of Technology (IR-E-U-0490)\n","  Student counts: Ug 4 Years: 35377, Pg 2 Years: 2684, Pg Integrated: 5238, Total Students: 43299\n","\n","[60/98] Processing: Jawaharlal Nehru Technological University (1).json\n","‚úì Inserted data for: Jawaharlal Nehru Technological University (IR-E-U-0017)\n","  Student counts: Ug 4 Years: 5546, Pg 2 Years: 1483, Total Students: 7029\n","\n","[61/98] Processing: Defence Institute of Adavanced Technology (1).json\n","‚úì Inserted data for: Defence Institute of Advanced Technology (IR-E-U-0297)\n","  Student counts: Pg 2 Years: 538, Total Students: 538\n","\n","[62/98] Processing: Lovely Professional University (1).json\n","‚úì Inserted data for: Lovely Professional University (IR-E-U-0379)\n","  Student counts: Ug 4 Years: 17857, Pg 2 Years: 235, Pg Integrated: 62, Total Students: 18154\n","\n","[63/98] Processing: NIT Meghalaya (1).json\n","‚úì Inserted data for: National Institute of Technology Meghalaya (IR-E-U-0619)\n","  Student counts: Ug 4 Years: 630, Pg 2 Years: 125, Total Students: 755\n","\n","[64/98] Processing: Madan Mohan Malaviya University of Technology (1).json\n","‚úì Inserted data for: Madan Mohan Malaviya University of Technology (IR-E-U-0739)\n","  Student counts: Ug 4 Years: 3000, Pg 2 Years: 235, Total Students: 3235\n","\n","[65/98] Processing: IIIT Allahabad (1).json\n","‚úì Inserted data for: Indian Institute of Information Technology Allahabad (IR-E-U-0516)\n","  Student counts: Ug 4 Years: 1715, Pg 2 Years: 330, Total Students: 2045\n","\n","[66/98] Processing: Guru Gobind Singh Indraprastha University (1).json\n","‚úì Inserted data for: Guru Gobind Singh Indraprastha University (IR-E-U-0099)\n","  Student counts: Ug 4 Years: 1847, Pg 2 Years: 232, Total Students: 2079\n","\n","[67/98] Processing: NIT  Puducherry (1).json\n","‚úì Inserted data for: National Institute of Technology Puducherry (IR-E-U-0621)\n","  Student counts: Ug 4 Years: 967, Pg 2 Years: 50, Total Students: 1017\n","\n","[68/98] Processing: AU College of Enginnering (1).json\n","‚úì Inserted data for: AU College of Engineering (A) (IR-E-C-24004)\n","  Student counts: Ug 4 Years: 2343, Pg 2 Years: 1018, Total Students: 3361\n","\n","[69/98] Processing: NIT Silchar (1).json\n","‚úì Inserted data for: National Institute of Technology Silchar (IR-E-U-0055)\n","  Student counts: Ug 4 Years: 3462, Pg 2 Years: 368, Total Students: 3830\n","\n","[70/98] Processing: NIT  Agartala (1).json\n","‚úì Inserted data for: National Institute of Technology Agartala (IR-E-U-0493)\n","  Student counts: Ug 4 Years: 3539, Pg 2 Years: 262, Total Students: 3801\n","\n","[71/98] Processing: Amity University (1).json\n","‚úì Inserted data for: Amity University (IR-E-U-0497)\n","  Student counts: Ug 4 Years: 5130, Pg 2 Years: 296, Pg Integrated: 276, Total Students: 5702\n","\n","[72/98] Processing: NIT Rourkela (1).json\n","‚úì Inserted data for: National Institute of Technology Rourkela (IR-E-U-0357)\n","  Student counts: Ug 4 Years: 4150, Pg 2 Years: 1054, Pg Integrated: 235, Total Students: 5439\n","\n","[73/98] Processing: Visvesvaraya National Institute of Technology Nagpur (1).json\n","‚úì Inserted data for: Visvesvaraya National Institute of Technology Nagpur (IR-E-U-0334)\n","  Student counts: Ug 4 Years: 3286, Pg 2 Years: 639, Total Students: 3925\n","\n","[74/98] Processing: Motilal Nehru National Institute of Technology (1).json\n","‚úì Inserted data for: Motilal Nehru National Institute of Technology (IR-E-U-0530)\n","  Student counts: Ug 4 Years: 4384, Pg 2 Years: 839, Total Students: 5223\n","\n","[75/98] Processing: NIT Raipur (1).json\n","‚úì Inserted data for: National Institute of Technology Raipur (IR-E-U-0092)\n","  Student counts: Ug 4 Years: 4150, Pg 2 Years: 187, Pg 3 Years: 51, Total Students: 4388\n","\n","[76/98] Processing: NIT Warangal (1).json\n","‚úì Inserted data for: National Institute of Technology Warangal (IR-E-U-0025)\n","  Student counts: Ug 4 Years: 4266, Pg 2 Years: 1182, Total Students: 5448\n","\n","[77/98] Processing: K L College of Engineering_Vaddeswaram_ (1).json\n","‚úì Inserted data for: Koneru Lakshmaiah Education Foundation University (K L College of Engineering) (IR-E-U-0020)\n","  Student counts: Ug 4 Years: 12743, Pg 2 Years: 505, Total Students: 13248\n","\n","[78/98] Processing: NIT Kurukshetra (1).json\n","‚úì Inserted data for: National Institute of Technology Kurukshetra (IR-E-U-0172)\n","  Student counts: Ug 4 Years: 4402, Pg 2 Years: 684, Total Students: 5086\n","\n","[79/98] Processing: Anna University (1).json\n","‚úì Inserted data for: Anna University (IR-E-U-0439)\n","  Student counts: Ug 4 Years: 8570, Pg 2 Years: 1450, Total Students: 10020\n","\n","[80/98] Processing: Indian Institute of Space Science and Technology (1).json\n","‚úì Inserted data for: Indian Institute of Space Science and Technology (IR-E-U-0255)\n","  Student counts: Ug 4 Years: 522, Ug 5 Years: 98, Pg 2 Years: 255, Total Students: 875\n","\n","[81/98] Processing: Birla Institute of Technology Ranchi (1).json\n","‚úì Inserted data for: Birla Institute of Technology (IR-E-U-0202)\n","  Student counts: Ug 4 Years: 3216, Pg 2 Years: 376, Total Students: 3592\n","\n","[82/98] Processing: R.V. College of Engineering (1).json\n","‚úì Inserted data for: R.V. College of Engineering (IR-E-C-1269)\n","  Student counts: Ug 4 Years: 5050, Pg 2 Years: 466, Total Students: 5516\n","\n","[83/98] Processing: Vignan_s Foundation for Science_ Technology and Research (1).json\n","‚úì Inserted data for: Vignan's Foundation for Science, Technology and Research (IR-E-U-0043)\n","  Student counts: Ug 4 Years: 6513, Pg 2 Years: 241, Total Students: 6754\n","\n","[84/98] Processing: NIT calicut (1).json\n","‚úì Inserted data for: National Institute of Technology Calicut (IR-E-U-0263)\n","  Student counts: Ug 4 Years: 3690, Pg 2 Years: 866, Total Students: 4556\n","\n","[85/98] Processing: Malaviya National Institute of Technology (1).json\n","‚úì Inserted data for: Malaviya National Institute of Technology (IR-E-U-0410)\n","  Student counts: Ug 4 Years: 3224, Pg 2 Years: 750, Total Students: 3974\n","\n","[86/98] Processing: Indraprastha Institute of Information Technology (1).json\n","‚úì Inserted data for: Indraprastha Institute of Information Technology (IR-E-U-0105)\n","  Student counts: Ug 4 Years: 2145, Pg 2 Years: 397, Total Students: 2542\n","\n","[87/98] Processing: Birla Institute of Technology  and Science_ Pilani (1).json\n","‚úì Inserted data for: Birla Institute of Technology and Science, Pilani (IR-E-U-0391)\n","  Student counts: Ug 4 Years: 11174, Pg 2 Years: 1286, Total Students: 12460\n","\n","[88/98] Processing: IIEST Shibpur (1).json\n","‚úì Inserted data for: Indian Institute of Engineering Science and Technology, Shibpur (IR-E-U-0584)\n","  Student counts: Ug 4 Years: 2667, Pg 2 Years: 426, Total Students: 3093\n","\n","[89/98] Processing: Manipal Institute of Technology (1).json\n","‚úì Inserted data for: Manipal Institute of Technology (IR-E-C-7252)\n","  Student counts: Ug 4 Years: 8375, Pg 2 Years: 775, Total Students: 9150\n","\n","[90/98] Processing: Sardar Vallabhbhai National Institute of Technology (1).json\n","‚úì Inserted data for: Sardar Vallabhbhai National Institute of Technology (IR-E-U-0149)\n","  Student counts: Ug 4 Years: 3367, Pg 2 Years: 642, Total Students: 4009\n","\n","[91/98] Processing: Chandigarh University (1).json\n","‚úì Inserted data for: Chandigarh University (IR-E-U-0747)\n","  Student counts: Ug 4 Years: 12895, Ug 5 Years: 86, Pg 2 Years: 462, Total Students: 13443\n","\n","[92/98] Processing: Siddaganga Institute of Technology (1).json\n","‚úì Inserted data for: Siddaganga Institute of Technology (IR-E-C-1297)\n","  Student counts: Ug 4 Years: 3605, Pg 2 Years: 323, Total Students: 3928\n","\n","[93/98] Processing: University of Hyderabad (1).json\n","‚úì Inserted data for: University of Hyderabad (IR-E-U-0042)\n","  Student counts: Pg 2 Years: 274, Pg Integrated: 140, Total Students: 414\n","\n","[94/98] Processing: NIT Srinagar (1).json\n","‚úì Inserted data for: National Institute of Technology Srinagar (IR-E-U-0197)\n","  Student counts: Ug 4 Years: 3170, Pg 2 Years: 323, Total Students: 3493\n","\n","[95/98] Processing: Shanmugha Arts Science Technology and Research Academy (1).json\n","‚úì Inserted data for: Shanmugha Arts Science Technology and Research Academy (IR-E-U-0476)\n","  Student counts: Ug 4 Years: 7966, Pg 2 Years: 213, Pg Integrated: 202, Total Students: 8381\n","\n","[96/98] Processing: IIT Madras (1).json\n","‚úì Inserted data for: Indian Institute of Technology Madras (IR-E-U-0456)\n","  Student counts: Ug 4 Years: 3440, Ug 5 Years: 1469, Pg 2 Years: 1205, Pg 3 Years: 498, Total Students: 6612\n","\n","[97/98] Processing: Banasthali Vidyapith (1).json\n","‚úì Inserted data for: Banasthali Vidyapith (IR-E-U-0389)\n","  Student counts: Ug 4 Years: 2976, Pg 2 Years: 198, Total Students: 3174\n","\n","[98/98] Processing: IIT Mandi (1).json\n","‚úì Inserted data for: Indian Institute of Technology Mandi (IR-E-U-0184)\n","  Student counts: Ug 4 Years: 1120, Ug 5 Years: 81, Pg 2 Years: 567, Total Students: 1768\n","\n","============================================================\n","PROCESSING SUMMARY\n","============================================================\n","üìä Total files: 98\n","‚úì Successfully inserted: 98\n","‚ö† Skipped (already exists): 0\n","‚ö† Skipped (no data): 0\n","‚ùå Failed: 0\n","============================================================\n","\n","‚úÖ All done!\n","üìä Check your Google Sheet: https://docs.google.com/spreadsheets/d/1AdMNjPdfv_YLknr3xVodq6KZHLvGyNHTNO1Sqbzt1wM/edit?usp=sharing\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DQ99wL32luHB","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1762971146216,"user_tz":-330,"elapsed":5138,"user":{"displayName":"Rahul Siddhu","userId":"12007764243202946991"}},"outputId":"1e4a1c40-f4dd-4ee5-def7-85d76ec44972"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: qdrant-client in /usr/local/lib/python3.12/dist-packages (1.15.1)\n","Requirement already satisfied: grpcio>=1.41.0 in /usr/local/lib/python3.12/dist-packages (from qdrant-client) (1.76.0)\n","Requirement already satisfied: httpx>=0.20.0 in /usr/local/lib/python3.12/dist-packages (from httpx[http2]>=0.20.0->qdrant-client) (0.28.1)\n","Requirement already satisfied: numpy>=1.26 in /usr/local/lib/python3.12/dist-packages (from qdrant-client) (2.0.2)\n","Requirement already satisfied: portalocker<4.0,>=2.7.0 in /usr/local/lib/python3.12/dist-packages (from qdrant-client) (3.2.0)\n","Requirement already satisfied: protobuf>=3.20.0 in /usr/local/lib/python3.12/dist-packages (from qdrant-client) (5.29.5)\n","Requirement already satisfied: pydantic!=2.0.*,!=2.1.*,!=2.2.0,>=1.10.8 in /usr/local/lib/python3.12/dist-packages (from qdrant-client) (2.11.10)\n","Requirement already satisfied: urllib3<3,>=1.26.14 in /usr/local/lib/python3.12/dist-packages (from qdrant-client) (2.5.0)\n","Requirement already satisfied: typing-extensions~=4.12 in /usr/local/lib/python3.12/dist-packages (from grpcio>=1.41.0->qdrant-client) (4.15.0)\n","Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client) (4.11.0)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client) (2025.10.5)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client) (1.0.9)\n","Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client) (3.11)\n","Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client) (0.16.0)\n","Requirement already satisfied: h2<5,>=3 in /usr/local/lib/python3.12/dist-packages (from httpx[http2]>=0.20.0->qdrant-client) (4.3.0)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic!=2.0.*,!=2.1.*,!=2.2.0,>=1.10.8->qdrant-client) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic!=2.0.*,!=2.1.*,!=2.2.0,>=1.10.8->qdrant-client) (2.33.2)\n","Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic!=2.0.*,!=2.1.*,!=2.2.0,>=1.10.8->qdrant-client) (0.4.2)\n","Requirement already satisfied: hyperframe<7,>=6.1 in /usr/local/lib/python3.12/dist-packages (from h2<5,>=3->httpx[http2]>=0.20.0->qdrant-client) (6.1.0)\n","Requirement already satisfied: hpack<5,>=4.1 in /usr/local/lib/python3.12/dist-packages (from h2<5,>=3->httpx[http2]>=0.20.0->qdrant-client) (4.1.0)\n","Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client) (1.3.1)\n"]}],"source":["!pip install qdrant-client\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"36fp9FSwoUca","colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["f95ae79d5b8a41c2a8a4cc5d071dc168","92836fd9e6444b8a953e5820045426ab","f4b9215cc4bf4265b4858ba864b5a072","fdce9f4e403f403aaaefe9d91f405bd3","991f4b1350eb4bd7b14670757e095a5d","9f8e9c6deb964e7f92a95be1777cd1ec","016bac5a4ada47498a131995b3f687d4","97b4a4229c0c440bab22532be039968a","3f60fa0ad2ca4a2da51fe861977529ec","26334de40b254b02b3efef9518caebcd","e35c68829cfc4a8db0274a39e10ea6d0","2cabb1e4f13c482b90fa7da2d88a886e","1d5fea18e826425095cd200d4fe45a18","b1aa6515a07549b098f74da12b1d9757","108f94f7b958442f8f9a53b3a0ec090f","1bc4cf22ff4d445d9006270014ebc612","a5ce2f08cf094a9ab9784943454d95b6","16b604ba150b4f67b5a0caa85f2096c0","691096338a1f428280e92b954e01fa65","65795ac97c2540e597384d00761c8cb8","984076454bfe4f99b41fd71f382af621","4252327f3c2a4ee392131163dc3e7054","474510d6f3ef4309b4526077bbba531c","32b22948ee5a42df9dabb840ffbfea23","84221745a880475db0a3db28ff7be1de","7698b8abf46a43038f4e6a8c64f4420f","2d554dfefd83404a946faefd027c639c","7ee3327a332c4c01a23588e570595d0e","44929dca1b6f45358f831cdb7077f7e4","46d0d5855e604a979b4669a9ebac7131","06463605d7504671b1399e0d8ecf07df","bf6195ba2c08406da0720da1e5be9eb0","665d7b3a0b1b4b5587a681e1deb7f656","f9e09ae2bec24e98a9f2e5e11f441af5","5b02ed9ab01743fda0e00e2d9b0358b1","1c7d2d385dda4e0093c102a901c663fd","630caf65f78041db8187bc1dc0a1bdb5","fe1396ff7efb4a3999f52a860865e7ca","a92ce7fa1a934f6a841732e225566b6e","b7dfc02e149348fdb83a2fdcebf6f10d","95ce5b59004c4727b849017af5183335","9e1ff1796b6e460cb8a0d3d4be5aa145","d1efe6b25c6549078d0cff3a5b24dba1","edfe7165a2ed42d880ddb33459be625b","4201c962a7c34898b9c145509a417421","12689ec67dbf453293bc41d84e6a0acd","1bb81b21220a48d3a6eb22dedb322b15","9153d72f15a44f519c6c04384e6680e1","c11fae1fbc714c0f962307008e1aab21","edc1c2dcc8f2467e82f200cc40146504","97a15bb239204065ad94dc99525a3f13","bc76c8060c814d3ab0f88634d252bf5c","9fb50acd4d6d4c92b68de022048fe031","cec7971b034f46598128d6fe2288edfe","bb3205fc9a9546ffa11e2cf6dfe6d49d","2136d8917db44db98dcc02463900ea38","afc583540aa94f4cb6d4452cbb63885a","639b79b4cc8a4d5ebbcacec19b70789e","495682c792674272b7c883ccd1e2ea4d","50fdfb38a869438d8d197cf4dd6c5875","e8f0e4c491d24abf96eae6a47731d0ea","7d5f32aff01f4d84865d9f2c59517143","d1f55b92f4494098801086a3dcd6211d","894777eb27624a978ac103296ff5f00a","8c1de9be2c594726a765f422cd39cfd3","23ad568ddcfa44afa1fe9ff0f8696f89","261bc4c738134c4f95663b3a1619d5a8","006c161197af41acbadd5e0f676a5c92","9b981b350d0440e78edba331b61c0566","4d644ea6bbfb407ca499fd40cc9ff896","72314221e58c4ef8a9eb87fc6e9ada93","5af1e51430d740358eff5c36dbe02732","5683cc0b8e454e37acbd5619f6c2b6fe","e4ab760ebd4a45ae8ea5333411cbeec1","da39818314694f0d99636642c1fc5214","85eab87956cf485f86c786f5ca99a024","6abec0588f624a8fae8229a1d3020833","dba89de6b32947f894be0db0b2e76608","e176bec1df0548baa4a584c28ee75ea0","cea3836b13b84a80b762bd4e2e90654a","4a507240ffe4408cbc5c895aa5286822","29e3246d13f94e31aae2e757dcdec04a","45506525148c4a4ab239871852e45e62","b9c4048c9bbd4b99946779701bba2896","906ef68b391644b982c5a651a4fbb658","9b5deec2246b423aa6126382de7a178e","d2ecc1999ee04cafb720e683a04be86c","483960ae859f4e30b4b749519edf60ce","4f2e748f10ac4bb6be8f19c014ca4fad","29fee262cf864ba1a91a385fde804c05","50610ac336e74b9989b42d8da7c87028","5dfada7e439845bc8da7ecbda4e1ae62","125cbd168d284e0c8c58f2cdf70ad387","17d0c20cb8774265af0a71ede5404498","8eaca7e348db44e79ad0fbad2e536307","58b671760f684dd7b54a881e79684090","b8d983c70c9a41e39352680cc2ac4b43","f61d544188284422a741ec165af45cf4","6ceae4fe18894f1f8c0576d819ac2a7f","4462aa364be944ba8738efa9f8b1cac1","3550dd8c0e0d41dc89e94b69afabe161","8fed12ca120e4ae7aae1c87083050a28","39418b72ac10462e8585d5ff9be0598d","220aca0009934f58b13ca4304330ad34","6fac5237c2034504b530b81384d6c361","ae3e199b953c4c5b8da3c0e1a46c4126","3ebd1d5e90144d609dd77335b14decd5","6122445f687941b3be4d58b12385e76f","89763c9b063a40f5bbfa3ae3640bb2da","f3b03bf5960b4407ba29ad52b63148a0","dadf7eadc7114f85a0012f8288986a22","889eac2861a34d529a009c8c84106999","07b37067529f44a9bd9dce7f2021aad0","294b7620ecb24c31a68e55a6f81105a5","5ef6cd4c99154fcea7b97e9026b54108","a122121140424e02ad51bf0fbbff7169","bf29d86cb10b4fbf855063604cc302e7","3e291645f4c14158b254f6b38a1e4582","887a7f86c72b4d0d917dfbc3495cdfa3","0242734b3f3d43d39eb48dff15121177","a076854a5f0844a5b9fea0062fe6f8b9"]},"executionInfo":{"status":"ok","timestamp":1762973517566,"user_tz":-330,"elapsed":222045,"user":{"displayName":"Rahul Siddhu","userId":"12007764243202946991"}},"outputId":"3cedbd13-f7f1-4d6b-b8ed-19460199e320"},"outputs":[{"output_type":"stream","name":"stdout","text":["Running in Google Colab\n","qdrant-client already installed\n","sentence-transformers already installed\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f95ae79d5b8a41c2a8a4cc5d071dc168"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2cabb1e4f13c482b90fa7da2d88a886e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["README.md: 0.00B [00:00, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"474510d6f3ef4309b4526077bbba531c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f9e09ae2bec24e98a9f2e5e11f441af5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4201c962a7c34898b9c145509a417421"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2136d8917db44db98dcc02463900ea38"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"261bc4c738134c4f95663b3a1619d5a8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["vocab.txt: 0.00B [00:00, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dba89de6b32947f894be0db0b2e76608"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer.json: 0.00B [00:00, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4f2e748f10ac4bb6be8f19c014ca4fad"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4462aa364be944ba8738efa9f8b1cac1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dadf7eadc7114f85a0012f8288986a22"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Embedding model loaded successfully\n","Qdrant Uploader - Compatible with Colab and VS Code\n","==================================================\n","Connected to Qdrant successfully\n","\n","============================================================\n","üöÄ GOOGLE COLAB DETECTED\n","============================================================\n","Choose how you want to provide your JSON files:\n","1Ô∏è‚É£ ¬†Upload files from your computer (Recommended)\n","2Ô∏è‚É£ ¬†Enter a path to files already in Colab\n","3Ô∏è‚É£ ¬†Use Google Drive (you need to mount it first)\n","------------------------------------------------------------\n","Enter your choice (1, 2, or 3): 1\n","\n","============================================================\n","üìÅ FILE UPLOAD FROM YOUR SYSTEM\n","============================================================\n","Choose one of the following options:\n","1Ô∏è‚É£ ¬†Upload individual JSON files\n","2Ô∏è‚É£ ¬†Upload a ZIP file containing your JSON files (Recommended)\n","------------------------------------------------------------\n","Enter your choice (1 or 2): 1\n","\n","üì§ Please select your JSON files from your computer...\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","     <input type=\"file\" id=\"files-915cd1f6-3fa2-4488-8932-fd64747dab26\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-915cd1f6-3fa2-4488-8932-fd64747dab26\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script>// Copyright 2017 Google LLC\n","//\n","// Licensed under the Apache License, Version 2.0 (the \"License\");\n","// you may not use this file except in compliance with the License.\n","// You may obtain a copy of the License at\n","//\n","//      http://www.apache.org/licenses/LICENSE-2.0\n","//\n","// Unless required by applicable law or agreed to in writing, software\n","// distributed under the License is distributed on an \"AS IS\" BASIS,\n","// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","// See the License for the specific language governing permissions and\n","// limitations under the License.\n","\n","/**\n"," * @fileoverview Helpers for google.colab Python module.\n"," */\n","(function(scope) {\n","function span(text, styleAttributes = {}) {\n","  const element = document.createElement('span');\n","  element.textContent = text;\n","  for (const key of Object.keys(styleAttributes)) {\n","    element.style[key] = styleAttributes[key];\n","  }\n","  return element;\n","}\n","\n","// Max number of bytes which will be uploaded at a time.\n","const MAX_PAYLOAD_SIZE = 100 * 1024;\n","\n","function _uploadFiles(inputId, outputId) {\n","  const steps = uploadFilesStep(inputId, outputId);\n","  const outputElement = document.getElementById(outputId);\n","  // Cache steps on the outputElement to make it available for the next call\n","  // to uploadFilesContinue from Python.\n","  outputElement.steps = steps;\n","\n","  return _uploadFilesContinue(outputId);\n","}\n","\n","// This is roughly an async generator (not supported in the browser yet),\n","// where there are multiple asynchronous steps and the Python side is going\n","// to poll for completion of each step.\n","// This uses a Promise to block the python side on completion of each step,\n","// then passes the result of the previous step as the input to the next step.\n","function _uploadFilesContinue(outputId) {\n","  const outputElement = document.getElementById(outputId);\n","  const steps = outputElement.steps;\n","\n","  const next = steps.next(outputElement.lastPromiseValue);\n","  return Promise.resolve(next.value.promise).then((value) => {\n","    // Cache the last promise value to make it available to the next\n","    // step of the generator.\n","    outputElement.lastPromiseValue = value;\n","    return next.value.response;\n","  });\n","}\n","\n","/**\n"," * Generator function which is called between each async step of the upload\n"," * process.\n"," * @param {string} inputId Element ID of the input file picker element.\n"," * @param {string} outputId Element ID of the output display.\n"," * @return {!Iterable<!Object>} Iterable of next steps.\n"," */\n","function* uploadFilesStep(inputId, outputId) {\n","  const inputElement = document.getElementById(inputId);\n","  inputElement.disabled = false;\n","\n","  const outputElement = document.getElementById(outputId);\n","  outputElement.innerHTML = '';\n","\n","  const pickedPromise = new Promise((resolve) => {\n","    inputElement.addEventListener('change', (e) => {\n","      resolve(e.target.files);\n","    });\n","  });\n","\n","  const cancel = document.createElement('button');\n","  inputElement.parentElement.appendChild(cancel);\n","  cancel.textContent = 'Cancel upload';\n","  const cancelPromise = new Promise((resolve) => {\n","    cancel.onclick = () => {\n","      resolve(null);\n","    };\n","  });\n","\n","  // Wait for the user to pick the files.\n","  const files = yield {\n","    promise: Promise.race([pickedPromise, cancelPromise]),\n","    response: {\n","      action: 'starting',\n","    }\n","  };\n","\n","  cancel.remove();\n","\n","  // Disable the input element since further picks are not allowed.\n","  inputElement.disabled = true;\n","\n","  if (!files) {\n","    return {\n","      response: {\n","        action: 'complete',\n","      }\n","    };\n","  }\n","\n","  for (const file of files) {\n","    const li = document.createElement('li');\n","    li.append(span(file.name, {fontWeight: 'bold'}));\n","    li.append(span(\n","        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n","        `last modified: ${\n","            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n","                                    'n/a'} - `));\n","    const percent = span('0% done');\n","    li.appendChild(percent);\n","\n","    outputElement.appendChild(li);\n","\n","    const fileDataPromise = new Promise((resolve) => {\n","      const reader = new FileReader();\n","      reader.onload = (e) => {\n","        resolve(e.target.result);\n","      };\n","      reader.readAsArrayBuffer(file);\n","    });\n","    // Wait for the data to be ready.\n","    let fileData = yield {\n","      promise: fileDataPromise,\n","      response: {\n","        action: 'continue',\n","      }\n","    };\n","\n","    // Use a chunked sending to avoid message size limits. See b/62115660.\n","    let position = 0;\n","    do {\n","      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n","      const chunk = new Uint8Array(fileData, position, length);\n","      position += length;\n","\n","      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n","      yield {\n","        response: {\n","          action: 'append',\n","          file: file.name,\n","          data: base64,\n","        },\n","      };\n","\n","      let percentDone = fileData.byteLength === 0 ?\n","          100 :\n","          Math.round((position / fileData.byteLength) * 100);\n","      percent.textContent = `${percentDone}% done`;\n","\n","    } while (position < fileData.byteLength);\n","  }\n","\n","  // All done.\n","  yield {\n","    response: {\n","      action: 'complete',\n","    }\n","  };\n","}\n","\n","scope.google = scope.google || {};\n","scope.google.colab = scope.google.colab || {};\n","scope.google.colab._files = {\n","  _uploadFiles,\n","  _uploadFilesContinue,\n","};\n","})(self);\n","</script> "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Saving Aligarh Muslim University.json to Aligarh Muslim University (1).json\n","Saving Amity University.json to Amity University (1).json\n","Saving Amrita Vishwa Vidyapeetham.json to Amrita Vishwa Vidyapeetham (1).json\n","Saving Anna University.json to Anna University (1).json\n","Saving AU College of Enginnering.json to AU College of Enginnering (1).json\n","Saving Banasthali Vidyapith.json to Banasthali Vidyapith (1).json\n","Saving Birla Institute of Technology  and Science_ Pilani.json to Birla Institute of Technology  and Science_ Pilani (1).json\n","Saving Birla Institute of Technology Ranchi.json to Birla Institute of Technology Ranchi (1).json\n","Saving C.V. Raman Global University_ Odisha.json to C.V. Raman Global University_ Odisha (1).json\n","Saving Chandigarh University.json to Chandigarh University (1).json\n","Saving Chithara University.json to Chithara University (1).json\n","Saving COEP Technological University.json to COEP Technological University (1).json\n","Saving Defence Institute of Adavanced Technology.json to Defence Institute of Adavanced Technology (1).json\n","Saving Delhi Technological University.json to Delhi Technological University (1).json\n","Saving Dr. B R Ambedkar National Institute of Technology Jalandhar.json to Dr. B R Ambedkar National Institute of Technology Jalandhar (1).json\n","Saving Engineering  2024.json to Engineering  2024 (1).json\n","Saving Guru Gobind Singh Indraprastha University.json to Guru Gobind Singh Indraprastha University (1).json\n","Saving IIEST Shibpur.json to IIEST Shibpur (1).json\n","Saving IIIT Allahabad.json to IIIT Allahabad (1).json\n","Saving IIIT Hyderabad .json to IIIT Hyderabad  (1).json\n","Saving IIT Bhilai.json to IIT Bhilai (1).json\n","Saving IIT Bhuvaneswar.json to IIT Bhuvaneswar (1).json\n","Saving IIT Bombay.json to IIT Bombay (1).json\n","Saving IIT Delhi.json to IIT Delhi (1).json\n","Saving IIT Gandhinagar.json to IIT Gandhinagar (1).json\n","Saving IIT Guwahati.json to IIT Guwahati (1).json\n","Saving IIT Hyderabad.json to IIT Hyderabad (1).json\n","Saving IIT Indore.json to IIT Indore (1).json\n","Saving IIT Jammu.json to IIT Jammu (1).json\n","Saving IIT Jodhpur.json to IIT Jodhpur (1).json\n","Saving IIT Kanpur.json to IIT Kanpur (1).json\n","Saving IIT Kharagpur.json to IIT Kharagpur (1).json\n","Saving IIT Madras.json to IIT Madras (1).json\n","Saving IIT Mandi.json to IIT Mandi (1).json\n","Saving IIT Palakkad.json to IIT Palakkad (1).json\n","Saving IIT Patna.json to IIT Patna (1).json\n","Saving IIT Roorkee 2024.json to IIT Roorkee 2024 (1).json\n","Saving IIT Ropar.json to IIT Ropar (1).json\n","Saving IIT Tirupati.json to IIT Tirupati (1).json\n","Saving IIT Varanasi_Banaras Hindu University_.json to IIT Varanasi_Banaras Hindu University_ (1).json\n","Saving Indian Institute of Space Science and Technology.json to Indian Institute of Space Science and Technology (1).json\n","Saving Indian Institute of Technology _Indian School of Mines_ Dhanbad.json to Indian Institute of Technology _Indian School of Mines_ Dhanbad (1).json\n","Saving Indraprastha Institute of Information Technology.json to Indraprastha Institute of Information Technology (1).json\n","Saving Institute of Chemical Technology.json to Institute of Chemical Technology (1).json\n","Saving International Institute of Information Technology Bangalore.json to International Institute of Information Technology Bangalore (1).json\n","Saving Jadavpur University.json to Jadavpur University (1).json\n","Saving Jain University_ Bangalore.json to Jain University_ Bangalore (1).json\n","Saving Jamia Millia Islamia.json to Jamia Millia Islamia (1).json\n","Saving Jawaharlal Nehru Technological University.json to Jawaharlal Nehru Technological University (1).json\n","Saving K L College of Engineering_Vaddeswaram_.json to K L College of Engineering_Vaddeswaram_ (1).json\n","Saving Kalasalingam Academy of Research and Education.json to Kalasalingam Academy of Research and Education (1).json\n","Saving Kalinga Institute of Industrial Technology.json to Kalinga Institute of Industrial Technology (1).json\n","Saving Lovely Professional University.json to Lovely Professional University (1).json\n","Saving M. S. Ramaiah Institute of Technology.json to M. S. Ramaiah Institute of Technology (1).json\n","Saving Madan Mohan Malaviya University of Technology.json to Madan Mohan Malaviya University of Technology (1).json\n","Saving Malaviya National Institute of Technology.json to Malaviya National Institute of Technology (1).json\n","Saving Manipal Institute of Technology.json to Manipal Institute of Technology (1).json\n","Saving Manipal University_ Jaipur.json to Manipal University_ Jaipur (1).json\n","Saving Maulana Azad National Institute of Technology.json to Maulana Azad National Institute of Technology (1).json\n","Saving Motilal Nehru National Institute of Technology.json to Motilal Nehru National Institute of Technology (1).json\n","Saving Netaji Subhas University of Technology _NSUT_.json to Netaji Subhas University of Technology _NSUT_ (1).json\n","Saving NIT  Agartala.json to NIT  Agartala (1).json\n","Saving NIT  Puducherry.json to NIT  Puducherry (1).json\n","Saving NIT calicut.json to NIT calicut (1).json\n","Saving NIT Delhi.json to NIT Delhi (1).json\n","Saving NIT Durgapur.json to NIT Durgapur (1).json\n","Saving NIT Kurukshetra.json to NIT Kurukshetra (1).json\n","Saving NIT Meghalaya.json to NIT Meghalaya (1).json\n","Saving NIT Patna.json to NIT Patna (1).json\n","Saving NIT Raipur.json to NIT Raipur (1).json\n","Saving NIT Rourkela.json to NIT Rourkela (1).json\n","Saving NIT Silchar.json to NIT Silchar (1).json\n","Saving NIT Srinagar.json to NIT Srinagar (1).json\n","Saving NIT Surathkal.json to NIT Surathkal (1).json\n","Saving NIT Tiruchirappalli.json to NIT Tiruchirappalli (1).json\n","Saving NIT Warangal.json to NIT Warangal (1).json\n","Saving PSG College of Technology.json to PSG College of Technology (1).json\n","Saving R.V. College of Engineering.json to R.V. College of Engineering (1).json\n","Saving Rajiv Gandhi Institute of Petroleum Technology.json to Rajiv Gandhi Institute of Petroleum Technology (1).json\n","Saving Sant Longowal Institute of Engineering and Technology.json to Sant Longowal Institute of Engineering and Technology (1).json\n","Saving Sardar Vallabhbhai National Institute of Technology.json to Sardar Vallabhbhai National Institute of Technology (1).json\n","Saving Sathyabama Institute of Science and Technology Chennai.json to Sathyabama Institute of Science and Technology Chennai (1).json\n","Saving Saveetha Institute of Medical and Technical Sciences.json to Saveetha Institute of Medical and Technical Sciences (1).json\n","Saving Shanmugha Arts Science Technology and Research Academy.json to Shanmugha Arts Science Technology and Research Academy (1).json\n","Saving Shoolini University of Biotechnology and Management Science.json to Shoolini University of Biotechnology and Management Science (1).json\n","Saving Siddaganga Institute of Technology.json to Siddaganga Institute of Technology (1).json\n","Saving SR University Warangal.json to SR University Warangal (1).json\n","Saving Sri Krishna College of Engineering and Technology.json to Sri Krishna College of Engineering and Technology (1).json\n","Saving Sri Sivasubramaniya Nadar College of Engineering.json to Sri Sivasubramaniya Nadar College of Engineering (1).json\n","Saving SRM Chennai.json to SRM Chennai (1).json\n","Saving Thapar Institute of Engineering and Technology _Deemed-to-be-university.json to Thapar Institute of Engineering and Technology _Deemed-to-be-university (1).json\n","Saving University of Hyderabad.json to University of Hyderabad (1).json\n","Saving UPES.json to UPES (1).json\n","Saving Vel Tech Rangarajan Dr. Sagunthala R _ D Institute of Science and Technology.json to Vel Tech Rangarajan Dr. Sagunthala R _ D Institute of Science and Technology (1).json\n","Saving Vignan_s Foundation for Science_ Technology and Research.json to Vignan_s Foundation for Science_ Technology and Research (1).json\n","Saving Visvesvaraya National Institute of Technology Nagpur.json to Visvesvaraya National Institute of Technology Nagpur (1).json\n","Saving Visvesvaraya Technological University.json to Visvesvaraya Technological University (1).json\n","Saving VIT Vellore.json to VIT Vellore (1).json\n","‚úÖ Saved: Aligarh Muslim University (1).json\n","‚úÖ Saved: Amity University (1).json\n","‚úÖ Saved: Amrita Vishwa Vidyapeetham (1).json\n","‚úÖ Saved: Anna University (1).json\n","‚úÖ Saved: AU College of Enginnering (1).json\n","‚úÖ Saved: Banasthali Vidyapith (1).json\n","‚úÖ Saved: Birla Institute of Technology  and Science_ Pilani (1).json\n","‚úÖ Saved: Birla Institute of Technology Ranchi (1).json\n","‚úÖ Saved: C.V. Raman Global University_ Odisha (1).json\n","‚úÖ Saved: Chandigarh University (1).json\n","‚úÖ Saved: Chithara University (1).json\n","‚úÖ Saved: COEP Technological University (1).json\n","‚úÖ Saved: Defence Institute of Adavanced Technology (1).json\n","‚úÖ Saved: Delhi Technological University (1).json\n","‚úÖ Saved: Dr. B R Ambedkar National Institute of Technology Jalandhar (1).json\n","‚úÖ Saved: Engineering  2024 (1).json\n","‚úÖ Saved: Guru Gobind Singh Indraprastha University (1).json\n","‚úÖ Saved: IIEST Shibpur (1).json\n","‚úÖ Saved: IIIT Allahabad (1).json\n","‚úÖ Saved: IIIT Hyderabad  (1).json\n","‚úÖ Saved: IIT Bhilai (1).json\n","‚úÖ Saved: IIT Bhuvaneswar (1).json\n","‚úÖ Saved: IIT Bombay (1).json\n","‚úÖ Saved: IIT Delhi (1).json\n","‚úÖ Saved: IIT Gandhinagar (1).json\n","‚úÖ Saved: IIT Guwahati (1).json\n","‚úÖ Saved: IIT Hyderabad (1).json\n","‚úÖ Saved: IIT Indore (1).json\n","‚úÖ Saved: IIT Jammu (1).json\n","‚úÖ Saved: IIT Jodhpur (1).json\n","‚úÖ Saved: IIT Kanpur (1).json\n","‚úÖ Saved: IIT Kharagpur (1).json\n","‚úÖ Saved: IIT Madras (1).json\n","‚úÖ Saved: IIT Mandi (1).json\n","‚úÖ Saved: IIT Palakkad (1).json\n","‚úÖ Saved: IIT Patna (1).json\n","‚úÖ Saved: IIT Roorkee 2024 (1).json\n","‚úÖ Saved: IIT Ropar (1).json\n","‚úÖ Saved: IIT Tirupati (1).json\n","‚úÖ Saved: IIT Varanasi_Banaras Hindu University_ (1).json\n","‚úÖ Saved: Indian Institute of Space Science and Technology (1).json\n","‚úÖ Saved: Indian Institute of Technology _Indian School of Mines_ Dhanbad (1).json\n","‚úÖ Saved: Indraprastha Institute of Information Technology (1).json\n","‚úÖ Saved: Institute of Chemical Technology (1).json\n","‚úÖ Saved: International Institute of Information Technology Bangalore (1).json\n","‚úÖ Saved: Jadavpur University (1).json\n","‚úÖ Saved: Jain University_ Bangalore (1).json\n","‚úÖ Saved: Jamia Millia Islamia (1).json\n","‚úÖ Saved: Jawaharlal Nehru Technological University (1).json\n","‚úÖ Saved: K L College of Engineering_Vaddeswaram_ (1).json\n","‚úÖ Saved: Kalasalingam Academy of Research and Education (1).json\n","‚úÖ Saved: Kalinga Institute of Industrial Technology (1).json\n","‚úÖ Saved: Lovely Professional University (1).json\n","‚úÖ Saved: M. S. Ramaiah Institute of Technology (1).json\n","‚úÖ Saved: Madan Mohan Malaviya University of Technology (1).json\n","‚úÖ Saved: Malaviya National Institute of Technology (1).json\n","‚úÖ Saved: Manipal Institute of Technology (1).json\n","‚úÖ Saved: Manipal University_ Jaipur (1).json\n","‚úÖ Saved: Maulana Azad National Institute of Technology (1).json\n","‚úÖ Saved: Motilal Nehru National Institute of Technology (1).json\n","‚úÖ Saved: Netaji Subhas University of Technology _NSUT_ (1).json\n","‚úÖ Saved: NIT  Agartala (1).json\n","‚úÖ Saved: NIT  Puducherry (1).json\n","‚úÖ Saved: NIT calicut (1).json\n","‚úÖ Saved: NIT Delhi (1).json\n","‚úÖ Saved: NIT Durgapur (1).json\n","‚úÖ Saved: NIT Kurukshetra (1).json\n","‚úÖ Saved: NIT Meghalaya (1).json\n","‚úÖ Saved: NIT Patna (1).json\n","‚úÖ Saved: NIT Raipur (1).json\n","‚úÖ Saved: NIT Rourkela (1).json\n","‚úÖ Saved: NIT Silchar (1).json\n","‚úÖ Saved: NIT Srinagar (1).json\n","‚úÖ Saved: NIT Surathkal (1).json\n","‚úÖ Saved: NIT Tiruchirappalli (1).json\n","‚úÖ Saved: NIT Warangal (1).json\n","‚úÖ Saved: PSG College of Technology (1).json\n","‚úÖ Saved: R.V. College of Engineering (1).json\n","‚úÖ Saved: Rajiv Gandhi Institute of Petroleum Technology (1).json\n","‚úÖ Saved: Sant Longowal Institute of Engineering and Technology (1).json\n","‚úÖ Saved: Sardar Vallabhbhai National Institute of Technology (1).json\n","‚úÖ Saved: Sathyabama Institute of Science and Technology Chennai (1).json\n","‚úÖ Saved: Saveetha Institute of Medical and Technical Sciences (1).json\n","‚úÖ Saved: Shanmugha Arts Science Technology and Research Academy (1).json\n","‚úÖ Saved: Shoolini University of Biotechnology and Management Science (1).json\n","‚úÖ Saved: Siddaganga Institute of Technology (1).json\n","‚úÖ Saved: SR University Warangal (1).json\n","‚úÖ Saved: Sri Krishna College of Engineering and Technology (1).json\n","‚úÖ Saved: Sri Sivasubramaniya Nadar College of Engineering (1).json\n","‚úÖ Saved: SRM Chennai (1).json\n","‚úÖ Saved: Thapar Institute of Engineering and Technology _Deemed-to-be-university (1).json\n","‚úÖ Saved: University of Hyderabad (1).json\n","‚úÖ Saved: UPES (1).json\n","‚úÖ Saved: Vel Tech Rangarajan Dr. Sagunthala R _ D Institute of Science and Technology (1).json\n","‚úÖ Saved: Vignan_s Foundation for Science_ Technology and Research (1).json\n","‚úÖ Saved: Visvesvaraya National Institute of Technology Nagpur (1).json\n","‚úÖ Saved: Visvesvaraya Technological University (1).json\n","‚úÖ Saved: VIT Vellore (1).json\n","\n","üéâ Successfully uploaded 98 JSON file(s) to /content/uploaded_json_files\n","üìÅ Processing folder: /content/uploaded_json_files\n","\n","Found 98 JSON files to process\n","Files: ['SR University Warangal (1).json', 'Sathyabama Institute of Science and Technology Chennai (1).json', 'IIT Bombay (1).json', 'SRM Chennai (1).json', 'M. S. Ramaiah Institute of Technology (1).json', 'IIT Gandhinagar (1).json', 'IIT Patna (1).json', 'Indian Institute of Technology _Indian School of Mines_ Dhanbad (1).json', 'IIT Varanasi_Banaras Hindu University_ (1).json', 'UPES (1).json', 'IIT Bhilai (1).json', 'Jain University_ Bangalore (1).json', 'IIT Jammu (1).json', 'Sri Krishna College of Engineering and Technology (1).json', 'Thapar Institute of Engineering and Technology _Deemed-to-be-university (1).json', 'IIT Delhi (1).json', 'Chithara University (1).json', 'IIT Ropar (1).json', 'Kalinga Institute of Industrial Technology (1).json', 'IIT Jodhpur (1).json', 'Kalasalingam Academy of Research and Education (1).json', 'Dr. B R Ambedkar National Institute of Technology Jalandhar (1).json', 'IIT Kanpur (1).json', 'IIT Roorkee 2024 (1).json', 'Manipal University_ Jaipur (1).json', 'IIT Bhuvaneswar (1).json', 'IIT Guwahati (1).json', 'NIT Delhi (1).json', 'IIT Palakkad (1).json', 'Delhi Technological University (1).json', 'PSG College of Technology (1).json', 'Saveetha Institute of Medical and Technical Sciences (1).json', 'C.V. Raman Global University_ Odisha (1).json', 'Engineering  2024 (1).json', 'IIIT Hyderabad  (1).json', 'NIT Surathkal (1).json', 'IIT Indore (1).json', 'Sri Sivasubramaniya Nadar College of Engineering (1).json', 'Maulana Azad National Institute of Technology (1).json', 'Rajiv Gandhi Institute of Petroleum Technology (1).json', 'Vel Tech Rangarajan Dr. Sagunthala R _ D Institute of Science and Technology (1).json', 'International Institute of Information Technology Bangalore (1).json', 'COEP Technological University (1).json', 'Visvesvaraya Technological University (1).json', 'Sant Longowal Institute of Engineering and Technology (1).json', 'Netaji Subhas University of Technology _NSUT_ (1).json', 'Jadavpur University (1).json', 'NIT Patna (1).json', 'IIT Kharagpur (1).json', 'NIT Durgapur (1).json', 'IIT Hyderabad (1).json', 'Shoolini University of Biotechnology and Management Science (1).json', 'IIT Tirupati (1).json', 'Amrita Vishwa Vidyapeetham (1).json', 'Jamia Millia Islamia (1).json', 'NIT Tiruchirappalli (1).json', 'Institute of Chemical Technology (1).json', 'Aligarh Muslim University (1).json', 'VIT Vellore (1).json', 'Jawaharlal Nehru Technological University (1).json', 'Defence Institute of Adavanced Technology (1).json', 'Lovely Professional University (1).json', 'NIT Meghalaya (1).json', 'Madan Mohan Malaviya University of Technology (1).json', 'IIIT Allahabad (1).json', 'Guru Gobind Singh Indraprastha University (1).json', 'NIT  Puducherry (1).json', 'AU College of Enginnering (1).json', 'NIT Silchar (1).json', 'NIT  Agartala (1).json', 'Amity University (1).json', 'NIT Rourkela (1).json', 'Visvesvaraya National Institute of Technology Nagpur (1).json', 'Motilal Nehru National Institute of Technology (1).json', 'NIT Raipur (1).json', 'NIT Warangal (1).json', 'K L College of Engineering_Vaddeswaram_ (1).json', 'NIT Kurukshetra (1).json', 'Anna University (1).json', 'Indian Institute of Space Science and Technology (1).json', 'Birla Institute of Technology Ranchi (1).json', 'R.V. College of Engineering (1).json', 'Vignan_s Foundation for Science_ Technology and Research (1).json', 'NIT calicut (1).json', 'Malaviya National Institute of Technology (1).json', 'Indraprastha Institute of Information Technology (1).json', 'Birla Institute of Technology  and Science_ Pilani (1).json', 'IIEST Shibpur (1).json', 'Manipal Institute of Technology (1).json', 'Sardar Vallabhbhai National Institute of Technology (1).json', 'Chandigarh University (1).json', 'Siddaganga Institute of Technology (1).json', 'University of Hyderabad (1).json', 'NIT Srinagar (1).json', 'Shanmugha Arts Science Technology and Research Academy (1).json', 'IIT Madras (1).json', 'Banasthali Vidyapith (1).json', 'IIT Mandi (1).json']\n","Using embedding model vector size: 384\n","‚úÖ Collection durden already exists\n","\n","--- Processing file: /content/uploaded_json_files/SR University Warangal (1).json ---\n","Loaded JSON file: /content/uploaded_json_files/SR University Warangal (1).json\n","üìä Found NIRF data with 12 points\n","üîÑ Processing 12 items for vectorization...\n","‚úÖ Generated vector for SR University - HEADER (dim: 384)\n","‚úÖ Generated vector for SR University - SANCTIONED_INTAKE (dim: 384)\n","‚úÖ Generated vector for SR University - STUDENT_STRENGTH (dim: 384)\n","‚úÖ Generated vector for SR University - PLACEMENT_STUDIES (dim: 384)\n","‚úÖ Generated vector for SR University - PHD_DETAILS (dim: 384)\n","‚úÖ Generated vector for SR University - FINANCIAL_RESOURCES (dim: 384)\n","‚úÖ Generated vector for SR University - FINANCIAL_RESOURCES (dim: 384)\n","‚úÖ Generated vector for SR University - SPONSORED_RESEARCH (dim: 384)\n","‚úÖ Generated vector for SR University - CONSULTANCY_PROJECTS (dim: 384)\n","‚úÖ Generated vector for SR University - PCS_FACILITIES (dim: 384)\n","‚úÖ Generated vector for SR University - FACULTY_DETAILS (dim: 384)\n","‚úÖ Generated vector for SR University - students_strength (dim: 384)\n","‚úÖ Successfully processed 12 points\n","Uploading 12 points in batches of 100\n","Uploaded batch 1/1: 12 points\n","Successfully uploaded 12 points from /content/uploaded_json_files/SR University Warangal (1).json\n","\n","--- Processing file: /content/uploaded_json_files/Sathyabama Institute of Science and Technology Chennai (1).json ---\n","Loaded JSON file: /content/uploaded_json_files/Sathyabama Institute of Science and Technology Chennai (1).json\n","üìä Found NIRF data with 12 points\n","üîÑ Processing 12 items for vectorization...\n","‚úÖ Generated vector for Sathyabama Institute of Science and Technology - HEADER (dim: 384)\n","‚úÖ Generated vector for Sathyabama Institute of Science and Technology - SANCTIONED_INTAKE (dim: 384)\n","‚úÖ Generated vector for Sathyabama Institute of Science and Technology - STUDENT_STRENGTH (dim: 384)\n","‚úÖ Generated vector for Sathyabama Institute of Science and Technology - PLACEMENT_STUDIES (dim: 384)\n","‚úÖ Generated vector for Sathyabama Institute of Science and Technology - PHD_DETAILS (dim: 384)\n","‚úÖ Generated vector for Sathyabama Institute of Science and Technology - FINANCIAL_RESOURCES (dim: 384)\n","‚úÖ Generated vector for Sathyabama Institute of Science and Technology - FINANCIAL_RESOURCES (dim: 384)\n","‚úÖ Generated vector for Sathyabama Institute of Science and Technology - SPONSORED_RESEARCH (dim: 384)\n","‚úÖ Generated vector for Sathyabama Institute of Science and Technology - CONSULTANCY_PROJECTS (dim: 384)\n","‚úÖ Generated vector for Sathyabama Institute of Science and Technology - PCS_FACILITIES (dim: 384)\n","‚úÖ Generated vector for Sathyabama Institute of Science and Technology - FACULTY_DETAILS (dim: 384)\n","‚úÖ Generated vector for Sathyabama Institute of Science and Technology - students_strength (dim: 384)\n","‚úÖ Successfully processed 12 points\n","Uploading 12 points in batches of 100\n","Uploaded batch 1/1: 12 points\n","Successfully uploaded 12 points from /content/uploaded_json_files/Sathyabama Institute of Science and Technology Chennai (1).json\n","\n","--- Processing file: /content/uploaded_json_files/IIT Bombay (1).json ---\n","Loaded JSON file: /content/uploaded_json_files/IIT Bombay (1).json\n","üìä Found NIRF data with 12 points\n","üîÑ Processing 12 items for vectorization...\n","‚úÖ Generated vector for Indian Institute of Technology Bombay - HEADER (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Technology Bombay - SANCTIONED_INTAKE (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Technology Bombay - STUDENT_STRENGTH (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Technology Bombay - PLACEMENT_STUDIES (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Technology Bombay - PHD_DETAILS (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Technology Bombay - FINANCIAL_RESOURCES (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Technology Bombay - FINANCIAL_RESOURCES (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Technology Bombay - SPONSORED_RESEARCH (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Technology Bombay - CONSULTANCY_PROJECTS (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Technology Bombay - PCS_FACILITIES (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Technology Bombay - FACULTY_DETAILS (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Technology Bombay - students_strength (dim: 384)\n","‚úÖ Successfully processed 12 points\n","Uploading 12 points in batches of 100\n","Uploaded batch 1/1: 12 points\n","Successfully uploaded 12 points from /content/uploaded_json_files/IIT Bombay (1).json\n","\n","--- Processing file: /content/uploaded_json_files/SRM Chennai (1).json ---\n","Loaded JSON file: /content/uploaded_json_files/SRM Chennai (1).json\n","üìä Found NIRF data with 13 points\n","üîÑ Processing 13 items for vectorization...\n","‚úÖ Generated vector for S.R.M. Institute of Science and Technology - HEADER (dim: 384)\n","‚úÖ Generated vector for S.R.M. Institute of Science and Technology - SANCTIONED_INTAKE (dim: 384)\n","‚úÖ Generated vector for S.R.M. Institute of Science and Technology - STUDENT_STRENGTH (dim: 384)\n","‚úÖ Generated vector for S.R.M. Institute of Science and Technology - PLACEMENT_STUDIES (dim: 384)\n","‚úÖ Generated vector for S.R.M. Institute of Science and Technology - PG_PLACEMENT (dim: 384)\n","‚úÖ Generated vector for S.R.M. Institute of Science and Technology - PHD_DETAILS (dim: 384)\n","‚úÖ Generated vector for S.R.M. Institute of Science and Technology - FINANCIAL_RESOURCES (dim: 384)\n","‚úÖ Generated vector for S.R.M. Institute of Science and Technology - FINANCIAL_RESOURCES (dim: 384)\n","‚úÖ Generated vector for S.R.M. Institute of Science and Technology - SPONSORED_RESEARCH (dim: 384)\n","‚úÖ Generated vector for S.R.M. Institute of Science and Technology - CONSULTANCY_PROJECTS (dim: 384)\n","‚úÖ Generated vector for S.R.M. Institute of Science and Technology - PCS_FACILITIES (dim: 384)\n","‚úÖ Generated vector for S.R.M. Institute of Science and Technology - FACULTY_DETAILS (dim: 384)\n","‚úÖ Generated vector for S.R.M. Institute of Science and Technology - students_strength (dim: 384)\n","‚úÖ Successfully processed 13 points\n","Uploading 13 points in batches of 100\n","Uploaded batch 1/1: 13 points\n","Successfully uploaded 13 points from /content/uploaded_json_files/SRM Chennai (1).json\n","\n","--- Processing file: /content/uploaded_json_files/M. S. Ramaiah Institute of Technology (1).json ---\n","Loaded JSON file: /content/uploaded_json_files/M. S. Ramaiah Institute of Technology (1).json\n","üìä Found NIRF data with 12 points\n","üîÑ Processing 12 items for vectorization...\n","‚úÖ Generated vector for M. S. Ramaiah Institute of Technology - HEADER (dim: 384)\n","‚úÖ Generated vector for M. S. Ramaiah Institute of Technology - SANCTIONED_INTAKE (dim: 384)\n","‚úÖ Generated vector for M. S. Ramaiah Institute of Technology - STUDENT_STRENGTH (dim: 384)\n","‚úÖ Generated vector for M. S. Ramaiah Institute of Technology - PLACEMENT_STUDIES (dim: 384)\n","‚úÖ Generated vector for M. S. Ramaiah Institute of Technology - PHD_DETAILS (dim: 384)\n","‚úÖ Generated vector for M. S. Ramaiah Institute of Technology - FINANCIAL_RESOURCES (dim: 384)\n","‚úÖ Generated vector for M. S. Ramaiah Institute of Technology - FINANCIAL_RESOURCES (dim: 384)\n","‚úÖ Generated vector for M. S. Ramaiah Institute of Technology - SPONSORED_RESEARCH (dim: 384)\n","‚úÖ Generated vector for M. S. Ramaiah Institute of Technology - CONSULTANCY_PROJECTS (dim: 384)\n","‚úÖ Generated vector for M. S. Ramaiah Institute of Technology - PCS_FACILITIES (dim: 384)\n","‚úÖ Generated vector for M. S. Ramaiah Institute of Technology - FACULTY_DETAILS (dim: 384)\n","‚úÖ Generated vector for M. S. Ramaiah Institute of Technology - students_strength (dim: 384)\n","‚úÖ Successfully processed 12 points\n","Uploading 12 points in batches of 100\n","Uploaded batch 1/1: 12 points\n","Successfully uploaded 12 points from /content/uploaded_json_files/M. S. Ramaiah Institute of Technology (1).json\n","\n","--- Processing file: /content/uploaded_json_files/IIT Gandhinagar (1).json ---\n","Loaded JSON file: /content/uploaded_json_files/IIT Gandhinagar (1).json\n","üìä Found NIRF data with 12 points\n","üîÑ Processing 12 items for vectorization...\n","‚úÖ Generated vector for Indian Institute of Technology Gandhinagar - HEADER (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Technology Gandhinagar - SANCTIONED_INTAKE (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Technology Gandhinagar - STUDENT_STRENGTH (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Technology Gandhinagar - PLACEMENT_STUDIES (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Technology Gandhinagar - PHD_DETAILS (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Technology Gandhinagar - FINANCIAL_RESOURCES (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Technology Gandhinagar - FINANCIAL_RESOURCES (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Technology Gandhinagar - SPONSORED_RESEARCH (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Technology Gandhinagar - CONSULTANCY_PROJECTS (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Technology Gandhinagar - PCS_FACILITIES (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Technology Gandhinagar - FACULTY_DETAILS (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Technology Gandhinagar - students_strength (dim: 384)\n","‚úÖ Successfully processed 12 points\n","Uploading 12 points in batches of 100\n","Uploaded batch 1/1: 12 points\n","Successfully uploaded 12 points from /content/uploaded_json_files/IIT Gandhinagar (1).json\n","\n","--- Processing file: /content/uploaded_json_files/IIT Patna (1).json ---\n","Loaded JSON file: /content/uploaded_json_files/IIT Patna (1).json\n","üìä Found NIRF data with 12 points\n","üîÑ Processing 12 items for vectorization...\n","‚úÖ Generated vector for Indian Institute of Technology Patna - HEADER (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Technology Patna - SANCTIONED_INTAKE (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Technology Patna - STUDENT_STRENGTH (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Technology Patna - PLACEMENT_STUDIES (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Technology Patna - PHD_DETAILS (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Technology Patna - FINANCIAL_RESOURCES (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Technology Patna - FINANCIAL_RESOURCES (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Technology Patna - SPONSORED_RESEARCH (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Technology Patna - CONSULTANCY_PROJECTS (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Technology Patna - PCS_FACILITIES (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Technology Patna - FACULTY_DETAILS (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Technology Patna - students_strength (dim: 384)\n","‚úÖ Successfully processed 12 points\n","Uploading 12 points in batches of 100\n","Uploaded batch 1/1: 12 points\n","Successfully uploaded 12 points from /content/uploaded_json_files/IIT Patna (1).json\n","\n","--- Processing file: /content/uploaded_json_files/Indian Institute of Technology _Indian School of Mines_ Dhanbad (1).json ---\n","Loaded JSON file: /content/uploaded_json_files/Indian Institute of Technology _Indian School of Mines_ Dhanbad (1).json\n","üìä Found NIRF data with 12 points\n","üîÑ Processing 12 items for vectorization...\n","‚úÖ Generated vector for Indian Institute of Technology (Indian School of Mines) Dhanbad - HEADER (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Technology (Indian School of Mines) Dhanbad - SANCTIONED_INTAKE (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Technology (Indian School of Mines) Dhanbad - STUDENT_STRENGTH (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Technology (Indian School of Mines) Dhanbad - PLACEMENT_STUDIES (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Technology (Indian School of Mines) Dhanbad - PHD_DETAILS (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Technology (Indian School of Mines) Dhanbad - FINANCIAL_RESOURCES (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Technology (Indian School of Mines) Dhanbad - FINANCIAL_RESOURCES (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Technology (Indian School of Mines) Dhanbad - SPONSORED_RESEARCH (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Technology (Indian School of Mines) Dhanbad - CONSULTANCY_PROJECTS (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Technology (Indian School of Mines) Dhanbad - PCS_FACILITIES (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Technology (Indian School of Mines) Dhanbad - FACULTY_DETAILS (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Technology (Indian School of Mines) Dhanbad - students_strength (dim: 384)\n","‚úÖ Successfully processed 12 points\n","Uploading 12 points in batches of 100\n","Uploaded batch 1/1: 12 points\n","Successfully uploaded 12 points from /content/uploaded_json_files/Indian Institute of Technology _Indian School of Mines_ Dhanbad (1).json\n","\n","--- Processing file: /content/uploaded_json_files/IIT Varanasi_Banaras Hindu University_ (1).json ---\n","Loaded JSON file: /content/uploaded_json_files/IIT Varanasi_Banaras Hindu University_ (1).json\n","üìä Found NIRF data with 12 points\n","üîÑ Processing 12 items for vectorization...\n","‚úÖ Generated vector for Indian Institute of Technology (Banaras Hindu University) Varanasi - HEADER (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Technology (Banaras Hindu University) Varanasi - SANCTIONED_INTAKE (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Technology (Banaras Hindu University) Varanasi - STUDENT_STRENGTH (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Technology (Banaras Hindu University) Varanasi - PLACEMENT_STUDIES (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Technology (Banaras Hindu University) Varanasi - PHD_DETAILS (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Technology (Banaras Hindu University) Varanasi - FINANCIAL_RESOURCES (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Technology (Banaras Hindu University) Varanasi - FINANCIAL_RESOURCES (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Technology (Banaras Hindu University) Varanasi - SPONSORED_RESEARCH (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Technology (Banaras Hindu University) Varanasi - CONSULTANCY_PROJECTS (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Technology (Banaras Hindu University) Varanasi - PCS_FACILITIES (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Technology (Banaras Hindu University) Varanasi - FACULTY_DETAILS (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Technology (Banaras Hindu University) Varanasi - students_strength (dim: 384)\n","‚úÖ Successfully processed 12 points\n","Uploading 12 points in batches of 100\n","Uploaded batch 1/1: 12 points\n","Successfully uploaded 12 points from /content/uploaded_json_files/IIT Varanasi_Banaras Hindu University_ (1).json\n","\n","--- Processing file: /content/uploaded_json_files/UPES (1).json ---\n","Loaded JSON file: /content/uploaded_json_files/UPES (1).json\n","üìä Found NIRF data with 12 points\n","üîÑ Processing 12 items for vectorization...\n","‚úÖ Generated vector for UPES - HEADER (dim: 384)\n","‚úÖ Generated vector for UPES - SANCTIONED_INTAKE (dim: 384)\n","‚úÖ Generated vector for UPES - STUDENT_STRENGTH (dim: 384)\n","‚úÖ Generated vector for UPES - PLACEMENT_STUDIES (dim: 384)\n","‚úÖ Generated vector for UPES - PHD_DETAILS (dim: 384)\n","‚úÖ Generated vector for UPES - FINANCIAL_RESOURCES (dim: 384)\n","‚úÖ Generated vector for UPES - FINANCIAL_RESOURCES (dim: 384)\n","‚úÖ Generated vector for UPES - SPONSORED_RESEARCH (dim: 384)\n","‚úÖ Generated vector for UPES - CONSULTANCY_PROJECTS (dim: 384)\n","‚úÖ Generated vector for UPES - PCS_FACILITIES (dim: 384)\n","‚úÖ Generated vector for UPES - FACULTY_DETAILS (dim: 384)\n","‚úÖ Generated vector for UPES - students_strength (dim: 384)\n","‚úÖ Successfully processed 12 points\n","Uploading 12 points in batches of 100\n","Uploaded batch 1/1: 12 points\n","Successfully uploaded 12 points from /content/uploaded_json_files/UPES (1).json\n","\n","--- Processing file: /content/uploaded_json_files/IIT Bhilai (1).json ---\n","Loaded JSON file: /content/uploaded_json_files/IIT Bhilai (1).json\n","üìä Found NIRF data with 12 points\n","üîÑ Processing 12 items for vectorization...\n","‚úÖ Generated vector for Indian Institute of Technology Bhilai - HEADER (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Technology Bhilai - SANCTIONED_INTAKE (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Technology Bhilai - STUDENT_STRENGTH (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Technology Bhilai - PLACEMENT_STUDIES (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Technology Bhilai - PHD_DETAILS (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Technology Bhilai - FINANCIAL_RESOURCES (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Technology Bhilai - FINANCIAL_RESOURCES (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Technology Bhilai - SPONSORED_RESEARCH (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Technology Bhilai - CONSULTANCY_PROJECTS (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Technology Bhilai - PCS_FACILITIES (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Technology Bhilai - FACULTY_DETAILS (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Technology Bhilai - students_strength (dim: 384)\n","‚úÖ Successfully processed 12 points\n","Uploading 12 points in batches of 100\n","Uploaded batch 1/1: 12 points\n","Successfully uploaded 12 points from /content/uploaded_json_files/IIT Bhilai (1).json\n","\n","--- Processing file: /content/uploaded_json_files/Jain University_ Bangalore (1).json ---\n","Loaded JSON file: /content/uploaded_json_files/Jain University_ Bangalore (1).json\n","üìä Found NIRF data with 12 points\n","üîÑ Processing 12 items for vectorization...\n","‚úÖ Generated vector for Jain University, Bangalore - HEADER (dim: 384)\n","‚úÖ Generated vector for Jain University, Bangalore - SANCTIONED_INTAKE (dim: 384)\n","‚úÖ Generated vector for Jain University, Bangalore - STUDENT_STRENGTH (dim: 384)\n","‚úÖ Generated vector for Jain University, Bangalore - PLACEMENT_STUDIES (dim: 384)\n","‚úÖ Generated vector for Jain University, Bangalore - PHD_DETAILS (dim: 384)\n","‚úÖ Generated vector for Jain University, Bangalore - FINANCIAL_RESOURCES (dim: 384)\n","‚úÖ Generated vector for Jain University, Bangalore - FINANCIAL_RESOURCES (dim: 384)\n","‚úÖ Generated vector for Jain University, Bangalore - SPONSORED_RESEARCH (dim: 384)\n","‚úÖ Generated vector for Jain University, Bangalore - CONSULTANCY_PROJECTS (dim: 384)\n","‚úÖ Generated vector for Jain University, Bangalore - PCS_FACILITIES (dim: 384)\n","‚úÖ Generated vector for Jain University, Bangalore - FACULTY_DETAILS (dim: 384)\n","‚úÖ Generated vector for Jain University, Bangalore - students_strength (dim: 384)\n","‚úÖ Successfully processed 12 points\n","Uploading 12 points in batches of 100\n","Uploaded batch 1/1: 12 points\n","Successfully uploaded 12 points from /content/uploaded_json_files/Jain University_ Bangalore (1).json\n","\n","--- Processing file: /content/uploaded_json_files/IIT Jammu (1).json ---\n","Loaded JSON file: /content/uploaded_json_files/IIT Jammu (1).json\n","üìä Found NIRF data with 12 points\n","üîÑ Processing 12 items for vectorization...\n","‚úÖ Generated vector for Indian Institute of Technology Jammu - HEADER (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Technology Jammu - SANCTIONED_INTAKE (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Technology Jammu - STUDENT_STRENGTH (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Technology Jammu - PLACEMENT_STUDIES (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Technology Jammu - PHD_DETAILS (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Technology Jammu - FINANCIAL_RESOURCES (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Technology Jammu - FINANCIAL_RESOURCES (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Technology Jammu - SPONSORED_RESEARCH (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Technology Jammu - CONSULTANCY_PROJECTS (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Technology Jammu - PCS_FACILITIES (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Technology Jammu - FACULTY_DETAILS (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Technology Jammu - students_strength (dim: 384)\n","‚úÖ Successfully processed 12 points\n","Uploading 12 points in batches of 100\n","Uploaded batch 1/1: 12 points\n","Successfully uploaded 12 points from /content/uploaded_json_files/IIT Jammu (1).json\n","\n","--- Processing file: /content/uploaded_json_files/Sri Krishna College of Engineering and Technology (1).json ---\n","Loaded JSON file: /content/uploaded_json_files/Sri Krishna College of Engineering and Technology (1).json\n","üìä Found NIRF data with 12 points\n","üîÑ Processing 12 items for vectorization...\n","‚úÖ Generated vector for Sri Krishna College of Engineering and Technology - HEADER (dim: 384)\n","‚úÖ Generated vector for Sri Krishna College of Engineering and Technology - SANCTIONED_INTAKE (dim: 384)\n","‚úÖ Generated vector for Sri Krishna College of Engineering and Technology - STUDENT_STRENGTH (dim: 384)\n","‚úÖ Generated vector for Sri Krishna College of Engineering and Technology - PLACEMENT_STUDIES (dim: 384)\n","‚úÖ Generated vector for Sri Krishna College of Engineering and Technology - PHD_DETAILS (dim: 384)\n","‚úÖ Generated vector for Sri Krishna College of Engineering and Technology - FINANCIAL_RESOURCES (dim: 384)\n","‚úÖ Generated vector for Sri Krishna College of Engineering and Technology - FINANCIAL_RESOURCES (dim: 384)\n","‚úÖ Generated vector for Sri Krishna College of Engineering and Technology - SPONSORED_RESEARCH (dim: 384)\n","‚úÖ Generated vector for Sri Krishna College of Engineering and Technology - CONSULTANCY_PROJECTS (dim: 384)\n","‚úÖ Generated vector for Sri Krishna College of Engineering and Technology - PCS_FACILITIES (dim: 384)\n","‚úÖ Generated vector for Sri Krishna College of Engineering and Technology - FACULTY_DETAILS (dim: 384)\n","‚úÖ Generated vector for Sri Krishna College of Engineering and Technology - students_strength (dim: 384)\n","‚úÖ Successfully processed 12 points\n","Uploading 12 points in batches of 100\n","Uploaded batch 1/1: 12 points\n","Successfully uploaded 12 points from /content/uploaded_json_files/Sri Krishna College of Engineering and Technology (1).json\n","\n","--- Processing file: /content/uploaded_json_files/Thapar Institute of Engineering and Technology _Deemed-to-be-university (1).json ---\n","Loaded JSON file: /content/uploaded_json_files/Thapar Institute of Engineering and Technology _Deemed-to-be-university (1).json\n","üìä Found NIRF data with 12 points\n","üîÑ Processing 12 items for vectorization...\n","‚úÖ Generated vector for Thapar Institute of Engineering and Technology (Deemed-to-be-university) - HEADER (dim: 384)\n","‚úÖ Generated vector for Thapar Institute of Engineering and Technology (Deemed-to-be-university) - SANCTIONED_INTAKE (dim: 384)\n","‚úÖ Generated vector for Thapar Institute of Engineering and Technology (Deemed-to-be-university) - STUDENT_STRENGTH (dim: 384)\n","‚úÖ Generated vector for Thapar Institute of Engineering and Technology (Deemed-to-be-university) - PLACEMENT_STUDIES (dim: 384)\n","‚úÖ Generated vector for Thapar Institute of Engineering and Technology (Deemed-to-be-university) - PHD_DETAILS (dim: 384)\n","‚úÖ Generated vector for Thapar Institute of Engineering and Technology (Deemed-to-be-university) - FINANCIAL_RESOURCES (dim: 384)\n","‚úÖ Generated vector for Thapar Institute of Engineering and Technology (Deemed-to-be-university) - FINANCIAL_RESOURCES (dim: 384)\n","‚úÖ Generated vector for Thapar Institute of Engineering and Technology (Deemed-to-be-university) - SPONSORED_RESEARCH (dim: 384)\n","‚úÖ Generated vector for Thapar Institute of Engineering and Technology (Deemed-to-be-university) - CONSULTANCY_PROJECTS (dim: 384)\n","‚úÖ Generated vector for Thapar Institute of Engineering and Technology (Deemed-to-be-university) - PCS_FACILITIES (dim: 384)\n","‚úÖ Generated vector for Thapar Institute of Engineering and Technology (Deemed-to-be-university) - FACULTY_DETAILS (dim: 384)\n","‚úÖ Generated vector for Thapar Institute of Engineering and Technology (Deemed-to-be-university) - students_strength (dim: 384)\n","‚úÖ Successfully processed 12 points\n","Uploading 12 points in batches of 100\n","Uploaded batch 1/1: 12 points\n","Successfully uploaded 12 points from /content/uploaded_json_files/Thapar Institute of Engineering and Technology _Deemed-to-be-university (1).json\n","\n","--- Processing file: /content/uploaded_json_files/IIT Delhi (1).json ---\n","Loaded JSON file: /content/uploaded_json_files/IIT Delhi (1).json\n","üìä Found NIRF data with 12 points\n","üîÑ Processing 12 items for vectorization...\n","‚úÖ Generated vector for Indian Institute of Technology Delhi - HEADER (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Technology Delhi - SANCTIONED_INTAKE (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Technology Delhi - STUDENT_STRENGTH (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Technology Delhi - PLACEMENT_STUDIES (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Technology Delhi - PHD_DETAILS (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Technology Delhi - FINANCIAL_RESOURCES (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Technology Delhi - FINANCIAL_RESOURCES (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Technology Delhi - SPONSORED_RESEARCH (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Technology Delhi - CONSULTANCY_PROJECTS (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Technology Delhi - PCS_FACILITIES (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Technology Delhi - FACULTY_DETAILS (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Technology Delhi - students_strength (dim: 384)\n","‚úÖ Successfully processed 12 points\n","Uploading 12 points in batches of 100\n","Uploaded batch 1/1: 12 points\n","Successfully uploaded 12 points from /content/uploaded_json_files/IIT Delhi (1).json\n","\n","--- Processing file: /content/uploaded_json_files/Chithara University (1).json ---\n","Loaded JSON file: /content/uploaded_json_files/Chithara University (1).json\n","üìä Found NIRF data with 12 points\n","üîÑ Processing 12 items for vectorization...\n","‚úÖ Generated vector for Chitkara University - HEADER (dim: 384)\n","‚úÖ Generated vector for Chitkara University - SANCTIONED_INTAKE (dim: 384)\n","‚úÖ Generated vector for Chitkara University - STUDENT_STRENGTH (dim: 384)\n","‚úÖ Generated vector for Chitkara University - PLACEMENT_STUDIES (dim: 384)\n","‚úÖ Generated vector for Chitkara University - PHD_DETAILS (dim: 384)\n","‚úÖ Generated vector for Chitkara University - FINANCIAL_RESOURCES (dim: 384)\n","‚úÖ Generated vector for Chitkara University - FINANCIAL_RESOURCES (dim: 384)\n","‚úÖ Generated vector for Chitkara University - SPONSORED_RESEARCH (dim: 384)\n","‚úÖ Generated vector for Chitkara University - CONSULTANCY_PROJECTS (dim: 384)\n","‚úÖ Generated vector for Chitkara University - PCS_FACILITIES (dim: 384)\n","‚úÖ Generated vector for Chitkara University - FACULTY_DETAILS (dim: 384)\n","‚úÖ Generated vector for Chitkara University - students_strength (dim: 384)\n","‚úÖ Successfully processed 12 points\n","Uploading 12 points in batches of 100\n","Uploaded batch 1/1: 12 points\n","Successfully uploaded 12 points from /content/uploaded_json_files/Chithara University (1).json\n","\n","--- Processing file: /content/uploaded_json_files/IIT Ropar (1).json ---\n","Loaded JSON file: /content/uploaded_json_files/IIT Ropar (1).json\n","üìä Found NIRF data with 13 points\n","üîÑ Processing 13 items for vectorization...\n","‚úÖ Generated vector for Indian Institute of Technology Ropar - HEADER (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Technology Ropar - SANCTIONED_INTAKE (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Technology Ropar - STUDENT_STRENGTH (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Technology Ropar - PLACEMENT_STUDIES (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Technology Ropar - PG_PLACEMENT (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Technology Ropar - PHD_DETAILS (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Technology Ropar - FINANCIAL_RESOURCES (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Technology Ropar - FINANCIAL_RESOURCES (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Technology Ropar - SPONSORED_RESEARCH (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Technology Ropar - CONSULTANCY_PROJECTS (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Technology Ropar - PCS_FACILITIES (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Technology Ropar - FACULTY_DETAILS (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Technology Ropar - students_strength (dim: 384)\n","‚úÖ Successfully processed 13 points\n","Uploading 13 points in batches of 100\n","Uploaded batch 1/1: 13 points\n","Successfully uploaded 13 points from /content/uploaded_json_files/IIT Ropar (1).json\n","\n","--- Processing file: /content/uploaded_json_files/Kalinga Institute of Industrial Technology (1).json ---\n","Loaded JSON file: /content/uploaded_json_files/Kalinga Institute of Industrial Technology (1).json\n","üìä Found NIRF data with 12 points\n","üîÑ Processing 12 items for vectorization...\n","‚úÖ Generated vector for Kalinga Institute of Industrial Technology - HEADER (dim: 384)\n","‚úÖ Generated vector for Kalinga Institute of Industrial Technology - SANCTIONED_INTAKE (dim: 384)\n","‚úÖ Generated vector for Kalinga Institute of Industrial Technology - STUDENT_STRENGTH (dim: 384)\n","‚úÖ Generated vector for Kalinga Institute of Industrial Technology - PLACEMENT_STUDIES (dim: 384)\n","‚úÖ Generated vector for Kalinga Institute of Industrial Technology - PHD_DETAILS (dim: 384)\n","‚úÖ Generated vector for Kalinga Institute of Industrial Technology - FINANCIAL_RESOURCES (dim: 384)\n","‚úÖ Generated vector for Kalinga Institute of Industrial Technology - FINANCIAL_RESOURCES (dim: 384)\n","‚úÖ Generated vector for Kalinga Institute of Industrial Technology - SPONSORED_RESEARCH (dim: 384)\n","‚úÖ Generated vector for Kalinga Institute of Industrial Technology - CONSULTANCY_PROJECTS (dim: 384)\n","‚úÖ Generated vector for Kalinga Institute of Industrial Technology - PCS_FACILITIES (dim: 384)\n","‚úÖ Generated vector for Kalinga Institute of Industrial Technology - FACULTY_DETAILS (dim: 384)\n","‚úÖ Generated vector for Kalinga Institute of Industrial Technology - students_strength (dim: 384)\n","‚úÖ Successfully processed 12 points\n","Uploading 12 points in batches of 100\n","Uploaded batch 1/1: 12 points\n","Successfully uploaded 12 points from /content/uploaded_json_files/Kalinga Institute of Industrial Technology (1).json\n","\n","--- Processing file: /content/uploaded_json_files/IIT Jodhpur (1).json ---\n","Loaded JSON file: /content/uploaded_json_files/IIT Jodhpur (1).json\n","üìä Found NIRF data with 12 points\n","üîÑ Processing 12 items for vectorization...\n","‚úÖ Generated vector for Indian Institute of Technology Jodhpur - HEADER (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Technology Jodhpur - SANCTIONED_INTAKE (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Technology Jodhpur - STUDENT_STRENGTH (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Technology Jodhpur - PLACEMENT_STUDIES (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Technology Jodhpur - PHD_DETAILS (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Technology Jodhpur - FINANCIAL_RESOURCES (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Technology Jodhpur - FINANCIAL_RESOURCES (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Technology Jodhpur - SPONSORED_RESEARCH (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Technology Jodhpur - CONSULTANCY_PROJECTS (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Technology Jodhpur - PCS_FACILITIES (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Technology Jodhpur - FACULTY_DETAILS (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Technology Jodhpur - students_strength (dim: 384)\n","‚úÖ Successfully processed 12 points\n","Uploading 12 points in batches of 100\n","Uploaded batch 1/1: 12 points\n","Successfully uploaded 12 points from /content/uploaded_json_files/IIT Jodhpur (1).json\n","\n","--- Processing file: /content/uploaded_json_files/Kalasalingam Academy of Research and Education (1).json ---\n","Loaded JSON file: /content/uploaded_json_files/Kalasalingam Academy of Research and Education (1).json\n","üìä Found NIRF data with 12 points\n","üîÑ Processing 12 items for vectorization...\n","‚úÖ Generated vector for Kalasalingam Academy of Research and Education - HEADER (dim: 384)\n","‚úÖ Generated vector for Kalasalingam Academy of Research and Education - SANCTIONED_INTAKE (dim: 384)\n","‚úÖ Generated vector for Kalasalingam Academy of Research and Education - STUDENT_STRENGTH (dim: 384)\n","‚úÖ Generated vector for Kalasalingam Academy of Research and Education - PLACEMENT_STUDIES (dim: 384)\n","‚úÖ Generated vector for Kalasalingam Academy of Research and Education - PHD_DETAILS (dim: 384)\n","‚úÖ Generated vector for Kalasalingam Academy of Research and Education - FINANCIAL_RESOURCES (dim: 384)\n","‚úÖ Generated vector for Kalasalingam Academy of Research and Education - FINANCIAL_RESOURCES (dim: 384)\n","‚úÖ Generated vector for Kalasalingam Academy of Research and Education - SPONSORED_RESEARCH (dim: 384)\n","‚úÖ Generated vector for Kalasalingam Academy of Research and Education - CONSULTANCY_PROJECTS (dim: 384)\n","‚úÖ Generated vector for Kalasalingam Academy of Research and Education - PCS_FACILITIES (dim: 384)\n","‚úÖ Generated vector for Kalasalingam Academy of Research and Education - FACULTY_DETAILS (dim: 384)\n","‚úÖ Generated vector for Kalasalingam Academy of Research and Education - students_strength (dim: 384)\n","‚úÖ Successfully processed 12 points\n","Uploading 12 points in batches of 100\n","Uploaded batch 1/1: 12 points\n","Successfully uploaded 12 points from /content/uploaded_json_files/Kalasalingam Academy of Research and Education (1).json\n","\n","--- Processing file: /content/uploaded_json_files/Dr. B R Ambedkar National Institute of Technology Jalandhar (1).json ---\n","Loaded JSON file: /content/uploaded_json_files/Dr. B R Ambedkar National Institute of Technology Jalandhar (1).json\n","üìä Found NIRF data with 12 points\n","üîÑ Processing 12 items for vectorization...\n","‚úÖ Generated vector for Dr. B R Ambedkar National Institute of Technology Jalandhar - HEADER (dim: 384)\n","‚úÖ Generated vector for Dr. B R Ambedkar National Institute of Technology Jalandhar - SANCTIONED_INTAKE (dim: 384)\n","‚úÖ Generated vector for Dr. B R Ambedkar National Institute of Technology Jalandhar - STUDENT_STRENGTH (dim: 384)\n","‚úÖ Generated vector for Dr. B R Ambedkar National Institute of Technology Jalandhar - PLACEMENT_STUDIES (dim: 384)\n","‚úÖ Generated vector for Dr. B R Ambedkar National Institute of Technology Jalandhar - PHD_DETAILS (dim: 384)\n","‚úÖ Generated vector for Dr. B R Ambedkar National Institute of Technology Jalandhar - FINANCIAL_RESOURCES (dim: 384)\n","‚úÖ Generated vector for Dr. B R Ambedkar National Institute of Technology Jalandhar - FINANCIAL_RESOURCES (dim: 384)\n","‚úÖ Generated vector for Dr. B R Ambedkar National Institute of Technology Jalandhar - SPONSORED_RESEARCH (dim: 384)\n","‚úÖ Generated vector for Dr. B R Ambedkar National Institute of Technology Jalandhar - CONSULTANCY_PROJECTS (dim: 384)\n","‚úÖ Generated vector for Dr. B R Ambedkar National Institute of Technology Jalandhar - PCS_FACILITIES (dim: 384)\n","‚úÖ Generated vector for Dr. B R Ambedkar National Institute of Technology Jalandhar - FACULTY_DETAILS (dim: 384)\n","‚úÖ Generated vector for Dr. B R Ambedkar National Institute of Technology Jalandhar - students_strength (dim: 384)\n","‚úÖ Successfully processed 12 points\n","Uploading 12 points in batches of 100\n","Uploaded batch 1/1: 12 points\n","Successfully uploaded 12 points from /content/uploaded_json_files/Dr. B R Ambedkar National Institute of Technology Jalandhar (1).json\n","\n","--- Processing file: /content/uploaded_json_files/IIT Kanpur (1).json ---\n","Loaded JSON file: /content/uploaded_json_files/IIT Kanpur (1).json\n","üìä Found NIRF data with 12 points\n","üîÑ Processing 12 items for vectorization...\n","‚úÖ Generated vector for Indian Institute of Technology Kanpur - HEADER (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Technology Kanpur - SANCTIONED_INTAKE (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Technology Kanpur - STUDENT_STRENGTH (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Technology Kanpur - PLACEMENT_STUDIES (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Technology Kanpur - PHD_DETAILS (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Technology Kanpur - FINANCIAL_RESOURCES (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Technology Kanpur - FINANCIAL_RESOURCES (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Technology Kanpur - SPONSORED_RESEARCH (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Technology Kanpur - CONSULTANCY_PROJECTS (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Technology Kanpur - PCS_FACILITIES (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Technology Kanpur - FACULTY_DETAILS (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Technology Kanpur - students_strength (dim: 384)\n","‚úÖ Successfully processed 12 points\n","Uploading 12 points in batches of 100\n","Uploaded batch 1/1: 12 points\n","Successfully uploaded 12 points from /content/uploaded_json_files/IIT Kanpur (1).json\n","\n","--- Processing file: /content/uploaded_json_files/IIT Roorkee 2024 (1).json ---\n","Loaded JSON file: /content/uploaded_json_files/IIT Roorkee 2024 (1).json\n","üìä Found NIRF data with 13 points\n","üîÑ Processing 13 items for vectorization...\n","‚úÖ Generated vector for Indian Institute of Technology Roorkee - HEADER (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Technology Roorkee - SANCTIONED_INTAKE (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Technology Roorkee - STUDENT_STRENGTH (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Technology Roorkee - PLACEMENT_STUDIES (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Technology Roorkee - PG_PLACEMENT (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Technology Roorkee - PHD_DETAILS (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Technology Roorkee - FINANCIAL_RESOURCES (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Technology Roorkee - FINANCIAL_RESOURCES (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Technology Roorkee - SPONSORED_RESEARCH (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Technology Roorkee - CONSULTANCY_PROJECTS (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Technology Roorkee - PCS_FACILITIES (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Technology Roorkee - FACULTY_DETAILS (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Technology Roorkee - students_strength (dim: 384)\n","‚úÖ Successfully processed 13 points\n","Uploading 13 points in batches of 100\n","Uploaded batch 1/1: 13 points\n","Successfully uploaded 13 points from /content/uploaded_json_files/IIT Roorkee 2024 (1).json\n","\n","--- Processing file: /content/uploaded_json_files/Manipal University_ Jaipur (1).json ---\n","Loaded JSON file: /content/uploaded_json_files/Manipal University_ Jaipur (1).json\n","üìä Found NIRF data with 12 points\n","üîÑ Processing 12 items for vectorization...\n","‚úÖ Generated vector for Manipal University, Jaipur - HEADER (dim: 384)\n","‚úÖ Generated vector for Manipal University, Jaipur - SANCTIONED_INTAKE (dim: 384)\n","‚úÖ Generated vector for Manipal University, Jaipur - STUDENT_STRENGTH (dim: 384)\n","‚úÖ Generated vector for Manipal University, Jaipur - PLACEMENT_STUDIES (dim: 384)\n","‚úÖ Generated vector for Manipal University, Jaipur - PHD_DETAILS (dim: 384)\n","‚úÖ Generated vector for Manipal University, Jaipur - FINANCIAL_RESOURCES (dim: 384)\n","‚úÖ Generated vector for Manipal University, Jaipur - FINANCIAL_RESOURCES (dim: 384)\n","‚úÖ Generated vector for Manipal University, Jaipur - SPONSORED_RESEARCH (dim: 384)\n","‚úÖ Generated vector for Manipal University, Jaipur - CONSULTANCY_PROJECTS (dim: 384)\n","‚úÖ Generated vector for Manipal University, Jaipur - PCS_FACILITIES (dim: 384)\n","‚úÖ Generated vector for Manipal University, Jaipur - FACULTY_DETAILS (dim: 384)\n","‚úÖ Generated vector for Manipal University, Jaipur - students_strength (dim: 384)\n","‚úÖ Successfully processed 12 points\n","Uploading 12 points in batches of 100\n","Uploaded batch 1/1: 12 points\n","Successfully uploaded 12 points from /content/uploaded_json_files/Manipal University_ Jaipur (1).json\n","\n","--- Processing file: /content/uploaded_json_files/IIT Bhuvaneswar (1).json ---\n","Loaded JSON file: /content/uploaded_json_files/IIT Bhuvaneswar (1).json\n","üìä Found NIRF data with 12 points\n","üîÑ Processing 12 items for vectorization...\n","‚úÖ Generated vector for Indian Institute of Technology Bhubaneswar - HEADER (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Technology Bhubaneswar - SANCTIONED_INTAKE (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Technology Bhubaneswar - STUDENT_STRENGTH (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Technology Bhubaneswar - PLACEMENT_STUDIES (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Technology Bhubaneswar - PHD_DETAILS (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Technology Bhubaneswar - FINANCIAL_RESOURCES (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Technology Bhubaneswar - FINANCIAL_RESOURCES (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Technology Bhubaneswar - SPONSORED_RESEARCH (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Technology Bhubaneswar - CONSULTANCY_PROJECTS (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Technology Bhubaneswar - PCS_FACILITIES (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Technology Bhubaneswar - FACULTY_DETAILS (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Technology Bhubaneswar - students_strength (dim: 384)\n","‚úÖ Successfully processed 12 points\n","Uploading 12 points in batches of 100\n","Uploaded batch 1/1: 12 points\n","Successfully uploaded 12 points from /content/uploaded_json_files/IIT Bhuvaneswar (1).json\n","\n","--- Processing file: /content/uploaded_json_files/IIT Guwahati (1).json ---\n","Loaded JSON file: /content/uploaded_json_files/IIT Guwahati (1).json\n","üìä Found NIRF data with 12 points\n","üîÑ Processing 12 items for vectorization...\n","‚úÖ Generated vector for Indian Institute of Technology Guwahati - HEADER (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Technology Guwahati - SANCTIONED_INTAKE (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Technology Guwahati - STUDENT_STRENGTH (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Technology Guwahati - PLACEMENT_STUDIES (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Technology Guwahati - PHD_DETAILS (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Technology Guwahati - FINANCIAL_RESOURCES (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Technology Guwahati - FINANCIAL_RESOURCES (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Technology Guwahati - SPONSORED_RESEARCH (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Technology Guwahati - CONSULTANCY_PROJECTS (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Technology Guwahati - PCS_FACILITIES (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Technology Guwahati - FACULTY_DETAILS (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Technology Guwahati - students_strength (dim: 384)\n","‚úÖ Successfully processed 12 points\n","Uploading 12 points in batches of 100\n","Uploaded batch 1/1: 12 points\n","Successfully uploaded 12 points from /content/uploaded_json_files/IIT Guwahati (1).json\n","\n","--- Processing file: /content/uploaded_json_files/NIT Delhi (1).json ---\n","Loaded JSON file: /content/uploaded_json_files/NIT Delhi (1).json\n","üìä Found NIRF data with 12 points\n","üîÑ Processing 12 items for vectorization...\n","‚úÖ Generated vector for National Institute of Technology Delhi - HEADER (dim: 384)\n","‚úÖ Generated vector for National Institute of Technology Delhi - SANCTIONED_INTAKE (dim: 384)\n","‚úÖ Generated vector for National Institute of Technology Delhi - STUDENT_STRENGTH (dim: 384)\n","‚úÖ Generated vector for National Institute of Technology Delhi - PLACEMENT_STUDIES (dim: 384)\n","‚úÖ Generated vector for National Institute of Technology Delhi - PHD_DETAILS (dim: 384)\n","‚úÖ Generated vector for National Institute of Technology Delhi - FINANCIAL_RESOURCES (dim: 384)\n","‚úÖ Generated vector for National Institute of Technology Delhi - FINANCIAL_RESOURCES (dim: 384)\n","‚úÖ Generated vector for National Institute of Technology Delhi - SPONSORED_RESEARCH (dim: 384)\n","‚úÖ Generated vector for National Institute of Technology Delhi - CONSULTANCY_PROJECTS (dim: 384)\n","‚úÖ Generated vector for National Institute of Technology Delhi - PCS_FACILITIES (dim: 384)\n","‚úÖ Generated vector for National Institute of Technology Delhi - FACULTY_DETAILS (dim: 384)\n","‚úÖ Generated vector for National Institute of Technology Delhi - students_strength (dim: 384)\n","‚úÖ Successfully processed 12 points\n","Uploading 12 points in batches of 100\n","Uploaded batch 1/1: 12 points\n","Successfully uploaded 12 points from /content/uploaded_json_files/NIT Delhi (1).json\n","\n","--- Processing file: /content/uploaded_json_files/IIT Palakkad (1).json ---\n","Loaded JSON file: /content/uploaded_json_files/IIT Palakkad (1).json\n","üìä Found NIRF data with 12 points\n","üîÑ Processing 12 items for vectorization...\n","‚úÖ Generated vector for Indian Institute of Technology Palakkad - HEADER (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Technology Palakkad - SANCTIONED_INTAKE (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Technology Palakkad - STUDENT_STRENGTH (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Technology Palakkad - PLACEMENT_STUDIES (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Technology Palakkad - PHD_DETAILS (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Technology Palakkad - FINANCIAL_RESOURCES (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Technology Palakkad - FINANCIAL_RESOURCES (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Technology Palakkad - SPONSORED_RESEARCH (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Technology Palakkad - CONSULTANCY_PROJECTS (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Technology Palakkad - PCS_FACILITIES (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Technology Palakkad - FACULTY_DETAILS (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Technology Palakkad - students_strength (dim: 384)\n","‚úÖ Successfully processed 12 points\n","Uploading 12 points in batches of 100\n","Uploaded batch 1/1: 12 points\n","Successfully uploaded 12 points from /content/uploaded_json_files/IIT Palakkad (1).json\n","\n","--- Processing file: /content/uploaded_json_files/Delhi Technological University (1).json ---\n","Loaded JSON file: /content/uploaded_json_files/Delhi Technological University (1).json\n","üìä Found NIRF data with 12 points\n","üîÑ Processing 12 items for vectorization...\n","‚úÖ Generated vector for Delhi Technological University - HEADER (dim: 384)\n","‚úÖ Generated vector for Delhi Technological University - SANCTIONED_INTAKE (dim: 384)\n","‚úÖ Generated vector for Delhi Technological University - STUDENT_STRENGTH (dim: 384)\n","‚úÖ Generated vector for Delhi Technological University - PLACEMENT_STUDIES (dim: 384)\n","‚úÖ Generated vector for Delhi Technological University - PHD_DETAILS (dim: 384)\n","‚úÖ Generated vector for Delhi Technological University - FINANCIAL_RESOURCES (dim: 384)\n","‚úÖ Generated vector for Delhi Technological University - FINANCIAL_RESOURCES (dim: 384)\n","‚úÖ Generated vector for Delhi Technological University - SPONSORED_RESEARCH (dim: 384)\n","‚úÖ Generated vector for Delhi Technological University - CONSULTANCY_PROJECTS (dim: 384)\n","‚úÖ Generated vector for Delhi Technological University - PCS_FACILITIES (dim: 384)\n","‚úÖ Generated vector for Delhi Technological University - FACULTY_DETAILS (dim: 384)\n","‚úÖ Generated vector for Delhi Technological University - students_strength (dim: 384)\n","‚úÖ Successfully processed 12 points\n","Uploading 12 points in batches of 100\n","Uploaded batch 1/1: 12 points\n","Successfully uploaded 12 points from /content/uploaded_json_files/Delhi Technological University (1).json\n","\n","--- Processing file: /content/uploaded_json_files/PSG College of Technology (1).json ---\n","Loaded JSON file: /content/uploaded_json_files/PSG College of Technology (1).json\n","üìä Found NIRF data with 12 points\n","üîÑ Processing 12 items for vectorization...\n","‚úÖ Generated vector for PSG College of Technology - HEADER (dim: 384)\n","‚úÖ Generated vector for PSG College of Technology - SANCTIONED_INTAKE (dim: 384)\n","‚úÖ Generated vector for PSG College of Technology - STUDENT_STRENGTH (dim: 384)\n","‚úÖ Generated vector for PSG College of Technology - PLACEMENT_STUDIES (dim: 384)\n","‚úÖ Generated vector for PSG College of Technology - PHD_DETAILS (dim: 384)\n","‚úÖ Generated vector for PSG College of Technology - FINANCIAL_RESOURCES (dim: 384)\n","‚úÖ Generated vector for PSG College of Technology - FINANCIAL_RESOURCES (dim: 384)\n","‚úÖ Generated vector for PSG College of Technology - SPONSORED_RESEARCH (dim: 384)\n","‚úÖ Generated vector for PSG College of Technology - CONSULTANCY_PROJECTS (dim: 384)\n","‚úÖ Generated vector for PSG College of Technology - PCS_FACILITIES (dim: 384)\n","‚úÖ Generated vector for PSG College of Technology - FACULTY_DETAILS (dim: 384)\n","‚úÖ Generated vector for PSG College of Technology - students_strength (dim: 384)\n","‚úÖ Successfully processed 12 points\n","Uploading 12 points in batches of 100\n","Uploaded batch 1/1: 12 points\n","Successfully uploaded 12 points from /content/uploaded_json_files/PSG College of Technology (1).json\n","\n","--- Processing file: /content/uploaded_json_files/Saveetha Institute of Medical and Technical Sciences (1).json ---\n","Loaded JSON file: /content/uploaded_json_files/Saveetha Institute of Medical and Technical Sciences (1).json\n","üìä Found NIRF data with 12 points\n","üîÑ Processing 12 items for vectorization...\n","‚úÖ Generated vector for Saveetha Institute of Medical and Technical Sciences - HEADER (dim: 384)\n","‚úÖ Generated vector for Saveetha Institute of Medical and Technical Sciences - SANCTIONED_INTAKE (dim: 384)\n","‚úÖ Generated vector for Saveetha Institute of Medical and Technical Sciences - STUDENT_STRENGTH (dim: 384)\n","‚úÖ Generated vector for Saveetha Institute of Medical and Technical Sciences - PLACEMENT_STUDIES (dim: 384)\n","‚úÖ Generated vector for Saveetha Institute of Medical and Technical Sciences - PHD_DETAILS (dim: 384)\n","‚úÖ Generated vector for Saveetha Institute of Medical and Technical Sciences - FINANCIAL_RESOURCES (dim: 384)\n","‚úÖ Generated vector for Saveetha Institute of Medical and Technical Sciences - FINANCIAL_RESOURCES (dim: 384)\n","‚úÖ Generated vector for Saveetha Institute of Medical and Technical Sciences - SPONSORED_RESEARCH (dim: 384)\n","‚úÖ Generated vector for Saveetha Institute of Medical and Technical Sciences - CONSULTANCY_PROJECTS (dim: 384)\n","‚úÖ Generated vector for Saveetha Institute of Medical and Technical Sciences - PCS_FACILITIES (dim: 384)\n","‚úÖ Generated vector for Saveetha Institute of Medical and Technical Sciences - FACULTY_DETAILS (dim: 384)\n","‚úÖ Generated vector for Saveetha Institute of Medical and Technical Sciences - students_strength (dim: 384)\n","‚úÖ Successfully processed 12 points\n","Uploading 12 points in batches of 100\n","Uploaded batch 1/1: 12 points\n","Successfully uploaded 12 points from /content/uploaded_json_files/Saveetha Institute of Medical and Technical Sciences (1).json\n","\n","--- Processing file: /content/uploaded_json_files/C.V. Raman Global University_ Odisha (1).json ---\n","Loaded JSON file: /content/uploaded_json_files/C.V. Raman Global University_ Odisha (1).json\n","üìä Found NIRF data with 12 points\n","üîÑ Processing 12 items for vectorization...\n","‚úÖ Generated vector for C.V. Raman Global University, Odisha - HEADER (dim: 384)\n","‚úÖ Generated vector for C.V. Raman Global University, Odisha - SANCTIONED_INTAKE (dim: 384)\n","‚úÖ Generated vector for C.V. Raman Global University, Odisha - STUDENT_STRENGTH (dim: 384)\n","‚úÖ Generated vector for C.V. Raman Global University, Odisha - PLACEMENT_STUDIES (dim: 384)\n","‚úÖ Generated vector for C.V. Raman Global University, Odisha - PHD_DETAILS (dim: 384)\n","‚úÖ Generated vector for C.V. Raman Global University, Odisha - FINANCIAL_RESOURCES (dim: 384)\n","‚úÖ Generated vector for C.V. Raman Global University, Odisha - FINANCIAL_RESOURCES (dim: 384)\n","‚úÖ Generated vector for C.V. Raman Global University, Odisha - SPONSORED_RESEARCH (dim: 384)\n","‚úÖ Generated vector for C.V. Raman Global University, Odisha - CONSULTANCY_PROJECTS (dim: 384)\n","‚úÖ Generated vector for C.V. Raman Global University, Odisha - PCS_FACILITIES (dim: 384)\n","‚úÖ Generated vector for C.V. Raman Global University, Odisha - FACULTY_DETAILS (dim: 384)\n","‚úÖ Generated vector for C.V. Raman Global University, Odisha - students_strength (dim: 384)\n","‚úÖ Successfully processed 12 points\n","Uploading 12 points in batches of 100\n","Uploaded batch 1/1: 12 points\n","Successfully uploaded 12 points from /content/uploaded_json_files/C.V. Raman Global University_ Odisha (1).json\n","\n","--- Processing file: /content/uploaded_json_files/Engineering  2024 (1).json ---\n","Loaded JSON file: /content/uploaded_json_files/Engineering  2024 (1).json\n","üìä Found NIRF data with 12 points\n","üîÑ Processing 12 items for vectorization...\n","‚úÖ Generated vector for Graphic Era University - HEADER (dim: 384)\n","‚úÖ Generated vector for Graphic Era University - SANCTIONED_INTAKE (dim: 384)\n","‚úÖ Generated vector for Graphic Era University - STUDENT_STRENGTH (dim: 384)\n","‚úÖ Generated vector for Graphic Era University - PLACEMENT_STUDIES (dim: 384)\n","‚úÖ Generated vector for Graphic Era University - PHD_DETAILS (dim: 384)\n","‚úÖ Generated vector for Graphic Era University - FINANCIAL_RESOURCES (dim: 384)\n","‚úÖ Generated vector for Graphic Era University - FINANCIAL_RESOURCES (dim: 384)\n","‚úÖ Generated vector for Graphic Era University - SPONSORED_RESEARCH (dim: 384)\n","‚úÖ Generated vector for Graphic Era University - CONSULTANCY_PROJECTS (dim: 384)\n","‚úÖ Generated vector for Graphic Era University - PCS_FACILITIES (dim: 384)\n","‚úÖ Generated vector for Graphic Era University - FACULTY_DETAILS (dim: 384)\n","‚úÖ Generated vector for Graphic Era University - students_strength (dim: 384)\n","‚úÖ Successfully processed 12 points\n","Uploading 12 points in batches of 100\n","Uploaded batch 1/1: 12 points\n","Successfully uploaded 12 points from /content/uploaded_json_files/Engineering  2024 (1).json\n","\n","--- Processing file: /content/uploaded_json_files/IIIT Hyderabad  (1).json ---\n","Loaded JSON file: /content/uploaded_json_files/IIIT Hyderabad  (1).json\n","üìä Found NIRF data with 12 points\n","üîÑ Processing 12 items for vectorization...\n","‚úÖ Generated vector for International Institute of Information Technology Hyderabad - HEADER (dim: 384)\n","‚úÖ Generated vector for International Institute of Information Technology Hyderabad - SANCTIONED_INTAKE (dim: 384)\n","‚úÖ Generated vector for International Institute of Information Technology Hyderabad - STUDENT_STRENGTH (dim: 384)\n","‚úÖ Generated vector for International Institute of Information Technology Hyderabad - PLACEMENT_STUDIES (dim: 384)\n","‚úÖ Generated vector for International Institute of Information Technology Hyderabad - PHD_DETAILS (dim: 384)\n","‚úÖ Generated vector for International Institute of Information Technology Hyderabad - FINANCIAL_RESOURCES (dim: 384)\n","‚úÖ Generated vector for International Institute of Information Technology Hyderabad - FINANCIAL_RESOURCES (dim: 384)\n","‚úÖ Generated vector for International Institute of Information Technology Hyderabad - SPONSORED_RESEARCH (dim: 384)\n","‚úÖ Generated vector for International Institute of Information Technology Hyderabad - CONSULTANCY_PROJECTS (dim: 384)\n","‚úÖ Generated vector for International Institute of Information Technology Hyderabad - PCS_FACILITIES (dim: 384)\n","‚úÖ Generated vector for International Institute of Information Technology Hyderabad - FACULTY_DETAILS (dim: 384)\n","‚úÖ Generated vector for International Institute of Information Technology Hyderabad - students_strength (dim: 384)\n","‚úÖ Successfully processed 12 points\n","Uploading 12 points in batches of 100\n","Uploaded batch 1/1: 12 points\n","Successfully uploaded 12 points from /content/uploaded_json_files/IIIT Hyderabad  (1).json\n","\n","--- Processing file: /content/uploaded_json_files/NIT Surathkal (1).json ---\n","Loaded JSON file: /content/uploaded_json_files/NIT Surathkal (1).json\n","üìä Found NIRF data with 12 points\n","üîÑ Processing 12 items for vectorization...\n","‚úÖ Generated vector for National Institute of Technology Karnataka, Surathkal - HEADER (dim: 384)\n","‚úÖ Generated vector for National Institute of Technology Karnataka, Surathkal - SANCTIONED_INTAKE (dim: 384)\n","‚úÖ Generated vector for National Institute of Technology Karnataka, Surathkal - STUDENT_STRENGTH (dim: 384)\n","‚úÖ Generated vector for National Institute of Technology Karnataka, Surathkal - PLACEMENT_STUDIES (dim: 384)\n","‚úÖ Generated vector for National Institute of Technology Karnataka, Surathkal - PHD_DETAILS (dim: 384)\n","‚úÖ Generated vector for National Institute of Technology Karnataka, Surathkal - FINANCIAL_RESOURCES (dim: 384)\n","‚úÖ Generated vector for National Institute of Technology Karnataka, Surathkal - FINANCIAL_RESOURCES (dim: 384)\n","‚úÖ Generated vector for National Institute of Technology Karnataka, Surathkal - SPONSORED_RESEARCH (dim: 384)\n","‚úÖ Generated vector for National Institute of Technology Karnataka, Surathkal - CONSULTANCY_PROJECTS (dim: 384)\n","‚úÖ Generated vector for National Institute of Technology Karnataka, Surathkal - PCS_FACILITIES (dim: 384)\n","‚úÖ Generated vector for National Institute of Technology Karnataka, Surathkal - FACULTY_DETAILS (dim: 384)\n","‚úÖ Generated vector for National Institute of Technology Karnataka, Surathkal - students_strength (dim: 384)\n","‚úÖ Successfully processed 12 points\n","Uploading 12 points in batches of 100\n","Uploaded batch 1/1: 12 points\n","Successfully uploaded 12 points from /content/uploaded_json_files/NIT Surathkal (1).json\n","\n","--- Processing file: /content/uploaded_json_files/IIT Indore (1).json ---\n","Loaded JSON file: /content/uploaded_json_files/IIT Indore (1).json\n","üìä Found NIRF data with 12 points\n","üîÑ Processing 12 items for vectorization...\n","‚úÖ Generated vector for Indian Institute of Technology Indore - HEADER (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Technology Indore - SANCTIONED_INTAKE (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Technology Indore - STUDENT_STRENGTH (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Technology Indore - PLACEMENT_STUDIES (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Technology Indore - PHD_DETAILS (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Technology Indore - FINANCIAL_RESOURCES (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Technology Indore - FINANCIAL_RESOURCES (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Technology Indore - SPONSORED_RESEARCH (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Technology Indore - CONSULTANCY_PROJECTS (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Technology Indore - PCS_FACILITIES (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Technology Indore - FACULTY_DETAILS (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Technology Indore - students_strength (dim: 384)\n","‚úÖ Successfully processed 12 points\n","Uploading 12 points in batches of 100\n","Uploaded batch 1/1: 12 points\n","Successfully uploaded 12 points from /content/uploaded_json_files/IIT Indore (1).json\n","\n","--- Processing file: /content/uploaded_json_files/Sri Sivasubramaniya Nadar College of Engineering (1).json ---\n","Loaded JSON file: /content/uploaded_json_files/Sri Sivasubramaniya Nadar College of Engineering (1).json\n","üìä Found NIRF data with 12 points\n","üîÑ Processing 12 items for vectorization...\n","‚úÖ Generated vector for Sri Sivasubramaniya Nadar College of Engineering - HEADER (dim: 384)\n","‚úÖ Generated vector for Sri Sivasubramaniya Nadar College of Engineering - SANCTIONED_INTAKE (dim: 384)\n","‚úÖ Generated vector for Sri Sivasubramaniya Nadar College of Engineering - STUDENT_STRENGTH (dim: 384)\n","‚úÖ Generated vector for Sri Sivasubramaniya Nadar College of Engineering - PLACEMENT_STUDIES (dim: 384)\n","‚úÖ Generated vector for Sri Sivasubramaniya Nadar College of Engineering - PHD_DETAILS (dim: 384)\n","‚úÖ Generated vector for Sri Sivasubramaniya Nadar College of Engineering - FINANCIAL_RESOURCES (dim: 384)\n","‚úÖ Generated vector for Sri Sivasubramaniya Nadar College of Engineering - FINANCIAL_RESOURCES (dim: 384)\n","‚úÖ Generated vector for Sri Sivasubramaniya Nadar College of Engineering - SPONSORED_RESEARCH (dim: 384)\n","‚úÖ Generated vector for Sri Sivasubramaniya Nadar College of Engineering - CONSULTANCY_PROJECTS (dim: 384)\n","‚úÖ Generated vector for Sri Sivasubramaniya Nadar College of Engineering - PCS_FACILITIES (dim: 384)\n","‚úÖ Generated vector for Sri Sivasubramaniya Nadar College of Engineering - FACULTY_DETAILS (dim: 384)\n","‚úÖ Generated vector for Sri Sivasubramaniya Nadar College of Engineering - students_strength (dim: 384)\n","‚úÖ Successfully processed 12 points\n","Uploading 12 points in batches of 100\n","Uploaded batch 1/1: 12 points\n","Successfully uploaded 12 points from /content/uploaded_json_files/Sri Sivasubramaniya Nadar College of Engineering (1).json\n","\n","--- Processing file: /content/uploaded_json_files/Maulana Azad National Institute of Technology (1).json ---\n","Loaded JSON file: /content/uploaded_json_files/Maulana Azad National Institute of Technology (1).json\n","üìä Found NIRF data with 13 points\n","üîÑ Processing 13 items for vectorization...\n","‚úÖ Generated vector for Maulana Azad National Institute of Technology - HEADER (dim: 384)\n","‚úÖ Generated vector for Maulana Azad National Institute of Technology - SANCTIONED_INTAKE (dim: 384)\n","‚úÖ Generated vector for Maulana Azad National Institute of Technology - STUDENT_STRENGTH (dim: 384)\n","‚úÖ Generated vector for Maulana Azad National Institute of Technology - PLACEMENT_STUDIES (dim: 384)\n","‚úÖ Generated vector for Maulana Azad National Institute of Technology - PG_PLACEMENT (dim: 384)\n","‚úÖ Generated vector for Maulana Azad National Institute of Technology - PHD_DETAILS (dim: 384)\n","‚úÖ Generated vector for Maulana Azad National Institute of Technology - FINANCIAL_RESOURCES (dim: 384)\n","‚úÖ Generated vector for Maulana Azad National Institute of Technology - FINANCIAL_RESOURCES (dim: 384)\n","‚úÖ Generated vector for Maulana Azad National Institute of Technology - SPONSORED_RESEARCH (dim: 384)\n","‚úÖ Generated vector for Maulana Azad National Institute of Technology - CONSULTANCY_PROJECTS (dim: 384)\n","‚úÖ Generated vector for Maulana Azad National Institute of Technology - PCS_FACILITIES (dim: 384)\n","‚úÖ Generated vector for Maulana Azad National Institute of Technology - FACULTY_DETAILS (dim: 384)\n","‚úÖ Generated vector for Maulana Azad National Institute of Technology - students_strength (dim: 384)\n","‚úÖ Successfully processed 13 points\n","Uploading 13 points in batches of 100\n","Uploaded batch 1/1: 13 points\n","Successfully uploaded 13 points from /content/uploaded_json_files/Maulana Azad National Institute of Technology (1).json\n","\n","--- Processing file: /content/uploaded_json_files/Rajiv Gandhi Institute of Petroleum Technology (1).json ---\n","Loaded JSON file: /content/uploaded_json_files/Rajiv Gandhi Institute of Petroleum Technology (1).json\n","üìä Found NIRF data with 12 points\n","üîÑ Processing 12 items for vectorization...\n","‚úÖ Generated vector for Rajiv Gandhi Institute of Petroleum Technology - HEADER (dim: 384)\n","‚úÖ Generated vector for Rajiv Gandhi Institute of Petroleum Technology - SANCTIONED_INTAKE (dim: 384)\n","‚úÖ Generated vector for Rajiv Gandhi Institute of Petroleum Technology - STUDENT_STRENGTH (dim: 384)\n","‚úÖ Generated vector for Rajiv Gandhi Institute of Petroleum Technology - PLACEMENT_STUDIES (dim: 384)\n","‚úÖ Generated vector for Rajiv Gandhi Institute of Petroleum Technology - PHD_DETAILS (dim: 384)\n","‚úÖ Generated vector for Rajiv Gandhi Institute of Petroleum Technology - FINANCIAL_RESOURCES (dim: 384)\n","‚úÖ Generated vector for Rajiv Gandhi Institute of Petroleum Technology - FINANCIAL_RESOURCES (dim: 384)\n","‚úÖ Generated vector for Rajiv Gandhi Institute of Petroleum Technology - SPONSORED_RESEARCH (dim: 384)\n","‚úÖ Generated vector for Rajiv Gandhi Institute of Petroleum Technology - CONSULTANCY_PROJECTS (dim: 384)\n","‚úÖ Generated vector for Rajiv Gandhi Institute of Petroleum Technology - PCS_FACILITIES (dim: 384)\n","‚úÖ Generated vector for Rajiv Gandhi Institute of Petroleum Technology - FACULTY_DETAILS (dim: 384)\n","‚úÖ Generated vector for Rajiv Gandhi Institute of Petroleum Technology - students_strength (dim: 384)\n","‚úÖ Successfully processed 12 points\n","Uploading 12 points in batches of 100\n","Uploaded batch 1/1: 12 points\n","Successfully uploaded 12 points from /content/uploaded_json_files/Rajiv Gandhi Institute of Petroleum Technology (1).json\n","\n","--- Processing file: /content/uploaded_json_files/Vel Tech Rangarajan Dr. Sagunthala R _ D Institute of Science and Technology (1).json ---\n","Loaded JSON file: /content/uploaded_json_files/Vel Tech Rangarajan Dr. Sagunthala R _ D Institute of Science and Technology (1).json\n","üìä Found NIRF data with 12 points\n","üîÑ Processing 12 items for vectorization...\n","‚úÖ Generated vector for Vel Tech Rangarajan Dr. Sagunthala R & D Institute of Science and Technology - HEADER (dim: 384)\n","‚úÖ Generated vector for Vel Tech Rangarajan Dr. Sagunthala R & D Institute of Science and Technology - SANCTIONED_INTAKE (dim: 384)\n","‚úÖ Generated vector for Vel Tech Rangarajan Dr. Sagunthala R & D Institute of Science and Technology - STUDENT_STRENGTH (dim: 384)\n","‚úÖ Generated vector for Vel Tech Rangarajan Dr. Sagunthala R & D Institute of Science and Technology - PLACEMENT_STUDIES (dim: 384)\n","‚úÖ Generated vector for Vel Tech Rangarajan Dr. Sagunthala R & D Institute of Science and Technology - PHD_DETAILS (dim: 384)\n","‚úÖ Generated vector for Vel Tech Rangarajan Dr. Sagunthala R & D Institute of Science and Technology - FINANCIAL_RESOURCES (dim: 384)\n","‚úÖ Generated vector for Vel Tech Rangarajan Dr. Sagunthala R & D Institute of Science and Technology - FINANCIAL_RESOURCES (dim: 384)\n","‚úÖ Generated vector for Vel Tech Rangarajan Dr. Sagunthala R & D Institute of Science and Technology - SPONSORED_RESEARCH (dim: 384)\n","‚úÖ Generated vector for Vel Tech Rangarajan Dr. Sagunthala R & D Institute of Science and Technology - CONSULTANCY_PROJECTS (dim: 384)\n","‚úÖ Generated vector for Vel Tech Rangarajan Dr. Sagunthala R & D Institute of Science and Technology - PCS_FACILITIES (dim: 384)\n","‚úÖ Generated vector for Vel Tech Rangarajan Dr. Sagunthala R & D Institute of Science and Technology - FACULTY_DETAILS (dim: 384)\n","‚úÖ Generated vector for Vel Tech Rangarajan Dr. Sagunthala R & D Institute of Science and Technology - students_strength (dim: 384)\n","‚úÖ Successfully processed 12 points\n","Uploading 12 points in batches of 100\n","Uploaded batch 1/1: 12 points\n","Successfully uploaded 12 points from /content/uploaded_json_files/Vel Tech Rangarajan Dr. Sagunthala R _ D Institute of Science and Technology (1).json\n","\n","--- Processing file: /content/uploaded_json_files/International Institute of Information Technology Bangalore (1).json ---\n","Loaded JSON file: /content/uploaded_json_files/International Institute of Information Technology Bangalore (1).json\n","üìä Found NIRF data with 13 points\n","üîÑ Processing 13 items for vectorization...\n","‚úÖ Generated vector for International Institute of Information Technology Bangalore - HEADER (dim: 384)\n","‚úÖ Generated vector for International Institute of Information Technology Bangalore - SANCTIONED_INTAKE (dim: 384)\n","‚úÖ Generated vector for International Institute of Information Technology Bangalore - STUDENT_STRENGTH (dim: 384)\n","‚úÖ Generated vector for International Institute of Information Technology Bangalore - PLACEMENT_STUDIES (dim: 384)\n","‚úÖ Generated vector for International Institute of Information Technology Bangalore - PG_PLACEMENT (dim: 384)\n","‚úÖ Generated vector for International Institute of Information Technology Bangalore - PHD_DETAILS (dim: 384)\n","‚úÖ Generated vector for International Institute of Information Technology Bangalore - FINANCIAL_RESOURCES (dim: 384)\n","‚úÖ Generated vector for International Institute of Information Technology Bangalore - FINANCIAL_RESOURCES (dim: 384)\n","‚úÖ Generated vector for International Institute of Information Technology Bangalore - SPONSORED_RESEARCH (dim: 384)\n","‚úÖ Generated vector for International Institute of Information Technology Bangalore - CONSULTANCY_PROJECTS (dim: 384)\n","‚úÖ Generated vector for International Institute of Information Technology Bangalore - PCS_FACILITIES (dim: 384)\n","‚úÖ Generated vector for International Institute of Information Technology Bangalore - FACULTY_DETAILS (dim: 384)\n","‚úÖ Generated vector for International Institute of Information Technology Bangalore - students_strength (dim: 384)\n","‚úÖ Successfully processed 13 points\n","Uploading 13 points in batches of 100\n","Uploaded batch 1/1: 13 points\n","Successfully uploaded 13 points from /content/uploaded_json_files/International Institute of Information Technology Bangalore (1).json\n","\n","--- Processing file: /content/uploaded_json_files/COEP Technological University (1).json ---\n","Loaded JSON file: /content/uploaded_json_files/COEP Technological University (1).json\n","üìä Found NIRF data with 12 points\n","üîÑ Processing 12 items for vectorization...\n","‚úÖ Generated vector for COEP Technological University - HEADER (dim: 384)\n","‚úÖ Generated vector for COEP Technological University - SANCTIONED_INTAKE (dim: 384)\n","‚úÖ Generated vector for COEP Technological University - STUDENT_STRENGTH (dim: 384)\n","‚úÖ Generated vector for COEP Technological University - PLACEMENT_STUDIES (dim: 384)\n","‚úÖ Generated vector for COEP Technological University - PHD_DETAILS (dim: 384)\n","‚úÖ Generated vector for COEP Technological University - FINANCIAL_RESOURCES (dim: 384)\n","‚úÖ Generated vector for COEP Technological University - FINANCIAL_RESOURCES (dim: 384)\n","‚úÖ Generated vector for COEP Technological University - SPONSORED_RESEARCH (dim: 384)\n","‚úÖ Generated vector for COEP Technological University - CONSULTANCY_PROJECTS (dim: 384)\n","‚úÖ Generated vector for COEP Technological University - PCS_FACILITIES (dim: 384)\n","‚úÖ Generated vector for COEP Technological University - FACULTY_DETAILS (dim: 384)\n","‚úÖ Generated vector for COEP Technological University - students_strength (dim: 384)\n","‚úÖ Successfully processed 12 points\n","Uploading 12 points in batches of 100\n","Uploaded batch 1/1: 12 points\n","Successfully uploaded 12 points from /content/uploaded_json_files/COEP Technological University (1).json\n","\n","--- Processing file: /content/uploaded_json_files/Visvesvaraya Technological University (1).json ---\n","Loaded JSON file: /content/uploaded_json_files/Visvesvaraya Technological University (1).json\n","üìä Found NIRF data with 12 points\n","üîÑ Processing 12 items for vectorization...\n","‚úÖ Generated vector for Visvesvaraya Technological University - HEADER (dim: 384)\n","‚úÖ Generated vector for Visvesvaraya Technological University - SANCTIONED_INTAKE (dim: 384)\n","‚úÖ Generated vector for Visvesvaraya Technological University - STUDENT_STRENGTH (dim: 384)\n","‚úÖ Generated vector for Visvesvaraya Technological University - PLACEMENT_STUDIES (dim: 384)\n","‚úÖ Generated vector for Visvesvaraya Technological University - PHD_DETAILS (dim: 384)\n","‚úÖ Generated vector for Visvesvaraya Technological University - FINANCIAL_RESOURCES (dim: 384)\n","‚úÖ Generated vector for Visvesvaraya Technological University - FINANCIAL_RESOURCES (dim: 384)\n","‚úÖ Generated vector for Visvesvaraya Technological University - SPONSORED_RESEARCH (dim: 384)\n","‚úÖ Generated vector for Visvesvaraya Technological University - CONSULTANCY_PROJECTS (dim: 384)\n","‚úÖ Generated vector for Visvesvaraya Technological University - PCS_FACILITIES (dim: 384)\n","‚úÖ Generated vector for Visvesvaraya Technological University - FACULTY_DETAILS (dim: 384)\n","‚úÖ Generated vector for Visvesvaraya Technological University - students_strength (dim: 384)\n","‚úÖ Successfully processed 12 points\n","Uploading 12 points in batches of 100\n","Uploaded batch 1/1: 12 points\n","Successfully uploaded 12 points from /content/uploaded_json_files/Visvesvaraya Technological University (1).json\n","\n","--- Processing file: /content/uploaded_json_files/Sant Longowal Institute of Engineering and Technology (1).json ---\n","Loaded JSON file: /content/uploaded_json_files/Sant Longowal Institute of Engineering and Technology (1).json\n","üìä Found NIRF data with 12 points\n","üîÑ Processing 12 items for vectorization...\n","‚úÖ Generated vector for Sant Longowal Institute of Engineering and Technology - HEADER (dim: 384)\n","‚úÖ Generated vector for Sant Longowal Institute of Engineering and Technology - SANCTIONED_INTAKE (dim: 384)\n","‚úÖ Generated vector for Sant Longowal Institute of Engineering and Technology - STUDENT_STRENGTH (dim: 384)\n","‚úÖ Generated vector for Sant Longowal Institute of Engineering and Technology - PLACEMENT_STUDIES (dim: 384)\n","‚úÖ Generated vector for Sant Longowal Institute of Engineering and Technology - PHD_DETAILS (dim: 384)\n","‚úÖ Generated vector for Sant Longowal Institute of Engineering and Technology - FINANCIAL_RESOURCES (dim: 384)\n","‚úÖ Generated vector for Sant Longowal Institute of Engineering and Technology - FINANCIAL_RESOURCES (dim: 384)\n","‚úÖ Generated vector for Sant Longowal Institute of Engineering and Technology - SPONSORED_RESEARCH (dim: 384)\n","‚úÖ Generated vector for Sant Longowal Institute of Engineering and Technology - CONSULTANCY_PROJECTS (dim: 384)\n","‚úÖ Generated vector for Sant Longowal Institute of Engineering and Technology - PCS_FACILITIES (dim: 384)\n","‚úÖ Generated vector for Sant Longowal Institute of Engineering and Technology - FACULTY_DETAILS (dim: 384)\n","‚úÖ Generated vector for Sant Longowal Institute of Engineering and Technology - students_strength (dim: 384)\n","‚úÖ Successfully processed 12 points\n","Uploading 12 points in batches of 100\n","Uploaded batch 1/1: 12 points\n","Successfully uploaded 12 points from /content/uploaded_json_files/Sant Longowal Institute of Engineering and Technology (1).json\n","\n","--- Processing file: /content/uploaded_json_files/Netaji Subhas University of Technology _NSUT_ (1).json ---\n","Loaded JSON file: /content/uploaded_json_files/Netaji Subhas University of Technology _NSUT_ (1).json\n","üìä Found NIRF data with 12 points\n","üîÑ Processing 12 items for vectorization...\n","‚úÖ Generated vector for Netaji Subhas University of Technology (NSUT) - HEADER (dim: 384)\n","‚úÖ Generated vector for Netaji Subhas University of Technology (NSUT) - SANCTIONED_INTAKE (dim: 384)\n","‚úÖ Generated vector for Netaji Subhas University of Technology (NSUT) - STUDENT_STRENGTH (dim: 384)\n","‚úÖ Generated vector for Netaji Subhas University of Technology (NSUT) - PLACEMENT_STUDIES (dim: 384)\n","‚úÖ Generated vector for Netaji Subhas University of Technology (NSUT) - PHD_DETAILS (dim: 384)\n","‚úÖ Generated vector for Netaji Subhas University of Technology (NSUT) - FINANCIAL_RESOURCES (dim: 384)\n","‚úÖ Generated vector for Netaji Subhas University of Technology (NSUT) - FINANCIAL_RESOURCES (dim: 384)\n","‚úÖ Generated vector for Netaji Subhas University of Technology (NSUT) - SPONSORED_RESEARCH (dim: 384)\n","‚úÖ Generated vector for Netaji Subhas University of Technology (NSUT) - CONSULTANCY_PROJECTS (dim: 384)\n","‚úÖ Generated vector for Netaji Subhas University of Technology (NSUT) - PCS_FACILITIES (dim: 384)\n","‚úÖ Generated vector for Netaji Subhas University of Technology (NSUT) - FACULTY_DETAILS (dim: 384)\n","‚úÖ Generated vector for Netaji Subhas University of Technology (NSUT) - students_strength (dim: 384)\n","‚úÖ Successfully processed 12 points\n","Uploading 12 points in batches of 100\n","Uploaded batch 1/1: 12 points\n","Successfully uploaded 12 points from /content/uploaded_json_files/Netaji Subhas University of Technology _NSUT_ (1).json\n","\n","--- Processing file: /content/uploaded_json_files/Jadavpur University (1).json ---\n","Loaded JSON file: /content/uploaded_json_files/Jadavpur University (1).json\n","üìä Found NIRF data with 12 points\n","üîÑ Processing 12 items for vectorization...\n","‚úÖ Generated vector for Jadavpur University - HEADER (dim: 384)\n","‚úÖ Generated vector for Jadavpur University - SANCTIONED_INTAKE (dim: 384)\n","‚úÖ Generated vector for Jadavpur University - STUDENT_STRENGTH (dim: 384)\n","‚úÖ Generated vector for Jadavpur University - PLACEMENT_STUDIES (dim: 384)\n","‚úÖ Generated vector for Jadavpur University - PHD_DETAILS (dim: 384)\n","‚úÖ Generated vector for Jadavpur University - FINANCIAL_RESOURCES (dim: 384)\n","‚úÖ Generated vector for Jadavpur University - FINANCIAL_RESOURCES (dim: 384)\n","‚úÖ Generated vector for Jadavpur University - SPONSORED_RESEARCH (dim: 384)\n","‚úÖ Generated vector for Jadavpur University - CONSULTANCY_PROJECTS (dim: 384)\n","‚úÖ Generated vector for Jadavpur University - PCS_FACILITIES (dim: 384)\n","‚úÖ Generated vector for Jadavpur University - FACULTY_DETAILS (dim: 384)\n","‚úÖ Generated vector for Jadavpur University - students_strength (dim: 384)\n","‚úÖ Successfully processed 12 points\n","Uploading 12 points in batches of 100\n","Uploaded batch 1/1: 12 points\n","Successfully uploaded 12 points from /content/uploaded_json_files/Jadavpur University (1).json\n","\n","--- Processing file: /content/uploaded_json_files/NIT Patna (1).json ---\n","Loaded JSON file: /content/uploaded_json_files/NIT Patna (1).json\n","üìä Found NIRF data with 12 points\n","üîÑ Processing 12 items for vectorization...\n","‚úÖ Generated vector for National Institute of Technology Patna - HEADER (dim: 384)\n","‚úÖ Generated vector for National Institute of Technology Patna - SANCTIONED_INTAKE (dim: 384)\n","‚úÖ Generated vector for National Institute of Technology Patna - STUDENT_STRENGTH (dim: 384)\n","‚úÖ Generated vector for National Institute of Technology Patna - PLACEMENT_STUDIES (dim: 384)\n","‚úÖ Generated vector for National Institute of Technology Patna - PHD_DETAILS (dim: 384)\n","‚úÖ Generated vector for National Institute of Technology Patna - FINANCIAL_RESOURCES (dim: 384)\n","‚úÖ Generated vector for National Institute of Technology Patna - FINANCIAL_RESOURCES (dim: 384)\n","‚úÖ Generated vector for National Institute of Technology Patna - SPONSORED_RESEARCH (dim: 384)\n","‚úÖ Generated vector for National Institute of Technology Patna - CONSULTANCY_PROJECTS (dim: 384)\n","‚úÖ Generated vector for National Institute of Technology Patna - PCS_FACILITIES (dim: 384)\n","‚úÖ Generated vector for National Institute of Technology Patna - FACULTY_DETAILS (dim: 384)\n","‚úÖ Generated vector for National Institute of Technology Patna - students_strength (dim: 384)\n","‚úÖ Successfully processed 12 points\n","Uploading 12 points in batches of 100\n","Uploaded batch 1/1: 12 points\n","Successfully uploaded 12 points from /content/uploaded_json_files/NIT Patna (1).json\n","\n","--- Processing file: /content/uploaded_json_files/IIT Kharagpur (1).json ---\n","Loaded JSON file: /content/uploaded_json_files/IIT Kharagpur (1).json\n","üìä Found NIRF data with 12 points\n","üîÑ Processing 12 items for vectorization...\n","‚úÖ Generated vector for Indian Institute of Technology Kharagpur - HEADER (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Technology Kharagpur - SANCTIONED_INTAKE (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Technology Kharagpur - STUDENT_STRENGTH (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Technology Kharagpur - PLACEMENT_STUDIES (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Technology Kharagpur - PHD_DETAILS (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Technology Kharagpur - FINANCIAL_RESOURCES (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Technology Kharagpur - FINANCIAL_RESOURCES (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Technology Kharagpur - SPONSORED_RESEARCH (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Technology Kharagpur - CONSULTANCY_PROJECTS (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Technology Kharagpur - PCS_FACILITIES (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Technology Kharagpur - FACULTY_DETAILS (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Technology Kharagpur - students_strength (dim: 384)\n","‚úÖ Successfully processed 12 points\n","Uploading 12 points in batches of 100\n","Uploaded batch 1/1: 12 points\n","Successfully uploaded 12 points from /content/uploaded_json_files/IIT Kharagpur (1).json\n","\n","--- Processing file: /content/uploaded_json_files/NIT Durgapur (1).json ---\n","Loaded JSON file: /content/uploaded_json_files/NIT Durgapur (1).json\n","üìä Found NIRF data with 12 points\n","üîÑ Processing 12 items for vectorization...\n","‚úÖ Generated vector for National Institute of Technology Durgapur - HEADER (dim: 384)\n","‚úÖ Generated vector for National Institute of Technology Durgapur - SANCTIONED_INTAKE (dim: 384)\n","‚úÖ Generated vector for National Institute of Technology Durgapur - STUDENT_STRENGTH (dim: 384)\n","‚úÖ Generated vector for National Institute of Technology Durgapur - PLACEMENT_STUDIES (dim: 384)\n","‚úÖ Generated vector for National Institute of Technology Durgapur - PHD_DETAILS (dim: 384)\n","‚úÖ Generated vector for National Institute of Technology Durgapur - FINANCIAL_RESOURCES (dim: 384)\n","‚úÖ Generated vector for National Institute of Technology Durgapur - FINANCIAL_RESOURCES (dim: 384)\n","‚úÖ Generated vector for National Institute of Technology Durgapur - SPONSORED_RESEARCH (dim: 384)\n","‚úÖ Generated vector for National Institute of Technology Durgapur - CONSULTANCY_PROJECTS (dim: 384)\n","‚úÖ Generated vector for National Institute of Technology Durgapur - PCS_FACILITIES (dim: 384)\n","‚úÖ Generated vector for National Institute of Technology Durgapur - FACULTY_DETAILS (dim: 384)\n","‚úÖ Generated vector for National Institute of Technology Durgapur - students_strength (dim: 384)\n","‚úÖ Successfully processed 12 points\n","Uploading 12 points in batches of 100\n","Uploaded batch 1/1: 12 points\n","Successfully uploaded 12 points from /content/uploaded_json_files/NIT Durgapur (1).json\n","\n","--- Processing file: /content/uploaded_json_files/IIT Hyderabad (1).json ---\n","Loaded JSON file: /content/uploaded_json_files/IIT Hyderabad (1).json\n","üìä Found NIRF data with 12 points\n","üîÑ Processing 12 items for vectorization...\n","‚úÖ Generated vector for Indian Institute of Technology Hyderabad - HEADER (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Technology Hyderabad - SANCTIONED_INTAKE (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Technology Hyderabad - STUDENT_STRENGTH (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Technology Hyderabad - PLACEMENT_STUDIES (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Technology Hyderabad - PHD_DETAILS (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Technology Hyderabad - FINANCIAL_RESOURCES (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Technology Hyderabad - FINANCIAL_RESOURCES (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Technology Hyderabad - SPONSORED_RESEARCH (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Technology Hyderabad - CONSULTANCY_PROJECTS (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Technology Hyderabad - PCS_FACILITIES (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Technology Hyderabad - FACULTY_DETAILS (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Technology Hyderabad - students_strength (dim: 384)\n","‚úÖ Successfully processed 12 points\n","Uploading 12 points in batches of 100\n","Uploaded batch 1/1: 12 points\n","Successfully uploaded 12 points from /content/uploaded_json_files/IIT Hyderabad (1).json\n","\n","--- Processing file: /content/uploaded_json_files/Shoolini University of Biotechnology and Management Science (1).json ---\n","Loaded JSON file: /content/uploaded_json_files/Shoolini University of Biotechnology and Management Science (1).json\n","üìä Found NIRF data with 11 points\n","üîÑ Processing 11 items for vectorization...\n","‚úÖ Generated vector for Shoolini University of Biotechnology and Management Sciences - HEADER (dim: 384)\n","‚úÖ Generated vector for Shoolini University of Biotechnology and Management Sciences - SANCTIONED_INTAKE (dim: 384)\n","‚úÖ Generated vector for Shoolini University of Biotechnology and Management Sciences - STUDENT_STRENGTH (dim: 384)\n","‚úÖ Generated vector for Shoolini University of Biotechnology and Management Sciences - PLACEMENT_STUDIES (dim: 384)\n","‚úÖ Generated vector for Shoolini University of Biotechnology and Management Sciences - PHD_DETAILS (dim: 384)\n","‚úÖ Generated vector for Shoolini University of Biotechnology and Management Sciences - FINANCIAL_RESOURCES (dim: 384)\n","‚úÖ Generated vector for Shoolini University of Biotechnology and Management Sciences - SPONSORED_RESEARCH (dim: 384)\n","‚úÖ Generated vector for Shoolini University of Biotechnology and Management Sciences - CONSULTANCY_PROJECTS (dim: 384)\n","‚úÖ Generated vector for Shoolini University of Biotechnology and Management Sciences - PCS_FACILITIES (dim: 384)\n","‚úÖ Generated vector for Shoolini University of Biotechnology and Management Sciences - FACULTY_DETAILS (dim: 384)\n","‚úÖ Generated vector for Shoolini University of Biotechnology and Management Sciences - students_strength (dim: 384)\n","‚úÖ Successfully processed 11 points\n","Uploading 11 points in batches of 100\n","Uploaded batch 1/1: 11 points\n","Successfully uploaded 11 points from /content/uploaded_json_files/Shoolini University of Biotechnology and Management Science (1).json\n","\n","--- Processing file: /content/uploaded_json_files/IIT Tirupati (1).json ---\n","Loaded JSON file: /content/uploaded_json_files/IIT Tirupati (1).json\n","üìä Found NIRF data with 13 points\n","üîÑ Processing 13 items for vectorization...\n","‚úÖ Generated vector for Indian Institute of Technology Tirupati - HEADER (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Technology Tirupati - SANCTIONED_INTAKE (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Technology Tirupati - STUDENT_STRENGTH (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Technology Tirupati - PLACEMENT_STUDIES (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Technology Tirupati - PG_PLACEMENT (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Technology Tirupati - PHD_DETAILS (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Technology Tirupati - FINANCIAL_RESOURCES (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Technology Tirupati - FINANCIAL_RESOURCES (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Technology Tirupati - SPONSORED_RESEARCH (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Technology Tirupati - CONSULTANCY_PROJECTS (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Technology Tirupati - PCS_FACILITIES (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Technology Tirupati - FACULTY_DETAILS (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Technology Tirupati - students_strength (dim: 384)\n","‚úÖ Successfully processed 13 points\n","Uploading 13 points in batches of 100\n","Uploaded batch 1/1: 13 points\n","Successfully uploaded 13 points from /content/uploaded_json_files/IIT Tirupati (1).json\n","\n","--- Processing file: /content/uploaded_json_files/Amrita Vishwa Vidyapeetham (1).json ---\n","Loaded JSON file: /content/uploaded_json_files/Amrita Vishwa Vidyapeetham (1).json\n","üìä Found NIRF data with 13 points\n","üîÑ Processing 13 items for vectorization...\n","‚úÖ Generated vector for Amrita Vishwa Vidyapeetham - HEADER (dim: 384)\n","‚úÖ Generated vector for Amrita Vishwa Vidyapeetham - SANCTIONED_INTAKE (dim: 384)\n","‚úÖ Generated vector for Amrita Vishwa Vidyapeetham - STUDENT_STRENGTH (dim: 384)\n","‚úÖ Generated vector for Amrita Vishwa Vidyapeetham - PLACEMENT_STUDIES (dim: 384)\n","‚úÖ Generated vector for Amrita Vishwa Vidyapeetham - PHD_DETAILS (dim: 384)\n","‚úÖ Generated vector for Amrita Vishwa Vidyapeetham - FINANCIAL_RESOURCES (dim: 384)\n","‚úÖ Generated vector for Amrita Vishwa Vidyapeetham - FINANCIAL_RESOURCES (dim: 384)\n","‚úÖ Generated vector for Amrita Vishwa Vidyapeetham - IPR (dim: 384)\n","‚úÖ Generated vector for Amrita Vishwa Vidyapeetham - SPONSORED_RESEARCH (dim: 384)\n","‚úÖ Generated vector for Amrita Vishwa Vidyapeetham - CONSULTANCY_PROJECTS (dim: 384)\n","‚úÖ Generated vector for Amrita Vishwa Vidyapeetham - PCS_FACILITIES (dim: 384)\n","‚úÖ Generated vector for Amrita Vishwa Vidyapeetham - FACULTY_DETAILS (dim: 384)\n","‚úÖ Generated vector for Amrita Vishwa Vidyapeetham - students_strength (dim: 384)\n","‚úÖ Successfully processed 13 points\n","Uploading 13 points in batches of 100\n","Uploaded batch 1/1: 13 points\n","Successfully uploaded 13 points from /content/uploaded_json_files/Amrita Vishwa Vidyapeetham (1).json\n","\n","--- Processing file: /content/uploaded_json_files/Jamia Millia Islamia (1).json ---\n","Loaded JSON file: /content/uploaded_json_files/Jamia Millia Islamia (1).json\n","üìä Found NIRF data with 12 points\n","üîÑ Processing 12 items for vectorization...\n","‚úÖ Generated vector for Jamia Millia Islamia - HEADER (dim: 384)\n","‚úÖ Generated vector for Jamia Millia Islamia - SANCTIONED_INTAKE (dim: 384)\n","‚úÖ Generated vector for Jamia Millia Islamia - STUDENT_STRENGTH (dim: 384)\n","‚úÖ Generated vector for Jamia Millia Islamia - PLACEMENT_STUDIES (dim: 384)\n","‚úÖ Generated vector for Jamia Millia Islamia - PHD_DETAILS (dim: 384)\n","‚úÖ Generated vector for Jamia Millia Islamia - FINANCIAL_RESOURCES (dim: 384)\n","‚úÖ Generated vector for Jamia Millia Islamia - FINANCIAL_RESOURCES (dim: 384)\n","‚úÖ Generated vector for Jamia Millia Islamia - SPONSORED_RESEARCH (dim: 384)\n","‚úÖ Generated vector for Jamia Millia Islamia - CONSULTANCY_PROJECTS (dim: 384)\n","‚úÖ Generated vector for Jamia Millia Islamia - PCS_FACILITIES (dim: 384)\n","‚úÖ Generated vector for Jamia Millia Islamia - FACULTY_DETAILS (dim: 384)\n","‚úÖ Generated vector for Jamia Millia Islamia - students_strength (dim: 384)\n","‚úÖ Successfully processed 12 points\n","Uploading 12 points in batches of 100\n","Uploaded batch 1/1: 12 points\n","Successfully uploaded 12 points from /content/uploaded_json_files/Jamia Millia Islamia (1).json\n","\n","--- Processing file: /content/uploaded_json_files/NIT Tiruchirappalli (1).json ---\n","Loaded JSON file: /content/uploaded_json_files/NIT Tiruchirappalli (1).json\n","üìä Found NIRF data with 12 points\n","üîÑ Processing 12 items for vectorization...\n","‚úÖ Generated vector for National Institute of Technology Tiruchirappalli - HEADER (dim: 384)\n","‚úÖ Generated vector for National Institute of Technology Tiruchirappalli - SANCTIONED_INTAKE (dim: 384)\n","‚úÖ Generated vector for National Institute of Technology Tiruchirappalli - STUDENT_STRENGTH (dim: 384)\n","‚úÖ Generated vector for National Institute of Technology Tiruchirappalli - PLACEMENT_STUDIES (dim: 384)\n","‚úÖ Generated vector for National Institute of Technology Tiruchirappalli - PHD_DETAILS (dim: 384)\n","‚úÖ Generated vector for National Institute of Technology Tiruchirappalli - FINANCIAL_RESOURCES (dim: 384)\n","‚úÖ Generated vector for National Institute of Technology Tiruchirappalli - FINANCIAL_RESOURCES (dim: 384)\n","‚úÖ Generated vector for National Institute of Technology Tiruchirappalli - SPONSORED_RESEARCH (dim: 384)\n","‚úÖ Generated vector for National Institute of Technology Tiruchirappalli - CONSULTANCY_PROJECTS (dim: 384)\n","‚úÖ Generated vector for National Institute of Technology Tiruchirappalli - PCS_FACILITIES (dim: 384)\n","‚úÖ Generated vector for National Institute of Technology Tiruchirappalli - FACULTY_DETAILS (dim: 384)\n","‚úÖ Generated vector for National Institute of Technology Tiruchirappalli - students_strength (dim: 384)\n","‚úÖ Successfully processed 12 points\n","Uploading 12 points in batches of 100\n","Uploaded batch 1/1: 12 points\n","Successfully uploaded 12 points from /content/uploaded_json_files/NIT Tiruchirappalli (1).json\n","\n","--- Processing file: /content/uploaded_json_files/Institute of Chemical Technology (1).json ---\n","Loaded JSON file: /content/uploaded_json_files/Institute of Chemical Technology (1).json\n","üìä Found NIRF data with 13 points\n","üîÑ Processing 13 items for vectorization...\n","‚úÖ Generated vector for Institute of Chemical Technology - HEADER (dim: 384)\n","‚úÖ Generated vector for Institute of Chemical Technology - SANCTIONED_INTAKE (dim: 384)\n","‚úÖ Generated vector for Institute of Chemical Technology - STUDENT_STRENGTH (dim: 384)\n","‚úÖ Generated vector for Institute of Chemical Technology - PLACEMENT_STUDIES (dim: 384)\n","‚úÖ Generated vector for Institute of Chemical Technology - PG_PLACEMENT (dim: 384)\n","‚úÖ Generated vector for Institute of Chemical Technology - PHD_DETAILS (dim: 384)\n","‚úÖ Generated vector for Institute of Chemical Technology - FINANCIAL_RESOURCES (dim: 384)\n","‚úÖ Generated vector for Institute of Chemical Technology - FINANCIAL_RESOURCES (dim: 384)\n","‚úÖ Generated vector for Institute of Chemical Technology - SPONSORED_RESEARCH (dim: 384)\n","‚úÖ Generated vector for Institute of Chemical Technology - CONSULTANCY_PROJECTS (dim: 384)\n","‚úÖ Generated vector for Institute of Chemical Technology - PCS_FACILITIES (dim: 384)\n","‚úÖ Generated vector for Institute of Chemical Technology - FACULTY_DETAILS (dim: 384)\n","‚úÖ Generated vector for Institute of Chemical Technology - students_strength (dim: 384)\n","‚úÖ Successfully processed 13 points\n","Uploading 13 points in batches of 100\n","Uploaded batch 1/1: 13 points\n","Successfully uploaded 13 points from /content/uploaded_json_files/Institute of Chemical Technology (1).json\n","\n","--- Processing file: /content/uploaded_json_files/Aligarh Muslim University (1).json ---\n","Loaded JSON file: /content/uploaded_json_files/Aligarh Muslim University (1).json\n","üìä Found NIRF data with 13 points\n","üîÑ Processing 13 items for vectorization...\n","‚úÖ Generated vector for Aligarh Muslim University - HEADER (dim: 384)\n","‚úÖ Generated vector for Aligarh Muslim University - SANCTIONED_INTAKE (dim: 384)\n","‚úÖ Generated vector for Aligarh Muslim University - STUDENT_STRENGTH (dim: 384)\n","‚úÖ Generated vector for Aligarh Muslim University - PLACEMENT_STUDIES (dim: 384)\n","‚úÖ Generated vector for Aligarh Muslim University - PHD_DETAILS (dim: 384)\n","‚úÖ Generated vector for Aligarh Muslim University - FINANCIAL_RESOURCES (dim: 384)\n","‚úÖ Generated vector for Aligarh Muslim University - FINANCIAL_RESOURCES (dim: 384)\n","‚úÖ Generated vector for Aligarh Muslim University - IPR (dim: 384)\n","‚úÖ Generated vector for Aligarh Muslim University - SPONSORED_RESEARCH (dim: 384)\n","‚úÖ Generated vector for Aligarh Muslim University - CONSULTANCY_PROJECTS (dim: 384)\n","‚úÖ Generated vector for Aligarh Muslim University - PCS_FACILITIES (dim: 384)\n","‚úÖ Generated vector for Aligarh Muslim University - FACULTY_DETAILS (dim: 384)\n","‚úÖ Generated vector for Aligarh Muslim University - students_strength (dim: 384)\n","‚úÖ Successfully processed 13 points\n","Uploading 13 points in batches of 100\n","Uploaded batch 1/1: 13 points\n","Successfully uploaded 13 points from /content/uploaded_json_files/Aligarh Muslim University (1).json\n","\n","--- Processing file: /content/uploaded_json_files/VIT Vellore (1).json ---\n","Loaded JSON file: /content/uploaded_json_files/VIT Vellore (1).json\n","üìä Found NIRF data with 13 points\n","üîÑ Processing 13 items for vectorization...\n","‚úÖ Generated vector for Vellore Institute of Technology - HEADER (dim: 384)\n","‚úÖ Generated vector for Vellore Institute of Technology - SANCTIONED_INTAKE (dim: 384)\n","‚úÖ Generated vector for Vellore Institute of Technology - STUDENT_STRENGTH (dim: 384)\n","‚úÖ Generated vector for Vellore Institute of Technology - PLACEMENT_STUDIES (dim: 384)\n","‚úÖ Generated vector for Vellore Institute of Technology - PG_PLACEMENT (dim: 384)\n","‚úÖ Generated vector for Vellore Institute of Technology - PHD_DETAILS (dim: 384)\n","‚úÖ Generated vector for Vellore Institute of Technology - FINANCIAL_RESOURCES (dim: 384)\n","‚úÖ Generated vector for Vellore Institute of Technology - FINANCIAL_RESOURCES (dim: 384)\n","‚úÖ Generated vector for Vellore Institute of Technology - SPONSORED_RESEARCH (dim: 384)\n","‚úÖ Generated vector for Vellore Institute of Technology - CONSULTANCY_PROJECTS (dim: 384)\n","‚úÖ Generated vector for Vellore Institute of Technology - PCS_FACILITIES (dim: 384)\n","‚úÖ Generated vector for Vellore Institute of Technology - FACULTY_DETAILS (dim: 384)\n","‚úÖ Generated vector for Vellore Institute of Technology - students_strength (dim: 384)\n","‚úÖ Successfully processed 13 points\n","Uploading 13 points in batches of 100\n","Uploaded batch 1/1: 13 points\n","Successfully uploaded 13 points from /content/uploaded_json_files/VIT Vellore (1).json\n","\n","--- Processing file: /content/uploaded_json_files/Jawaharlal Nehru Technological University (1).json ---\n","Loaded JSON file: /content/uploaded_json_files/Jawaharlal Nehru Technological University (1).json\n","üìä Found NIRF data with 12 points\n","üîÑ Processing 12 items for vectorization...\n","‚úÖ Generated vector for Jawaharlal Nehru Technological University - HEADER (dim: 384)\n","‚úÖ Generated vector for Jawaharlal Nehru Technological University - SANCTIONED_INTAKE (dim: 384)\n","‚úÖ Generated vector for Jawaharlal Nehru Technological University - STUDENT_STRENGTH (dim: 384)\n","‚úÖ Generated vector for Jawaharlal Nehru Technological University - PLACEMENT_STUDIES (dim: 384)\n","‚úÖ Generated vector for Jawaharlal Nehru Technological University - PHD_DETAILS (dim: 384)\n","‚úÖ Generated vector for Jawaharlal Nehru Technological University - FINANCIAL_RESOURCES (dim: 384)\n","‚úÖ Generated vector for Jawaharlal Nehru Technological University - FINANCIAL_RESOURCES (dim: 384)\n","‚úÖ Generated vector for Jawaharlal Nehru Technological University - SPONSORED_RESEARCH (dim: 384)\n","‚úÖ Generated vector for Jawaharlal Nehru Technological University - CONSULTANCY_PROJECTS (dim: 384)\n","‚úÖ Generated vector for Jawaharlal Nehru Technological University - PCS_FACILITIES (dim: 384)\n","‚úÖ Generated vector for Jawaharlal Nehru Technological University - FACULTY_DETAILS (dim: 384)\n","‚úÖ Generated vector for Jawaharlal Nehru Technological University - students_strength (dim: 384)\n","‚úÖ Successfully processed 12 points\n","Uploading 12 points in batches of 100\n","Uploaded batch 1/1: 12 points\n","Successfully uploaded 12 points from /content/uploaded_json_files/Jawaharlal Nehru Technological University (1).json\n","\n","--- Processing file: /content/uploaded_json_files/Defence Institute of Adavanced Technology (1).json ---\n","Loaded JSON file: /content/uploaded_json_files/Defence Institute of Adavanced Technology (1).json\n","üìä Found NIRF data with 12 points\n","üîÑ Processing 12 items for vectorization...\n","‚úÖ Generated vector for Defence Institute of Advanced Technology - HEADER (dim: 384)\n","‚úÖ Generated vector for Defence Institute of Advanced Technology - SANCTIONED_INTAKE (dim: 384)\n","‚úÖ Generated vector for Defence Institute of Advanced Technology - STUDENT_STRENGTH (dim: 384)\n","‚úÖ Generated vector for Defence Institute of Advanced Technology - PLACEMENT_STUDIES (dim: 384)\n","‚úÖ Generated vector for Defence Institute of Advanced Technology - PHD_DETAILS (dim: 384)\n","‚úÖ Generated vector for Defence Institute of Advanced Technology - FINANCIAL_RESOURCES (dim: 384)\n","‚úÖ Generated vector for Defence Institute of Advanced Technology - FINANCIAL_RESOURCES (dim: 384)\n","‚úÖ Generated vector for Defence Institute of Advanced Technology - SPONSORED_RESEARCH (dim: 384)\n","‚úÖ Generated vector for Defence Institute of Advanced Technology - CONSULTANCY_PROJECTS (dim: 384)\n","‚úÖ Generated vector for Defence Institute of Advanced Technology - PCS_FACILITIES (dim: 384)\n","‚úÖ Generated vector for Defence Institute of Advanced Technology - FACULTY_DETAILS (dim: 384)\n","‚úÖ Generated vector for Defence Institute of Advanced Technology - students_strength (dim: 384)\n","‚úÖ Successfully processed 12 points\n","Uploading 12 points in batches of 100\n","Uploaded batch 1/1: 12 points\n","Successfully uploaded 12 points from /content/uploaded_json_files/Defence Institute of Adavanced Technology (1).json\n","\n","--- Processing file: /content/uploaded_json_files/Lovely Professional University (1).json ---\n","Loaded JSON file: /content/uploaded_json_files/Lovely Professional University (1).json\n","üìä Found NIRF data with 13 points\n","üîÑ Processing 13 items for vectorization...\n","‚úÖ Generated vector for Lovely Professional University - HEADER (dim: 384)\n","‚úÖ Generated vector for Lovely Professional University - SANCTIONED_INTAKE (dim: 384)\n","‚úÖ Generated vector for Lovely Professional University - STUDENT_STRENGTH (dim: 384)\n","‚úÖ Generated vector for Lovely Professional University - PLACEMENT_STUDIES (dim: 384)\n","‚úÖ Generated vector for Lovely Professional University - PG_PLACEMENT (dim: 384)\n","‚úÖ Generated vector for Lovely Professional University - PHD_DETAILS (dim: 384)\n","‚úÖ Generated vector for Lovely Professional University - FINANCIAL_RESOURCES (dim: 384)\n","‚úÖ Generated vector for Lovely Professional University - FINANCIAL_RESOURCES (dim: 384)\n","‚úÖ Generated vector for Lovely Professional University - SPONSORED_RESEARCH (dim: 384)\n","‚úÖ Generated vector for Lovely Professional University - CONSULTANCY_PROJECTS (dim: 384)\n","‚úÖ Generated vector for Lovely Professional University - PCS_FACILITIES (dim: 384)\n","‚úÖ Generated vector for Lovely Professional University - FACULTY_DETAILS (dim: 384)\n","‚úÖ Generated vector for Lovely Professional University - students_strength (dim: 384)\n","‚úÖ Successfully processed 13 points\n","Uploading 13 points in batches of 100\n","Uploaded batch 1/1: 13 points\n","Successfully uploaded 13 points from /content/uploaded_json_files/Lovely Professional University (1).json\n","\n","--- Processing file: /content/uploaded_json_files/NIT Meghalaya (1).json ---\n","Loaded JSON file: /content/uploaded_json_files/NIT Meghalaya (1).json\n","üìä Found NIRF data with 12 points\n","üîÑ Processing 12 items for vectorization...\n","‚úÖ Generated vector for National Institute of Technology Meghalaya - HEADER (dim: 384)\n","‚úÖ Generated vector for National Institute of Technology Meghalaya - SANCTIONED_INTAKE (dim: 384)\n","‚úÖ Generated vector for National Institute of Technology Meghalaya - STUDENT_STRENGTH (dim: 384)\n","‚úÖ Generated vector for National Institute of Technology Meghalaya - PLACEMENT_STUDIES (dim: 384)\n","‚úÖ Generated vector for National Institute of Technology Meghalaya - PHD_DETAILS (dim: 384)\n","‚úÖ Generated vector for National Institute of Technology Meghalaya - FINANCIAL_RESOURCES (dim: 384)\n","‚úÖ Generated vector for National Institute of Technology Meghalaya - FINANCIAL_RESOURCES (dim: 384)\n","‚úÖ Generated vector for National Institute of Technology Meghalaya - SPONSORED_RESEARCH (dim: 384)\n","‚úÖ Generated vector for National Institute of Technology Meghalaya - CONSULTANCY_PROJECTS (dim: 384)\n","‚úÖ Generated vector for National Institute of Technology Meghalaya - PCS_FACILITIES (dim: 384)\n","‚úÖ Generated vector for National Institute of Technology Meghalaya - FACULTY_DETAILS (dim: 384)\n","‚úÖ Generated vector for National Institute of Technology Meghalaya - students_strength (dim: 384)\n","‚úÖ Successfully processed 12 points\n","Uploading 12 points in batches of 100\n","Uploaded batch 1/1: 12 points\n","Successfully uploaded 12 points from /content/uploaded_json_files/NIT Meghalaya (1).json\n","\n","--- Processing file: /content/uploaded_json_files/Madan Mohan Malaviya University of Technology (1).json ---\n","Loaded JSON file: /content/uploaded_json_files/Madan Mohan Malaviya University of Technology (1).json\n","üìä Found NIRF data with 12 points\n","üîÑ Processing 12 items for vectorization...\n","‚úÖ Generated vector for Madan Mohan Malaviya University of Technology - HEADER (dim: 384)\n","‚úÖ Generated vector for Madan Mohan Malaviya University of Technology - SANCTIONED_INTAKE (dim: 384)\n","‚úÖ Generated vector for Madan Mohan Malaviya University of Technology - STUDENT_STRENGTH (dim: 384)\n","‚úÖ Generated vector for Madan Mohan Malaviya University of Technology - PLACEMENT_STUDIES (dim: 384)\n","‚úÖ Generated vector for Madan Mohan Malaviya University of Technology - PHD_DETAILS (dim: 384)\n","‚úÖ Generated vector for Madan Mohan Malaviya University of Technology - FINANCIAL_RESOURCES (dim: 384)\n","‚úÖ Generated vector for Madan Mohan Malaviya University of Technology - FINANCIAL_RESOURCES (dim: 384)\n","‚úÖ Generated vector for Madan Mohan Malaviya University of Technology - SPONSORED_RESEARCH (dim: 384)\n","‚úÖ Generated vector for Madan Mohan Malaviya University of Technology - CONSULTANCY_PROJECTS (dim: 384)\n","‚úÖ Generated vector for Madan Mohan Malaviya University of Technology - PCS_FACILITIES (dim: 384)\n","‚úÖ Generated vector for Madan Mohan Malaviya University of Technology - FACULTY_DETAILS (dim: 384)\n","‚úÖ Generated vector for Madan Mohan Malaviya University of Technology - students_strength (dim: 384)\n","‚úÖ Successfully processed 12 points\n","Uploading 12 points in batches of 100\n","Uploaded batch 1/1: 12 points\n","Successfully uploaded 12 points from /content/uploaded_json_files/Madan Mohan Malaviya University of Technology (1).json\n","\n","--- Processing file: /content/uploaded_json_files/IIIT Allahabad (1).json ---\n","Loaded JSON file: /content/uploaded_json_files/IIIT Allahabad (1).json\n","üìä Found NIRF data with 12 points\n","üîÑ Processing 12 items for vectorization...\n","‚úÖ Generated vector for Indian Institute of Information Technology Allahabad - HEADER (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Information Technology Allahabad - SANCTIONED_INTAKE (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Information Technology Allahabad - STUDENT_STRENGTH (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Information Technology Allahabad - PLACEMENT_STUDIES (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Information Technology Allahabad - PHD_DETAILS (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Information Technology Allahabad - FINANCIAL_RESOURCES (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Information Technology Allahabad - FINANCIAL_RESOURCES (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Information Technology Allahabad - SPONSORED_RESEARCH (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Information Technology Allahabad - CONSULTANCY_PROJECTS (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Information Technology Allahabad - PCS_FACILITIES (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Information Technology Allahabad - FACULTY_DETAILS (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Information Technology Allahabad - students_strength (dim: 384)\n","‚úÖ Successfully processed 12 points\n","Uploading 12 points in batches of 100\n","Uploaded batch 1/1: 12 points\n","Successfully uploaded 12 points from /content/uploaded_json_files/IIIT Allahabad (1).json\n","\n","--- Processing file: /content/uploaded_json_files/Guru Gobind Singh Indraprastha University (1).json ---\n","Loaded JSON file: /content/uploaded_json_files/Guru Gobind Singh Indraprastha University (1).json\n","üìä Found NIRF data with 12 points\n","üîÑ Processing 12 items for vectorization...\n","‚úÖ Generated vector for Guru Gobind Singh Indraprastha University - HEADER (dim: 384)\n","‚úÖ Generated vector for Guru Gobind Singh Indraprastha University - SANCTIONED_INTAKE (dim: 384)\n","‚úÖ Generated vector for Guru Gobind Singh Indraprastha University - STUDENT_STRENGTH (dim: 384)\n","‚úÖ Generated vector for Guru Gobind Singh Indraprastha University - PLACEMENT_STUDIES (dim: 384)\n","‚úÖ Generated vector for Guru Gobind Singh Indraprastha University - PHD_DETAILS (dim: 384)\n","‚úÖ Generated vector for Guru Gobind Singh Indraprastha University - FINANCIAL_RESOURCES (dim: 384)\n","‚úÖ Generated vector for Guru Gobind Singh Indraprastha University - FINANCIAL_RESOURCES (dim: 384)\n","‚úÖ Generated vector for Guru Gobind Singh Indraprastha University - SPONSORED_RESEARCH (dim: 384)\n","‚úÖ Generated vector for Guru Gobind Singh Indraprastha University - CONSULTANCY_PROJECTS (dim: 384)\n","‚úÖ Generated vector for Guru Gobind Singh Indraprastha University - PCS_FACILITIES (dim: 384)\n","‚úÖ Generated vector for Guru Gobind Singh Indraprastha University - FACULTY_DETAILS (dim: 384)\n","‚úÖ Generated vector for Guru Gobind Singh Indraprastha University - students_strength (dim: 384)\n","‚úÖ Successfully processed 12 points\n","Uploading 12 points in batches of 100\n","Uploaded batch 1/1: 12 points\n","Successfully uploaded 12 points from /content/uploaded_json_files/Guru Gobind Singh Indraprastha University (1).json\n","\n","--- Processing file: /content/uploaded_json_files/NIT  Puducherry (1).json ---\n","Loaded JSON file: /content/uploaded_json_files/NIT  Puducherry (1).json\n","üìä Found NIRF data with 12 points\n","üîÑ Processing 12 items for vectorization...\n","‚úÖ Generated vector for National Institute of Technology Puducherry - HEADER (dim: 384)\n","‚úÖ Generated vector for National Institute of Technology Puducherry - SANCTIONED_INTAKE (dim: 384)\n","‚úÖ Generated vector for National Institute of Technology Puducherry - STUDENT_STRENGTH (dim: 384)\n","‚úÖ Generated vector for National Institute of Technology Puducherry - PLACEMENT_STUDIES (dim: 384)\n","‚úÖ Generated vector for National Institute of Technology Puducherry - PHD_DETAILS (dim: 384)\n","‚úÖ Generated vector for National Institute of Technology Puducherry - FINANCIAL_RESOURCES (dim: 384)\n","‚úÖ Generated vector for National Institute of Technology Puducherry - FINANCIAL_RESOURCES (dim: 384)\n","‚úÖ Generated vector for National Institute of Technology Puducherry - SPONSORED_RESEARCH (dim: 384)\n","‚úÖ Generated vector for National Institute of Technology Puducherry - CONSULTANCY_PROJECTS (dim: 384)\n","‚úÖ Generated vector for National Institute of Technology Puducherry - PCS_FACILITIES (dim: 384)\n","‚úÖ Generated vector for National Institute of Technology Puducherry - FACULTY_DETAILS (dim: 384)\n","‚úÖ Generated vector for National Institute of Technology Puducherry - students_strength (dim: 384)\n","‚úÖ Successfully processed 12 points\n","Uploading 12 points in batches of 100\n","Uploaded batch 1/1: 12 points\n","Successfully uploaded 12 points from /content/uploaded_json_files/NIT  Puducherry (1).json\n","\n","--- Processing file: /content/uploaded_json_files/AU College of Enginnering (1).json ---\n","Loaded JSON file: /content/uploaded_json_files/AU College of Enginnering (1).json\n","üìä Found NIRF data with 12 points\n","üîÑ Processing 12 items for vectorization...\n","‚úÖ Generated vector for AU College of Engineering (A) - HEADER (dim: 384)\n","‚úÖ Generated vector for AU College of Engineering (A) - SANCTIONED_INTAKE (dim: 384)\n","‚úÖ Generated vector for AU College of Engineering (A) - STUDENT_STRENGTH (dim: 384)\n","‚úÖ Generated vector for AU College of Engineering (A) - PLACEMENT_STUDIES (dim: 384)\n","‚úÖ Generated vector for AU College of Engineering (A) - PHD_DETAILS (dim: 384)\n","‚úÖ Generated vector for AU College of Engineering (A) - FINANCIAL_RESOURCES (dim: 384)\n","‚úÖ Generated vector for AU College of Engineering (A) - FINANCIAL_RESOURCES (dim: 384)\n","‚úÖ Generated vector for AU College of Engineering (A) - SPONSORED_RESEARCH (dim: 384)\n","‚úÖ Generated vector for AU College of Engineering (A) - CONSULTANCY_PROJECTS (dim: 384)\n","‚úÖ Generated vector for AU College of Engineering (A) - PCS_FACILITIES (dim: 384)\n","‚úÖ Generated vector for AU College of Engineering (A) - FACULTY_DETAILS (dim: 384)\n","‚úÖ Generated vector for AU College of Engineering (A) - students_strength (dim: 384)\n","‚úÖ Successfully processed 12 points\n","Uploading 12 points in batches of 100\n","Uploaded batch 1/1: 12 points\n","Successfully uploaded 12 points from /content/uploaded_json_files/AU College of Enginnering (1).json\n","\n","--- Processing file: /content/uploaded_json_files/NIT Silchar (1).json ---\n","Loaded JSON file: /content/uploaded_json_files/NIT Silchar (1).json\n","üìä Found NIRF data with 12 points\n","üîÑ Processing 12 items for vectorization...\n","‚úÖ Generated vector for National Institute of Technology Silchar - HEADER (dim: 384)\n","‚úÖ Generated vector for National Institute of Technology Silchar - SANCTIONED_INTAKE (dim: 384)\n","‚úÖ Generated vector for National Institute of Technology Silchar - STUDENT_STRENGTH (dim: 384)\n","‚úÖ Generated vector for National Institute of Technology Silchar - PLACEMENT_STUDIES (dim: 384)\n","‚úÖ Generated vector for National Institute of Technology Silchar - PHD_DETAILS (dim: 384)\n","‚úÖ Generated vector for National Institute of Technology Silchar - FINANCIAL_RESOURCES (dim: 384)\n","‚úÖ Generated vector for National Institute of Technology Silchar - FINANCIAL_RESOURCES (dim: 384)\n","‚úÖ Generated vector for National Institute of Technology Silchar - SPONSORED_RESEARCH (dim: 384)\n","‚úÖ Generated vector for National Institute of Technology Silchar - CONSULTANCY_PROJECTS (dim: 384)\n","‚úÖ Generated vector for National Institute of Technology Silchar - PCS_FACILITIES (dim: 384)\n","‚úÖ Generated vector for National Institute of Technology Silchar - FACULTY_DETAILS (dim: 384)\n","‚úÖ Generated vector for National Institute of Technology Silchar - students_strength (dim: 384)\n","‚úÖ Successfully processed 12 points\n","Uploading 12 points in batches of 100\n","Uploaded batch 1/1: 12 points\n","Successfully uploaded 12 points from /content/uploaded_json_files/NIT Silchar (1).json\n","\n","--- Processing file: /content/uploaded_json_files/NIT  Agartala (1).json ---\n","Loaded JSON file: /content/uploaded_json_files/NIT  Agartala (1).json\n","üìä Found NIRF data with 12 points\n","üîÑ Processing 12 items for vectorization...\n","‚úÖ Generated vector for National Institute of Technology Agartala - HEADER (dim: 384)\n","‚úÖ Generated vector for National Institute of Technology Agartala - SANCTIONED_INTAKE (dim: 384)\n","‚úÖ Generated vector for National Institute of Technology Agartala - STUDENT_STRENGTH (dim: 384)\n","‚úÖ Generated vector for National Institute of Technology Agartala - PLACEMENT_STUDIES (dim: 384)\n","‚úÖ Generated vector for National Institute of Technology Agartala - PHD_DETAILS (dim: 384)\n","‚úÖ Generated vector for National Institute of Technology Agartala - FINANCIAL_RESOURCES (dim: 384)\n","‚úÖ Generated vector for National Institute of Technology Agartala - FINANCIAL_RESOURCES (dim: 384)\n","‚úÖ Generated vector for National Institute of Technology Agartala - SPONSORED_RESEARCH (dim: 384)\n","‚úÖ Generated vector for National Institute of Technology Agartala - CONSULTANCY_PROJECTS (dim: 384)\n","‚úÖ Generated vector for National Institute of Technology Agartala - PCS_FACILITIES (dim: 384)\n","‚úÖ Generated vector for National Institute of Technology Agartala - FACULTY_DETAILS (dim: 384)\n","‚úÖ Generated vector for National Institute of Technology Agartala - students_strength (dim: 384)\n","‚úÖ Successfully processed 12 points\n","Uploading 12 points in batches of 100\n","Uploaded batch 1/1: 12 points\n","Successfully uploaded 12 points from /content/uploaded_json_files/NIT  Agartala (1).json\n","\n","--- Processing file: /content/uploaded_json_files/Amity University (1).json ---\n","Loaded JSON file: /content/uploaded_json_files/Amity University (1).json\n","üìä Found NIRF data with 13 points\n","üîÑ Processing 13 items for vectorization...\n","‚úÖ Generated vector for Amity University - HEADER (dim: 384)\n","‚úÖ Generated vector for Amity University - SANCTIONED_INTAKE (dim: 384)\n","‚úÖ Generated vector for Amity University - STUDENT_STRENGTH (dim: 384)\n","‚úÖ Generated vector for Amity University - PLACEMENT_STUDIES (dim: 384)\n","‚úÖ Generated vector for Amity University - PG_PLACEMENT (dim: 384)\n","‚úÖ Generated vector for Amity University - PHD_DETAILS (dim: 384)\n","‚úÖ Generated vector for Amity University - FINANCIAL_RESOURCES (dim: 384)\n","‚úÖ Generated vector for Amity University - FINANCIAL_RESOURCES (dim: 384)\n","‚úÖ Generated vector for Amity University - SPONSORED_RESEARCH (dim: 384)\n","‚úÖ Generated vector for Amity University - CONSULTANCY_PROJECTS (dim: 384)\n","‚úÖ Generated vector for Amity University - PCS_FACILITIES (dim: 384)\n","‚úÖ Generated vector for Amity University - FACULTY_DETAILS (dim: 384)\n","‚úÖ Generated vector for Amity University - students_strength (dim: 384)\n","‚úÖ Successfully processed 13 points\n","Uploading 13 points in batches of 100\n","Uploaded batch 1/1: 13 points\n","Successfully uploaded 13 points from /content/uploaded_json_files/Amity University (1).json\n","\n","--- Processing file: /content/uploaded_json_files/NIT Rourkela (1).json ---\n","Loaded JSON file: /content/uploaded_json_files/NIT Rourkela (1).json\n","üìä Found NIRF data with 13 points\n","üîÑ Processing 13 items for vectorization...\n","‚úÖ Generated vector for National Institute of Technology Rourkela - HEADER (dim: 384)\n","‚úÖ Generated vector for National Institute of Technology Rourkela - SANCTIONED_INTAKE (dim: 384)\n","‚úÖ Generated vector for National Institute of Technology Rourkela - STUDENT_STRENGTH (dim: 384)\n","‚úÖ Generated vector for National Institute of Technology Rourkela - PLACEMENT_STUDIES (dim: 384)\n","‚úÖ Generated vector for National Institute of Technology Rourkela - PG_PLACEMENT (dim: 384)\n","‚úÖ Generated vector for National Institute of Technology Rourkela - PHD_DETAILS (dim: 384)\n","‚úÖ Generated vector for National Institute of Technology Rourkela - FINANCIAL_RESOURCES (dim: 384)\n","‚úÖ Generated vector for National Institute of Technology Rourkela - FINANCIAL_RESOURCES (dim: 384)\n","‚úÖ Generated vector for National Institute of Technology Rourkela - SPONSORED_RESEARCH (dim: 384)\n","‚úÖ Generated vector for National Institute of Technology Rourkela - CONSULTANCY_PROJECTS (dim: 384)\n","‚úÖ Generated vector for National Institute of Technology Rourkela - PCS_FACILITIES (dim: 384)\n","‚úÖ Generated vector for National Institute of Technology Rourkela - FACULTY_DETAILS (dim: 384)\n","‚úÖ Generated vector for National Institute of Technology Rourkela - students_strength (dim: 384)\n","‚úÖ Successfully processed 13 points\n","Uploading 13 points in batches of 100\n","Uploaded batch 1/1: 13 points\n","Successfully uploaded 13 points from /content/uploaded_json_files/NIT Rourkela (1).json\n","\n","--- Processing file: /content/uploaded_json_files/Visvesvaraya National Institute of Technology Nagpur (1).json ---\n","Loaded JSON file: /content/uploaded_json_files/Visvesvaraya National Institute of Technology Nagpur (1).json\n","üìä Found NIRF data with 12 points\n","üîÑ Processing 12 items for vectorization...\n","‚úÖ Generated vector for Visvesvaraya National Institute of Technology Nagpur - HEADER (dim: 384)\n","‚úÖ Generated vector for Visvesvaraya National Institute of Technology Nagpur - SANCTIONED_INTAKE (dim: 384)\n","‚úÖ Generated vector for Visvesvaraya National Institute of Technology Nagpur - STUDENT_STRENGTH (dim: 384)\n","‚úÖ Generated vector for Visvesvaraya National Institute of Technology Nagpur - PLACEMENT_STUDIES (dim: 384)\n","‚úÖ Generated vector for Visvesvaraya National Institute of Technology Nagpur - PHD_DETAILS (dim: 384)\n","‚úÖ Generated vector for Visvesvaraya National Institute of Technology Nagpur - FINANCIAL_RESOURCES (dim: 384)\n","‚úÖ Generated vector for Visvesvaraya National Institute of Technology Nagpur - FINANCIAL_RESOURCES (dim: 384)\n","‚úÖ Generated vector for Visvesvaraya National Institute of Technology Nagpur - SPONSORED_RESEARCH (dim: 384)\n","‚úÖ Generated vector for Visvesvaraya National Institute of Technology Nagpur - CONSULTANCY_PROJECTS (dim: 384)\n","‚úÖ Generated vector for Visvesvaraya National Institute of Technology Nagpur - PCS_FACILITIES (dim: 384)\n","‚úÖ Generated vector for Visvesvaraya National Institute of Technology Nagpur - FACULTY_DETAILS (dim: 384)\n","‚úÖ Generated vector for Visvesvaraya National Institute of Technology Nagpur - students_strength (dim: 384)\n","‚úÖ Successfully processed 12 points\n","Uploading 12 points in batches of 100\n","Uploaded batch 1/1: 12 points\n","Successfully uploaded 12 points from /content/uploaded_json_files/Visvesvaraya National Institute of Technology Nagpur (1).json\n","\n","--- Processing file: /content/uploaded_json_files/Motilal Nehru National Institute of Technology (1).json ---\n","Loaded JSON file: /content/uploaded_json_files/Motilal Nehru National Institute of Technology (1).json\n","üìä Found NIRF data with 12 points\n","üîÑ Processing 12 items for vectorization...\n","‚úÖ Generated vector for Motilal Nehru National Institute of Technology - HEADER (dim: 384)\n","‚úÖ Generated vector for Motilal Nehru National Institute of Technology - SANCTIONED_INTAKE (dim: 384)\n","‚úÖ Generated vector for Motilal Nehru National Institute of Technology - STUDENT_STRENGTH (dim: 384)\n","‚úÖ Generated vector for Motilal Nehru National Institute of Technology - PLACEMENT_STUDIES (dim: 384)\n","‚úÖ Generated vector for Motilal Nehru National Institute of Technology - PHD_DETAILS (dim: 384)\n","‚úÖ Generated vector for Motilal Nehru National Institute of Technology - FINANCIAL_RESOURCES (dim: 384)\n","‚úÖ Generated vector for Motilal Nehru National Institute of Technology - FINANCIAL_RESOURCES (dim: 384)\n","‚úÖ Generated vector for Motilal Nehru National Institute of Technology - SPONSORED_RESEARCH (dim: 384)\n","‚úÖ Generated vector for Motilal Nehru National Institute of Technology - CONSULTANCY_PROJECTS (dim: 384)\n","‚úÖ Generated vector for Motilal Nehru National Institute of Technology - PCS_FACILITIES (dim: 384)\n","‚úÖ Generated vector for Motilal Nehru National Institute of Technology - FACULTY_DETAILS (dim: 384)\n","‚úÖ Generated vector for Motilal Nehru National Institute of Technology - students_strength (dim: 384)\n","‚úÖ Successfully processed 12 points\n","Uploading 12 points in batches of 100\n","Uploaded batch 1/1: 12 points\n","Successfully uploaded 12 points from /content/uploaded_json_files/Motilal Nehru National Institute of Technology (1).json\n","\n","--- Processing file: /content/uploaded_json_files/NIT Raipur (1).json ---\n","Loaded JSON file: /content/uploaded_json_files/NIT Raipur (1).json\n","üìä Found NIRF data with 12 points\n","üîÑ Processing 12 items for vectorization...\n","‚úÖ Generated vector for National Institute of Technology Raipur - HEADER (dim: 384)\n","‚úÖ Generated vector for National Institute of Technology Raipur - SANCTIONED_INTAKE (dim: 384)\n","‚úÖ Generated vector for National Institute of Technology Raipur - STUDENT_STRENGTH (dim: 384)\n","‚úÖ Generated vector for National Institute of Technology Raipur - PLACEMENT_STUDIES (dim: 384)\n","‚úÖ Generated vector for National Institute of Technology Raipur - PHD_DETAILS (dim: 384)\n","‚úÖ Generated vector for National Institute of Technology Raipur - FINANCIAL_RESOURCES (dim: 384)\n","‚úÖ Generated vector for National Institute of Technology Raipur - FINANCIAL_RESOURCES (dim: 384)\n","‚úÖ Generated vector for National Institute of Technology Raipur - SPONSORED_RESEARCH (dim: 384)\n","‚úÖ Generated vector for National Institute of Technology Raipur - CONSULTANCY_PROJECTS (dim: 384)\n","‚úÖ Generated vector for National Institute of Technology Raipur - PCS_FACILITIES (dim: 384)\n","‚úÖ Generated vector for National Institute of Technology Raipur - FACULTY_DETAILS (dim: 384)\n","‚úÖ Generated vector for National Institute of Technology Raipur - students_strength (dim: 384)\n","‚úÖ Successfully processed 12 points\n","Uploading 12 points in batches of 100\n","Uploaded batch 1/1: 12 points\n","Successfully uploaded 12 points from /content/uploaded_json_files/NIT Raipur (1).json\n","\n","--- Processing file: /content/uploaded_json_files/NIT Warangal (1).json ---\n","Loaded JSON file: /content/uploaded_json_files/NIT Warangal (1).json\n","üìä Found NIRF data with 12 points\n","üîÑ Processing 12 items for vectorization...\n","‚úÖ Generated vector for National Institute of Technology Warangal - HEADER (dim: 384)\n","‚úÖ Generated vector for National Institute of Technology Warangal - SANCTIONED_INTAKE (dim: 384)\n","‚úÖ Generated vector for National Institute of Technology Warangal - STUDENT_STRENGTH (dim: 384)\n","‚úÖ Generated vector for National Institute of Technology Warangal - PLACEMENT_STUDIES (dim: 384)\n","‚úÖ Generated vector for National Institute of Technology Warangal - PHD_DETAILS (dim: 384)\n","‚úÖ Generated vector for National Institute of Technology Warangal - FINANCIAL_RESOURCES (dim: 384)\n","‚úÖ Generated vector for National Institute of Technology Warangal - FINANCIAL_RESOURCES (dim: 384)\n","‚úÖ Generated vector for National Institute of Technology Warangal - SPONSORED_RESEARCH (dim: 384)\n","‚úÖ Generated vector for National Institute of Technology Warangal - CONSULTANCY_PROJECTS (dim: 384)\n","‚úÖ Generated vector for National Institute of Technology Warangal - PCS_FACILITIES (dim: 384)\n","‚úÖ Generated vector for National Institute of Technology Warangal - FACULTY_DETAILS (dim: 384)\n","‚úÖ Generated vector for National Institute of Technology Warangal - students_strength (dim: 384)\n","‚úÖ Successfully processed 12 points\n","Uploading 12 points in batches of 100\n","Uploaded batch 1/1: 12 points\n","Successfully uploaded 12 points from /content/uploaded_json_files/NIT Warangal (1).json\n","\n","--- Processing file: /content/uploaded_json_files/K L College of Engineering_Vaddeswaram_ (1).json ---\n","Loaded JSON file: /content/uploaded_json_files/K L College of Engineering_Vaddeswaram_ (1).json\n","üìä Found NIRF data with 12 points\n","üîÑ Processing 12 items for vectorization...\n","‚úÖ Generated vector for Koneru Lakshmaiah Education Foundation University (K L College of Engineering) - HEADER (dim: 384)\n","‚úÖ Generated vector for Koneru Lakshmaiah Education Foundation University (K L College of Engineering) - SANCTIONED_INTAKE (dim: 384)\n","‚úÖ Generated vector for Koneru Lakshmaiah Education Foundation University (K L College of Engineering) - STUDENT_STRENGTH (dim: 384)\n","‚úÖ Generated vector for Koneru Lakshmaiah Education Foundation University (K L College of Engineering) - PLACEMENT_STUDIES (dim: 384)\n","‚úÖ Generated vector for Koneru Lakshmaiah Education Foundation University (K L College of Engineering) - PHD_DETAILS (dim: 384)\n","‚úÖ Generated vector for Koneru Lakshmaiah Education Foundation University (K L College of Engineering) - FINANCIAL_RESOURCES (dim: 384)\n","‚úÖ Generated vector for Koneru Lakshmaiah Education Foundation University (K L College of Engineering) - FINANCIAL_RESOURCES (dim: 384)\n","‚úÖ Generated vector for Koneru Lakshmaiah Education Foundation University (K L College of Engineering) - SPONSORED_RESEARCH (dim: 384)\n","‚úÖ Generated vector for Koneru Lakshmaiah Education Foundation University (K L College of Engineering) - CONSULTANCY_PROJECTS (dim: 384)\n","‚úÖ Generated vector for Koneru Lakshmaiah Education Foundation University (K L College of Engineering) - PCS_FACILITIES (dim: 384)\n","‚úÖ Generated vector for Koneru Lakshmaiah Education Foundation University (K L College of Engineering) - FACULTY_DETAILS (dim: 384)\n","‚úÖ Generated vector for Koneru Lakshmaiah Education Foundation University (K L College of Engineering) - students_strength (dim: 384)\n","‚úÖ Successfully processed 12 points\n","Uploading 12 points in batches of 100\n","Uploaded batch 1/1: 12 points\n","Successfully uploaded 12 points from /content/uploaded_json_files/K L College of Engineering_Vaddeswaram_ (1).json\n","\n","--- Processing file: /content/uploaded_json_files/NIT Kurukshetra (1).json ---\n","Loaded JSON file: /content/uploaded_json_files/NIT Kurukshetra (1).json\n","üìä Found NIRF data with 12 points\n","üîÑ Processing 12 items for vectorization...\n","‚úÖ Generated vector for National Institute of Technology Kurukshetra - HEADER (dim: 384)\n","‚úÖ Generated vector for National Institute of Technology Kurukshetra - SANCTIONED_INTAKE (dim: 384)\n","‚úÖ Generated vector for National Institute of Technology Kurukshetra - STUDENT_STRENGTH (dim: 384)\n","‚úÖ Generated vector for National Institute of Technology Kurukshetra - PLACEMENT_STUDIES (dim: 384)\n","‚úÖ Generated vector for National Institute of Technology Kurukshetra - PHD_DETAILS (dim: 384)\n","‚úÖ Generated vector for National Institute of Technology Kurukshetra - FINANCIAL_RESOURCES (dim: 384)\n","‚úÖ Generated vector for National Institute of Technology Kurukshetra - FINANCIAL_RESOURCES (dim: 384)\n","‚úÖ Generated vector for National Institute of Technology Kurukshetra - SPONSORED_RESEARCH (dim: 384)\n","‚úÖ Generated vector for National Institute of Technology Kurukshetra - CONSULTANCY_PROJECTS (dim: 384)\n","‚úÖ Generated vector for National Institute of Technology Kurukshetra - PCS_FACILITIES (dim: 384)\n","‚úÖ Generated vector for National Institute of Technology Kurukshetra - FACULTY_DETAILS (dim: 384)\n","‚úÖ Generated vector for National Institute of Technology Kurukshetra - students_strength (dim: 384)\n","‚úÖ Successfully processed 12 points\n","Uploading 12 points in batches of 100\n","Uploaded batch 1/1: 12 points\n","Successfully uploaded 12 points from /content/uploaded_json_files/NIT Kurukshetra (1).json\n","\n","--- Processing file: /content/uploaded_json_files/Anna University (1).json ---\n","Loaded JSON file: /content/uploaded_json_files/Anna University (1).json\n","üìä Found NIRF data with 13 points\n","üîÑ Processing 13 items for vectorization...\n","‚úÖ Generated vector for Anna University - HEADER (dim: 384)\n","‚úÖ Generated vector for Anna University - SANCTIONED_INTAKE (dim: 384)\n","‚úÖ Generated vector for Anna University - STUDENT_STRENGTH (dim: 384)\n","‚úÖ Generated vector for Anna University - PLACEMENT_STUDIES (dim: 384)\n","‚úÖ Generated vector for Anna University - PHD_DETAILS (dim: 384)\n","‚úÖ Generated vector for Anna University - FINANCIAL_RESOURCES (dim: 384)\n","‚úÖ Generated vector for Anna University - FINANCIAL_RESOURCES (dim: 384)\n","‚úÖ Generated vector for Anna University - IPR (dim: 384)\n","‚úÖ Generated vector for Anna University - SPONSORED_RESEARCH (dim: 384)\n","‚úÖ Generated vector for Anna University - CONSULTANCY_PROJECTS (dim: 384)\n","‚úÖ Generated vector for Anna University - PCS_FACILITIES (dim: 384)\n","‚úÖ Generated vector for Anna University - FACULTY_DETAILS (dim: 384)\n","‚úÖ Generated vector for Anna University - students_strength (dim: 384)\n","‚úÖ Successfully processed 13 points\n","Uploading 13 points in batches of 100\n","Uploaded batch 1/1: 13 points\n","Successfully uploaded 13 points from /content/uploaded_json_files/Anna University (1).json\n","\n","--- Processing file: /content/uploaded_json_files/Indian Institute of Space Science and Technology (1).json ---\n","Loaded JSON file: /content/uploaded_json_files/Indian Institute of Space Science and Technology (1).json\n","üìä Found NIRF data with 12 points\n","üîÑ Processing 12 items for vectorization...\n","‚úÖ Generated vector for Indian Institute of Space Science and Technology - HEADER (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Space Science and Technology - SANCTIONED_INTAKE (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Space Science and Technology - STUDENT_STRENGTH (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Space Science and Technology - PLACEMENT_STUDIES (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Space Science and Technology - PHD_DETAILS (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Space Science and Technology - FINANCIAL_RESOURCES (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Space Science and Technology - FINANCIAL_RESOURCES (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Space Science and Technology - SPONSORED_RESEARCH (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Space Science and Technology - CONSULTANCY_PROJECTS (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Space Science and Technology - PCS_FACILITIES (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Space Science and Technology - FACULTY_DETAILS (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Space Science and Technology - students_strength (dim: 384)\n","‚úÖ Successfully processed 12 points\n","Uploading 12 points in batches of 100\n","Uploaded batch 1/1: 12 points\n","Successfully uploaded 12 points from /content/uploaded_json_files/Indian Institute of Space Science and Technology (1).json\n","\n","--- Processing file: /content/uploaded_json_files/Birla Institute of Technology Ranchi (1).json ---\n","Loaded JSON file: /content/uploaded_json_files/Birla Institute of Technology Ranchi (1).json\n","üìä Found NIRF data with 12 points\n","üîÑ Processing 12 items for vectorization...\n","‚úÖ Generated vector for Birla Institute of Technology - HEADER (dim: 384)\n","‚úÖ Generated vector for Birla Institute of Technology - SANCTIONED_INTAKE (dim: 384)\n","‚úÖ Generated vector for Birla Institute of Technology - STUDENT_STRENGTH (dim: 384)\n","‚úÖ Generated vector for Birla Institute of Technology - PLACEMENT_STUDIES (dim: 384)\n","‚úÖ Generated vector for Birla Institute of Technology - PHD_DETAILS (dim: 384)\n","‚úÖ Generated vector for Birla Institute of Technology - FINANCIAL_RESOURCES (dim: 384)\n","‚úÖ Generated vector for Birla Institute of Technology - FINANCIAL_RESOURCES (dim: 384)\n","‚úÖ Generated vector for Birla Institute of Technology - SPONSORED_RESEARCH (dim: 384)\n","‚úÖ Generated vector for Birla Institute of Technology - CONSULTANCY_PROJECTS (dim: 384)\n","‚úÖ Generated vector for Birla Institute of Technology - PCS_FACILITIES (dim: 384)\n","‚úÖ Generated vector for Birla Institute of Technology - FACULTY_DETAILS (dim: 384)\n","‚úÖ Generated vector for Birla Institute of Technology - students_strength (dim: 384)\n","‚úÖ Successfully processed 12 points\n","Uploading 12 points in batches of 100\n","Uploaded batch 1/1: 12 points\n","Successfully uploaded 12 points from /content/uploaded_json_files/Birla Institute of Technology Ranchi (1).json\n","\n","--- Processing file: /content/uploaded_json_files/R.V. College of Engineering (1).json ---\n","Loaded JSON file: /content/uploaded_json_files/R.V. College of Engineering (1).json\n","üìä Found NIRF data with 12 points\n","üîÑ Processing 12 items for vectorization...\n","‚úÖ Generated vector for R.V. College of Engineering - HEADER (dim: 384)\n","‚úÖ Generated vector for R.V. College of Engineering - SANCTIONED_INTAKE (dim: 384)\n","‚úÖ Generated vector for R.V. College of Engineering - STUDENT_STRENGTH (dim: 384)\n","‚úÖ Generated vector for R.V. College of Engineering - PLACEMENT_STUDIES (dim: 384)\n","‚úÖ Generated vector for R.V. College of Engineering - PHD_DETAILS (dim: 384)\n","‚úÖ Generated vector for R.V. College of Engineering - FINANCIAL_RESOURCES (dim: 384)\n","‚úÖ Generated vector for R.V. College of Engineering - FINANCIAL_RESOURCES (dim: 384)\n","‚úÖ Generated vector for R.V. College of Engineering - SPONSORED_RESEARCH (dim: 384)\n","‚úÖ Generated vector for R.V. College of Engineering - CONSULTANCY_PROJECTS (dim: 384)\n","‚úÖ Generated vector for R.V. College of Engineering - PCS_FACILITIES (dim: 384)\n","‚úÖ Generated vector for R.V. College of Engineering - FACULTY_DETAILS (dim: 384)\n","‚úÖ Generated vector for R.V. College of Engineering - students_strength (dim: 384)\n","‚úÖ Successfully processed 12 points\n","Uploading 12 points in batches of 100\n","Uploaded batch 1/1: 12 points\n","Successfully uploaded 12 points from /content/uploaded_json_files/R.V. College of Engineering (1).json\n","\n","--- Processing file: /content/uploaded_json_files/Vignan_s Foundation for Science_ Technology and Research (1).json ---\n","Loaded JSON file: /content/uploaded_json_files/Vignan_s Foundation for Science_ Technology and Research (1).json\n","üìä Found NIRF data with 12 points\n","üîÑ Processing 12 items for vectorization...\n","‚úÖ Generated vector for Vignan's Foundation for Science, Technology and Research - HEADER (dim: 384)\n","‚úÖ Generated vector for Vignan's Foundation for Science, Technology and Research - SANCTIONED_INTAKE (dim: 384)\n","‚úÖ Generated vector for Vignan's Foundation for Science, Technology and Research - STUDENT_STRENGTH (dim: 384)\n","‚úÖ Generated vector for Vignan's Foundation for Science, Technology and Research - PLACEMENT_STUDIES (dim: 384)\n","‚úÖ Generated vector for Vignan's Foundation for Science, Technology and Research - PHD_DETAILS (dim: 384)\n","‚úÖ Generated vector for Vignan's Foundation for Science, Technology and Research - FINANCIAL_RESOURCES (dim: 384)\n","‚úÖ Generated vector for Vignan's Foundation for Science, Technology and Research - FINANCIAL_RESOURCES (dim: 384)\n","‚úÖ Generated vector for Vignan's Foundation for Science, Technology and Research - SPONSORED_RESEARCH (dim: 384)\n","‚úÖ Generated vector for Vignan's Foundation for Science, Technology and Research - CONSULTANCY_PROJECTS (dim: 384)\n","‚úÖ Generated vector for Vignan's Foundation for Science, Technology and Research - PCS_FACILITIES (dim: 384)\n","‚úÖ Generated vector for Vignan's Foundation for Science, Technology and Research - FACULTY_DETAILS (dim: 384)\n","‚úÖ Generated vector for Vignan's Foundation for Science, Technology and Research - students_strength (dim: 384)\n","‚úÖ Successfully processed 12 points\n","Uploading 12 points in batches of 100\n","Uploaded batch 1/1: 12 points\n","Successfully uploaded 12 points from /content/uploaded_json_files/Vignan_s Foundation for Science_ Technology and Research (1).json\n","\n","--- Processing file: /content/uploaded_json_files/NIT calicut (1).json ---\n","Loaded JSON file: /content/uploaded_json_files/NIT calicut (1).json\n","üìä Found NIRF data with 12 points\n","üîÑ Processing 12 items for vectorization...\n","‚úÖ Generated vector for National Institute of Technology Calicut - HEADER (dim: 384)\n","‚úÖ Generated vector for National Institute of Technology Calicut - SANCTIONED_INTAKE (dim: 384)\n","‚úÖ Generated vector for National Institute of Technology Calicut - STUDENT_STRENGTH (dim: 384)\n","‚úÖ Generated vector for National Institute of Technology Calicut - PLACEMENT_STUDIES (dim: 384)\n","‚úÖ Generated vector for National Institute of Technology Calicut - PHD_DETAILS (dim: 384)\n","‚úÖ Generated vector for National Institute of Technology Calicut - FINANCIAL_RESOURCES (dim: 384)\n","‚úÖ Generated vector for National Institute of Technology Calicut - FINANCIAL_RESOURCES (dim: 384)\n","‚úÖ Generated vector for National Institute of Technology Calicut - SPONSORED_RESEARCH (dim: 384)\n","‚úÖ Generated vector for National Institute of Technology Calicut - CONSULTANCY_PROJECTS (dim: 384)\n","‚úÖ Generated vector for National Institute of Technology Calicut - PCS_FACILITIES (dim: 384)\n","‚úÖ Generated vector for National Institute of Technology Calicut - FACULTY_DETAILS (dim: 384)\n","‚úÖ Generated vector for National Institute of Technology Calicut - students_strength (dim: 384)\n","‚úÖ Successfully processed 12 points\n","Uploading 12 points in batches of 100\n","Uploaded batch 1/1: 12 points\n","Successfully uploaded 12 points from /content/uploaded_json_files/NIT calicut (1).json\n","\n","--- Processing file: /content/uploaded_json_files/Malaviya National Institute of Technology (1).json ---\n","Loaded JSON file: /content/uploaded_json_files/Malaviya National Institute of Technology (1).json\n","üìä Found NIRF data with 12 points\n","üîÑ Processing 12 items for vectorization...\n","‚úÖ Generated vector for Malaviya National Institute of Technology - HEADER (dim: 384)\n","‚úÖ Generated vector for Malaviya National Institute of Technology - SANCTIONED_INTAKE (dim: 384)\n","‚úÖ Generated vector for Malaviya National Institute of Technology - STUDENT_STRENGTH (dim: 384)\n","‚úÖ Generated vector for Malaviya National Institute of Technology - PLACEMENT_STUDIES (dim: 384)\n","‚úÖ Generated vector for Malaviya National Institute of Technology - PHD_DETAILS (dim: 384)\n","‚úÖ Generated vector for Malaviya National Institute of Technology - FINANCIAL_RESOURCES (dim: 384)\n","‚úÖ Generated vector for Malaviya National Institute of Technology - FINANCIAL_RESOURCES (dim: 384)\n","‚úÖ Generated vector for Malaviya National Institute of Technology - SPONSORED_RESEARCH (dim: 384)\n","‚úÖ Generated vector for Malaviya National Institute of Technology - CONSULTANCY_PROJECTS (dim: 384)\n","‚úÖ Generated vector for Malaviya National Institute of Technology - PCS_FACILITIES (dim: 384)\n","‚úÖ Generated vector for Malaviya National Institute of Technology - FACULTY_DETAILS (dim: 384)\n","‚úÖ Generated vector for Malaviya National Institute of Technology - students_strength (dim: 384)\n","‚úÖ Successfully processed 12 points\n","Uploading 12 points in batches of 100\n","Uploaded batch 1/1: 12 points\n","Successfully uploaded 12 points from /content/uploaded_json_files/Malaviya National Institute of Technology (1).json\n","\n","--- Processing file: /content/uploaded_json_files/Indraprastha Institute of Information Technology (1).json ---\n","Loaded JSON file: /content/uploaded_json_files/Indraprastha Institute of Information Technology (1).json\n","üìä Found NIRF data with 12 points\n","üîÑ Processing 12 items for vectorization...\n","‚úÖ Generated vector for Indraprastha Institute of Information Technology - HEADER (dim: 384)\n","‚úÖ Generated vector for Indraprastha Institute of Information Technology - SANCTIONED_INTAKE (dim: 384)\n","‚úÖ Generated vector for Indraprastha Institute of Information Technology - STUDENT_STRENGTH (dim: 384)\n","‚úÖ Generated vector for Indraprastha Institute of Information Technology - PLACEMENT_STUDIES (dim: 384)\n","‚úÖ Generated vector for Indraprastha Institute of Information Technology - PHD_DETAILS (dim: 384)\n","‚úÖ Generated vector for Indraprastha Institute of Information Technology - FINANCIAL_RESOURCES (dim: 384)\n","‚úÖ Generated vector for Indraprastha Institute of Information Technology - FINANCIAL_RESOURCES (dim: 384)\n","‚úÖ Generated vector for Indraprastha Institute of Information Technology - SPONSORED_RESEARCH (dim: 384)\n","‚úÖ Generated vector for Indraprastha Institute of Information Technology - CONSULTANCY_PROJECTS (dim: 384)\n","‚úÖ Generated vector for Indraprastha Institute of Information Technology - PCS_FACILITIES (dim: 384)\n","‚úÖ Generated vector for Indraprastha Institute of Information Technology - FACULTY_DETAILS (dim: 384)\n","‚úÖ Generated vector for Indraprastha Institute of Information Technology - students_strength (dim: 384)\n","‚úÖ Successfully processed 12 points\n","Uploading 12 points in batches of 100\n","Uploaded batch 1/1: 12 points\n","Successfully uploaded 12 points from /content/uploaded_json_files/Indraprastha Institute of Information Technology (1).json\n","\n","--- Processing file: /content/uploaded_json_files/Birla Institute of Technology  and Science_ Pilani (1).json ---\n","Loaded JSON file: /content/uploaded_json_files/Birla Institute of Technology  and Science_ Pilani (1).json\n","üìä Found NIRF data with 12 points\n","üîÑ Processing 12 items for vectorization...\n","‚úÖ Generated vector for Birla Institute of Technology and Science, Pilani - HEADER (dim: 384)\n","‚úÖ Generated vector for Birla Institute of Technology and Science, Pilani - SANCTIONED_INTAKE (dim: 384)\n","‚úÖ Generated vector for Birla Institute of Technology and Science, Pilani - STUDENT_STRENGTH (dim: 384)\n","‚úÖ Generated vector for Birla Institute of Technology and Science, Pilani - PLACEMENT_STUDIES (dim: 384)\n","‚úÖ Generated vector for Birla Institute of Technology and Science, Pilani - PHD_DETAILS (dim: 384)\n","‚úÖ Generated vector for Birla Institute of Technology and Science, Pilani - FINANCIAL_RESOURCES (dim: 384)\n","‚úÖ Generated vector for Birla Institute of Technology and Science, Pilani - FINANCIAL_RESOURCES (dim: 384)\n","‚úÖ Generated vector for Birla Institute of Technology and Science, Pilani - SPONSORED_RESEARCH (dim: 384)\n","‚úÖ Generated vector for Birla Institute of Technology and Science, Pilani - CONSULTANCY_PROJECTS (dim: 384)\n","‚úÖ Generated vector for Birla Institute of Technology and Science, Pilani - PCS_FACILITIES (dim: 384)\n","‚úÖ Generated vector for Birla Institute of Technology and Science, Pilani - FACULTY_DETAILS (dim: 384)\n","‚úÖ Generated vector for Birla Institute of Technology and Science, Pilani - students_strength (dim: 384)\n","‚úÖ Successfully processed 12 points\n","Uploading 12 points in batches of 100\n","Uploaded batch 1/1: 12 points\n","Successfully uploaded 12 points from /content/uploaded_json_files/Birla Institute of Technology  and Science_ Pilani (1).json\n","\n","--- Processing file: /content/uploaded_json_files/IIEST Shibpur (1).json ---\n","Loaded JSON file: /content/uploaded_json_files/IIEST Shibpur (1).json\n","üìä Found NIRF data with 12 points\n","üîÑ Processing 12 items for vectorization...\n","‚úÖ Generated vector for Indian Institute of Engineering Science and Technology, Shibpur - HEADER (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Engineering Science and Technology, Shibpur - SANCTIONED_INTAKE (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Engineering Science and Technology, Shibpur - STUDENT_STRENGTH (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Engineering Science and Technology, Shibpur - PLACEMENT_STUDIES (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Engineering Science and Technology, Shibpur - PHD_DETAILS (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Engineering Science and Technology, Shibpur - FINANCIAL_RESOURCES (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Engineering Science and Technology, Shibpur - FINANCIAL_RESOURCES (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Engineering Science and Technology, Shibpur - SPONSORED_RESEARCH (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Engineering Science and Technology, Shibpur - CONSULTANCY_PROJECTS (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Engineering Science and Technology, Shibpur - PCS_FACILITIES (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Engineering Science and Technology, Shibpur - FACULTY_DETAILS (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Engineering Science and Technology, Shibpur - students_strength (dim: 384)\n","‚úÖ Successfully processed 12 points\n","Uploading 12 points in batches of 100\n","Uploaded batch 1/1: 12 points\n","Successfully uploaded 12 points from /content/uploaded_json_files/IIEST Shibpur (1).json\n","\n","--- Processing file: /content/uploaded_json_files/Manipal Institute of Technology (1).json ---\n","Loaded JSON file: /content/uploaded_json_files/Manipal Institute of Technology (1).json\n","üìä Found NIRF data with 12 points\n","üîÑ Processing 12 items for vectorization...\n","‚úÖ Generated vector for Manipal Institute of Technology - HEADER (dim: 384)\n","‚úÖ Generated vector for Manipal Institute of Technology - SANCTIONED_INTAKE (dim: 384)\n","‚úÖ Generated vector for Manipal Institute of Technology - STUDENT_STRENGTH (dim: 384)\n","‚úÖ Generated vector for Manipal Institute of Technology - PLACEMENT_STUDIES (dim: 384)\n","‚úÖ Generated vector for Manipal Institute of Technology - PHD_DETAILS (dim: 384)\n","‚úÖ Generated vector for Manipal Institute of Technology - FINANCIAL_RESOURCES (dim: 384)\n","‚úÖ Generated vector for Manipal Institute of Technology - FINANCIAL_RESOURCES (dim: 384)\n","‚úÖ Generated vector for Manipal Institute of Technology - SPONSORED_RESEARCH (dim: 384)\n","‚úÖ Generated vector for Manipal Institute of Technology - CONSULTANCY_PROJECTS (dim: 384)\n","‚úÖ Generated vector for Manipal Institute of Technology - PCS_FACILITIES (dim: 384)\n","‚úÖ Generated vector for Manipal Institute of Technology - FACULTY_DETAILS (dim: 384)\n","‚úÖ Generated vector for Manipal Institute of Technology - students_strength (dim: 384)\n","‚úÖ Successfully processed 12 points\n","Uploading 12 points in batches of 100\n","Uploaded batch 1/1: 12 points\n","Successfully uploaded 12 points from /content/uploaded_json_files/Manipal Institute of Technology (1).json\n","\n","--- Processing file: /content/uploaded_json_files/Sardar Vallabhbhai National Institute of Technology (1).json ---\n","Loaded JSON file: /content/uploaded_json_files/Sardar Vallabhbhai National Institute of Technology (1).json\n","üìä Found NIRF data with 12 points\n","üîÑ Processing 12 items for vectorization...\n","‚úÖ Generated vector for Sardar Vallabhbhai National Institute of Technology - HEADER (dim: 384)\n","‚úÖ Generated vector for Sardar Vallabhbhai National Institute of Technology - SANCTIONED_INTAKE (dim: 384)\n","‚úÖ Generated vector for Sardar Vallabhbhai National Institute of Technology - STUDENT_STRENGTH (dim: 384)\n","‚úÖ Generated vector for Sardar Vallabhbhai National Institute of Technology - PLACEMENT_STUDIES (dim: 384)\n","‚úÖ Generated vector for Sardar Vallabhbhai National Institute of Technology - PHD_DETAILS (dim: 384)\n","‚úÖ Generated vector for Sardar Vallabhbhai National Institute of Technology - FINANCIAL_RESOURCES (dim: 384)\n","‚úÖ Generated vector for Sardar Vallabhbhai National Institute of Technology - FINANCIAL_RESOURCES (dim: 384)\n","‚úÖ Generated vector for Sardar Vallabhbhai National Institute of Technology - SPONSORED_RESEARCH (dim: 384)\n","‚úÖ Generated vector for Sardar Vallabhbhai National Institute of Technology - CONSULTANCY_PROJECTS (dim: 384)\n","‚úÖ Generated vector for Sardar Vallabhbhai National Institute of Technology - PCS_FACILITIES (dim: 384)\n","‚úÖ Generated vector for Sardar Vallabhbhai National Institute of Technology - FACULTY_DETAILS (dim: 384)\n","‚úÖ Generated vector for Sardar Vallabhbhai National Institute of Technology - students_strength (dim: 384)\n","‚úÖ Successfully processed 12 points\n","Uploading 12 points in batches of 100\n","Uploaded batch 1/1: 12 points\n","Successfully uploaded 12 points from /content/uploaded_json_files/Sardar Vallabhbhai National Institute of Technology (1).json\n","\n","--- Processing file: /content/uploaded_json_files/Chandigarh University (1).json ---\n","Loaded JSON file: /content/uploaded_json_files/Chandigarh University (1).json\n","üìä Found NIRF data with 12 points\n","üîÑ Processing 12 items for vectorization...\n","‚úÖ Generated vector for Chandigarh University - HEADER (dim: 384)\n","‚úÖ Generated vector for Chandigarh University - SANCTIONED_INTAKE (dim: 384)\n","‚úÖ Generated vector for Chandigarh University - STUDENT_STRENGTH (dim: 384)\n","‚úÖ Generated vector for Chandigarh University - PLACEMENT_STUDIES (dim: 384)\n","‚úÖ Generated vector for Chandigarh University - PHD_DETAILS (dim: 384)\n","‚úÖ Generated vector for Chandigarh University - FINANCIAL_RESOURCES (dim: 384)\n","‚úÖ Generated vector for Chandigarh University - FINANCIAL_RESOURCES (dim: 384)\n","‚úÖ Generated vector for Chandigarh University - SPONSORED_RESEARCH (dim: 384)\n","‚úÖ Generated vector for Chandigarh University - CONSULTANCY_PROJECTS (dim: 384)\n","‚úÖ Generated vector for Chandigarh University - PCS_FACILITIES (dim: 384)\n","‚úÖ Generated vector for Chandigarh University - FACULTY_DETAILS (dim: 384)\n","‚úÖ Generated vector for Chandigarh University - students_strength (dim: 384)\n","‚úÖ Successfully processed 12 points\n","Uploading 12 points in batches of 100\n","Uploaded batch 1/1: 12 points\n","Successfully uploaded 12 points from /content/uploaded_json_files/Chandigarh University (1).json\n","\n","--- Processing file: /content/uploaded_json_files/Siddaganga Institute of Technology (1).json ---\n","Loaded JSON file: /content/uploaded_json_files/Siddaganga Institute of Technology (1).json\n","üìä Found NIRF data with 12 points\n","üîÑ Processing 12 items for vectorization...\n","‚úÖ Generated vector for Siddaganga Institute of Technology - HEADER (dim: 384)\n","‚úÖ Generated vector for Siddaganga Institute of Technology - SANCTIONED_INTAKE (dim: 384)\n","‚úÖ Generated vector for Siddaganga Institute of Technology - STUDENT_STRENGTH (dim: 384)\n","‚úÖ Generated vector for Siddaganga Institute of Technology - PLACEMENT_STUDIES (dim: 384)\n","‚úÖ Generated vector for Siddaganga Institute of Technology - PHD_DETAILS (dim: 384)\n","‚úÖ Generated vector for Siddaganga Institute of Technology - FINANCIAL_RESOURCES (dim: 384)\n","‚úÖ Generated vector for Siddaganga Institute of Technology - FINANCIAL_RESOURCES (dim: 384)\n","‚úÖ Generated vector for Siddaganga Institute of Technology - SPONSORED_RESEARCH (dim: 384)\n","‚úÖ Generated vector for Siddaganga Institute of Technology - CONSULTANCY_PROJECTS (dim: 384)\n","‚úÖ Generated vector for Siddaganga Institute of Technology - PCS_FACILITIES (dim: 384)\n","‚úÖ Generated vector for Siddaganga Institute of Technology - FACULTY_DETAILS (dim: 384)\n","‚úÖ Generated vector for Siddaganga Institute of Technology - students_strength (dim: 384)\n","‚úÖ Successfully processed 12 points\n","Uploading 12 points in batches of 100\n","Uploaded batch 1/1: 12 points\n","Successfully uploaded 12 points from /content/uploaded_json_files/Siddaganga Institute of Technology (1).json\n","\n","--- Processing file: /content/uploaded_json_files/University of Hyderabad (1).json ---\n","Loaded JSON file: /content/uploaded_json_files/University of Hyderabad (1).json\n","üìä Found NIRF data with 12 points\n","üîÑ Processing 12 items for vectorization...\n","‚úÖ Generated vector for University of Hyderabad - HEADER (dim: 384)\n","‚úÖ Generated vector for University of Hyderabad - SANCTIONED_INTAKE (dim: 384)\n","‚úÖ Generated vector for University of Hyderabad - STUDENT_STRENGTH (dim: 384)\n","‚úÖ Generated vector for University of Hyderabad - PLACEMENT_STUDIES (dim: 384)\n","‚úÖ Generated vector for University of Hyderabad - PG_PLACEMENT (dim: 384)\n","‚úÖ Generated vector for University of Hyderabad - PHD_DETAILS (dim: 384)\n","‚úÖ Generated vector for University of Hyderabad - FINANCIAL_RESOURCES (dim: 384)\n","‚úÖ Generated vector for University of Hyderabad - SPONSORED_RESEARCH (dim: 384)\n","‚úÖ Generated vector for University of Hyderabad - CONSULTANCY_PROJECTS (dim: 384)\n","‚úÖ Generated vector for University of Hyderabad - PCS_FACILITIES (dim: 384)\n","‚úÖ Generated vector for University of Hyderabad - FACULTY_DETAILS (dim: 384)\n","‚úÖ Generated vector for University of Hyderabad - students_strength (dim: 384)\n","‚úÖ Successfully processed 12 points\n","Uploading 12 points in batches of 100\n","Uploaded batch 1/1: 12 points\n","Successfully uploaded 12 points from /content/uploaded_json_files/University of Hyderabad (1).json\n","\n","--- Processing file: /content/uploaded_json_files/NIT Srinagar (1).json ---\n","Loaded JSON file: /content/uploaded_json_files/NIT Srinagar (1).json\n","üìä Found NIRF data with 12 points\n","üîÑ Processing 12 items for vectorization...\n","‚úÖ Generated vector for National Institute of Technology Srinagar - HEADER (dim: 384)\n","‚úÖ Generated vector for National Institute of Technology Srinagar - SANCTIONED_INTAKE (dim: 384)\n","‚úÖ Generated vector for National Institute of Technology Srinagar - STUDENT_STRENGTH (dim: 384)\n","‚úÖ Generated vector for National Institute of Technology Srinagar - PLACEMENT_STUDIES (dim: 384)\n","‚úÖ Generated vector for National Institute of Technology Srinagar - PHD_DETAILS (dim: 384)\n","‚úÖ Generated vector for National Institute of Technology Srinagar - FINANCIAL_RESOURCES (dim: 384)\n","‚úÖ Generated vector for National Institute of Technology Srinagar - FINANCIAL_RESOURCES (dim: 384)\n","‚úÖ Generated vector for National Institute of Technology Srinagar - SPONSORED_RESEARCH (dim: 384)\n","‚úÖ Generated vector for National Institute of Technology Srinagar - CONSULTANCY_PROJECTS (dim: 384)\n","‚úÖ Generated vector for National Institute of Technology Srinagar - PCS_FACILITIES (dim: 384)\n","‚úÖ Generated vector for National Institute of Technology Srinagar - FACULTY_DETAILS (dim: 384)\n","‚úÖ Generated vector for National Institute of Technology Srinagar - students_strength (dim: 384)\n","‚úÖ Successfully processed 12 points\n","Uploading 12 points in batches of 100\n","Uploaded batch 1/1: 12 points\n","Successfully uploaded 12 points from /content/uploaded_json_files/NIT Srinagar (1).json\n","\n","--- Processing file: /content/uploaded_json_files/Shanmugha Arts Science Technology and Research Academy (1).json ---\n","Loaded JSON file: /content/uploaded_json_files/Shanmugha Arts Science Technology and Research Academy (1).json\n","üìä Found NIRF data with 13 points\n","üîÑ Processing 13 items for vectorization...\n","‚úÖ Generated vector for Shanmugha Arts Science Technology and Research Academy - HEADER (dim: 384)\n","‚úÖ Generated vector for Shanmugha Arts Science Technology and Research Academy - SANCTIONED_INTAKE (dim: 384)\n","‚úÖ Generated vector for Shanmugha Arts Science Technology and Research Academy - STUDENT_STRENGTH (dim: 384)\n","‚úÖ Generated vector for Shanmugha Arts Science Technology and Research Academy - PLACEMENT_STUDIES (dim: 384)\n","‚úÖ Generated vector for Shanmugha Arts Science Technology and Research Academy - PG_PLACEMENT (dim: 384)\n","‚úÖ Generated vector for Shanmugha Arts Science Technology and Research Academy - PHD_DETAILS (dim: 384)\n","‚úÖ Generated vector for Shanmugha Arts Science Technology and Research Academy - FINANCIAL_RESOURCES (dim: 384)\n","‚úÖ Generated vector for Shanmugha Arts Science Technology and Research Academy - FINANCIAL_RESOURCES (dim: 384)\n","‚úÖ Generated vector for Shanmugha Arts Science Technology and Research Academy - SPONSORED_RESEARCH (dim: 384)\n","‚úÖ Generated vector for Shanmugha Arts Science Technology and Research Academy - CONSULTANCY_PROJECTS (dim: 384)\n","‚úÖ Generated vector for Shanmugha Arts Science Technology and Research Academy - PCS_FACILITIES (dim: 384)\n","‚úÖ Generated vector for Shanmugha Arts Science Technology and Research Academy - FACULTY_DETAILS (dim: 384)\n","‚úÖ Generated vector for Shanmugha Arts Science Technology and Research Academy - students_strength (dim: 384)\n","‚úÖ Successfully processed 13 points\n","Uploading 13 points in batches of 100\n","Uploaded batch 1/1: 13 points\n","Successfully uploaded 13 points from /content/uploaded_json_files/Shanmugha Arts Science Technology and Research Academy (1).json\n","\n","--- Processing file: /content/uploaded_json_files/IIT Madras (1).json ---\n","Loaded JSON file: /content/uploaded_json_files/IIT Madras (1).json\n","üìä Found NIRF data with 12 points\n","üîÑ Processing 12 items for vectorization...\n","‚úÖ Generated vector for Indian Institute of Technology Madras - HEADER (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Technology Madras - SANCTIONED_INTAKE (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Technology Madras - STUDENT_STRENGTH (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Technology Madras - PLACEMENT_STUDIES (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Technology Madras - PHD_DETAILS (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Technology Madras - FINANCIAL_RESOURCES (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Technology Madras - FINANCIAL_RESOURCES (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Technology Madras - SPONSORED_RESEARCH (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Technology Madras - CONSULTANCY_PROJECTS (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Technology Madras - PCS_FACILITIES (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Technology Madras - FACULTY_DETAILS (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Technology Madras - students_strength (dim: 384)\n","‚úÖ Successfully processed 12 points\n","Uploading 12 points in batches of 100\n","Uploaded batch 1/1: 12 points\n","Successfully uploaded 12 points from /content/uploaded_json_files/IIT Madras (1).json\n","\n","--- Processing file: /content/uploaded_json_files/Banasthali Vidyapith (1).json ---\n","Loaded JSON file: /content/uploaded_json_files/Banasthali Vidyapith (1).json\n","üìä Found NIRF data with 12 points\n","üîÑ Processing 12 items for vectorization...\n","‚úÖ Generated vector for Banasthali Vidyapith - HEADER (dim: 384)\n","‚úÖ Generated vector for Banasthali Vidyapith - SANCTIONED_INTAKE (dim: 384)\n","‚úÖ Generated vector for Banasthali Vidyapith - STUDENT_STRENGTH (dim: 384)\n","‚úÖ Generated vector for Banasthali Vidyapith - PLACEMENT_STUDIES (dim: 384)\n","‚úÖ Generated vector for Banasthali Vidyapith - PHD_DETAILS (dim: 384)\n","‚úÖ Generated vector for Banasthali Vidyapith - FINANCIAL_RESOURCES (dim: 384)\n","‚úÖ Generated vector for Banasthali Vidyapith - FINANCIAL_RESOURCES (dim: 384)\n","‚úÖ Generated vector for Banasthali Vidyapith - SPONSORED_RESEARCH (dim: 384)\n","‚úÖ Generated vector for Banasthali Vidyapith - CONSULTANCY_PROJECTS (dim: 384)\n","‚úÖ Generated vector for Banasthali Vidyapith - PCS_FACILITIES (dim: 384)\n","‚úÖ Generated vector for Banasthali Vidyapith - FACULTY_DETAILS (dim: 384)\n","‚úÖ Generated vector for Banasthali Vidyapith - students_strength (dim: 384)\n","‚úÖ Successfully processed 12 points\n","Uploading 12 points in batches of 100\n","Uploaded batch 1/1: 12 points\n","Successfully uploaded 12 points from /content/uploaded_json_files/Banasthali Vidyapith (1).json\n","\n","--- Processing file: /content/uploaded_json_files/IIT Mandi (1).json ---\n","Loaded JSON file: /content/uploaded_json_files/IIT Mandi (1).json\n","üìä Found NIRF data with 12 points\n","üîÑ Processing 12 items for vectorization...\n","‚úÖ Generated vector for Indian Institute of Technology Mandi - HEADER (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Technology Mandi - SANCTIONED_INTAKE (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Technology Mandi - STUDENT_STRENGTH (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Technology Mandi - PLACEMENT_STUDIES (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Technology Mandi - PHD_DETAILS (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Technology Mandi - FINANCIAL_RESOURCES (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Technology Mandi - FINANCIAL_RESOURCES (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Technology Mandi - SPONSORED_RESEARCH (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Technology Mandi - CONSULTANCY_PROJECTS (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Technology Mandi - PCS_FACILITIES (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Technology Mandi - FACULTY_DETAILS (dim: 384)\n","‚úÖ Generated vector for Indian Institute of Technology Mandi - students_strength (dim: 384)\n","‚úÖ Successfully processed 12 points\n","Uploading 12 points in batches of 100\n","Uploaded batch 1/1: 12 points\n","Successfully uploaded 12 points from /content/uploaded_json_files/IIT Mandi (1).json\n","\n","==================================================\n","UPLOAD SUMMARY\n","==================================================\n","Total files processed: 98\n","Successful uploads: 98\n","Failed uploads: 0\n","Total points uploaded: 1190\n","\n","==================================================\n","POST-UPLOAD VALIDATION AND SEARCH TEST\n","==================================================\n","Collection 'durden' info:\n","- Points count: 1190\n","- Vector size: 384\n","- Distance metric: Cosine\n","\n","üìä NIRF Data Validation Report\n","==================================================\n","Total Points: 1190\n","\n","üîç Sample Data Check:\n","\n","Sample 1:\n","  - Institute: National Institute of Technology Warangal\n","  - Content Type: STUDENT_STRENGTH\n","  - Source File: NIT Warangal (1)\n","  - Has Vector: ‚ùå\n","  - Metadata Fields: 14 fields preserved\n","\n","Sample 2:\n","  - Institute: Guru Gobind Singh Indraprastha University\n","  - Content Type: PHD_DETAILS\n","  - Source File: Guru Gobind Singh Indraprastha University (1)\n","  - Has Vector: ‚ùå\n","  - Metadata Fields: 14 fields preserved\n","\n","Sample 3:\n","  - Institute: Thapar Institute of Engineering and Technology (Deemed-to-be-university)\n","  - Content Type: STUDENT_STRENGTH\n","  - Source File: Thapar Institute of Engineering and Technology _Deemed-to-be-university (1)\n","  - Has Vector: ‚ùå\n","  - Metadata Fields: 14 fields preserved\n","\n","üß™ Testing search functionality...\n","\n","üîç NIRF Search Results for: 'faculty student ratio'\n","\n","--- Result 1 (Score: 0.5015) ---\n","üèõÔ∏è  Institute: UPES\n","üè∑Ô∏è  Code: IR-E-U-0564\n","üìä Type: FACULTY_DETAILS\n","üìÑ Content: Number of faculty members entered 509...\n","üìÅ Source: UPES (1)\n","\n","--- Result 2 (Score: 0.4955) ---\n","üèõÔ∏è  Institute: SR University\n","üè∑Ô∏è  Code: IR-E-C-19754\n","üìä Type: FACULTY_DETAILS\n","üìÑ Content: Number of faculty members entered 296...\n","üìÅ Source: SR University Warangal (1)\n","\n","--- Result 3 (Score: 0.4674) ---\n","üèõÔ∏è  Institute: R.V. College of Engineering\n","üè∑Ô∏è  Code: IR-E-C-1269\n","üìä Type: students_strength\n","üìÑ Content: Students Strength - UG 4 Years: 5050, PG 2 Years: 466, Total Students: 5516...\n","üìÅ Source: R.V. College of Engineering (1)\n","\n","--- Result 4 (Score: 0.4618) ---\n","üèõÔ∏è  Institute: Graphic Era University\n","üè∑Ô∏è  Code: IR-E-U-0555\n","üìä Type: students_strength\n","üìÑ Content: Students Strength - UG 4 Years: 4528, PG 2 Years: 90, Total Students: 4618...\n","üìÅ Source: Engineering  2024 (1)\n","\n","--- Result 5 (Score: 0.4606) ---\n","üèõÔ∏è  Institute: COEP Technological University\n","üè∑Ô∏è  Code: IR-E-C-41593\n","üìä Type: students_strength\n","üìÑ Content: Students Strength - UG 4 Years: 3134, PG 2 Years: 534, Total Students: 3668...\n","üìÅ Source: COEP Technological University (1)\n","\n","üéØ Testing filtered searches...\n","\n","--- Searching for 'faculty student ratio' with 'STUDENT_STRENGTH' filter ---\n","‚ùå Search failed: Unexpected Response: 400 (Bad Request)\n","Raw response content:\n","b'{\"status\":{\"error\":\"Bad request: Index required but not found for \\\\\"content_type\\\\\" of one of the following types: [keyword]. Help: Create an index for this key or use a different filter.\"},\"time\":3 ...'\n","\n","--- Searching for 'faculty student ratio' with 'PLACEMENT_STUDIES' filter ---\n","‚ùå Search failed: Unexpected Response: 400 (Bad Request)\n","Raw response content:\n","b'{\"status\":{\"error\":\"Bad request: Index required but not found for \\\\\"content_type\\\\\" of one of the following types: [keyword]. Help: Create an index for this key or use a different filter.\"},\"time\":2 ...'\n","\n","--- Searching for 'faculty student ratio' with 'FINANCIAL_RESOURCES' filter ---\n","‚ùå Search failed: Unexpected Response: 400 (Bad Request)\n","Raw response content:\n","b'{\"status\":{\"error\":\"Bad request: Index required but not found for \\\\\"content_type\\\\\" of one of the following types: [keyword]. Help: Create an index for this key or use a different filter.\"},\"time\":3 ...'\n","\n","‚úÖ Upload process completed successfully!\n"]},{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-1371213218.py:378: DeprecationWarning: `search` method is deprecated and will be removed in the future. Use `query_points` instead.\n","  results = self.client.search(\n"]}],"source":["import json\n","import os\n","import sys\n","import logging\n","from typing import List, Dict, Any, Optional\n","import uuid\n","from pathlib import Path\n","from qdrant_client import QdrantClient\n","from qdrant_client.models import Distance, VectorParams, PointStruct, Filter, FieldCondition, MatchValue\n","from datetime import datetime\n","import warnings\n","\n","# Suppress harmless Sentence-Transformers warnings\n","warnings.filterwarnings(\"ignore\", category=UserWarning, module='huggingface_hub.file_download')\n","\n","\n","# --- Core Functions: Environment Setup & Embedding Model Loading ---\n","def setup_environment():\n","    \"\"\"Detect environment and install dependencies\"\"\"\n","    try:\n","        import google.colab\n","        IN_COLAB = True\n","        print(\"Running in Google Colab\")\n","    except ImportError:\n","        IN_COLAB = False\n","        print(\"Running in local environment\")\n","\n","    try:\n","        import qdrant_client\n","        print(\"qdrant-client already installed\")\n","    except ImportError:\n","        print(\"Installing qdrant-client...\")\n","        if IN_COLAB:\n","            os.system(\"pip install qdrant-client\")\n","        else:\n","            os.system(f\"{sys.executable} -m pip install qdrant-client\")\n","\n","    global QdrantClient, Distance, VectorParams, PointStruct\n","    from qdrant_client import QdrantClient\n","    from qdrant_client.models import Distance, VectorParams, PointStruct, Filter, FieldCondition, MatchValue\n","\n","\n","def setup_embedding_model():\n","    \"\"\"Setup sentence transformer for embeddings\"\"\"\n","    try:\n","        from sentence_transformers import SentenceTransformer\n","        print(\"sentence-transformers already installed\")\n","    except ImportError:\n","        print(\"Installing sentence-transformers...\")\n","        try:\n","            import google.colab\n","            os.system(\"pip install sentence-transformers\")\n","        except ImportError:\n","            os.system(f\"{sys.executable} -m pip install sentence-transformers\")\n","        from sentence_transformers import SentenceTransformer\n","\n","    try:\n","        model = SentenceTransformer('all-MiniLM-L6-v2')  # 384 dimensions\n","        print(\"Embedding model loaded successfully\")\n","        return model\n","    except Exception as e:\n","        print(f\"‚ùå Failed to load embedding model: {e}\")\n","        return None\n","\n","\n","# Run setup functions\n","setup_environment()\n","EMBEDDING_MODEL = setup_embedding_model()\n","\n","\n","# --- Qdrant Uploader Class (Enhanced) ---\n","class QdrantUploader:\n","    def __init__(self):\n","        self.QDRANT_URL = \"https://b5651607-31ce-49ba-916d-c35c89d731d2.us-east4-0.gcp.cloud.qdrant.io\"\n","        self.QDRANT_API_KEY = \"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJhY2Nlc3MiOiJtIn0.0ApHZL4Qn_A8bx7FCC62nx-IOrHI84W7GZlUZEyVgKk\"\n","        self.COLLECTION_NAME = \"durden\"\n","\n","        # Initialize Qdrant client\n","        try:\n","            self.client = QdrantClient(\n","                url=self.QDRANT_URL,\n","                api_key=self.QDRANT_API_KEY\n","            )\n","            print(\"Connected to Qdrant successfully\")\n","        except Exception as e:\n","            print(f\"Failed to connect to Qdrant: {str(e)}\")\n","            raise\n","\n","        logging.basicConfig(\n","            level=logging.INFO,\n","            format='%(asctime)s - %(levelname)s - %(message)s'\n","        )\n","        self.logger = logging.getLogger(__name__)\n","\n","    def ensure_collection_exists(self, vector_size: int = 384):\n","        \"\"\"Create collection if it doesn't exist\"\"\"\n","        try:\n","            collections = self.client.get_collections()\n","            collection_names = [col.name for col in collections.collections]\n","\n","            if self.COLLECTION_NAME not in collection_names:\n","                print(f\"Creating collection: {self.COLLECTION_NAME}\")\n","                self.client.create_collection(\n","                    collection_name=self.COLLECTION_NAME,\n","                    vectors_config=VectorParams(\n","                        size=vector_size,\n","                        distance=Distance.COSINE\n","                    )\n","                )\n","                print(f\"‚úÖ Collection {self.COLLECTION_NAME} created successfully\")\n","                print(f\"üìä Vector size: {vector_size}\")\n","                print(f\"üìè Distance metric: COSINE\")\n","            else:\n","                print(f\"‚úÖ Collection {self.COLLECTION_NAME} already exists\")\n","        except Exception as e:\n","            print(f\"‚ùå Error ensuring collection exists: {str(e)}\")\n","            raise\n","\n","    def load_json_file(self, file_path: str) -> Dict[str, Any]:\n","        \"\"\"Load and parse JSON file\"\"\"\n","        try:\n","            with open(file_path, 'r', encoding='utf-8') as file:\n","                data = json.load(file)\n","                print(f\"Loaded JSON file: {file_path}\")\n","                return data\n","        except Exception as e:\n","            print(f\"Error loading JSON file {file_path}: {str(e)}\")\n","            raise\n","\n","    def prepare_points_from_json(self, json_data: Dict[str, Any], file_name: str = \"\") -> List[PointStruct]:\n","        \"\"\"\n","        Convert NIRF JSON data to Qdrant points with vector embeddings.\n","        - Handles the nested NIRF structure.\n","        - Creates a rich text string for embedding.\n","        - Preserves all original metadata in the payload.\n","        \"\"\"\n","        points = []\n","        skipped_count = 0\n","\n","        if EMBEDDING_MODEL is None:\n","            print(\"‚ùå Embedding model not available!\")\n","            return []\n","\n","        data_items = []\n","        if 'points' in json_data:\n","            data_items = json_data['points']\n","            print(f\"üìä Found NIRF data with {json_data.get('total_points', len(data_items))} points\")\n","        elif isinstance(json_data, list):\n","            data_items = json_data\n","        elif isinstance(json_data, dict):\n","            data_items = [json_data]\n","        else:\n","            print(\"‚ùå Unsupported JSON structure\")\n","            return []\n","\n","        print(f\"üîÑ Processing {len(data_items)} items for vectorization...\")\n","\n","        for i, item in enumerate(data_items):\n","            try:\n","                # Assuming the NIRF data has a 'payload' key\n","                if isinstance(item, dict) and 'payload' in item:\n","                    payload_data = item['payload'].copy()\n","                    original_id = item.get('id', f\"{file_name}_{i}_{str(uuid.uuid4())[:8]}\")\n","\n","                    # Create comprehensive content string for embedding\n","                    content_parts = []\n","                    if 'institute_name' in payload_data:\n","                        content_parts.append(f\"Institute: {payload_data['institute_name']}\")\n","                    if 'institute_code' in payload_data:\n","                        content_parts.append(f\"Code: {payload_data['institute_code']}\")\n","                    if 'content_type' in payload_data:\n","                        content_parts.append(f\"Content Type: {payload_data['content_type']}\")\n","                    if 'content' in payload_data and payload_data['content']:\n","                        content_parts.append(f\"Content: {payload_data['content']}\")\n","\n","                    content_text = \" | \".join(content_parts)\n","\n","                    # Preserve ALL original metadata and add new, useful fields\n","                    enhanced_payload = {\n","                        **payload_data,  # Unpack original payload data\n","                        'original_id': original_id,\n","                        'source_file': file_name,\n","                        'item_index': i,\n","                        'vector_model': 'all-MiniLM-L6-v2',\n","                        'upload_timestamp': datetime.now().isoformat(),\n","                        'content_for_embedding': content_text,\n","                        'data_type': 'NIRF_REPORT',\n","                    }\n","\n","                else:\n","                    # Fallback for other JSON structures\n","                    content_text = str(item)\n","                    enhanced_payload = {\n","                        'original_data': item,\n","                        'source_file': file_name,\n","                        'item_index': i,\n","                        'vector_model': 'all-MiniLM-L6-v2',\n","                        'upload_timestamp': datetime.now().isoformat(),\n","                        'content_for_embedding': content_text\n","                    }\n","                    original_id = f\"{file_name}_{i}_{str(uuid.uuid4())[:8]}\"\n","\n","                # Skip if no meaningful content\n","                if not content_text or content_text.strip() == \"\":\n","                    print(f\"‚ö†Ô∏è  Skipping item {i+1}: No content found\")\n","                    skipped_count += 1\n","                    continue\n","\n","                # Generate vector embedding\n","                try:\n","                    vector = EMBEDDING_MODEL.encode(content_text).tolist()\n","                    institute_name = enhanced_payload.get('institute_name', 'item')\n","                    content_type = enhanced_payload.get('content_type', 'unknown')\n","                    print(f\"‚úÖ Generated vector for {institute_name} - {content_type} (dim: {len(vector)})\")\n","                except Exception as e:\n","                    print(f\"‚ùå Vector generation failed for item {i+1}: {e}\")\n","                    skipped_count += 1\n","                    continue\n","\n","                # Create point with preserved metadata\n","                point = PointStruct(\n","                    id=str(original_id),\n","                    vector=vector,\n","                    payload=enhanced_payload\n","                )\n","                points.append(point)\n","\n","            except Exception as e:\n","                print(f\"‚ùå Error processing item {i+1}: {str(e)}\")\n","                skipped_count += 1\n","                continue\n","\n","        print(f\"‚úÖ Successfully processed {len(points)} points\")\n","        if skipped_count > 0:\n","            print(f\"‚ö†Ô∏è  Skipped {skipped_count} items\")\n","        return points\n","\n","    def upload_batch(self, points: List[PointStruct], batch_size: int = 100):\n","        \"\"\"Upload points in batches with progress tracking\"\"\"\n","        total_points = len(points)\n","        print(f\"Uploading {total_points} points in batches of {batch_size}\")\n","\n","        for i in range(0, total_points, batch_size):\n","            batch = points[i:i + batch_size]\n","            try:\n","                self.client.upsert(\n","                    collection_name=self.COLLECTION_NAME,\n","                    points=batch\n","                )\n","                batch_num = i // batch_size + 1\n","                total_batches = (total_points + batch_size - 1) // batch_size\n","                print(f\"Uploaded batch {batch_num}/{total_batches}: {len(batch)} points\")\n","            except Exception as e:\n","                print(f\"Error uploading batch {i//batch_size + 1}: {str(e)}\")\n","                raise\n","\n","    def upload_json_file(self, file_path: str):\n","        \"\"\"Upload a single JSON file to Qdrant\"\"\"\n","        print(f\"\\n--- Processing file: {file_path} ---\")\n","        file_name = Path(file_path).stem\n","        json_data = self.load_json_file(file_path)\n","        points = self.prepare_points_from_json(json_data, file_name)\n","\n","        if not points:\n","            print(f\"No valid points found in {file_path}\")\n","            return 0\n","\n","        self.upload_batch(points)\n","        print(f\"Successfully uploaded {len(points)} points from {file_path}\")\n","        return len(points)\n","\n","    def upload_folder(self, folder_path: str):\n","        \"\"\"Upload all JSON files from a folder\"\"\"\n","        folder = Path(folder_path)\n","        if not folder.exists():\n","            raise FileNotFoundError(f\"Folder not found: {folder_path}\")\n","\n","        json_files = list(folder.glob(\"*.json\"))\n","        if not json_files:\n","            print(f\"No JSON files found in {folder_path}\")\n","            return\n","\n","        print(f\"\\nFound {len(json_files)} JSON files to process\")\n","        print(\"Files:\", [f.name for f in json_files])\n","\n","        vector_size = 384\n","        print(f\"Using embedding model vector size: {vector_size}\")\n","        self.ensure_collection_exists(vector_size)\n","\n","        total_points = 0\n","        successful_files = 0\n","        failed_files = []\n","\n","        for json_file in json_files:\n","            try:\n","                points_uploaded = self.upload_json_file(str(json_file))\n","                if points_uploaded > 0:\n","                    successful_files += 1\n","                    total_points += points_uploaded\n","            except Exception as e:\n","                print(f\"Failed to process {json_file.name}: {str(e)}\")\n","                failed_files.append(json_file.name)\n","                continue\n","\n","        print(f\"\\n{'='*50}\")\n","        print(f\"UPLOAD SUMMARY\")\n","        print(f\"{'='*50}\")\n","        print(f\"Total files processed: {len(json_files)}\")\n","        print(f\"Successful uploads: {successful_files}\")\n","        print(f\"Failed uploads: {len(failed_files)}\")\n","        print(f\"Total points uploaded: {total_points}\")\n","        if failed_files:\n","            print(f\"Failed files: {failed_files}\")\n","\n","    def get_collection_info(self):\n","        \"\"\"Get information about the collection\"\"\"\n","        try:\n","            info = self.client.get_collection(self.COLLECTION_NAME)\n","            print(f\"Collection '{self.COLLECTION_NAME}' info:\")\n","            print(f\"- Points count: {info.points_count}\")\n","            print(f\"- Vector size: {info.config.params.vectors.size}\")\n","            print(f\"- Distance metric: {info.config.params.vectors.distance}\")\n","            return info\n","        except Exception as e:\n","            print(f\"Error getting collection info: {str(e)}\")\n","            return None\n","\n","    def validate_nirf_upload(self):\n","        \"\"\"Validate the uploaded NIRF data\"\"\"\n","        try:\n","            info = self.client.get_collection(self.COLLECTION_NAME)\n","            print(f\"\\nüìä NIRF Data Validation Report\")\n","            print(f\"=\" * 50)\n","            print(f\"Total Points: {info.points_count}\")\n","\n","            sample_results = self.client.scroll(\n","                collection_name=self.COLLECTION_NAME,\n","                limit=3,\n","                with_payload=True\n","            )\n","\n","            print(f\"\\nüîç Sample Data Check:\")\n","            if not sample_results[0]:\n","                print(\"No points found to sample.\")\n","                return\n","\n","            for i, point in enumerate(sample_results[0]):\n","                payload = point.payload\n","                print(f\"\\nSample {i+1}:\")\n","                print(f\"  - Institute: {payload.get('institute_name', 'N/A')}\")\n","                print(f\"  - Content Type: {payload.get('content_type', 'N/A')}\")\n","                print(f\"  - Source File: {payload.get('source_file', 'N/A')}\")\n","                print(f\"  - Has Vector: {'‚úÖ' if point.vector else '‚ùå'}\")\n","                print(f\"  - Metadata Fields: {len(payload)} fields preserved\")\n","        except Exception as e:\n","            print(f\"‚ùå Validation failed: {str(e)}\")\n","\n","    def search_nirf_data(self, query_text: str, limit: int = 5, content_type_filter: str = None):\n","        \"\"\"Enhanced search for NIRF data with filtering options\"\"\"\n","        try:\n","            if EMBEDDING_MODEL is None:\n","                print(\"‚ùå Embedding model not available\")\n","                return None\n","            query_vector = EMBEDDING_MODEL.encode(query_text).tolist()\n","\n","            # Build filter for NIRF data\n","            search_filter = None\n","            if content_type_filter:\n","                search_filter = Filter(\n","                    must=[\n","                        FieldCondition(\n","                            key=\"content_type\",\n","                            match=MatchValue(value=content_type_filter)\n","                        )\n","                    ]\n","                )\n","\n","            results = self.client.search(\n","                collection_name=self.COLLECTION_NAME,\n","                query_vector=query_vector,\n","                limit=limit,\n","                query_filter=search_filter,\n","                with_payload=True\n","            )\n","            print(f\"\\nüîç NIRF Search Results for: '{query_text}'\")\n","            if content_type_filter:\n","                print(f\"üìã Filtered by content type: {content_type_filter}\")\n","\n","            if not results:\n","                print(\"‚ùå No results found\")\n","                return None\n","\n","            for i, point in enumerate(results):\n","                payload = point.payload\n","                print(f\"\\n--- Result {i+1} (Score: {point.score:.4f}) ---\")\n","                print(f\"üèõÔ∏è  Institute: {payload.get('institute_name', 'N/A')}\")\n","                print(f\"üè∑Ô∏è  Code: {payload.get('institute_code', 'N/A')}\")\n","                print(f\"üìä Type: {payload.get('content_type', 'N/A')}\")\n","                content = payload.get('content', '')[:200].replace('\\n', ' ')\n","                print(f\"üìÑ Content: {content}...\")\n","                print(f\"üìÅ Source: {payload.get('source_file', 'N/A')}\")\n","            return results\n","        except Exception as e:\n","            print(f\"‚ùå Search failed: {str(e)}\")\n","            return None\n","\n","    def search_test(self, query_text: str = \"faculty student ratio\", limit: int = 5):\n","        \"\"\"Test search functionality with NIRF-specific examples\"\"\"\n","        print(f\"\\nüß™ Testing search functionality...\")\n","\n","        # Test general search\n","        self.search_nirf_data(query_text, limit)\n","\n","        # Test filtered searches for NIRF data\n","        print(f\"\\nüéØ Testing filtered searches...\")\n","        content_types = [\"STUDENT_STRENGTH\", \"PLACEMENT_STUDIES\", \"FINANCIAL_RESOURCES\"]\n","        for content_type in content_types:\n","            print(f\"\\n--- Searching for '{query_text}' with '{content_type}' filter ---\")\n","            self.search_nirf_data(query_text, limit=2, content_type_filter=content_type)\n","\n","\n","# --- User Input & Main Execution ---\n","def upload_files_from_system():\n","    \"\"\"Upload files directly from user's system in Google Colab\"\"\"\n","    try:\n","        from google.colab import files\n","        import zipfile\n","        import os\n","    except ImportError:\n","        print(\"‚ùå This function only works in Google Colab!\")\n","        return None\n","\n","    print(\"\\n\" + \"=\"*60)\n","    print(\"üìÅ FILE UPLOAD FROM YOUR SYSTEM\")\n","    print(\"=\"*60)\n","    print(\"Choose one of the following options:\")\n","    print(\"1Ô∏è‚É£ ¬†Upload individual JSON files\")\n","    print(\"2Ô∏è‚É£ ¬†Upload a ZIP file containing your JSON files (Recommended)\")\n","    print(\"-\" * 60)\n","\n","    choice = input(\"Enter your choice (1 or 2): \").strip()\n","    if choice == \"1\":\n","        print(\"\\nüì§ Please select your JSON files from your computer...\")\n","        uploaded = files.upload()\n","        upload_folder = \"/content/uploaded_json_files\"\n","        os.makedirs(upload_folder, exist_ok=True)\n","        json_count = 0\n","        for filename, content in uploaded.items():\n","            if filename.endswith('.json'):\n","                file_path = os.path.join(upload_folder, filename)\n","                with open(file_path, 'wb') as f:\n","                    f.write(content)\n","                json_count += 1\n","                print(f\"‚úÖ Saved: {filename}\")\n","        if json_count > 0:\n","            print(f\"\\nüéâ Successfully uploaded {json_count} JSON file(s) to {upload_folder}\")\n","            return upload_folder\n","        else:\n","            print(\"‚ùå No JSON files were uploaded!\")\n","            return None\n","    elif choice == \"2\":\n","        print(\"\\nüì§ Please select a ZIP file containing your JSON files...\")\n","        uploaded = files.upload()\n","        for filename, content in uploaded.items():\n","            if filename.endswith('.zip'):\n","                zip_path = f\"/content/{filename}\"\n","                with open(zip_path, 'wb') as f:\n","                    f.write(content)\n","                extract_folder = \"/content/uploaded_json_files\"\n","                os.makedirs(extract_folder, exist_ok=True)\n","                try:\n","                    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n","                        zip_ref.extractall(extract_folder)\n","                    json_files = list(Path(extract_folder).glob(\"*.json\"))\n","                    if json_files:\n","                        print(f\"\\nüéâ Successfully extracted ZIP file!\")\n","                        print(f\"üìä Found {len(json_files)} JSON files\")\n","                        os.remove(zip_path)\n","                        return extract_folder\n","                    else:\n","                        print(\"‚ùå No JSON files found in the ZIP archive!\")\n","                        return None\n","                except zipfile.BadZipFile:\n","                    print(\"‚ùå Invalid ZIP file!\")\n","                    return None\n","            else:\n","                print(\"‚ùå Please upload a ZIP file!\")\n","                return None\n","    else:\n","        print(\"‚ùå Invalid choice! Please enter 1 or 2.\")\n","        return None\n","\n","def get_user_input():\n","    \"\"\"Get folder or file path from user input or upload files\"\"\"\n","    try:\n","        import google.colab\n","        IN_COLAB = True\n","    except ImportError:\n","        IN_COLAB = False\n","\n","    if IN_COLAB:\n","        print(\"\\n\" + \"=\"*60)\n","        print(\"üöÄ GOOGLE COLAB DETECTED\")\n","        print(\"=\"*60)\n","        print(\"Choose how you want to provide your JSON files:\")\n","        print(\"1Ô∏è‚É£ ¬†Upload files from your computer (Recommended)\")\n","        print(\"2Ô∏è‚É£ ¬†Enter a path to files already in Colab\")\n","        print(\"3Ô∏è‚É£ ¬†Use Google Drive (you need to mount it first)\")\n","        print(\"-\" * 60)\n","        option = input(\"Enter your choice (1, 2, or 3): \").strip()\n","        if option == \"1\":\n","            return upload_files_from_system()\n","        elif option == \"2\":\n","            path_input = input(\"Enter path: \").strip()\n","            return path_input.strip('\"').strip(\"'\") if path_input else None\n","        elif option == \"3\":\n","            print(\"\\nüìÅ To use Google Drive, first run this command:\")\n","            print(\"from google.colab import drive\")\n","            print(\"drive.mount('/content/drive')\")\n","            print(\"\\nThen use paths like: /content/drive/MyDrive/your_folder\")\n","            path_input = input(\"Enter Google Drive path: \").strip()\n","            return path_input.strip('\"').strip(\"'\") if path_input else None\n","        else:\n","            print(\"‚ùå Invalid choice!\")\n","            return None\n","    else:\n","        print(\"\\n\" + \"=\"*60)\n","        print(\"QDRANT UPLOADER - LOCAL MODE\")\n","        print(\"=\"*60)\n","        print(\"Please provide the path to your JSON files:\")\n","        print(\"- For a single file: /path/to/file.json\")\n","        print(\"- For a folder: /path/to/folder/\")\n","        print(\"-\" * 60)\n","        path_input = input(\"Enter path: \").strip()\n","        return path_input.strip('\"').strip(\"'\") if path_input else None\n","\n","def upload_interactive():\n","    \"\"\"Interactive upload function that asks for user input and runs the full process\"\"\"\n","    uploader = QdrantUploader()\n","    user_path = get_user_input()\n","    if not user_path:\n","        print(\"‚ùå No valid path or files provided!\")\n","        return\n","\n","    path = Path(user_path)\n","    try:\n","        if not path.exists():\n","            print(f\"‚ùå Path does not exist: {user_path}\")\n","            print(\"Please check your path and try again.\")\n","            return\n","\n","        if path.is_file() and path.suffix == '.json':\n","            print(f\"üìÑ Processing single JSON file: {path.name}\")\n","            uploader.upload_json_file(str(path))\n","        elif path.is_dir():\n","            print(f\"üìÅ Processing folder: {path}\")\n","            uploader.upload_folder(str(path))\n","        else:\n","            print(f\"‚ùå Invalid path. Please provide a JSON file or folder containing JSON files.\")\n","            return\n","\n","        print(\"\\n\" + \"=\"*50)\n","        print(\"POST-UPLOAD VALIDATION AND SEARCH TEST\")\n","        print(\"=\"*50)\n","        uploader.get_collection_info()\n","        uploader.validate_nirf_upload()\n","        uploader.search_test()\n","        print(\"\\n‚úÖ Upload process completed successfully!\")\n","    except Exception as e:\n","        print(f\"‚ùå Upload failed: {str(e)}\")\n","\n","if __name__ == \"__main__\":\n","    print(\"Qdrant Uploader - Compatible with Colab and VS Code\")\n","    print(\"=\" * 50)\n","    upload_interactive()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nIui2mNHpiDW","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1762973759443,"user_tz":-330,"elapsed":93014,"user":{"displayName":"Rahul Siddhu","userId":"12007764243202946991"}},"outputId":"87cc4a58-fb1e-4fcf-9609-7749c87d0a16"},"outputs":[{"output_type":"stream","name":"stdout","text":["Upload your faculty data files (e.g., as a .zip or multiple .txt):\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","     <input type=\"file\" id=\"files-44bb53bb-69df-4f0b-b374-d7e5b74ddb8f\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-44bb53bb-69df-4f0b-b374-d7e5b74ddb8f\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script>// Copyright 2017 Google LLC\n","//\n","// Licensed under the Apache License, Version 2.0 (the \"License\");\n","// you may not use this file except in compliance with the License.\n","// You may obtain a copy of the License at\n","//\n","//      http://www.apache.org/licenses/LICENSE-2.0\n","//\n","// Unless required by applicable law or agreed to in writing, software\n","// distributed under the License is distributed on an \"AS IS\" BASIS,\n","// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","// See the License for the specific language governing permissions and\n","// limitations under the License.\n","\n","/**\n"," * @fileoverview Helpers for google.colab Python module.\n"," */\n","(function(scope) {\n","function span(text, styleAttributes = {}) {\n","  const element = document.createElement('span');\n","  element.textContent = text;\n","  for (const key of Object.keys(styleAttributes)) {\n","    element.style[key] = styleAttributes[key];\n","  }\n","  return element;\n","}\n","\n","// Max number of bytes which will be uploaded at a time.\n","const MAX_PAYLOAD_SIZE = 100 * 1024;\n","\n","function _uploadFiles(inputId, outputId) {\n","  const steps = uploadFilesStep(inputId, outputId);\n","  const outputElement = document.getElementById(outputId);\n","  // Cache steps on the outputElement to make it available for the next call\n","  // to uploadFilesContinue from Python.\n","  outputElement.steps = steps;\n","\n","  return _uploadFilesContinue(outputId);\n","}\n","\n","// This is roughly an async generator (not supported in the browser yet),\n","// where there are multiple asynchronous steps and the Python side is going\n","// to poll for completion of each step.\n","// This uses a Promise to block the python side on completion of each step,\n","// then passes the result of the previous step as the input to the next step.\n","function _uploadFilesContinue(outputId) {\n","  const outputElement = document.getElementById(outputId);\n","  const steps = outputElement.steps;\n","\n","  const next = steps.next(outputElement.lastPromiseValue);\n","  return Promise.resolve(next.value.promise).then((value) => {\n","    // Cache the last promise value to make it available to the next\n","    // step of the generator.\n","    outputElement.lastPromiseValue = value;\n","    return next.value.response;\n","  });\n","}\n","\n","/**\n"," * Generator function which is called between each async step of the upload\n"," * process.\n"," * @param {string} inputId Element ID of the input file picker element.\n"," * @param {string} outputId Element ID of the output display.\n"," * @return {!Iterable<!Object>} Iterable of next steps.\n"," */\n","function* uploadFilesStep(inputId, outputId) {\n","  const inputElement = document.getElementById(inputId);\n","  inputElement.disabled = false;\n","\n","  const outputElement = document.getElementById(outputId);\n","  outputElement.innerHTML = '';\n","\n","  const pickedPromise = new Promise((resolve) => {\n","    inputElement.addEventListener('change', (e) => {\n","      resolve(e.target.files);\n","    });\n","  });\n","\n","  const cancel = document.createElement('button');\n","  inputElement.parentElement.appendChild(cancel);\n","  cancel.textContent = 'Cancel upload';\n","  const cancelPromise = new Promise((resolve) => {\n","    cancel.onclick = () => {\n","      resolve(null);\n","    };\n","  });\n","\n","  // Wait for the user to pick the files.\n","  const files = yield {\n","    promise: Promise.race([pickedPromise, cancelPromise]),\n","    response: {\n","      action: 'starting',\n","    }\n","  };\n","\n","  cancel.remove();\n","\n","  // Disable the input element since further picks are not allowed.\n","  inputElement.disabled = true;\n","\n","  if (!files) {\n","    return {\n","      response: {\n","        action: 'complete',\n","      }\n","    };\n","  }\n","\n","  for (const file of files) {\n","    const li = document.createElement('li');\n","    li.append(span(file.name, {fontWeight: 'bold'}));\n","    li.append(span(\n","        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n","        `last modified: ${\n","            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n","                                    'n/a'} - `));\n","    const percent = span('0% done');\n","    li.appendChild(percent);\n","\n","    outputElement.appendChild(li);\n","\n","    const fileDataPromise = new Promise((resolve) => {\n","      const reader = new FileReader();\n","      reader.onload = (e) => {\n","        resolve(e.target.result);\n","      };\n","      reader.readAsArrayBuffer(file);\n","    });\n","    // Wait for the data to be ready.\n","    let fileData = yield {\n","      promise: fileDataPromise,\n","      response: {\n","        action: 'continue',\n","      }\n","    };\n","\n","    // Use a chunked sending to avoid message size limits. See b/62115660.\n","    let position = 0;\n","    do {\n","      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n","      const chunk = new Uint8Array(fileData, position, length);\n","      position += length;\n","\n","      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n","      yield {\n","        response: {\n","          action: 'append',\n","          file: file.name,\n","          data: base64,\n","        },\n","      };\n","\n","      let percentDone = fileData.byteLength === 0 ?\n","          100 :\n","          Math.round((position / fileData.byteLength) * 100);\n","      percent.textContent = `${percentDone}% done`;\n","\n","    } while (position < fileData.byteLength);\n","  }\n","\n","  // All done.\n","  yield {\n","    response: {\n","      action: 'complete',\n","    }\n","  };\n","}\n","\n","scope.google = scope.google || {};\n","scope.google.colab = scope.google.colab || {};\n","scope.google.colab._files = {\n","  _uploadFiles,\n","  _uploadFilesContinue,\n","};\n","})(self);\n","</script> "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Saving Aligarh Muslim University.txt to Aligarh Muslim University.txt\n","Saving Amity University.txt to Amity University.txt\n","Saving Amrita Vishwa Vidyapeetham.txt to Amrita Vishwa Vidyapeetham.txt\n","Saving Anna University.txt to Anna University.txt\n","Saving AU College of Enginnering.txt to AU College of Enginnering.txt\n","Saving Banasthali Vidyapith.txt to Banasthali Vidyapith.txt\n","Saving Birla Institute of Technology  and Science_ Pilani.txt to Birla Institute of Technology  and Science_ Pilani.txt\n","Saving Birla Institute of Technology Ranchi.txt to Birla Institute of Technology Ranchi.txt\n","Saving C.V. Raman Global University_ Odisha.txt to C.V. Raman Global University_ Odisha.txt\n","Saving Chandigarh University.txt to Chandigarh University.txt\n","Saving Chithara University.txt to Chithara University.txt\n","Saving COEP Technological University.txt to COEP Technological University.txt\n","Saving Defence Institute of Adavanced Technology.txt to Defence Institute of Adavanced Technology.txt\n","Saving Delhi Technological University.txt to Delhi Technological University.txt\n","Saving Dr. B R Ambedkar National Institute of Technology Jalandhar.txt to Dr. B R Ambedkar National Institute of Technology Jalandhar.txt\n","Saving Engineering  2024.txt to Engineering  2024.txt\n","Saving Guru Gobind Singh Indraprastha University.txt to Guru Gobind Singh Indraprastha University.txt\n","Saving IIEST Shibpur.txt to IIEST Shibpur.txt\n","Saving IIIT Allahabad.txt to IIIT Allahabad.txt\n","Saving IIIT Hyderabad .txt to IIIT Hyderabad .txt\n","Saving IIT Bhilai.txt to IIT Bhilai.txt\n","Saving IIT Bhuvaneswar.txt to IIT Bhuvaneswar.txt\n","Saving IIT Bombay.txt to IIT Bombay.txt\n","Saving IIT Delhi.txt to IIT Delhi.txt\n","Saving IIT Gandhinagar.txt to IIT Gandhinagar.txt\n","Saving IIT Guwahati.txt to IIT Guwahati.txt\n","Saving IIT Hyderabad.txt to IIT Hyderabad.txt\n","Saving IIT Indore.txt to IIT Indore.txt\n","Saving IIT Jammu.txt to IIT Jammu.txt\n","Saving IIT Jodhpur.txt to IIT Jodhpur.txt\n","Saving IIT Kanpur.txt to IIT Kanpur.txt\n","Saving IIT Kharagpur.txt to IIT Kharagpur.txt\n","Saving IIT Madras.txt to IIT Madras.txt\n","Saving IIT Mandi.txt to IIT Mandi.txt\n","Saving IIT Palakkad.txt to IIT Palakkad.txt\n","Saving IIT Patna.txt to IIT Patna.txt\n","Saving IIT Roorkee 2024.txt to IIT Roorkee 2024.txt\n","Saving IIT Ropar.txt to IIT Ropar.txt\n","Saving IIT Tirupati.txt to IIT Tirupati.txt\n","Saving IIT Varanasi_Banaras Hindu University_.txt to IIT Varanasi_Banaras Hindu University_.txt\n","Saving Indian Institute of Space Science and Technology.txt to Indian Institute of Space Science and Technology.txt\n","Saving Indian Institute of Technology _Indian School of Mines_ Dhanbad.txt to Indian Institute of Technology _Indian School of Mines_ Dhanbad.txt\n","Saving Indraprastha Institute of Information Technology.txt to Indraprastha Institute of Information Technology.txt\n","Saving Institute of Chemical Technology.txt to Institute of Chemical Technology.txt\n","Saving International Institute of Information Technology Bangalore.txt to International Institute of Information Technology Bangalore.txt\n","Saving Jadavpur University.txt to Jadavpur University.txt\n","Saving Jain University_ Bangalore.txt to Jain University_ Bangalore.txt\n","Saving Jamia Millia Islamia.txt to Jamia Millia Islamia.txt\n","Saving Jawaharlal Nehru Technological University.txt to Jawaharlal Nehru Technological University.txt\n","Saving K L College of Engineering_Vaddeswaram_.txt to K L College of Engineering_Vaddeswaram_.txt\n","Saving Kalasalingam Academy of Research and Education.txt to Kalasalingam Academy of Research and Education.txt\n","Saving Kalinga Institute of Industrial Technology.txt to Kalinga Institute of Industrial Technology.txt\n","Saving Lovely Professional University.txt to Lovely Professional University.txt\n","Saving M. S. Ramaiah Institute of Technology.txt to M. S. Ramaiah Institute of Technology.txt\n","Saving Madan Mohan Malaviya University of Technology.txt to Madan Mohan Malaviya University of Technology.txt\n","Saving Malaviya National Institute of Technology.txt to Malaviya National Institute of Technology.txt\n","Saving Manipal Institute of Technology.txt to Manipal Institute of Technology.txt\n","Saving Manipal University_ Jaipur.txt to Manipal University_ Jaipur.txt\n","Saving Maulana Azad National Institute of Technology.txt to Maulana Azad National Institute of Technology.txt\n","Saving Motilal Nehru National Institute of Technology.txt to Motilal Nehru National Institute of Technology.txt\n","Saving Netaji Subhas University of Technology _NSUT_.txt to Netaji Subhas University of Technology _NSUT_.txt\n","Saving NIT  Agartala.txt to NIT  Agartala.txt\n","Saving NIT  Puducherry.txt to NIT  Puducherry.txt\n","Saving NIT calicut.txt to NIT calicut.txt\n","Saving NIT Delhi.txt to NIT Delhi.txt\n","Saving NIT Durgapur.txt to NIT Durgapur.txt\n","Saving NIT Kurukshetra.txt to NIT Kurukshetra.txt\n","Saving NIT Meghalaya.txt to NIT Meghalaya.txt\n","Saving NIT Patna.txt to NIT Patna.txt\n","Saving NIT Raipur.txt to NIT Raipur.txt\n","Saving NIT Rourkela.txt to NIT Rourkela.txt\n","Saving NIT Silchar.txt to NIT Silchar.txt\n","Saving NIT Srinagar.txt to NIT Srinagar.txt\n","Saving NIT Surathkal.txt to NIT Surathkal.txt\n","Saving NIT Tiruchirappalli.txt to NIT Tiruchirappalli.txt\n","Saving NIT Warangal.txt to NIT Warangal.txt\n","Saving PSG College of Technology.txt to PSG College of Technology.txt\n","Saving R.V. College of Engineering.txt to R.V. College of Engineering.txt\n","Saving Rajiv Gandhi Institute of Petroleum Technology.txt to Rajiv Gandhi Institute of Petroleum Technology.txt\n","Saving Sant Longowal Institute of Engineering and Technology.txt to Sant Longowal Institute of Engineering and Technology.txt\n","Saving Sardar Vallabhbhai National Institute of Technology.txt to Sardar Vallabhbhai National Institute of Technology.txt\n","Saving Sathyabama Institute of Science and Technology Chennai.txt to Sathyabama Institute of Science and Technology Chennai.txt\n","Saving Saveetha Institute of Medical and Technical Sciences.txt to Saveetha Institute of Medical and Technical Sciences.txt\n","Saving Shanmugha Arts Science Technology and Research Academy.txt to Shanmugha Arts Science Technology and Research Academy.txt\n","Saving Shoolini University of Biotechnology and Management Science.txt to Shoolini University of Biotechnology and Management Science.txt\n","Saving Siddaganga Institute of Technology.txt to Siddaganga Institute of Technology.txt\n","Saving SR University Warangal.txt to SR University Warangal.txt\n","Saving Sri Krishna College of Engineering and Technology.txt to Sri Krishna College of Engineering and Technology.txt\n","Saving Sri Sivasubramaniya Nadar College of Engineering.txt to Sri Sivasubramaniya Nadar College of Engineering.txt\n","Saving SRM Chennai.txt to SRM Chennai.txt\n","Saving Thapar Institute of Engineering and Technology _Deemed-to-be-university.txt to Thapar Institute of Engineering and Technology _Deemed-to-be-university.txt\n","Saving University of Hyderabad.txt to University of Hyderabad.txt\n","Saving UPES.txt to UPES.txt\n","Saving Vel Tech Rangarajan Dr. Sagunthala R _ D Institute of Science and Technology.txt to Vel Tech Rangarajan Dr. Sagunthala R _ D Institute of Science and Technology.txt\n","Saving Vignan_s Foundation for Science_ Technology and Research.txt to Vignan_s Foundation for Science_ Technology and Research.txt\n","Saving Visvesvaraya National Institute of Technology Nagpur.txt to Visvesvaraya National Institute of Technology Nagpur.txt\n","Saving Visvesvaraya Technological University.txt to Visvesvaraya Technological University.txt\n","Saving VIT Vellore.txt to VIT Vellore.txt\n","üè´ Processing: Aligarh Muslim University\n","    ‚úÖ Found 224 faculty members\n","    üíæ Saved: Aligarh Muslim University_faculty_data.json\n","üè´ Processing: Amity University\n","    ‚ùå No faculty records could be parsed.\n","üè´ Processing: Amrita Vishwa Vidyapeetham\n","    ‚úÖ Found 951 faculty members\n","    üíæ Saved: Amrita Vishwa Vidyapeetham_faculty_data.json\n","üè´ Processing: Anna University\n","    ‚úÖ Found 890 faculty members\n","    üíæ Saved: Anna University_faculty_data.json\n","üè´ Processing: AU College of Enginnering\n","    ‚ùå No faculty records could be parsed.\n","üè´ Processing: Banasthali Vidyapith\n","    ‚ùå No faculty records could be parsed.\n","üè´ Processing: Birla Institute of Technology  and Science_ Pilani\n","    ‚ùå No faculty records could be parsed.\n","üè´ Processing: Birla Institute of Technology Ranchi\n","    ‚ùå No faculty records could be parsed.\n","üè´ Processing: C.V. Raman Global University_ Odisha\n","    ‚ùå No faculty records could be parsed.\n","üè´ Processing: Chandigarh University\n","    ‚ùå No faculty records could be parsed.\n","üè´ Processing: Chithara University\n","    ‚ùå No faculty records could be parsed.\n","üè´ Processing: COEP Technological University\n","    ‚ùå No faculty records could be parsed.\n","üè´ Processing: Defence Institute of Adavanced Technology\n","    ‚ùå No faculty records could be parsed.\n","üè´ Processing: Delhi Technological University\n","    ‚ùå No faculty records could be parsed.\n","üè´ Processing: Dr. B R Ambedkar National Institute of Technology Jalandhar\n","    ‚ùå No faculty records could be parsed.\n","üè´ Processing: Engineering  2024\n","    ‚ùå No faculty records could be parsed.\n","üè´ Processing: Guru Gobind Singh Indraprastha University\n","    ‚ùå No faculty records could be parsed.\n","üè´ Processing: IIEST Shibpur\n","    ‚ùå No faculty records could be parsed.\n","üè´ Processing: IIIT Allahabad\n","    ‚ùå No faculty records could be parsed.\n","üè´ Processing: IIIT Hyderabad \n","    ‚ùå No faculty records could be parsed.\n","üè´ Processing: IIT Bhilai\n","    ‚ùå No faculty records could be parsed.\n","üè´ Processing: IIT Bhuvaneswar\n","    ‚ùå No faculty records could be parsed.\n","üè´ Processing: IIT Bombay\n","    ‚ùå No faculty records could be parsed.\n","üè´ Processing: IIT Delhi\n","    ‚ùå No faculty records could be parsed.\n","üè´ Processing: IIT Gandhinagar\n","    ‚ùå No faculty records could be parsed.\n","üè´ Processing: IIT Guwahati\n","    ‚ùå No faculty records could be parsed.\n","üè´ Processing: IIT Hyderabad\n","    ‚ùå No faculty records could be parsed.\n","üè´ Processing: IIT Indore\n","    ‚ùå No faculty records could be parsed.\n","üè´ Processing: IIT Jammu\n","    ‚ùå No faculty records could be parsed.\n","üè´ Processing: IIT Jodhpur\n","    ‚ùå No faculty records could be parsed.\n","üè´ Processing: IIT Kanpur\n","    ‚ùå No faculty records could be parsed.\n","üè´ Processing: IIT Kharagpur\n","    ‚ùå No faculty records could be parsed.\n","üè´ Processing: IIT Madras\n","    ‚ùå No faculty records could be parsed.\n","üè´ Processing: IIT Mandi\n","    ‚ùå No faculty records could be parsed.\n","üè´ Processing: IIT Palakkad\n","    ‚ùå No faculty records could be parsed.\n","üè´ Processing: IIT Patna\n","    ‚ùå No faculty records could be parsed.\n","üè´ Processing: IIT Roorkee 2024\n","    ‚ùå No faculty records could be parsed.\n","üè´ Processing: IIT Ropar\n","    ‚ùå No faculty records could be parsed.\n","üè´ Processing: IIT Tirupati\n","    ‚ùå No faculty records could be parsed.\n","üè´ Processing: IIT Varanasi_Banaras Hindu University_\n","    ‚ùå No faculty records could be parsed.\n","üè´ Processing: Indian Institute of Space Science and Technology\n","    ‚ùå No faculty records could be parsed.\n","üè´ Processing: Indian Institute of Technology _Indian School of Mines_ Dhanbad\n","    ‚ùå No faculty records could be parsed.\n","üè´ Processing: Indraprastha Institute of Information Technology\n","    ‚ùå No faculty records could be parsed.\n","üè´ Processing: Institute of Chemical Technology\n","    ‚ùå No faculty records could be parsed.\n","üè´ Processing: International Institute of Information Technology Bangalore\n","    ‚ùå No faculty records could be parsed.\n","üè´ Processing: Jadavpur University\n","    ‚ùå No faculty records could be parsed.\n","üè´ Processing: Jain University_ Bangalore\n","    ‚ùå No faculty records could be parsed.\n","üè´ Processing: Jamia Millia Islamia\n","    ‚ùå No faculty records could be parsed.\n","üè´ Processing: Jawaharlal Nehru Technological University\n","    ‚ùå No faculty records could be parsed.\n","üè´ Processing: K L College of Engineering_Vaddeswaram_\n","    ‚ùå No faculty records could be parsed.\n","üè´ Processing: Kalasalingam Academy of Research and Education\n","    ‚ùå No faculty records could be parsed.\n","üè´ Processing: Kalinga Institute of Industrial Technology\n","    ‚ùå No faculty records could be parsed.\n","üè´ Processing: Lovely Professional University\n","    ‚ùå No faculty records could be parsed.\n","üè´ Processing: M. S. Ramaiah Institute of Technology\n","    ‚ùå No faculty records could be parsed.\n","üè´ Processing: Madan Mohan Malaviya University of Technology\n","    ‚ùå No faculty records could be parsed.\n","üè´ Processing: Malaviya National Institute of Technology\n","    ‚ùå No faculty records could be parsed.\n","üè´ Processing: Manipal Institute of Technology\n","    ‚ùå No faculty records could be parsed.\n","üè´ Processing: Manipal University_ Jaipur\n","    ‚ùå No faculty records could be parsed.\n","üè´ Processing: Maulana Azad National Institute of Technology\n","    ‚ùå No faculty records could be parsed.\n","üè´ Processing: Motilal Nehru National Institute of Technology\n","    ‚ùå No faculty records could be parsed.\n","üè´ Processing: Netaji Subhas University of Technology _NSUT_\n","    ‚ùå No faculty records could be parsed.\n","üè´ Processing: NIT  Agartala\n","    ‚ùå No faculty records could be parsed.\n","üè´ Processing: NIT  Puducherry\n","    ‚ùå No faculty records could be parsed.\n","üè´ Processing: NIT calicut\n","    ‚ùå No faculty records could be parsed.\n","üè´ Processing: NIT Delhi\n","    ‚ùå No faculty records could be parsed.\n","üè´ Processing: NIT Durgapur\n","    ‚ùå No faculty records could be parsed.\n","üè´ Processing: NIT Kurukshetra\n","    ‚ùå No faculty records could be parsed.\n","üè´ Processing: NIT Meghalaya\n","    ‚ùå No faculty records could be parsed.\n","üè´ Processing: NIT Patna\n","    ‚ùå No faculty records could be parsed.\n","üè´ Processing: NIT Raipur\n","    ‚ùå No faculty records could be parsed.\n","üè´ Processing: NIT Rourkela\n","    ‚ùå No faculty records could be parsed.\n","üè´ Processing: NIT Silchar\n","    ‚ùå No faculty records could be parsed.\n","üè´ Processing: NIT Srinagar\n","    ‚ùå No faculty records could be parsed.\n","üè´ Processing: NIT Surathkal\n","    ‚ùå No faculty records could be parsed.\n","üè´ Processing: NIT Tiruchirappalli\n","    ‚ùå No faculty records could be parsed.\n","üè´ Processing: NIT Warangal\n","    ‚ùå No faculty records could be parsed.\n","üè´ Processing: PSG College of Technology\n","    ‚ùå No faculty records could be parsed.\n","üè´ Processing: R.V. College of Engineering\n","    ‚ùå No faculty records could be parsed.\n","üè´ Processing: Rajiv Gandhi Institute of Petroleum Technology\n","    ‚ùå No faculty records could be parsed.\n","üè´ Processing: Sant Longowal Institute of Engineering and Technology\n","    ‚ùå No faculty records could be parsed.\n","üè´ Processing: Sardar Vallabhbhai National Institute of Technology\n","    ‚ùå No faculty records could be parsed.\n","üè´ Processing: Sathyabama Institute of Science and Technology Chennai\n","    ‚ùå No faculty records could be parsed.\n","üè´ Processing: Saveetha Institute of Medical and Technical Sciences\n","    ‚ùå No faculty records could be parsed.\n","üè´ Processing: Shanmugha Arts Science Technology and Research Academy\n","    ‚ùå No faculty records could be parsed.\n","üè´ Processing: Shoolini University of Biotechnology and Management Science\n","    ‚ùå No faculty records could be parsed.\n","üè´ Processing: Siddaganga Institute of Technology\n","    ‚ùå No faculty records could be parsed.\n","üè´ Processing: SR University Warangal\n","    ‚ùå No faculty records could be parsed.\n","üè´ Processing: Sri Krishna College of Engineering and Technology\n","    ‚ùå No faculty records could be parsed.\n","üè´ Processing: Sri Sivasubramaniya Nadar College of Engineering\n","    ‚ùå No faculty records could be parsed.\n","üè´ Processing: SRM Chennai\n","    ‚ùå No faculty records could be parsed.\n","üè´ Processing: Thapar Institute of Engineering and Technology _Deemed-to-be-university\n","    ‚ùå No faculty records could be parsed.\n","üè´ Processing: University of Hyderabad\n","    ‚ùå No faculty records could be parsed.\n","üè´ Processing: UPES\n","    ‚ùå No faculty records could be parsed.\n","üè´ Processing: Vel Tech Rangarajan Dr. Sagunthala R _ D Institute of Science and Technology\n","    ‚ùå No faculty records could be parsed.\n","üè´ Processing: Vignan_s Foundation for Science_ Technology and Research\n","    ‚ùå No faculty records could be parsed.\n","üè´ Processing: Visvesvaraya National Institute of Technology Nagpur\n","    ‚ùå No faculty records could be parsed.\n","üè´ Processing: Visvesvaraya Technological University\n","    ‚ùå No faculty records could be parsed.\n","üè´ Processing: VIT Vellore\n","    ‚ùå No faculty records could be parsed.\n","\n","================================================================================\n","PROCESSING COMPLETE - INDIVIDUAL OUTPUTS CREATED\n","================================================================================\n","‚úÖ SUCCESS: 3 colleges processed\n","\n","üìÇ INDIVIDUAL JSON FILES CREATED:\n","    ‚Ä¢ Aligarh Muslim University_faculty_data.json (224 faculty)\n","    ‚Ä¢ Amrita Vishwa Vidyapeetham_faculty_data.json (951 faculty)\n","    ‚Ä¢ Anna University_faculty_data.json (890 faculty)\n","\n","üéØ Total faculty across all colleges: 2065\n","Added to ZIP: Aligarh Muslim University_faculty_data.json\n","Added to ZIP: Amrita Vishwa Vidyapeetham_faculty_data.json\n","Added to ZIP: Anna University_faculty_data.json\n","\n","üì¶ Created ZIP file: all_college_faculty_data_20251112_185601.zip\n","Contains 3 JSON files\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["download(\"download_67601b64-a6f2-4646-a2a8-eac64f7f9453\", \"all_college_faculty_data_20251112_185601.zip\", 992325)"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["‚úÖ ZIP file downloaded!\n","\n","================================================================================\n","FAILED TO PROCESS\n","================================================================================\n","‚ùå Amity University.txt (Reason: No faculty records could be parsed.)\n","‚ùå AU College of Enginnering.txt (Reason: No faculty records could be parsed.)\n","‚ùå Banasthali Vidyapith.txt (Reason: No faculty records could be parsed.)\n","‚ùå Birla Institute of Technology  and Science_ Pilani.txt (Reason: No faculty records could be parsed.)\n","‚ùå Birla Institute of Technology Ranchi.txt (Reason: No faculty records could be parsed.)\n","‚ùå C.V. Raman Global University_ Odisha.txt (Reason: No faculty records could be parsed.)\n","‚ùå Chandigarh University.txt (Reason: No faculty records could be parsed.)\n","‚ùå Chithara University.txt (Reason: No faculty records could be parsed.)\n","‚ùå COEP Technological University.txt (Reason: No faculty records could be parsed.)\n","‚ùå Defence Institute of Adavanced Technology.txt (Reason: No faculty records could be parsed.)\n","‚ùå Delhi Technological University.txt (Reason: No faculty records could be parsed.)\n","‚ùå Dr. B R Ambedkar National Institute of Technology Jalandhar.txt (Reason: No faculty records could be parsed.)\n","‚ùå Engineering  2024.txt (Reason: No faculty records could be parsed.)\n","‚ùå Guru Gobind Singh Indraprastha University.txt (Reason: No faculty records could be parsed.)\n","‚ùå IIEST Shibpur.txt (Reason: No faculty records could be parsed.)\n","‚ùå IIIT Allahabad.txt (Reason: No faculty records could be parsed.)\n","‚ùå IIIT Hyderabad .txt (Reason: No faculty records could be parsed.)\n","‚ùå IIT Bhilai.txt (Reason: No faculty records could be parsed.)\n","‚ùå IIT Bhuvaneswar.txt (Reason: No faculty records could be parsed.)\n","‚ùå IIT Bombay.txt (Reason: No faculty records could be parsed.)\n","‚ùå IIT Delhi.txt (Reason: No faculty records could be parsed.)\n","‚ùå IIT Gandhinagar.txt (Reason: No faculty records could be parsed.)\n","‚ùå IIT Guwahati.txt (Reason: No faculty records could be parsed.)\n","‚ùå IIT Hyderabad.txt (Reason: No faculty records could be parsed.)\n","‚ùå IIT Indore.txt (Reason: No faculty records could be parsed.)\n","‚ùå IIT Jammu.txt (Reason: No faculty records could be parsed.)\n","‚ùå IIT Jodhpur.txt (Reason: No faculty records could be parsed.)\n","‚ùå IIT Kanpur.txt (Reason: No faculty records could be parsed.)\n","‚ùå IIT Kharagpur.txt (Reason: No faculty records could be parsed.)\n","‚ùå IIT Madras.txt (Reason: No faculty records could be parsed.)\n","‚ùå IIT Mandi.txt (Reason: No faculty records could be parsed.)\n","‚ùå IIT Palakkad.txt (Reason: No faculty records could be parsed.)\n","‚ùå IIT Patna.txt (Reason: No faculty records could be parsed.)\n","‚ùå IIT Roorkee 2024.txt (Reason: No faculty records could be parsed.)\n","‚ùå IIT Ropar.txt (Reason: No faculty records could be parsed.)\n","‚ùå IIT Tirupati.txt (Reason: No faculty records could be parsed.)\n","‚ùå IIT Varanasi_Banaras Hindu University_.txt (Reason: No faculty records could be parsed.)\n","‚ùå Indian Institute of Space Science and Technology.txt (Reason: No faculty records could be parsed.)\n","‚ùå Indian Institute of Technology _Indian School of Mines_ Dhanbad.txt (Reason: No faculty records could be parsed.)\n","‚ùå Indraprastha Institute of Information Technology.txt (Reason: No faculty records could be parsed.)\n","‚ùå Institute of Chemical Technology.txt (Reason: No faculty records could be parsed.)\n","‚ùå International Institute of Information Technology Bangalore.txt (Reason: No faculty records could be parsed.)\n","‚ùå Jadavpur University.txt (Reason: No faculty records could be parsed.)\n","‚ùå Jain University_ Bangalore.txt (Reason: No faculty records could be parsed.)\n","‚ùå Jamia Millia Islamia.txt (Reason: No faculty records could be parsed.)\n","‚ùå Jawaharlal Nehru Technological University.txt (Reason: No faculty records could be parsed.)\n","‚ùå K L College of Engineering_Vaddeswaram_.txt (Reason: No faculty records could be parsed.)\n","‚ùå Kalasalingam Academy of Research and Education.txt (Reason: No faculty records could be parsed.)\n","‚ùå Kalinga Institute of Industrial Technology.txt (Reason: No faculty records could be parsed.)\n","‚ùå Lovely Professional University.txt (Reason: No faculty records could be parsed.)\n","‚ùå M. S. Ramaiah Institute of Technology.txt (Reason: No faculty records could be parsed.)\n","‚ùå Madan Mohan Malaviya University of Technology.txt (Reason: No faculty records could be parsed.)\n","‚ùå Malaviya National Institute of Technology.txt (Reason: No faculty records could be parsed.)\n","‚ùå Manipal Institute of Technology.txt (Reason: No faculty records could be parsed.)\n","‚ùå Manipal University_ Jaipur.txt (Reason: No faculty records could be parsed.)\n","‚ùå Maulana Azad National Institute of Technology.txt (Reason: No faculty records could be parsed.)\n","‚ùå Motilal Nehru National Institute of Technology.txt (Reason: No faculty records could be parsed.)\n","‚ùå Netaji Subhas University of Technology _NSUT_.txt (Reason: No faculty records could be parsed.)\n","‚ùå NIT  Agartala.txt (Reason: No faculty records could be parsed.)\n","‚ùå NIT  Puducherry.txt (Reason: No faculty records could be parsed.)\n","‚ùå NIT calicut.txt (Reason: No faculty records could be parsed.)\n","‚ùå NIT Delhi.txt (Reason: No faculty records could be parsed.)\n","‚ùå NIT Durgapur.txt (Reason: No faculty records could be parsed.)\n","‚ùå NIT Kurukshetra.txt (Reason: No faculty records could be parsed.)\n","‚ùå NIT Meghalaya.txt (Reason: No faculty records could be parsed.)\n","‚ùå NIT Patna.txt (Reason: No faculty records could be parsed.)\n","‚ùå NIT Raipur.txt (Reason: No faculty records could be parsed.)\n","‚ùå NIT Rourkela.txt (Reason: No faculty records could be parsed.)\n","‚ùå NIT Silchar.txt (Reason: No faculty records could be parsed.)\n","‚ùå NIT Srinagar.txt (Reason: No faculty records could be parsed.)\n","‚ùå NIT Surathkal.txt (Reason: No faculty records could be parsed.)\n","‚ùå NIT Tiruchirappalli.txt (Reason: No faculty records could be parsed.)\n","‚ùå NIT Warangal.txt (Reason: No faculty records could be parsed.)\n","‚ùå PSG College of Technology.txt (Reason: No faculty records could be parsed.)\n","‚ùå R.V. College of Engineering.txt (Reason: No faculty records could be parsed.)\n","‚ùå Rajiv Gandhi Institute of Petroleum Technology.txt (Reason: No faculty records could be parsed.)\n","‚ùå Sant Longowal Institute of Engineering and Technology.txt (Reason: No faculty records could be parsed.)\n","‚ùå Sardar Vallabhbhai National Institute of Technology.txt (Reason: No faculty records could be parsed.)\n","‚ùå Sathyabama Institute of Science and Technology Chennai.txt (Reason: No faculty records could be parsed.)\n","‚ùå Saveetha Institute of Medical and Technical Sciences.txt (Reason: No faculty records could be parsed.)\n","‚ùå Shanmugha Arts Science Technology and Research Academy.txt (Reason: No faculty records could be parsed.)\n","‚ùå Shoolini University of Biotechnology and Management Science.txt (Reason: No faculty records could be parsed.)\n","‚ùå Siddaganga Institute of Technology.txt (Reason: No faculty records could be parsed.)\n","‚ùå SR University Warangal.txt (Reason: No faculty records could be parsed.)\n","‚ùå Sri Krishna College of Engineering and Technology.txt (Reason: No faculty records could be parsed.)\n","‚ùå Sri Sivasubramaniya Nadar College of Engineering.txt (Reason: No faculty records could be parsed.)\n","‚ùå SRM Chennai.txt (Reason: No faculty records could be parsed.)\n","‚ùå Thapar Institute of Engineering and Technology _Deemed-to-be-university.txt (Reason: No faculty records could be parsed.)\n","‚ùå University of Hyderabad.txt (Reason: No faculty records could be parsed.)\n","‚ùå UPES.txt (Reason: No faculty records could be parsed.)\n","‚ùå Vel Tech Rangarajan Dr. Sagunthala R _ D Institute of Science and Technology.txt (Reason: No faculty records could be parsed.)\n","‚ùå Vignan_s Foundation for Science_ Technology and Research.txt (Reason: No faculty records could be parsed.)\n","‚ùå Visvesvaraya National Institute of Technology Nagpur.txt (Reason: No faculty records could be parsed.)\n","‚ùå Visvesvaraya Technological University.txt (Reason: No faculty records could be parsed.)\n","‚ùå VIT Vellore.txt (Reason: No faculty records could be parsed.)\n"]}],"source":["#code1\n","import re\n","import json\n","import uuid\n","import os\n","import zipfile\n","from datetime import datetime\n","from typing import Dict, List, Any, Optional\n","from collections import Counter\n","import io\n","\n","try:\n","    from google.colab import files\n","except ImportError:\n","    files = None\n","\n","class FacultyDataProcessor:\n","    def __init__(self):\n","        # Designation mapping for standardization\n","        self.designation_mapping = {\n","            'assistant professor': 'Assistant Professor',\n","            'associate professor': 'Associate Professor',\n","            'professor': 'Professor',\n","            'dean': 'Dean',\n","            'principal': 'Principal',\n","            'director': 'Director',\n","            'vice chancellor': 'Vice Chancellor',\n","            'associate dean': 'Associate Dean',\n","            'lecturer': 'Lecturer',\n","            'head of department': 'HOD',\n","            'hod': 'HOD',\n","        }\n","\n","        # Qualification mapping for standardization\n","        self.qualification_mapping = {\n","            'ph.d': 'Ph.D', 'phd': 'Ph.D', 'ph d': 'Ph.D', 'd.phil': 'Ph.D',\n","            'm.tech': 'M.Tech', 'mtech': 'M.Tech', 'm.sc': 'M.Sc', 'msc': 'M.Sc',\n","            'b.tech': 'B.Tech', 'btech': 'B.Tech', 'master of design': 'M.Des',\n","            'm.a': 'M.A', 'ma': 'M.A', 'b.ed': 'B.Ed', 'm.phil': 'M.Phil',\n","            'llm': 'LLM', 'mba': 'MBA', 'p.g.d.m': 'PGDM', 'b.com': 'B.Com'\n","        }\n","\n","        # Regular expressions for robust parsing\n","        self.patterns = [\n","            # Pattern 1: Basic pipe or multiple space separated values\n","            r'(\\d+)\\s*\\|\\s*([^|]+?)\\s*\\|\\s*(\\d+)\\s*\\|\\s*([^|]+?)\\s*\\|\\s*([^|]+?)\\s*\\|\\s*([^|]+?)\\s*\\|\\s*(\\d+)\\s*\\|\\s*([^|]+?)\\s*\\|\\s*([^|]+?)\\s*\\|\\s*([^|]+?)\\s*\\|\\s*([^|]+)',\n","            # Pattern 2: Space-separated table format\n","            r'(\\d+)\\s+([A-Za-z\\s.]+?)\\s+(\\d+)\\s+([A-Za-z.\\s]+?)\\s+(Male|Female)\\s+([A-Z.\\s]+?)\\s+(\\d+)\\s+(Yes|No)\\s+(\\d{2}-\\d{2}-\\d{4})',\n","            # Pattern 3: Key-value pairs\n","            r'Name:\\s*([A-Za-z\\s]+?)\\s*\\|\\s*Designation:\\s*([^|]+)\\s*\\|\\s*Gender:\\s*([^|]+)\\s*\\|\\s*Qualification:\\s*([^|]+)'\n","        ]\n","\n","    def extract_faculty_section(self, text: str) -> str:\n","        \"\"\"Improved faculty section detection with multiple patterns.\"\"\"\n","        faculty_patterns = [\n","            r'###SECTION:FACULTY_DETAILS###(.*?)(?=###SECTION:|$)',\n","            r'FACULTY\\s*DETAILS?(.*?)(?=\\n\\s*[A-Z\\s]+:|\\n\\s*###|\\Z)',\n","            r'Faculty\\s*Information(.*?)(?=\\n\\s*[A-Z\\s]+:|\\n\\s*###|\\Z)',\n","            r'Teaching\\s*Staff(.*?)(?=\\n\\s*[A-Z\\s]+:|\\n\\s*###|\\Z)'\n","        ]\n","\n","        for pattern in faculty_patterns:\n","            match = re.search(pattern, text, re.DOTALL | re.IGNORECASE)\n","            if match:\n","                section = match.group(1).strip()\n","                if len(section) > 100:\n","                    return section\n","\n","        lines = text.split('\\n')\n","        faculty_start = -1\n","\n","        header_patterns = [\n","            r'(srno|s\\.?\\s*no|serial).*name.*designation',\n","            r'name.*age.*designation',\n","            r'faculty.*name.*department',\n","            r'professor.*department.*qualification'\n","        ]\n","\n","        for i, line in enumerate(lines):\n","            line_lower = line.lower().strip()\n","            for pattern in header_patterns:\n","                if re.search(pattern, line_lower):\n","                    faculty_start = i\n","                    break\n","            if faculty_start != -1:\n","                break\n","\n","        if faculty_start != -1:\n","            faculty_end = len(lines)\n","            data_lines = 0\n","\n","            for i in range(faculty_start + 1, len(lines)):\n","                line = lines[i].strip()\n","                if line:\n","                    if re.match(r'^\\d+\\s+', line):\n","                        data_lines += 1\n","                    elif line.startswith('###') or (data_lines > 5 and len(line.split()) < 3):\n","                        faculty_end = i\n","                        break\n","\n","            if data_lines > 0:\n","                return '\\n'.join(lines[faculty_start:faculty_end])\n","\n","        faculty_pattern = r'(?:Dr\\.|Prof\\.|Mr\\.|Ms\\.|Mrs\\.)\\s+[A-Za-z\\s]+\\s+(?:Ph\\.?D|M\\.Tech|M\\.Sc|Professor)'\n","        matches = re.findall(faculty_pattern, text, re.IGNORECASE)\n","\n","        if len(matches) > 3:\n","            for match in matches[:1]:\n","                match_pos = text.find(match[0])\n","                if match_pos != -1:\n","                    start = max(0, match_pos - 500)\n","                    end = min(len(text), match_pos + 2000)\n","                    return text[start:end]\n","\n","        return \"\"\n","\n","    def parse_faculty_data(self, faculty_text: str) -> List[Dict[str, Any]]:\n","        \"\"\"Parse faculty data from the extracted text and sort by seniority.\"\"\"\n","        faculty_records = []\n","        if not faculty_text:\n","            return []\n","\n","        # Use the most specific pattern that works\n","        for pattern in self.patterns:\n","            matches = re.findall(pattern, faculty_text, re.IGNORECASE | re.MULTILINE)\n","            if matches:\n","                for match in matches:\n","                    record = self.parse_match(match)\n","                    if record:\n","                        faculty_records.append(record)\n","                if faculty_records:\n","                    # ADDED: Sort by seniority score\n","                    faculty_records.sort(key=lambda x: x.get('seniority_score', 0), reverse=True)\n","                    return faculty_records\n","\n","        # Fallback to line-by-line parsing\n","        lines = faculty_text.split('\\n')\n","        for line in lines:\n","            line = line.strip()\n","            if line and self.is_valid_faculty_line(line):\n","                record = self.parse_fallback_line(line)\n","                if record:\n","                    faculty_records.append(record)\n","\n","        # ADDED: Sort by seniority score even for fallback\n","        faculty_records.sort(key=lambda x: x.get('seniority_score', 0), reverse=True)\n","        return faculty_records\n","\n","    def parse_match(self, match: tuple) -> Optional[Dict[str, Any]]:\n","        \"\"\"Parse a regex match into a structured faculty record.\"\"\"\n","        record = {}\n","        try:\n","            if len(match) == 9:\n","                record = {\n","                    'serial_no': match[0], 'name': self.clean_name(match[1]), 'age': match[2],\n","                    'designation': self.standardize_designation(match[3]), 'gender': match[4],\n","                    'qualification': self.standardize_qualification(match[5]), 'experience': match[6],\n","                    'phd_status': match[7], 'joining_date': self.parse_date(match[8])\n","                }\n","            elif len(match) == 4:\n","                record = {\n","                    'name': self.clean_name(match[0]), 'designation': self.standardize_designation(match[1]),\n","                    'gender': match[2], 'qualification': self.standardize_qualification(match[3])\n","                }\n","            elif len(match) == 11:\n","                record = {\n","                    'serial_no': match[0], 'name': self.clean_name(match[1]), 'age': match[2],\n","                    'designation': self.standardize_designation(match[3]), 'gender': match[4],\n","                    'qualification': self.standardize_qualification(match[5]), 'experience': match[6],\n","                    'currently_working': match[7], 'joining_date': self.parse_date(match[8]),\n","                    'leaving_date': self.parse_date(match[9]), 'association_type': match[10]\n","                }\n","\n","            if record and record.get('name'):\n","                record['id'] = str(uuid.uuid4())\n","                # ADDED: new score calculations\n","                record['seniority_score'] = self.calculate_seniority_score(record)\n","                record['quality_score'] = self.calculate_record_quality_score(record)\n","                # ADDED: enhanced career stage logic\n","                record['career_stage'] = self.determine_career_stage(record['designation'], record.get('experience', ''), record.get('age', ''))\n","                record['data_year'] = str(datetime.now().year)\n","                return record\n","        except Exception as e:\n","            pass\n","        return None\n","\n","    def is_valid_faculty_line(self, line: str) -> bool:\n","        \"\"\"Heuristically checks if a line is likely to contain faculty data.\"\"\"\n","        line_lower = line.lower()\n","        if len(line) < 20: return False\n","        keywords = ['professor', 'lecturer', 'phd', 'male', 'female']\n","        if not any(k in line_lower for k in keywords):\n","            return False\n","        if re.search(r'\\d{2,3}', line) and re.search(r'[A-Z][a-z]+', line):\n","            return True\n","        return False\n","\n","    def parse_fallback_line(self, line: str) -> Optional[Dict[str, Any]]:\n","        \"\"\"Parses a line using a more generalized, keyword-based approach.\"\"\"\n","        record = {}\n","        line_lower = line.lower()\n","\n","        for key, val in self.designation_mapping.items():\n","            if key in line_lower:\n","                record['designation'] = val\n","                break\n","\n","        for key, val in self.qualification_mapping.items():\n","            if key in line_lower:\n","                record['qualification'] = val\n","                break\n","\n","        if 'male' in line_lower: record['gender'] = 'Male'\n","        elif 'female' in line_lower: record['gender'] = 'Female'\n","\n","        exp_match = re.search(r'(\\d+)\\s+(?:years|exp|experience)', line_lower)\n","        if exp_match: record['experience'] = exp_match.group(1)\n","\n","        name_match = re.search(r'^(?:dr\\.|prof\\.)?\\s*([A-Z][a-z]+(?:\\s+[A-Z][a-z]+)*)', line, re.IGNORECASE)\n","        if name_match: record['name'] = self.clean_name(name_match.group(1))\n","\n","        if 'name' in record and 'designation' in record:\n","            record['id'] = str(uuid.uuid4())\n","            # ADDED: new score calculations\n","            record['seniority_score'] = self.calculate_seniority_score(record)\n","            record['quality_score'] = self.calculate_record_quality_score(record)\n","            # ADDED: enhanced career stage logic\n","            record['career_stage'] = self.determine_career_stage(record.get('designation', ''), record.get('experience', ''), record.get('age', ''))\n","            record['data_year'] = str(datetime.now().year)\n","            return record\n","\n","        return None\n","\n","    def clean_name(self, name: str) -> str:\n","        \"\"\"Clean and format faculty name.\"\"\"\n","        if not name: return \"\"\n","        name = re.sub(r'\\s+', ' ', name.strip())\n","        return name.title()\n","\n","    def standardize_designation(self, designation: str) -> str:\n","        \"\"\"Standardize designation using mapping.\"\"\"\n","        if not designation: return \"\"\n","        designation_lower = designation.lower().strip()\n","        return self.designation_mapping.get(designation_lower, designation.title())\n","\n","    def standardize_qualification(self, qualification: str) -> str:\n","        \"\"\"Standardize qualification using mapping.\"\"\"\n","        if not qualification: return \"\"\n","        qual_lower = qualification.lower().strip().replace('.', '')\n","        return self.qualification_mapping.get(qual_lower, qualification)\n","\n","    def parse_date(self, date_str: str) -> str:\n","        \"\"\"Parse and standardize date format to YYYY-MM-DD.\"\"\"\n","        if not date_str or date_str == '--': return \"\"\n","        date_patterns = [\n","            r'(\\d{1,2})[-/](\\d{1,2})[-/](\\d{4})',\n","            r'(\\d{4})[-/](\\d{1,2})[-/](\\d{1,2})'\n","        ]\n","\n","        for pattern in date_patterns:\n","            match = re.search(pattern, date_str)\n","            if match:\n","                if len(match.group(3)) == 4:\n","                    d, m, y = match.groups()\n","                else:\n","                    y, m, d = match.groups()\n","                try:\n","                    return f\"{int(y):04d}-{int(m):02d}-{int(d):02d}\"\n","                except ValueError:\n","                    return date_str\n","        return date_str\n","\n","    def calculate_seniority_score(self, record: Dict[str, Any]) -> int:\n","        \"\"\"Enhanced seniority score with weighted factors.\"\"\"\n","        score = 0\n","        designation_scores = {\n","            \"Assistant Professor\": 30, \"Associate Professor\": 60, \"Professor\": 90,\n","            \"Dean\": 120, \"Director\": 130, \"Vice Chancellor\": 150, \"Principal\": 110,\n","            \"Lecturer\": 15, \"HOD\": 100\n","        }\n","        score += designation_scores.get(record.get('designation', ''), 15)\n","\n","        if record.get('experience', '').isdigit():\n","            exp_years = int(record['experience']) // 12\n","            if exp_years <= 5:\n","                score += exp_years * 5\n","            elif exp_years <= 15:\n","                score += 25 + (exp_years - 5) * 3\n","            else:\n","                score += 55 + (exp_years - 15) * 2\n","\n","        qual = record.get('qualification', '').lower()\n","        if 'ph.d' in qual or 'phd' in qual:\n","            score += 40\n","        elif 'm.tech' in qual or 'mtech' in qual:\n","            score += 25\n","        elif 'm.sc' in qual or 'msc' in qual:\n","            score += 20\n","        elif 'b.tech' in qual or 'btech' in qual:\n","            score += 10\n","\n","        if record.get('age', '').isdigit():\n","            age = int(record['age'])\n","            if age > 50:\n","                score += 15\n","            elif age > 40:\n","                score += 10\n","            elif age > 35:\n","                score += 5\n","\n","        return min(score, 200)\n","\n","    def calculate_record_quality_score(self, record: Dict[str, Any]) -> float:\n","        \"\"\"Calculate quality score for individual faculty record.\"\"\"\n","        score = 0\n","        essential_fields = {\n","            'name': 20, 'designation': 15, 'qualification': 15, 'experience': 10\n","        }\n","        for field, points in essential_fields.items():\n","            if record.get(field) and record[field].strip():\n","                score += points\n","\n","        additional_fields = {\n","            'age': 10, 'gender': 5, 'joining_date': 10, 'currently_working': 5, 'association_type': 10\n","        }\n","        for field, points in additional_fields.items():\n","            if record.get(field) and record[field].strip() and record[field] != '--':\n","                score += points\n","\n","        return round(score, 1)\n","\n","    def determine_career_stage(self, designation: str, experience: str, age: str = \"\") -> str:\n","        \"\"\"Enhanced career stage determination.\"\"\"\n","        if not designation:\n","            return \"Unknown\"\n","\n","        designation_lower = designation.lower()\n","        exp_years = int(experience) // 12 if experience.isdigit() else 0\n","        age_num = int(age) if age.isdigit() else 0\n","\n","        if any(word in designation_lower for word in ['dean', 'director', 'vice chancellor', 'principal']):\n","            return \"Senior Career\"\n","\n","        if 'professor' in designation_lower and 'assistant' not in designation_lower and 'associate' not in designation_lower:\n","            return \"Senior Career\"\n","\n","        if 'associate' in designation_lower:\n","            return \"Mid Career\" if exp_years < 20 else \"Senior Career\"\n","\n","        if 'assistant' in designation_lower:\n","            if exp_years < 3 or age_num < 30:\n","                return \"Early Career\"\n","            elif exp_years < 8:\n","                return \"Early Career\"\n","            else:\n","                return \"Mid Career\"\n","\n","        if exp_years > 15 or age_num > 50:\n","            return \"Senior Career\"\n","        elif exp_years > 5 or age_num > 35:\n","            return \"Mid Career\"\n","\n","        return \"Early Career\"\n","\n","    def calculate_quality_score(self, records: List[Dict[str, Any]]) -> float:\n","        \"\"\"Calculate overall quality score for the faculty data.\"\"\"\n","        if not records: return 0.0\n","        total_score = sum(r.get('quality_score', 0) for r in records)\n","        return round(total_score / len(records), 2)\n","\n","    def create_content_summary(self, records: List[Dict[str, Any]]) -> str:\n","        \"\"\"Create enhanced summary with statistics.\"\"\"\n","        if not records:\n","            return \"\"\n","\n","        total_faculty = len(records)\n","        phd_count = sum(1 for r in records if r.get('phd_status') == 'Yes')\n","\n","        career_stages = Counter(r.get('career_stage', 'Unknown') for r in records)\n","        designation_counts = Counter(r.get('designation', 'Unknown') for r in records)\n","\n","        avg_seniority = sum(r.get('seniority_score', 0) for r in records) / total_faculty\n","        avg_quality = sum(r.get('quality_score', 0) for r in records) / total_faculty\n","\n","        summary_parts = [\n","            f\"Faculty dataset with {total_faculty} members ({phd_count} with Ph.D).\",\n","            f\"Average seniority score: {avg_seniority:.1f}, Quality score: {avg_quality:.1f}.\",\n","            \"Career stages: \" + \", \".join(f\"{k}: {v}\" for k, v in career_stages.items()),\n","            \"Top designations: \" + \", \".join(f\"{k}: {v}\" for k, v in sorted(designation_counts.items(), key=lambda x: x[1], reverse=True)[:3])\n","        ]\n","\n","        return \" \".join(summary_parts)\n","\n","    def create_json_output(self, faculty_records: List[Dict[str, Any]], filename: str) -> Dict[str, Any]:\n","        \"\"\"Create the final JSON output in Qdrant format without a vector field.\"\"\"\n","        if not faculty_records:\n","            return {}\n","\n","        quality_score = self.calculate_quality_score(faculty_records)\n","        content = self.create_content_summary(faculty_records)\n","        title = f\"Faculty Data - {len(faculty_records)} members from {filename}\"\n","\n","        output = {\n","            \"id\": str(uuid.uuid4()),\n","            \"payload\": {\n","                \"content\": content, \"title\": title, \"source_file\": filename,\n","                \"content_type\": \"faculty\", \"chunk_type\": \"faculty\", \"category\": \"Faculty\",\n","                \"faculty_count\": len(faculty_records), \"processing_timestamp\": datetime.now().isoformat(),\n","                \"enhanced_structure\": True, \"quality_score\": quality_score,\n","                \"data_source\": \"processed_file\", \"faculty_records\": faculty_records\n","            }\n","        }\n","        return output\n","\n","    def process_file_content(self, text_content: str, filename: str) -> Dict[str, Any]:\n","        \"\"\"Main method to process a file's text content.\"\"\"\n","        if not text_content or not text_content.strip():\n","            return {\"error\": \"No content provided.\"}\n","        faculty_section = self.extract_faculty_section(text_content)\n","        if not faculty_section:\n","            return {\"error\": \"No faculty section found in the text.\"}\n","        faculty_records = self.parse_faculty_data(faculty_section)\n","        if not faculty_records:\n","            return {\"error\": \"No faculty records could be parsed.\"}\n","        json_output = self.create_json_output(faculty_records, filename)\n","        return json_output\n","\n","def process_files_individual_output():\n","    \"\"\"Process all uploaded files and create separate JSON output for each college.\"\"\"\n","    if files is None:\n","        print(\"This function requires Google Colab. Please run in a Colab environment.\")\n","        return\n","\n","    print(\"Upload your faculty data files (e.g., as a .zip or multiple .txt):\")\n","    uploaded = files.upload()\n","\n","    if not uploaded:\n","        print(\"No files uploaded!\")\n","        return\n","\n","    processor = FacultyDataProcessor()\n","    successful_outputs = []\n","    failed_files = []\n","\n","    for filename, content in uploaded.items():\n","        if filename.endswith('.zip'):\n","            with zipfile.ZipFile(io.BytesIO(content), 'r') as zip_ref:\n","                print(f\"üì¶ Unzipping {filename}...\")\n","                zip_ref.extractall(\"uploaded_files\")\n","\n","            txt_files = [f for f in os.listdir(\"uploaded_files\") if f.endswith('.txt')]\n","            if not txt_files:\n","                print(\"No .txt files found in the zip.\")\n","                continue\n","\n","            for txt_filename in txt_files:\n","                txt_filepath = os.path.join(\"uploaded_files\", txt_filename)\n","                with open(txt_filepath, 'r', encoding='utf-8') as f:\n","                    text_content = f.read()\n","\n","                print(f\"üè´ Processing: {txt_filename}\")\n","                college_name = txt_filename.replace('.txt', '')\n","\n","                try:\n","                    result = processor.process_file_content(text_content, txt_filename)\n","                    if \"error\" in result:\n","                        print(f\"    ‚ùå {result['error']}\")\n","                        failed_files.append((college_name, result['error']))\n","                    else:\n","                        faculty_count = result['payload']['faculty_count']\n","                        print(f\"    ‚úÖ Found {faculty_count} faculty members\")\n","\n","                        output_filename = f\"{college_name}_faculty_data.json\"\n","                        with open(output_filename, 'w', encoding='utf-8') as f:\n","                            json.dump(result, f, indent=2, ensure_ascii=False)\n","\n","                        successful_outputs.append({'college': college_name, 'faculty_count': faculty_count, 'output_file': output_filename})\n","                        print(f\"    üíæ Saved: {output_filename}\")\n","                except Exception as e:\n","                    print(f\"    ‚ùå Error: {str(e)}\")\n","                    failed_files.append((college_name, str(e)))\n","\n","        elif filename.endswith('.txt'):\n","            college_name = filename.replace('.txt', '')\n","            print(f\"üè´ Processing: {college_name}\")\n","            try:\n","                text_content = io.BytesIO(content).read().decode('utf-8')\n","                result = processor.process_file_content(text_content, filename)\n","                if \"error\" in result:\n","                    print(f\"    ‚ùå {result['error']}\")\n","                    failed_files.append((college_name, result['error']))\n","                else:\n","                    faculty_count = result['payload']['faculty_count']\n","                    print(f\"    ‚úÖ Found {faculty_count} faculty members\")\n","                    output_filename = f\"{college_name}_faculty_data.json\"\n","                    with open(output_filename, 'w', encoding='utf-8') as f:\n","                        json.dump(result, f, indent=2, ensure_ascii=False)\n","                    successful_outputs.append({'college': college_name, 'faculty_count': faculty_count, 'output_file': output_filename})\n","                    print(f\"    üíæ Saved: {output_filename}\")\n","            except Exception as e:\n","                print(f\"    ‚ùå Error: {str(e)}\")\n","                failed_files.append((college_name, str(e)))\n","        else:\n","            print(f\"Skipping {filename}: Not a supported .txt or .zip file.\")\n","\n","    return successful_outputs, failed_files\n","\n","def create_zip_download(successful_outputs: list):\n","    \"\"\"Create a ZIP file with all generated JSON outputs for easy download.\"\"\"\n","    if not successful_outputs:\n","        print(\"No successful outputs to zip.\")\n","        return\n","\n","    zip_filename = f\"all_college_faculty_data_{datetime.now().strftime('%Y%m%d_%H%M%S')}.zip\"\n","    with zipfile.ZipFile(zip_filename, 'w') as zipf:\n","        for output in successful_outputs:\n","            try:\n","                zipf.write(output['output_file'])\n","                print(f\"Added to ZIP: {output['output_file']}\")\n","            except FileNotFoundError:\n","                print(f\"File not found: {output['output_file']}. Skipping.\")\n","\n","    print(f\"\\nüì¶ Created ZIP file: {zip_filename}\")\n","    print(f\"Contains {len(successful_outputs)} JSON files\")\n","\n","    if files:\n","        files.download(zip_filename)\n","        print(\"‚úÖ ZIP file downloaded!\")\n","    else:\n","        print(\"Google Colab environment not detected. Cannot auto-download.\")\n","\n","# MAIN EXECUTION\n","if __name__ == \"__main__\":\n","    successful_outputs, failed_files = process_files_individual_output()\n","\n","    if successful_outputs:\n","        print(\"\\n\" + \"=\"*80)\n","        print(\"PROCESSING COMPLETE - INDIVIDUAL OUTPUTS CREATED\")\n","        print(\"=\"*80)\n","\n","        print(f\"‚úÖ SUCCESS: {len(successful_outputs)} colleges processed\")\n","        print(\"\\nüìÇ INDIVIDUAL JSON FILES CREATED:\")\n","\n","        total_faculty = sum(output['faculty_count'] for output in successful_outputs)\n","        for output in successful_outputs:\n","            print(f\"    ‚Ä¢ {output['output_file']} ({output['faculty_count']} faculty)\")\n","        print(f\"\\nüéØ Total faculty across all colleges: {total_faculty}\")\n","\n","        create_zip_download(successful_outputs)\n","\n","    if failed_files:\n","        print(\"\\n\" + \"=\"*80)\n","        print(\"FAILED TO PROCESS\")\n","        print(\"=\"*80)\n","        for college, reason in failed_files:\n","            print(f\"‚ùå {college}.txt (Reason: {reason})\")"]},{"cell_type":"code","source":["#code2 =  code 1\n","import re\n","\n","import json\n","\n","import uuid\n","\n","import os\n","\n","import zipfile\n","\n","from datetime import datetime\n","\n","from typing import Dict, List, Any, Optional\n","\n","from collections import Counter\n","\n","import io\n","\n","\n","\n","try:\n","\n","    from google.colab import files\n","\n","except ImportError:\n","\n","    files = None\n","\n","\n","\n","class FacultyDataProcessor:\n","\n","    def __init__(self):\n","\n","        # Designation mapping for standardization\n","\n","        self.designation_mapping = {\n","\n","            'assistant professor': 'Assistant Professor',\n","\n","            'associate professor': 'Associate Professor',\n","\n","            'professor': 'Professor',\n","\n","            'dean': 'Dean',\n","\n","            'principal': 'Principal',\n","\n","            'director': 'Director',\n","\n","            'vice chancellor': 'Vice Chancellor',\n","\n","            'associate dean': 'Associate Dean',\n","\n","            'lecturer': 'Lecturer',\n","\n","            'head of department': 'HOD',\n","\n","            'hod': 'HOD',\n","\n","        }\n","\n","\n","\n","        # Qualification mapping for standardization\n","\n","        self.qualification_mapping = {\n","\n","            'ph.d': 'Ph.D', 'phd': 'Ph.D', 'ph d': 'Ph.D', 'd.phil': 'Ph.D',\n","\n","            'm.tech': 'M.Tech', 'mtech': 'M.Tech', 'm.sc': 'M.Sc', 'msc': 'M.Sc',\n","\n","            'b.tech': 'B.Tech', 'btech': 'B.Tech', 'master of design': 'M.Des',\n","\n","            'm.a': 'M.A', 'ma': 'M.A', 'b.ed': 'B.Ed', 'm.phil': 'M.Phil',\n","\n","            'llm': 'LLM', 'mba': 'MBA', 'p.g.d.m': 'PGDM', 'b.com': 'B.Com'\n","\n","        }\n","\n","\n","\n","        # Regular expressions for robust parsing\n","\n","        self.patterns = [\n","\n","            # Pattern 1: Basic pipe or multiple space separated values\n","\n","            r'(\\d+)\\s*\\|\\s*([^|]+?)\\s*\\|\\s*(\\d+)\\s*\\|\\s*([^|]+?)\\s*\\|\\s*([^|]+?)\\s*\\|\\s*([^|]+?)\\s*\\|\\s*(\\d+)\\s*\\|\\s*([^|]+?)\\s*\\|\\s*([^|]+?)\\s*\\|\\s*([^|]+?)\\s*\\|\\s*([^|]+)',\n","\n","            # Pattern 2: Space-separated table format\n","\n","            r'(\\d+)\\s+([A-Za-z\\s.]+?)\\s+(\\d+)\\s+([A-Za-z.\\s]+?)\\s+(Male|Female)\\s+([A-Z.\\s]+?)\\s+(\\d+)\\s+(Yes|No)\\s+(\\d{2}-\\d{2}-\\d{4})',\n","\n","            # Pattern 3: Key-value pairs\n","\n","            r'Name:\\s*([A-Za-z\\s]+?)\\s*\\|\\s*Designation:\\s*([^|]+)\\s*\\|\\s*Gender:\\s*([^|]+)\\s*\\|\\s*Qualification:\\s*([^|]+)'\n","\n","        ]\n","\n","\n","\n","    def extract_faculty_section(self, text: str) -> str:\n","\n","        \"\"\"Improved faculty section detection with multiple patterns.\"\"\"\n","\n","        faculty_patterns = [\n","\n","            r'###SECTION:FACULTY_DETAILS###(.*?)(?=###SECTION:|$)',\n","\n","            r'FACULTY\\s*DETAILS?(.*?)(?=\\n\\s*[A-Z\\s]+:|\\n\\s*###|\\Z)',\n","\n","            r'Faculty\\s*Information(.*?)(?=\\n\\s*[A-Z\\s]+:|\\n\\s*###|\\Z)',\n","\n","            r'Teaching\\s*Staff(.*?)(?=\\n\\s*[A-Z\\s]+:|\\n\\s*###|\\Z)'\n","\n","        ]\n","\n","\n","\n","        for pattern in faculty_patterns:\n","\n","            match = re.search(pattern, text, re.DOTALL | re.IGNORECASE)\n","\n","            if match:\n","\n","                section = match.group(1).strip()\n","\n","                if len(section) > 100:\n","\n","                    return section\n","\n","\n","\n","        lines = text.split('\\n')\n","\n","        faculty_start = -1\n","\n","\n","\n","        header_patterns = [\n","\n","            r'(srno|s\\.?\\s*no|serial).*name.*designation',\n","\n","            r'name.*age.*designation',\n","\n","            r'faculty.*name.*department',\n","\n","            r'professor.*department.*qualification'\n","\n","        ]\n","\n","\n","\n","        for i, line in enumerate(lines):\n","\n","            line_lower = line.lower().strip()\n","\n","            for pattern in header_patterns:\n","\n","                if re.search(pattern, line_lower):\n","\n","                    faculty_start = i\n","\n","                    break\n","\n","            if faculty_start != -1:\n","\n","                break\n","\n","\n","\n","        if faculty_start != -1:\n","\n","            faculty_end = len(lines)\n","\n","            data_lines = 0\n","\n","\n","\n","            for i in range(faculty_start + 1, len(lines)):\n","\n","                line = lines[i].strip()\n","\n","                if line:\n","\n","                    if re.match(r'^\\d+\\s+', line):\n","\n","                        data_lines += 1\n","\n","                    elif line.startswith('###') or (data_lines > 5 and len(line.split()) < 3):\n","\n","                        faculty_end = i\n","\n","                        break\n","\n","\n","\n","            if data_lines > 0:\n","\n","                return '\\n'.join(lines[faculty_start:faculty_end])\n","\n","\n","\n","        faculty_pattern = r'(?:Dr\\.|Prof\\.|Mr\\.|Ms\\.|Mrs\\.)\\s+[A-Za-z\\s]+\\s+(?:Ph\\.?D|M\\.Tech|M\\.Sc|Professor)'\n","\n","        matches = re.findall(faculty_pattern, text, re.IGNORECASE)\n","\n","\n","\n","        if len(matches) > 3:\n","\n","            for match in matches[:1]:\n","\n","                match_pos = text.find(match[0])\n","\n","                if match_pos != -1:\n","\n","                    start = max(0, match_pos - 500)\n","\n","                    end = min(len(text), match_pos + 2000)\n","\n","                    return text[start:end]\n","\n","\n","\n","        return \"\"\n","\n","\n","\n","    def parse_faculty_data(self, faculty_text: str) -> List[Dict[str, Any]]:\n","\n","        \"\"\"Parse faculty data from the extracted text and sort by seniority.\"\"\"\n","\n","        faculty_records = []\n","\n","        if not faculty_text:\n","\n","            return []\n","\n","\n","\n","        # Use the most specific pattern that works\n","\n","        for pattern in self.patterns:\n","\n","            matches = re.findall(pattern, faculty_text, re.IGNORECASE | re.MULTILINE)\n","\n","            if matches:\n","\n","                for match in matches:\n","\n","                    record = self.parse_match(match)\n","\n","                    if record:\n","\n","                        faculty_records.append(record)\n","\n","                if faculty_records:\n","\n","                    # ADDED: Sort by seniority score\n","\n","                    faculty_records.sort(key=lambda x: x.get('seniority_score', 0), reverse=True)\n","\n","                    return faculty_records\n","\n","\n","\n","        # Fallback to line-by-line parsing\n","\n","        lines = faculty_text.split('\\n')\n","\n","        for line in lines:\n","\n","            line = line.strip()\n","\n","            if line and self.is_valid_faculty_line(line):\n","\n","                record = self.parse_fallback_line(line)\n","\n","                if record:\n","\n","                    faculty_records.append(record)\n","\n","\n","\n","        # ADDED: Sort by seniority score even for fallback\n","\n","        faculty_records.sort(key=lambda x: x.get('seniority_score', 0), reverse=True)\n","\n","        return faculty_records\n","\n","\n","\n","    def parse_match(self, match: tuple) -> Optional[Dict[str, Any]]:\n","\n","        \"\"\"Parse a regex match into a structured faculty record.\"\"\"\n","\n","        record = {}\n","\n","        try:\n","\n","            if len(match) == 9:\n","\n","                record = {\n","\n","                    'serial_no': match[0], 'name': self.clean_name(match[1]), 'age': match[2],\n","\n","                    'designation': self.standardize_designation(match[3]), 'gender': match[4],\n","\n","                    'qualification': self.standardize_qualification(match[5]), 'experience': match[6],\n","\n","                    'phd_status': match[7], 'joining_date': self.parse_date(match[8])\n","\n","                }\n","\n","            elif len(match) == 4:\n","\n","                record = {\n","\n","                    'name': self.clean_name(match[0]), 'designation': self.standardize_designation(match[1]),\n","\n","                    'gender': match[2], 'qualification': self.standardize_qualification(match[3])\n","\n","                }\n","\n","            elif len(match) == 11:\n","\n","                record = {\n","\n","                    'serial_no': match[0], 'name': self.clean_name(match[1]), 'age': match[2],\n","\n","                    'designation': self.standardize_designation(match[3]), 'gender': match[4],\n","\n","                    'qualification': self.standardize_qualification(match[5]), 'experience': match[6],\n","\n","                    'currently_working': match[7], 'joining_date': self.parse_date(match[8]),\n","\n","                    'leaving_date': self.parse_date(match[9]), 'association_type': match[10]\n","\n","                }\n","\n","\n","\n","            if record and record.get('name'):\n","\n","                record['id'] = str(uuid.uuid4())\n","\n","                # ADDED: new score calculations\n","\n","                record['seniority_score'] = self.calculate_seniority_score(record)\n","\n","                record['quality_score'] = self.calculate_record_quality_score(record)\n","\n","                # ADDED: enhanced career stage logic\n","\n","                record['career_stage'] = self.determine_career_stage(record['designation'], record.get('experience', ''), record.get('age', ''))\n","\n","                record['data_year'] = str(datetime.now().year)\n","\n","                return record\n","\n","        except Exception as e:\n","\n","            pass\n","\n","        return None\n","\n","\n","\n","    def is_valid_faculty_line(self, line: str) -> bool:\n","\n","        \"\"\"Heuristically checks if a line is likely to contain faculty data.\"\"\"\n","\n","        line_lower = line.lower()\n","\n","        if len(line) < 20: return False\n","\n","        keywords = ['professor', 'lecturer', 'phd', 'male', 'female']\n","\n","        if not any(k in line_lower for k in keywords):\n","\n","            return False\n","\n","        if re.search(r'\\d{2,3}', line) and re.search(r'[A-Z][a-z]+', line):\n","\n","            return True\n","\n","        return False\n","\n","\n","\n","    def parse_fallback_line(self, line: str) -> Optional[Dict[str, Any]]:\n","\n","        \"\"\"Parses a line using a more generalized, keyword-based approach.\"\"\"\n","\n","        record = {}\n","\n","        line_lower = line.lower()\n","\n","\n","\n","        for key, val in self.designation_mapping.items():\n","\n","            if key in line_lower:\n","\n","                record['designation'] = val\n","\n","                break\n","\n","\n","\n","        for key, val in self.qualification_mapping.items():\n","\n","            if key in line_lower:\n","\n","                record['qualification'] = val\n","\n","                break\n","\n","\n","\n","        if 'male' in line_lower: record['gender'] = 'Male'\n","\n","        elif 'female' in line_lower: record['gender'] = 'Female'\n","\n","\n","\n","        exp_match = re.search(r'(\\d+)\\s+(?:years|exp|experience)', line_lower)\n","\n","        if exp_match: record['experience'] = exp_match.group(1)\n","\n","\n","\n","        name_match = re.search(r'^(?:dr\\.|prof\\.)?\\s*([A-Z][a-z]+(?:\\s+[A-Z][a-z]+)*)', line, re.IGNORECASE)\n","\n","        if name_match: record['name'] = self.clean_name(name_match.group(1))\n","\n","\n","\n","        if 'name' in record and 'designation' in record:\n","\n","            record['id'] = str(uuid.uuid4())\n","\n","            # ADDED: new score calculations\n","\n","            record['seniority_score'] = self.calculate_seniority_score(record)\n","\n","            record['quality_score'] = self.calculate_record_quality_score(record)\n","\n","            # ADDED: enhanced career stage logic\n","\n","            record['career_stage'] = self.determine_career_stage(record.get('designation', ''), record.get('experience', ''), record.get('age', ''))\n","\n","            record['data_year'] = str(datetime.now().year)\n","\n","            return record\n","\n","\n","\n","        return None\n","\n","\n","\n","    def clean_name(self, name: str) -> str:\n","\n","        \"\"\"Clean and format faculty name.\"\"\"\n","\n","        if not name: return \"\"\n","\n","        name = re.sub(r'\\s+', ' ', name.strip())\n","\n","        return name.title()\n","\n","\n","\n","    def standardize_designation(self, designation: str) -> str:\n","\n","        \"\"\"Standardize designation using mapping.\"\"\"\n","\n","        if not designation: return \"\"\n","\n","        designation_lower = designation.lower().strip()\n","\n","        return self.designation_mapping.get(designation_lower, designation.title())\n","\n","\n","\n","    def standardize_qualification(self, qualification: str) -> str:\n","\n","        \"\"\"Standardize qualification using mapping.\"\"\"\n","\n","        if not qualification: return \"\"\n","\n","        qual_lower = qualification.lower().strip().replace('.', '')\n","\n","        return self.qualification_mapping.get(qual_lower, qualification)\n","\n","\n","\n","    def parse_date(self, date_str: str) -> str:\n","\n","        \"\"\"Parse and standardize date format to YYYY-MM-DD.\"\"\"\n","\n","        if not date_str or date_str == '--': return \"\"\n","\n","        date_patterns = [\n","\n","            r'(\\d{1,2})[-/](\\d{1,2})[-/](\\d{4})',\n","\n","            r'(\\d{4})[-/](\\d{1,2})[-/](\\d{1,2})'\n","\n","        ]\n","\n","\n","\n","        for pattern in date_patterns:\n","\n","            match = re.search(pattern, date_str)\n","\n","            if match:\n","\n","                if len(match.group(3)) == 4:\n","\n","                    d, m, y = match.groups()\n","\n","                else:\n","\n","                    y, m, d = match.groups()\n","\n","                try:\n","\n","                    return f\"{int(y):04d}-{int(m):02d}-{int(d):02d}\"\n","\n","                except ValueError:\n","\n","                    return date_str\n","\n","        return date_str\n","\n","\n","\n","    def calculate_seniority_score(self, record: Dict[str, Any]) -> int:\n","\n","        \"\"\"Enhanced seniority score with weighted factors.\"\"\"\n","\n","        score = 0\n","\n","        designation_scores = {\n","\n","            \"Assistant Professor\": 30, \"Associate Professor\": 60, \"Professor\": 90,\n","\n","            \"Dean\": 120, \"Director\": 130, \"Vice Chancellor\": 150, \"Principal\": 110,\n","\n","            \"Lecturer\": 15, \"HOD\": 100\n","\n","        }\n","\n","        score += designation_scores.get(record.get('designation', ''), 15)\n","\n","\n","\n","        if record.get('experience', '').isdigit():\n","\n","            exp_years = int(record['experience']) // 12\n","\n","            if exp_years <= 5:\n","\n","                score += exp_years * 5\n","\n","            elif exp_years <= 15:\n","\n","                score += 25 + (exp_years - 5) * 3\n","\n","            else:\n","\n","                score += 55 + (exp_years - 15) * 2\n","\n","\n","\n","        qual = record.get('qualification', '').lower()\n","\n","        if 'ph.d' in qual or 'phd' in qual:\n","\n","            score += 40\n","\n","        elif 'm.tech' in qual or 'mtech' in qual:\n","\n","            score += 25\n","\n","        elif 'm.sc' in qual or 'msc' in qual:\n","\n","            score += 20\n","\n","        elif 'b.tech' in qual or 'btech' in qual:\n","\n","            score += 10\n","\n","\n","\n","        if record.get('age', '').isdigit():\n","\n","            age = int(record['age'])\n","\n","            if age > 50:\n","\n","                score += 15\n","\n","            elif age > 40:\n","\n","                score += 10\n","\n","            elif age > 35:\n","\n","                score += 5\n","\n","\n","\n","        return min(score, 200)\n","\n","\n","\n","    def calculate_record_quality_score(self, record: Dict[str, Any]) -> float:\n","\n","        \"\"\"Calculate quality score for individual faculty record.\"\"\"\n","\n","        score = 0\n","\n","        essential_fields = {\n","\n","            'name': 20, 'designation': 15, 'qualification': 15, 'experience': 10\n","\n","        }\n","\n","        for field, points in essential_fields.items():\n","\n","            if record.get(field) and record[field].strip():\n","\n","                score += points\n","\n","\n","\n","        additional_fields = {\n","\n","            'age': 10, 'gender': 5, 'joining_date': 10, 'currently_working': 5, 'association_type': 10\n","\n","        }\n","\n","        for field, points in additional_fields.items():\n","\n","            if record.get(field) and record[field].strip() and record[field] != '--':\n","\n","                score += points\n","\n","\n","\n","        return round(score, 1)\n","\n","\n","\n","    def determine_career_stage(self, designation: str, experience: str, age: str = \"\") -> str:\n","\n","        \"\"\"Enhanced career stage determination.\"\"\"\n","\n","        if not designation:\n","\n","            return \"Unknown\"\n","\n","\n","\n","        designation_lower = designation.lower()\n","\n","        exp_years = int(experience) // 12 if experience.isdigit() else 0\n","\n","        age_num = int(age) if age.isdigit() else 0\n","\n","\n","\n","        if any(word in designation_lower for word in ['dean', 'director', 'vice chancellor', 'principal']):\n","\n","            return \"Senior Career\"\n","\n","\n","\n","        if 'professor' in designation_lower and 'assistant' not in designation_lower and 'associate' not in designation_lower:\n","\n","            return \"Senior Career\"\n","\n","\n","\n","        if 'associate' in designation_lower:\n","\n","            return \"Mid Career\" if exp_years < 20 else \"Senior Career\"\n","\n","\n","\n","        if 'assistant' in designation_lower:\n","\n","            if exp_years < 3 or age_num < 30:\n","\n","                return \"Early Career\"\n","\n","            elif exp_years < 8:\n","\n","                return \"Early Career\"\n","\n","            else:\n","\n","                return \"Mid Career\"\n","\n","\n","\n","        if exp_years > 15 or age_num > 50:\n","\n","            return \"Senior Career\"\n","\n","        elif exp_years > 5 or age_num > 35:\n","\n","            return \"Mid Career\"\n","\n","\n","\n","        return \"Early Career\"\n","\n","\n","\n","    def calculate_quality_score(self, records: List[Dict[str, Any]]) -> float:\n","\n","        \"\"\"Calculate overall quality score for the faculty data.\"\"\"\n","\n","        if not records: return 0.0\n","\n","        total_score = sum(r.get('quality_score', 0) for r in records)\n","\n","        return round(total_score / len(records), 2)\n","\n","\n","\n","    def create_content_summary(self, records: List[Dict[str, Any]]) -> str:\n","\n","        \"\"\"Create enhanced summary with statistics.\"\"\"\n","\n","        if not records:\n","\n","            return \"\"\n","\n","\n","\n","        total_faculty = len(records)\n","\n","        phd_count = sum(1 for r in records if r.get('phd_status') == 'Yes')\n","\n","\n","\n","        career_stages = Counter(r.get('career_stage', 'Unknown') for r in records)\n","\n","        designation_counts = Counter(r.get('designation', 'Unknown') for r in records)\n","\n","\n","\n","        avg_seniority = sum(r.get('seniority_score', 0) for r in records) / total_faculty\n","\n","        avg_quality = sum(r.get('quality_score', 0) for r in records) / total_faculty\n","\n","\n","\n","        summary_parts = [\n","\n","            f\"Faculty dataset with {total_faculty} members ({phd_count} with Ph.D).\",\n","\n","            f\"Average seniority score: {avg_seniority:.1f}, Quality score: {avg_quality:.1f}.\",\n","\n","            \"Career stages: \" + \", \".join(f\"{k}: {v}\" for k, v in career_stages.items()),\n","\n","            \"Top designations: \" + \", \".join(f\"{k}: {v}\" for k, v in sorted(designation_counts.items(), key=lambda x: x[1], reverse=True)[:3])\n","\n","        ]\n","\n","\n","\n","        return \" \".join(summary_parts)\n","\n","\n","\n","    def create_json_output(self, faculty_records: List[Dict[str, Any]], filename: str) -> Dict[str, Any]:\n","\n","        \"\"\"Create the final JSON output in Qdrant format without a vector field.\"\"\"\n","\n","        if not faculty_records:\n","\n","            return {}\n","\n","\n","\n","        quality_score = self.calculate_quality_score(faculty_records)\n","\n","        content = self.create_content_summary(faculty_records)\n","\n","        title = f\"Faculty Data - {len(faculty_records)} members from {filename}\"\n","\n","\n","\n","        output = {\n","\n","            \"id\": str(uuid.uuid4()),\n","\n","            \"payload\": {\n","\n","                \"content\": content, \"title\": title, \"source_file\": filename,\n","\n","                \"content_type\": \"faculty\", \"chunk_type\": \"faculty\", \"category\": \"Faculty\",\n","\n","                \"faculty_count\": len(faculty_records), \"processing_timestamp\": datetime.now().isoformat(),\n","\n","                \"enhanced_structure\": True, \"quality_score\": quality_score,\n","\n","                \"data_source\": \"processed_file\", \"faculty_records\": faculty_records\n","\n","            }\n","\n","        }\n","\n","        return output\n","\n","\n","\n","    def process_file_content(self, text_content: str, filename: str) -> Dict[str, Any]:\n","\n","        \"\"\"Main method to process a file's text content.\"\"\"\n","\n","        if not text_content or not text_content.strip():\n","\n","            return {\"error\": \"No content provided.\"}\n","\n","        faculty_section = self.extract_faculty_section(text_content)\n","\n","        if not faculty_section:\n","\n","            return {\"error\": \"No faculty section found in the text.\"}\n","\n","        faculty_records = self.parse_faculty_data(faculty_section)\n","\n","        if not faculty_records:\n","\n","            return {\"error\": \"No faculty records could be parsed.\"}\n","\n","        json_output = self.create_json_output(faculty_records, filename)\n","\n","        return json_output\n","\n","\n","\n","def process_files_individual_output():\n","\n","    \"\"\"Process all uploaded files and create separate JSON output for each college.\"\"\"\n","\n","    if files is None:\n","\n","        print(\"This function requires Google Colab. Please run in a Colab environment.\")\n","\n","        return\n","\n","\n","\n","    print(\"Upload your faculty data files (e.g., as a .zip or multiple .txt):\")\n","\n","    uploaded = files.upload()\n","\n","\n","\n","    if not uploaded:\n","\n","        print(\"No files uploaded!\")\n","\n","        return\n","\n","\n","\n","    processor = FacultyDataProcessor()\n","\n","    successful_outputs = []\n","\n","    failed_files = []\n","\n","\n","\n","    for filename, content in uploaded.items():\n","\n","        if filename.endswith('.zip'):\n","\n","            with zipfile.ZipFile(io.BytesIO(content), 'r') as zip_ref:\n","\n","                print(f\"üì¶ Unzipping {filename}...\")\n","\n","                zip_ref.extractall(\"uploaded_files\")\n","\n","\n","\n","            txt_files = [f for f in os.listdir(\"uploaded_files\") if f.endswith('.txt')]\n","\n","            if not txt_files:\n","\n","                print(\"No .txt files found in the zip.\")\n","\n","                continue\n","\n","\n","\n","            for txt_filename in txt_files:\n","\n","                txt_filepath = os.path.join(\"uploaded_files\", txt_filename)\n","\n","                with open(txt_filepath, 'r', encoding='utf-8') as f:\n","\n","                    text_content = f.read()\n","\n","\n","\n","                print(f\"üè´ Processing: {txt_filename}\")\n","\n","                college_name = txt_filename.replace('.txt', '')\n","\n","\n","\n","                try:\n","\n","                    result = processor.process_file_content(text_content, txt_filename)\n","\n","                    if \"error\" in result:\n","\n","                        print(f\"    ‚ùå {result['error']}\")\n","\n","                        failed_files.append((college_name, result['error']))\n","\n","                    else:\n","\n","                        faculty_count = result['payload']['faculty_count']\n","\n","                        print(f\"    ‚úÖ Found {faculty_count} faculty members\")\n","\n","\n","\n","                        output_filename = f\"{college_name}_faculty_data.json\"\n","\n","                        with open(output_filename, 'w', encoding='utf-8') as f:\n","\n","                            json.dump(result, f, indent=2, ensure_ascii=False)\n","\n","\n","\n","                        successful_outputs.append({'college': college_name, 'faculty_count': faculty_count, 'output_file': output_filename})\n","\n","                        print(f\"    üíæ Saved: {output_filename}\")\n","\n","                except Exception as e:\n","\n","                    print(f\"    ‚ùå Error: {str(e)}\")\n","\n","                    failed_files.append((college_name, str(e)))\n","\n","\n","\n","        elif filename.endswith('.txt'):\n","\n","            college_name = filename.replace('.txt', '')\n","\n","            print(f\"üè´ Processing: {college_name}\")\n","\n","            try:\n","\n","                text_content = io.BytesIO(content).read().decode('utf-8')\n","\n","                result = processor.process_file_content(text_content, filename)\n","\n","                if \"error\" in result:\n","\n","                    print(f\"    ‚ùå {result['error']}\")\n","\n","                    failed_files.append((college_name, result['error']))\n","\n","                else:\n","\n","                    faculty_count = result['payload']['faculty_count']\n","\n","                    print(f\"    ‚úÖ Found {faculty_count} faculty members\")\n","\n","                    output_filename = f\"{college_name}_faculty_data.json\"\n","\n","                    with open(output_filename, 'w', encoding='utf-8') as f:\n","\n","                        json.dump(result, f, indent=2, ensure_ascii=False)\n","\n","                    successful_outputs.append({'college': college_name, 'faculty_count': faculty_count, 'output_file': output_filename})\n","\n","                    print(f\"    üíæ Saved: {output_filename}\")\n","\n","            except Exception as e:\n","\n","                print(f\"    ‚ùå Error: {str(e)}\")\n","\n","                failed_files.append((college_name, str(e)))\n","\n","        else:\n","\n","            print(f\"Skipping {filename}: Not a supported .txt or .zip file.\")\n","\n","\n","\n","    return successful_outputs, failed_files\n","\n","\n","\n","def create_zip_download(successful_outputs: list):\n","\n","    \"\"\"Create a ZIP file with all generated JSON outputs for easy download.\"\"\"\n","\n","    if not successful_outputs:\n","\n","        print(\"No successful outputs to zip.\")\n","\n","        return\n","\n","\n","\n","    zip_filename = f\"all_college_faculty_data_{datetime.now().strftime('%Y%m%d_%H%M%S')}.zip\"\n","\n","    with zipfile.ZipFile(zip_filename, 'w') as zipf:\n","\n","        for output in successful_outputs:\n","\n","            try:\n","\n","                zipf.write(output['output_file'])\n","\n","                print(f\"Added to ZIP: {output['output_file']}\")\n","\n","            except FileNotFoundError:\n","\n","                print(f\"File not found: {output['output_file']}. Skipping.\")\n","\n","\n","\n","    print(f\"\\nüì¶ Created ZIP file: {zip_filename}\")\n","\n","    print(f\"Contains {len(successful_outputs)} JSON files\")\n","\n","\n","\n","    if files:\n","\n","        files.download(zip_filename)\n","\n","        print(\"‚úÖ ZIP file downloaded!\")\n","\n","    else:\n","\n","        print(\"Google Colab environment not detected. Cannot auto-download.\")\n","\n","\n","\n","# MAIN EXECUTION\n","\n","if __name__ == \"__main__\":\n","\n","    successful_outputs, failed_files = process_files_individual_output()\n","\n","\n","\n","    if successful_outputs:\n","\n","        print(\"\\n\" + \"=\"*80)\n","\n","        print(\"PROCESSING COMPLETE - INDIVIDUAL OUTPUTS CREATED\")\n","\n","        print(\"=\"*80)\n","\n","\n","\n","        print(f\"‚úÖ SUCCESS: {len(successful_outputs)} colleges processed\")\n","\n","        print(\"\\nüìÇ INDIVIDUAL JSON FILES CREATED:\")\n","\n","\n","\n","        total_faculty = sum(output['faculty_count'] for output in successful_outputs)\n","\n","        for output in successful_outputs:\n","\n","            print(f\"    ‚Ä¢ {output['output_file']} ({output['faculty_count']} faculty)\")\n","\n","        print(f\"\\nüéØ Total faculty across all colleges: {total_faculty}\")\n","\n","\n","\n","        create_zip_download(successful_outputs)\n","\n","\n","\n","    if failed_files:\n","\n","        print(\"\\n\" + \"=\"*80)\n","\n","        print(\"FAILED TO PROCESS\")\n","\n","        print(\"=\"*80)\n","\n","        for college, reason in failed_files:\n","\n","            print(f\"‚ùå {college}.txt (Reason: {reason})\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":645},"id":"lgwyX7qUKrdu","executionInfo":{"status":"ok","timestamp":1762974665242,"user_tz":-330,"elapsed":56080,"user":{"displayName":"Rahul Siddhu","userId":"12007764243202946991"}},"outputId":"83db9ba4-dc32-4b8c-f153-5697f5aab660"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Upload your faculty data files (e.g., as a .zip or multiple .txt):\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","     <input type=\"file\" id=\"files-cc974c17-c721-403a-887d-aa7823fad28d\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-cc974c17-c721-403a-887d-aa7823fad28d\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script>// Copyright 2017 Google LLC\n","//\n","// Licensed under the Apache License, Version 2.0 (the \"License\");\n","// you may not use this file except in compliance with the License.\n","// You may obtain a copy of the License at\n","//\n","//      http://www.apache.org/licenses/LICENSE-2.0\n","//\n","// Unless required by applicable law or agreed to in writing, software\n","// distributed under the License is distributed on an \"AS IS\" BASIS,\n","// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","// See the License for the specific language governing permissions and\n","// limitations under the License.\n","\n","/**\n"," * @fileoverview Helpers for google.colab Python module.\n"," */\n","(function(scope) {\n","function span(text, styleAttributes = {}) {\n","  const element = document.createElement('span');\n","  element.textContent = text;\n","  for (const key of Object.keys(styleAttributes)) {\n","    element.style[key] = styleAttributes[key];\n","  }\n","  return element;\n","}\n","\n","// Max number of bytes which will be uploaded at a time.\n","const MAX_PAYLOAD_SIZE = 100 * 1024;\n","\n","function _uploadFiles(inputId, outputId) {\n","  const steps = uploadFilesStep(inputId, outputId);\n","  const outputElement = document.getElementById(outputId);\n","  // Cache steps on the outputElement to make it available for the next call\n","  // to uploadFilesContinue from Python.\n","  outputElement.steps = steps;\n","\n","  return _uploadFilesContinue(outputId);\n","}\n","\n","// This is roughly an async generator (not supported in the browser yet),\n","// where there are multiple asynchronous steps and the Python side is going\n","// to poll for completion of each step.\n","// This uses a Promise to block the python side on completion of each step,\n","// then passes the result of the previous step as the input to the next step.\n","function _uploadFilesContinue(outputId) {\n","  const outputElement = document.getElementById(outputId);\n","  const steps = outputElement.steps;\n","\n","  const next = steps.next(outputElement.lastPromiseValue);\n","  return Promise.resolve(next.value.promise).then((value) => {\n","    // Cache the last promise value to make it available to the next\n","    // step of the generator.\n","    outputElement.lastPromiseValue = value;\n","    return next.value.response;\n","  });\n","}\n","\n","/**\n"," * Generator function which is called between each async step of the upload\n"," * process.\n"," * @param {string} inputId Element ID of the input file picker element.\n"," * @param {string} outputId Element ID of the output display.\n"," * @return {!Iterable<!Object>} Iterable of next steps.\n"," */\n","function* uploadFilesStep(inputId, outputId) {\n","  const inputElement = document.getElementById(inputId);\n","  inputElement.disabled = false;\n","\n","  const outputElement = document.getElementById(outputId);\n","  outputElement.innerHTML = '';\n","\n","  const pickedPromise = new Promise((resolve) => {\n","    inputElement.addEventListener('change', (e) => {\n","      resolve(e.target.files);\n","    });\n","  });\n","\n","  const cancel = document.createElement('button');\n","  inputElement.parentElement.appendChild(cancel);\n","  cancel.textContent = 'Cancel upload';\n","  const cancelPromise = new Promise((resolve) => {\n","    cancel.onclick = () => {\n","      resolve(null);\n","    };\n","  });\n","\n","  // Wait for the user to pick the files.\n","  const files = yield {\n","    promise: Promise.race([pickedPromise, cancelPromise]),\n","    response: {\n","      action: 'starting',\n","    }\n","  };\n","\n","  cancel.remove();\n","\n","  // Disable the input element since further picks are not allowed.\n","  inputElement.disabled = true;\n","\n","  if (!files) {\n","    return {\n","      response: {\n","        action: 'complete',\n","      }\n","    };\n","  }\n","\n","  for (const file of files) {\n","    const li = document.createElement('li');\n","    li.append(span(file.name, {fontWeight: 'bold'}));\n","    li.append(span(\n","        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n","        `last modified: ${\n","            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n","                                    'n/a'} - `));\n","    const percent = span('0% done');\n","    li.appendChild(percent);\n","\n","    outputElement.appendChild(li);\n","\n","    const fileDataPromise = new Promise((resolve) => {\n","      const reader = new FileReader();\n","      reader.onload = (e) => {\n","        resolve(e.target.result);\n","      };\n","      reader.readAsArrayBuffer(file);\n","    });\n","    // Wait for the data to be ready.\n","    let fileData = yield {\n","      promise: fileDataPromise,\n","      response: {\n","        action: 'continue',\n","      }\n","    };\n","\n","    // Use a chunked sending to avoid message size limits. See b/62115660.\n","    let position = 0;\n","    do {\n","      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n","      const chunk = new Uint8Array(fileData, position, length);\n","      position += length;\n","\n","      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n","      yield {\n","        response: {\n","          action: 'append',\n","          file: file.name,\n","          data: base64,\n","        },\n","      };\n","\n","      let percentDone = fileData.byteLength === 0 ?\n","          100 :\n","          Math.round((position / fileData.byteLength) * 100);\n","      percent.textContent = `${percentDone}% done`;\n","\n","    } while (position < fileData.byteLength);\n","  }\n","\n","  // All done.\n","  yield {\n","    response: {\n","      action: 'complete',\n","    }\n","  };\n","}\n","\n","scope.google = scope.google || {};\n","scope.google.colab = scope.google.colab || {};\n","scope.google.colab._files = {\n","  _uploadFiles,\n","  _uploadFilesContinue,\n","};\n","})(self);\n","</script> "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Saving Aligarh Muslim University.txt to Aligarh Muslim University (1).txt\n","Saving Amrita Vishwa Vidyapeetham.txt to Amrita Vishwa Vidyapeetham (1).txt\n","Saving Anna University.txt to Anna University (1).txt\n","üè´ Processing: Aligarh Muslim University (1)\n","    ‚úÖ Found 224 faculty members\n","    üíæ Saved: Aligarh Muslim University (1)_faculty_data.json\n","üè´ Processing: Amrita Vishwa Vidyapeetham (1)\n","    ‚úÖ Found 951 faculty members\n","    üíæ Saved: Amrita Vishwa Vidyapeetham (1)_faculty_data.json\n","üè´ Processing: Anna University (1)\n","    ‚úÖ Found 890 faculty members\n","    üíæ Saved: Anna University (1)_faculty_data.json\n","\n","================================================================================\n","PROCESSING COMPLETE - INDIVIDUAL OUTPUTS CREATED\n","================================================================================\n","‚úÖ SUCCESS: 3 colleges processed\n","\n","üìÇ INDIVIDUAL JSON FILES CREATED:\n","    ‚Ä¢ Aligarh Muslim University (1)_faculty_data.json (224 faculty)\n","    ‚Ä¢ Amrita Vishwa Vidyapeetham (1)_faculty_data.json (951 faculty)\n","    ‚Ä¢ Anna University (1)_faculty_data.json (890 faculty)\n","\n","üéØ Total faculty across all colleges: 2065\n","Added to ZIP: Aligarh Muslim University (1)_faculty_data.json\n","Added to ZIP: Amrita Vishwa Vidyapeetham (1)_faculty_data.json\n","Added to ZIP: Anna University (1)_faculty_data.json\n","\n","üì¶ Created ZIP file: all_college_faculty_data_20251112_191107.zip\n","Contains 3 JSON files\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["download(\"download_b7488b46-8103-4f52-921f-c497ba70d562\", \"all_college_faculty_data_20251112_191107.zip\", 992373)"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["‚úÖ ZIP file downloaded!\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WWsshcjVsPOg"},"outputs":[],"source":["!pip install qdrant-client sentence-transformers pandas openpyxl ipywidgets requests\n","#hi ra sidd\n","\n","import pandas as pd\n","import numpy as np\n","from qdrant_client import QdrantClient\n","from qdrant_client.models import Distance, VectorParams, PointStruct, Filter, FieldCondition, MatchValue\n","import json\n","from typing import Dict, List, Optional, Any\n","import uuid\n","import os\n","from google.colab import files\n","import ipywidgets as widgets\n","from IPython.display import display, HTML, clear_output\n","import io\n","import hashlib\n","import requests\n","from datetime import datetime\n","\n","class NIRFDataUploader:\n","    def __init__(self):\n","        self.qdrant_client = None\n","        self.collection_name = \"Nirf_Report\"\n","        self.VECTOR_SIZE = 384\n","        self.df = None\n","        self._file_uploaded = False  # Add this line\n","\n","        # Qdrant cloud configuration\n","        self.QDRANT_URL = \"https://b5651607-31ce-49ba-916d-c35c89d731d2.us-east4-0.gcp.cloud.qdrant.io\"\n","        self.QDRANT_API_KEY = \"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJhY2Nlc3MiOiJtIn0.0ApHZL4Qn_A8bx7FCC62nx-IOrHI84W7GZlUZEyVgKk\"\n","\n","        # Expected columns in the Excel file\n","        self.expected_columns = ['Rank', 'College_Name', 'City', 'State', 'TLR', 'RPC', 'GO', 'OI', 'Perception', 'Score']\n","\n","        # Initialize widgets\n","        self.setup_widgets()\n","\n","    def setup_widgets(self):\n","        \"\"\"Setup interactive widgets for Colab\"\"\"\n","\n","        # Header\n","        print(\"üéì NIRF Data Updater for Existing Vector DB\")\n","        print(\"=\" * 50)\n","\n","        self.url_widget = widgets.Text(\n","            value=self.QDRANT_URL,\n","            description=\"Qdrant URL:\",\n","            style={'description_width': 'initial'},\n","            layout=widgets.Layout(width='600px'),\n","            disabled=False\n","        )\n","\n","        self.api_key_widget = widgets.Password(\n","            value=self.QDRANT_API_KEY,\n","            description=\"API Key:\",\n","            style={'description_width': 'initial'},\n","            layout=widgets.Layout(width='600px'),\n","            disabled=False\n","        )\n","\n","        self.collection_widget = widgets.Text(\n","            value=self.collection_name,\n","            description=\"Collection:\",\n","            style={'description_width': 'initial'},\n","            layout=widgets.Layout(width='400px')\n","        )\n","\n","        self.connect_button = widgets.Button(\n","            description=\"Connect to Qdrant\",\n","            button_style='primary',\n","            layout=widgets.Layout(width='200px')\n","        )\n","\n","        self.upload_button = widgets.Button(\n","            description=\"Upload Excel File\",\n","            button_style='success',\n","            layout=widgets.Layout(width='200px')\n","        )\n","\n","        self.process_button = widgets.Button(\n","            description=\"Update NIRF Data\", # Changed button text\n","            button_style='warning',\n","            layout=widgets.Layout(width='200px')\n","        )\n","\n","        self.output = widgets.Output()\n","\n","        self.status_label = widgets.HTML(\n","            value=\"<b style='color: orange;'>Ready to Connect</b>\"\n","        )\n","\n","        self.connect_button.on_click(self.connect_qdrant)\n","        self.upload_button.on_click(self.upload_file)\n","        self.process_button.on_click(self.upload_metadata)\n","\n","    def display_interface(self):\n","        \"\"\"Display the complete interface\"\"\"\n","        connection_box = widgets.VBox([\n","            widgets.HTML(\"<h3>üîó Qdrant Cloud Connection</h3>\"),\n","            self.url_widget,\n","            self.api_key_widget,\n","            self.collection_widget,\n","            widgets.HBox([self.connect_button, self.status_label]),\n","        ])\n","\n","        file_box = widgets.VBox([\n","            widgets.HTML(\"<h3>üìÅ Single NIRF Excel File Upload</h3>\"),\n","            self.upload_button,\n","            widgets.HTML(\"<p><i>Upload your Excel file with columns: Rank, College_Name, City, State, TLR, RPC, GO, OI, Perception, Score</i></p>\")\n","        ])\n","\n","        process_box = widgets.VBox([\n","            widgets.HTML(\"<h3>‚öôÔ∏è Update Existing Records</h3>\"),\n","            self.process_button,\n","        ])\n","\n","        main_interface = widgets.VBox([\n","            connection_box,\n","            widgets.HTML(\"<hr>\"),\n","            file_box,\n","            widgets.HTML(\"<hr>\"),\n","            process_box,\n","            widgets.HTML(\"<hr>\"),\n","            widgets.HTML(\"<h3>üìä Output & Status</h3>\"),\n","            self.output\n","        ])\n","\n","        display(main_interface)\n","\n","    def log_status(self, message: str):\n","        \"\"\"Log status messages\"\"\"\n","        with self.output:\n","            print(f\"[{pd.Timestamp.now().strftime('%H:%M:%S')}] {message}\")\n","\n","    def connect_qdrant(self, button):\n","        \"\"\"Connect to Qdrant cloud database and ensure collection exists\"\"\"\n","        try:\n","            url = self.url_widget.value.strip()\n","            api_key = self.api_key_widget.value.strip()\n","            collection_name = self.collection_widget.value.strip()\n","\n","            if not url or not api_key or not collection_name:\n","                self.log_status(\"‚ùå Please provide all connection details\")\n","                return\n","\n","            self.log_status(f\"üîÑ Connecting to Qdrant Cloud...\")\n","\n","            self.qdrant_client = QdrantClient(\n","                url=url,\n","                api_key=api_key,\n","                timeout=60\n","            )\n","\n","            self.collection_name = collection_name\n","\n","            try:\n","                self.qdrant_client.get_collection(self.collection_name)\n","                self.status_label.value = \"<b style='color: green;'>‚úÖ Connected to Qdrant Cloud</b>\"\n","                self.log_status(\"üéâ Successfully connected to Qdrant Cloud!\")\n","            except Exception as e:\n","                self.status_label.value = \"<b style='color: red;'>‚ùå Connection Failed</b>\"\n","                self.log_status(f\"‚ùå Failed to find collection '{self.collection_name}'. Please ensure it exists.\")\n","\n","        except Exception as e:\n","            error_msg = f\"‚ùå Failed to connect to Qdrant: {str(e)}\"\n","            self.log_status(error_msg)\n","            self.status_label.value = \"<b style='color: red;'>‚ùå Connection Failed</b>\"\n","\n","    def upload_file(self, button):\n","        \"\"\"Upload single Excel file\"\"\"\n","        if hasattr(self, '_file_uploaded') and self._file_uploaded:\n","            self.log_status(\"üìÅ File already uploaded. Processing existing file...\")\n","            return\n","\n","        self.log_status(\"üì§ Please select your NIRF Excel file...\")\n","        self.log_status(\"üìã Expected columns: Rank, College_Name, City, State, TLR, RPC, GO, OI, Perception, Score\")\n","\n","        try:\n","            uploaded = files.upload()\n","\n","            if uploaded:\n","                filename = list(uploaded.keys())[0]\n","                self.log_status(f\"üìÅ File uploaded: {filename}\")\n","\n","                file_content = uploaded[filename]\n","                self.df = pd.read_excel(io.BytesIO(file_content))\n","\n","                self._file_uploaded = True\n","\n","                missing_cols = [col for col in self.expected_columns if col not in self.df.columns]\n","                if missing_cols:\n","                    self.log_status(f\"‚ùå Missing required columns: {missing_cols}\")\n","                    self.df = None\n","                    self._file_uploaded = False\n","                    return\n","\n","                initial_rows = len(self.df)\n","                self.df = self.df.dropna(subset=['College_Name'])\n","                final_rows = len(self.df)\n","\n","                if initial_rows != final_rows:\n","                    self.log_status(f\"üóëÔ∏è Removed {initial_rows - final_rows} rows with missing college names\")\n","\n","                self.log_status(f\"‚úÖ File processed! Ready to update {len(self.df)} records\")\n","\n","                with self.output:\n","                    print(\"\\nüìã Data Preview:\")\n","                    display(self.df[self.expected_columns].head(3))\n","\n","        except Exception as e:\n","            self.log_status(f\"‚ùå Error uploading file: {str(e)}\")\n","            self._file_uploaded = False\n","\n","    def upload_metadata(self, button):\n","        \"\"\"Update existing records in Qdrant based on college name matching\"\"\"\n","        if self.qdrant_client is None:\n","            self.log_status(\"‚ùå Please connect to Qdrant first\")\n","            return\n","\n","        if self.df is None:\n","            self.log_status(\"‚ùå Please upload Excel file first\")\n","            return\n","\n","        try:\n","            self.log_status(\"üîÑ Starting to update existing records...\")\n","\n","            updated_count = 0\n","            not_found_count = 0\n","            error_count = 0\n","\n","            for index, row in self.df.iterrows():\n","                try:\n","                    excel_college_name = str(row['College_Name']).strip()\n","\n","                    search_results = self.qdrant_client.scroll(\n","                        collection_name=self.collection_name,\n","                        scroll_filter=Filter(\n","                            must=[\n","                                FieldCondition(\n","                                    key=\"institute_name\",\n","                                    match=MatchValue(value=excel_college_name)\n","                                )\n","                            ]\n","                        ),\n","                        limit=1,\n","                        with_payload=True,\n","                        with_vectors=True\n","                    )\n","\n","                    if search_results[0]:\n","                        point = search_results[0][0]\n","                        point_id = point.id\n","\n","                        updated_payload = point.payload.copy()\n","\n","                        if pd.notna(row.get('Rank')):\n","                            updated_payload['rank'] = int(float(row['Rank']))\n","                        if pd.notna(row.get('City')):\n","                            updated_payload['city'] = str(row['City']).strip()\n","                        if pd.notna(row.get('State')):\n","                            updated_payload['state'] = str(row['State']).strip()\n","                        if pd.notna(row.get('TLR')):\n","                            updated_payload['tlr_score'] = float(row['TLR'])\n","                        if pd.notna(row.get('RPC')):\n","                            updated_payload['rpc_score'] = float(row['RPC'])\n","                        if pd.notna(row.get('GO')):\n","                            updated_payload['go_score'] = float(row['GO'])\n","                        if pd.notna(row.get('OI')):\n","                            updated_payload['oi_score'] = float(row['OI'])\n","                        if pd.notna(row.get('Perception')):\n","                            updated_payload['perception_score'] = float(row['Perception'])\n","                        if pd.notna(row.get('Score')):\n","                            updated_payload['overall_score'] = float(row['Score'])\n","\n","                        updated_point = PointStruct(\n","                            id=point_id,\n","                            vector=point.vector,\n","                            payload=updated_payload\n","                        )\n","\n","                        self.qdrant_client.upsert(\n","                            collection_name=self.collection_name,\n","                            points=[updated_point],\n","                            wait=True\n","                        )\n","\n","                        updated_count += 1\n","                        self.log_status(f\"‚úÖ Updated: {excel_college_name}\")\n","\n","                    else:\n","                        not_found_count += 1\n","                        self.log_status(f\"‚ùå Not found: {excel_college_name}\")\n","\n","                except Exception as e:\n","                    error_count += 1\n","                    self.log_status(f\"‚ùå Error updating {row['College_Name']}: {str(e)}\")\n","\n","            self.log_status(\"üéâ Update Complete!\")\n","            self.log_status(f\"‚úÖ Updated: {updated_count} records\")\n","            self.log_status(f\"‚ùå Not found: {not_found_count} records\")\n","            self.log_status(f\"‚ö†Ô∏è Errors: {error_count} records\")\n","\n","        except Exception as e:\n","            self.log_status(f\"‚ùå Error during update: {str(e)}\")\n","\n","    def run(self):\n","        \"\"\"Main execution method\"\"\"\n","        try:\n","            print(\"=== NIRF Data Updater for Existing Vector DB ===\\n\")\n","            self.display_interface()\n","        except Exception as e:\n","            print(f\"Error during execution: {e}\")\n","            return False\n","\n","        return True\n","\n","# Main execution function\n","def run_metadata_uploader():\n","    \"\"\"Main function to run the metadata uploader\"\"\"\n","    uploader = NIRFDataUploader()\n","    uploader.display_interface()\n","    return uploader\n","\n","print(\"\"\"üéì NIRF Data Updater for Existing Vector DB\n","==========================================\n","‚úÖ Updates existing records by matching college names\n","\n","üìã Required Excel Format:\n","   Columns: Rank | College_Name | City | State | TLR | RPC | GO | OI | Perception | Score\n","\n","üéØ What this does:\n","   ‚Ä¢ Finds existing records by matching \"College_Name\" with \"institute_name\" in vector DB\n","   ‚Ä¢ Updates records with: Rank, City, State, TLR, RPC, GO, OI, Perception, Score\n","   ‚Ä¢ Keeps all existing data intact, just adds NIRF parameters\n","\n","üìã Steps:\n","   1. Connect to Qdrant\n","   2. Upload Excel file\n","   3. Click 'Update NIRF Data' - matches names and updates records\n","\"\"\")\n","\n","# Create and run the system\n","uploader = run_metadata_uploader()\n","\n","#This video demonstrates how to use the `files.upload()` and `files.download()` functions to manage files in Google Colab, which is relevant to the prompt's discussion of file uploads and local storage."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TaOfgjwWsc4_","executionInfo":{"status":"ok","timestamp":1762974830025,"user_tz":-330,"elapsed":2171,"user":{"displayName":"Rahul Siddhu","userId":"12007764243202946991"}},"outputId":"d1e367eb-d9ce-4f65-c692-f8ef2b371603","colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"stream","name":"stderr","text":["2025-11-12 19:13:50,874 - QdrantAutoIndexer - INFO - üöÄ Starting auto-indexing for collection 'durden'\n","INFO:QdrantAutoIndexer:üöÄ Starting auto-indexing for collection 'durden'\n","2025-11-12 19:13:50,917 - QdrantAutoIndexer - INFO - Found 0 existing indexed fields in 'durden'\n","INFO:QdrantAutoIndexer:Found 0 existing indexed fields in 'durden'\n","2025-11-12 19:13:50,939 - QdrantAutoIndexer - INFO - Sampled 20 payloads from 'durden'\n","INFO:QdrantAutoIndexer:Sampled 20 payloads from 'durden'\n","2025-11-12 19:13:50,959 - QdrantAutoIndexer - INFO - Found 0 existing indexed fields in 'durden'\n","INFO:QdrantAutoIndexer:Found 0 existing indexed fields in 'durden'\n","2025-11-12 19:13:51,056 - QdrantAutoIndexer - INFO - ‚úÖ Successfully indexed 'institute_name' as keyword\n","INFO:QdrantAutoIndexer:‚úÖ Successfully indexed 'institute_name' as keyword\n","2025-11-12 19:13:51,141 - QdrantAutoIndexer - INFO - ‚úÖ Successfully indexed 'institute_code' as keyword\n","INFO:QdrantAutoIndexer:‚úÖ Successfully indexed 'institute_code' as keyword\n","2025-11-12 19:13:51,231 - QdrantAutoIndexer - INFO - ‚úÖ Successfully indexed 'content_type' as keyword\n","INFO:QdrantAutoIndexer:‚úÖ Successfully indexed 'content_type' as keyword\n","2025-11-12 19:13:51,350 - QdrantAutoIndexer - INFO - ‚úÖ Successfully indexed 'chunk_index' as integer\n","INFO:QdrantAutoIndexer:‚úÖ Successfully indexed 'chunk_index' as integer\n","2025-11-12 19:13:51,476 - QdrantAutoIndexer - INFO - ‚úÖ Successfully indexed 'total_chunks' as integer\n","INFO:QdrantAutoIndexer:‚úÖ Successfully indexed 'total_chunks' as integer\n","2025-11-12 19:13:51,595 - QdrantAutoIndexer - INFO - ‚úÖ Successfully indexed 'content' as text\n","INFO:QdrantAutoIndexer:‚úÖ Successfully indexed 'content' as text\n","2025-11-12 19:13:51,753 - QdrantAutoIndexer - INFO - ‚úÖ Successfully indexed 'content_length' as integer\n","INFO:QdrantAutoIndexer:‚úÖ Successfully indexed 'content_length' as integer\n","2025-11-12 19:13:51,845 - QdrantAutoIndexer - INFO - ‚úÖ Successfully indexed 'original_id' as keyword\n","INFO:QdrantAutoIndexer:‚úÖ Successfully indexed 'original_id' as keyword\n","2025-11-12 19:13:51,956 - QdrantAutoIndexer - INFO - ‚úÖ Successfully indexed 'source_file' as keyword\n","INFO:QdrantAutoIndexer:‚úÖ Successfully indexed 'source_file' as keyword\n","2025-11-12 19:13:52,100 - QdrantAutoIndexer - INFO - ‚úÖ Successfully indexed 'item_index' as integer\n","INFO:QdrantAutoIndexer:‚úÖ Successfully indexed 'item_index' as integer\n","2025-11-12 19:13:52,187 - QdrantAutoIndexer - INFO - ‚úÖ Successfully indexed 'vector_model' as keyword\n","INFO:QdrantAutoIndexer:‚úÖ Successfully indexed 'vector_model' as keyword\n","2025-11-12 19:13:52,274 - QdrantAutoIndexer - INFO - ‚úÖ Successfully indexed 'upload_timestamp' as keyword\n","INFO:QdrantAutoIndexer:‚úÖ Successfully indexed 'upload_timestamp' as keyword\n","2025-11-12 19:13:52,397 - QdrantAutoIndexer - INFO - ‚úÖ Successfully indexed 'content_for_embedding' as text\n","INFO:QdrantAutoIndexer:‚úÖ Successfully indexed 'content_for_embedding' as text\n","2025-11-12 19:13:52,505 - QdrantAutoIndexer - INFO - ‚úÖ Successfully indexed 'data_type' as keyword\n","INFO:QdrantAutoIndexer:‚úÖ Successfully indexed 'data_type' as keyword\n","2025-11-12 19:13:52,510 - QdrantAutoIndexer - INFO - üéâ Completed auto-indexing in 1.63s: 14 successful, 0 skipped, 0 failed\n","INFO:QdrantAutoIndexer:üéâ Completed auto-indexing in 1.63s: 14 successful, 0 skipped, 0 failed\n"]},{"output_type":"stream","name":"stdout","text":["\n","üìä SUMMARY:\n","Collection: durden\n","Duration: 1.63s\n","Detected fields: 14\n","Successfully indexed: 14\n","Skipped: 0\n","Failed: 0\n","\n","üîç FIELD TYPES DETECTED:\n","‚úÖ institute_name: keyword\n","‚úÖ institute_code: keyword\n","‚úÖ content_type: keyword\n","‚úÖ chunk_index: integer\n","‚úÖ total_chunks: integer\n","‚úÖ content: text\n","‚úÖ content_length: integer\n","‚úÖ original_id: keyword\n","‚úÖ source_file: keyword\n","‚úÖ item_index: integer\n","‚úÖ vector_model: keyword\n","‚úÖ upload_timestamp: keyword\n","‚úÖ content_for_embedding: text\n","‚úÖ data_type: keyword\n"]}],"source":["from qdrant_client import QdrantClient\n","from qdrant_client.http import models\n","from typing import Dict, Any, Optional, List, Union\n","import logging\n","from datetime import datetime\n","\n","class QdrantAutoIndexer:\n","    \"\"\"\n","    Automatically detects fields from Qdrant collection payloads and creates appropriate indexes.\n","    \"\"\"\n","\n","    def __init__(self, url: str, api_key: str, timeout: int = 30):\n","        \"\"\"\n","        Initialize the QdrantAutoIndexer.\n","\n","        Args:\n","            url: Qdrant cluster URL\n","            api_key: API key for authentication\n","            timeout: Connection timeout in seconds\n","        \"\"\"\n","        self.client = QdrantClient(url=url, api_key=api_key, timeout=timeout)\n","        self.logger = self._setup_logger()\n","\n","    def _setup_logger(self) -> logging.Logger:\n","        \"\"\"Setup logging configuration.\"\"\"\n","        logger = logging.getLogger('QdrantAutoIndexer')\n","        logger.setLevel(logging.INFO)\n","\n","        if not logger.handlers:\n","            handler = logging.StreamHandler()\n","            formatter = logging.Formatter(\n","                '%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n","            )\n","            handler.setFormatter(formatter)\n","            logger.addHandler(handler)\n","\n","        return logger\n","\n","    def _detect_field_type(self, value: Any) -> models.PayloadSchemaType:\n","        \"\"\"\n","        Detect the appropriate Qdrant schema type for a given value.\n","\n","        Args:\n","            value: The value to analyze\n","\n","        Returns:\n","            Appropriate PayloadSchemaType\n","        \"\"\"\n","        if isinstance(value, bool):\n","            return models.PayloadSchemaType.BOOL\n","        elif isinstance(value, int):\n","            return models.PayloadSchemaType.INTEGER\n","        elif isinstance(value, float):\n","            return models.PayloadSchemaType.FLOAT\n","        elif isinstance(value, str):\n","            # Check if it's a potential UUID or long text\n","            if len(value) > 100:  # Long text - might want full-text search\n","                return models.PayloadSchemaType.TEXT\n","            else:\n","                return models.PayloadSchemaType.KEYWORD\n","        elif isinstance(value, list):\n","            if value:  # Non-empty list\n","                first_item = value[0]\n","                if isinstance(first_item, str):\n","                    return models.PayloadSchemaType.KEYWORD\n","                elif isinstance(first_item, (int, float)):\n","                    return models.PayloadSchemaType.FLOAT\n","            return models.PayloadSchemaType.KEYWORD\n","        elif isinstance(value, dict):\n","            # For nested objects, create keyword index for searchability\n","            return models.PayloadSchemaType.KEYWORD\n","        else:\n","            # Default fallback\n","            return models.PayloadSchemaType.KEYWORD\n","\n","    def get_existing_schema(self, collection_name: str) -> Dict[str, Any]:\n","        \"\"\"\n","        Get existing payload schema for a collection.\n","\n","        Args:\n","            collection_name: Name of the collection\n","\n","        Returns:\n","            Dictionary containing existing schema information\n","        \"\"\"\n","        try:\n","            collection_info = self.client.get_collection(collection_name)\n","            schema = collection_info.payload_schema or {}\n","            self.logger.info(f\"Found {len(schema)} existing indexed fields in '{collection_name}'\")\n","            return schema\n","        except Exception as e:\n","            self.logger.error(f\"Error getting collection schema: {e}\")\n","            return {}\n","\n","    def sample_payloads(self, collection_name: str, sample_size: int = 10) -> List[Dict[str, Any]]:\n","        \"\"\"\n","        Sample multiple payloads from the collection for better field detection.\n","\n","        Args:\n","            collection_name: Name of the collection\n","            sample_size: Number of points to sample\n","\n","        Returns:\n","            List of payload dictionaries\n","        \"\"\"\n","        try:\n","            points, _ = self.client.scroll(\n","                collection_name=collection_name,\n","                limit=sample_size,\n","                with_payload=True\n","            )\n","\n","            payloads = []\n","            for point in points:\n","                if point.payload:\n","                    payloads.append(point.payload)\n","\n","            self.logger.info(f\"Sampled {len(payloads)} payloads from '{collection_name}'\")\n","            return payloads\n","\n","        except Exception as e:\n","            self.logger.error(f\"Error sampling payloads: {e}\")\n","            return []\n","\n","    def analyze_fields(self, payloads: List[Dict[str, Any]]) -> Dict[str, models.PayloadSchemaType]:\n","        \"\"\"\n","        Analyze sampled payloads to detect field types.\n","\n","        Args:\n","            payloads: List of payload dictionaries\n","\n","        Returns:\n","            Dictionary mapping field names to detected types\n","        \"\"\"\n","        field_types = {}\n","        field_samples = {}\n","\n","        # Collect all field values\n","        for payload in payloads:\n","            for field, value in payload.items():\n","                if field not in field_samples:\n","                    field_samples[field] = []\n","                field_samples[field].append(value)\n","\n","        # Analyze each field\n","        for field, values in field_samples.items():\n","            # Filter out None values\n","            non_null_values = [v for v in values if v is not None]\n","\n","            if not non_null_values:\n","                continue\n","\n","            # Use the first non-null value for type detection\n","            # In a more sophisticated version, you might analyze all values\n","            detected_type = self._detect_field_type(non_null_values[0])\n","            field_types[field] = detected_type\n","\n","            self.logger.debug(f\"Field '{field}': detected type {detected_type}\")\n","\n","        return field_types\n","\n","    def create_indexes(\n","        self,\n","        collection_name: str,\n","        field_types: Dict[str, models.PayloadSchemaType],\n","        skip_existing: bool = True,\n","        dry_run: bool = False\n","    ) -> Dict[str, Union[str, Exception]]:\n","        \"\"\"\n","        Create indexes for the detected fields.\n","\n","        Args:\n","            collection_name: Name of the collection\n","            field_types: Dictionary mapping field names to schema types\n","            skip_existing: Whether to skip fields that already have indexes\n","            dry_run: If True, only simulate the operation\n","\n","        Returns:\n","            Dictionary with results for each field\n","        \"\"\"\n","        results = {}\n","        existing_schema = self.get_existing_schema(collection_name) if skip_existing else {}\n","\n","        for field, schema_type in field_types.items():\n","            if skip_existing and field in existing_schema:\n","                results[field] = \"SKIPPED - Already indexed\"\n","                self.logger.info(f\"‚è≠Ô∏è Skipped '{field}' - already indexed\")\n","                continue\n","\n","            if dry_run:\n","                results[field] = f\"DRY RUN - Would create {schema_type} index\"\n","                self.logger.info(f\"üîç DRY RUN: Would create {schema_type} index for '{field}'\")\n","                continue\n","\n","            try:\n","                self.client.create_payload_index(\n","                    collection_name=collection_name,\n","                    field_name=field,\n","                    field_schema=schema_type\n","                )\n","                results[field] = \"SUCCESS\"\n","                self.logger.info(f\"‚úÖ Successfully indexed '{field}' as {schema_type}\")\n","\n","            except Exception as e:\n","                results[field] = e\n","                self.logger.warning(f\"‚ö†Ô∏è Failed to index '{field}': {e}\")\n","\n","        return results\n","\n","    def auto_index_collection(\n","        self,\n","        collection_name: str,\n","        sample_size: int = 10,\n","        skip_existing: bool = True,\n","        dry_run: bool = False\n","    ) -> Dict[str, Any]:\n","        \"\"\"\n","        Complete auto-indexing workflow for a collection.\n","\n","        Args:\n","            collection_name: Name of the collection to index\n","            sample_size: Number of points to sample for field detection\n","            skip_existing: Whether to skip already indexed fields\n","            dry_run: If True, only simulate the operation\n","\n","        Returns:\n","            Dictionary with complete results\n","        \"\"\"\n","        self.logger.info(f\"üöÄ Starting auto-indexing for collection '{collection_name}'\")\n","\n","        start_time = datetime.now()\n","\n","        # Step 1: Get existing schema\n","        existing_schema = self.get_existing_schema(collection_name)\n","\n","        # Step 2: Sample payloads\n","        payloads = self.sample_payloads(collection_name, sample_size)\n","\n","        if not payloads:\n","            self.logger.warning(\"No payloads found or accessible\")\n","            return {\"error\": \"No payloads found\", \"results\": {}}\n","\n","        # Step 3: Analyze fields\n","        detected_fields = self.analyze_fields(payloads)\n","\n","        # Step 4: Create indexes\n","        indexing_results = self.create_indexes(\n","            collection_name,\n","            detected_fields,\n","            skip_existing=skip_existing,\n","            dry_run=dry_run\n","        )\n","\n","        end_time = datetime.now()\n","        duration = (end_time - start_time).total_seconds()\n","\n","        # Summary\n","        successful = sum(1 for result in indexing_results.values() if result == \"SUCCESS\")\n","        skipped = sum(1 for result in indexing_results.values() if isinstance(result, str) and \"SKIPPED\" in result)\n","        failed = sum(1 for result in indexing_results.values() if isinstance(result, Exception))\n","\n","        summary = {\n","            \"collection_name\": collection_name,\n","            \"duration_seconds\": duration,\n","            \"existing_fields\": len(existing_schema),\n","            \"detected_fields\": len(detected_fields),\n","            \"successful_indexes\": successful,\n","            \"skipped_indexes\": skipped,\n","            \"failed_indexes\": failed,\n","            \"results\": indexing_results,\n","            \"field_types\": {k: str(v) for k, v in detected_fields.items()}\n","        }\n","\n","        self.logger.info(f\"üéâ Completed auto-indexing in {duration:.2f}s: \"\n","                        f\"{successful} successful, {skipped} skipped, {failed} failed\")\n","\n","        return summary\n","\n","\n","# Usage Example\n","def main():\n","    # Configuration\n","    QDRANT_URL = \"https://b5651607-31ce-49ba-916d-c35c89d731d2.us-east4-0.gcp.cloud.qdrant.io\"\n","    QDRANT_API_KEY = \"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJhY2Nlc3MiOiJtIn0.0ApHZL4Qn_A8bx7FCC62nx-IOrHI84W7GZlUZEyVgKk\"\n","    COLLECTION_NAME = \"durden\"\n","\n","\n","    # Initialize auto-indexer\n","    indexer = QdrantAutoIndexer(url=QDRANT_URL, api_key=QDRANT_API_KEY)\n","\n","    # Option 1: Full auto-indexing (recommended)\n","    results = indexer.auto_index_collection(\n","        collection_name=COLLECTION_NAME,\n","        sample_size=20,  # Sample more points for better detection\n","        skip_existing=True,  # Skip already indexed fields\n","        dry_run=False  # Set to True to simulate first\n","    )\n","\n","    print(\"\\nüìä SUMMARY:\")\n","    print(f\"Collection: {results['collection_name']}\")\n","    print(f\"Duration: {results['duration_seconds']:.2f}s\")\n","    print(f\"Detected fields: {results['detected_fields']}\")\n","    print(f\"Successfully indexed: {results['successful_indexes']}\")\n","    print(f\"Skipped: {results['skipped_indexes']}\")\n","    print(f\"Failed: {results['failed_indexes']}\")\n","\n","    print(f\"\\nüîç FIELD TYPES DETECTED:\")\n","    for field, field_type in results['field_types'].items():\n","        status = results['results'][field]\n","        status_icon = \"‚úÖ\" if status == \"SUCCESS\" else \"‚è≠Ô∏è\" if \"SKIPPED\" in str(status) else \"‚ùå\"\n","        print(f\"{status_icon} {field}: {field_type}\")\n","\n","    # Option 2: Step-by-step approach (for more control)\n","    \"\"\"\n","    # Get existing schema\n","    existing = indexer.get_existing_schema(COLLECTION_NAME)\n","    print(f\"Existing schema: {existing}\")\n","\n","    # Sample and analyze\n","    payloads = indexer.sample_payloads(COLLECTION_NAME, sample_size=5)\n","    field_types = indexer.analyze_fields(payloads)\n","    print(f\"Detected field types: {field_types}\")\n","\n","    # Create indexes (with dry run first)\n","    dry_results = indexer.create_indexes(COLLECTION_NAME, field_types, dry_run=True)\n","    print(f\"Dry run results: {dry_results}\")\n","\n","    # Actually create indexes\n","    real_results = indexer.create_indexes(COLLECTION_NAME, field_types, dry_run=False)\n","    print(f\"Actual results: {real_results}\")\n","    \"\"\"\n","\n","\n","if __name__ == \"__main__\":\n","    main()"]},{"cell_type":"code","source":["import json\n","import pandas as pd\n","from typing import List, Dict, Any\n","from collections import defaultdict\n","from datetime import datetime\n","from google.colab import files\n","import os\n","\n","class FacultyDataToExcelConverter:\n","    def __init__(self):\n","        self.output_folder = \"faculty_excel_files\"\n","\n","        # Create output folder if it doesn't exist\n","        if not os.path.exists(self.output_folder):\n","            os.makedirs(self.output_folder)\n","\n","    def upload_files(self):\n","        \"\"\"Upload and select JSON files from local system\"\"\"\n","        print(\"Please select your JSON files to upload:\")\n","        uploaded = files.upload()\n","        if not uploaded:\n","            raise ValueError(\"No files were uploaded\")\n","        json_files = [filename for filename in uploaded.keys() if filename.endswith('.json')]\n","        print(f\"Found {len(json_files)} JSON files: {json_files}\")\n","        return json_files\n","\n","    def load_json_data(self, filename: str) -> Dict[Any, Any]:\n","        \"\"\"Load and parse JSON data from uploaded file\"\"\"\n","        try:\n","            with open(filename, 'r', encoding='utf-8') as file:\n","                data = json.load(file)\n","            print(f\"JSON data from '{filename}' loaded successfully!\")\n","            return data\n","        except json.JSONDecodeError as e:\n","            raise ValueError(f\"Invalid JSON format in file '{filename}': {e}\")\n","        except Exception as e:\n","            raise ValueError(f\"Error reading file '{filename}': {e}\")\n","\n","    def extract_faculty_records(self, data: Dict[str, Any]) -> List[Dict[str, Any]]:\n","        \"\"\"Extract faculty records from the JSON structure\"\"\"\n","        if 'payload' in data and 'faculty_records' in data['payload']:\n","            return data['payload']['faculty_records']\n","        elif 'faculty_records' in data:\n","            return data['faculty_records']\n","        else:\n","            raise ValueError(\"Could not find faculty_records in the JSON data\")\n","\n","    def extract_essential_faculty_data(self, record: Dict[str, Any], university_name: str) -> Dict[str, Any]:\n","        \"\"\"Extract only the essential columns specified by the user\"\"\"\n","        return {\n","            'university_name': university_name,\n","            'name': record.get('name', ''),\n","            'age': record.get('age', ''),\n","            'designation': record.get('designation', ''),\n","            'gender': record.get('gender', ''),\n","            'qualification': record.get('qualification', ''),\n","            'experience': record.get('experience', ''),\n","            'phd_status': record.get('phd_status', ''),\n","            'joining_date': record.get('joining_date', ''),\n","            'career_stage': record.get('career_stage', ''),\n","            'seniority_score': record.get('seniority_score', ''),\n","        }\n","\n","    def create_designation_summary_sheet(self, faculty_records: List[Dict[str, Any]], university_name: str) -> pd.DataFrame:\n","        \"\"\"Create a summary sheet grouped by designation with essential stats\"\"\"\n","        grouped_faculties = defaultdict(list)\n","\n","        for record in faculty_records:\n","            designation = record.get('designation', 'Unknown Designation')\n","            grouped_faculties[designation].append(record)\n","\n","        summary_data = []\n","\n","        for designation, faculty_list in grouped_faculties.items():\n","            # Calculate basic statistics\n","            total_count = len(faculty_list)\n","\n","            # Gender distribution\n","            male_count = sum(1 for f in faculty_list if f.get('gender', '').lower() == 'male')\n","            female_count = sum(1 for f in faculty_list if f.get('gender', '').lower() == 'female')\n","\n","            # PhD status\n","            phd_count = sum(1 for f in faculty_list if f.get('phd_status', '').lower() == 'yes')\n","\n","            # Average age\n","            ages = []\n","            for f in faculty_list:\n","                try:\n","                    age = int(f.get('age', 0))\n","                    if age > 0:\n","                        ages.append(age)\n","                except (ValueError, TypeError):\n","                    continue\n","            avg_age = sum(ages) / len(ages) if ages else 0\n","\n","            # Experience statistics\n","            experiences = []\n","            for f in faculty_list:\n","                try:\n","                    exp = int(f.get('experience', 0))\n","                    experiences.append(exp)\n","                except (ValueError, TypeError):\n","                    experiences.append(0)\n","\n","            avg_experience = sum(experiences) / len(experiences) if experiences else 0\n","\n","            summary_data.append({\n","                'university_name': university_name,\n","                'designation': designation,\n","                'total_faculty': total_count,\n","                'male_count': male_count,\n","                'female_count': female_count,\n","                'phd_holders': phd_count,\n","                'avg_age': round(avg_age, 1),\n","                'avg_experience_months': round(avg_experience, 1),\n","                'min_experience': min(experiences) if experiences else 0,\n","                'max_experience': max(experiences) if experiences else 0\n","            })\n","\n","        return pd.DataFrame(summary_data)\n","\n","    def process_and_convert_to_excel(self, data: Dict[str, Any], filename: str):\n","        \"\"\"Process faculty data and convert to Excel format with essential columns only\"\"\"\n","        try:\n","            university_name = filename.replace('_faculty_data.json', '').replace(' (4)', '').replace('_', ' ').replace('(3)', '').strip()\n","            faculty_records = self.extract_faculty_records(data)\n","\n","            print(f\"Processing {university_name}: Found {len(faculty_records)} faculty records\")\n","\n","            # Create essential faculty data with only required columns\n","            essential_faculty_data = []\n","            for record in faculty_records:\n","                essential_record = self.extract_essential_faculty_data(record, university_name)\n","                essential_faculty_data.append(essential_record)\n","\n","            # Create DataFrames\n","            faculty_df = pd.DataFrame(essential_faculty_data)\n","            summary_df = self.create_designation_summary_sheet(faculty_records, university_name)\n","\n","            # Create Excel file with multiple sheets\n","            excel_filename = f\"{self.output_folder}/{university_name.replace(' ', '_')}_faculty_data.xlsx\"\n","\n","            with pd.ExcelWriter(excel_filename, engine='openpyxl') as writer:\n","                # Write essential faculty data\n","                faculty_df.to_excel(writer, sheet_name='Faculty_Data', index=False)\n","\n","                # Write designation summary\n","                summary_df.to_excel(writer, sheet_name='Summary_by_Designation', index=False)\n","\n","                # Write university overview\n","                overview_data = {\n","                    'university_name': [university_name],\n","                    'total_faculty_count': [len(faculty_records)],\n","                    'total_designations': [len(summary_df)],\n","                    'extraction_date': [datetime.now().strftime('%Y-%m-%d %H:%M:%S')],\n","                    'source_file': [filename]\n","                }\n","                overview_df = pd.DataFrame(overview_data)\n","                overview_df.to_excel(writer, sheet_name='University_Overview', index=False)\n","\n","            print(f\"‚úÖ Excel file created: {excel_filename}\")\n","            print(f\"   - Faculty Data: {len(essential_faculty_data)} records\")\n","            print(f\"   - Designations: {len(summary_df)} unique designations\")\n","\n","            return excel_filename\n","\n","        except Exception as e:\n","            print(f\"Error processing {filename}: {e}\")\n","            return None\n","\n","    def create_combined_excel(self, all_data: List[Dict[str, Any]]):\n","        \"\"\"Create a combined Excel file with all universities\"\"\"\n","        try:\n","            combined_faculty = []\n","            combined_summary = []\n","            combined_overview = []\n","\n","            for data_info in all_data:\n","                data = data_info['data']\n","                filename = data_info['filename']\n","                university_name = filename.replace('_faculty_data.json', '').replace(' (4)', '').replace('_', ' ').replace('(3)', '').strip()\n","\n","                faculty_records = self.extract_faculty_records(data)\n","\n","                # Add to combined faculty data\n","                for record in faculty_records:\n","                    essential_record = self.extract_essential_faculty_data(record, university_name)\n","                    combined_faculty.append(essential_record)\n","\n","                # Add to combined summary\n","                summary_df = self.create_designation_summary_sheet(faculty_records, university_name)\n","                combined_summary.extend(summary_df.to_dict('records'))\n","\n","                # Add to combined overview\n","                combined_overview.append({\n","                    'university_name': university_name,\n","                    'total_faculty_count': len(faculty_records),\n","                    'total_designations': len(summary_df),\n","                    'extraction_date': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n","                    'source_file': filename\n","                })\n","\n","            # Create combined Excel file\n","            combined_filename = f\"{self.output_folder}/Combined_All_Universities_Faculty_Data.xlsx\"\n","\n","            with pd.ExcelWriter(combined_filename, engine='openpyxl') as writer:\n","                # All faculty data combined\n","                pd.DataFrame(combined_faculty).to_excel(writer, sheet_name='All_Faculty_Data', index=False)\n","\n","                # All summaries combined\n","                pd.DataFrame(combined_summary).to_excel(writer, sheet_name='All_Summaries', index=False)\n","\n","                # All university overviews\n","                pd.DataFrame(combined_overview).to_excel(writer, sheet_name='Universities_Overview', index=False)\n","\n","                # Create overall statistics\n","                overall_stats = {\n","                    'metric': [\n","                        'Total Universities',\n","                        'Total Faculty Members',\n","                        'Total Unique Designations',\n","                        'Average Faculty per University'\n","                    ],\n","                    'value': [\n","                        len(combined_overview),\n","                        len(combined_faculty),\n","                        len(set(item['designation'] for item in combined_summary)),\n","                        round(len(combined_faculty) / len(combined_overview), 1) if combined_overview else 0\n","                    ]\n","                }\n","                pd.DataFrame(overall_stats).to_excel(writer, sheet_name='Overall_Statistics', index=False)\n","\n","            print(f\"‚úÖ Combined Excel file created: {combined_filename}\")\n","            print(f\"   - Total faculty records: {len(combined_faculty)}\")\n","            print(f\"   - Total universities: {len(combined_overview)}\")\n","\n","            return combined_filename\n","\n","        except Exception as e:\n","            print(f\"Error creating combined Excel: {e}\")\n","            return None\n","\n","    def download_files(self, file_paths: List[str]):\n","        \"\"\"Download the created Excel files\"\"\"\n","        for file_path in file_paths:\n","            if file_path and os.path.exists(file_path):\n","                files.download(file_path)\n","                print(f\"üì• Downloaded: {file_path}\")\n","\n","    def run(self):\n","        \"\"\"Main execution method\"\"\"\n","        try:\n","            print(\"=== Faculty Data to Excel Converter (Essential Columns) ===\\n\")\n","            print(\"Columns included: name, age, designation, gender, qualification,\")\n","            print(\"experience, phd_status, joining_date, career_stage, seniority_score\\n\")\n","\n","            filenames = self.upload_files()\n","\n","            all_data = []\n","            created_files = []\n","\n","            # Process each file individually\n","            for filename in filenames:\n","                try:\n","                    print(f\"\\n--- Processing {filename} ---\")\n","                    data = self.load_json_data(filename)\n","                    all_data.append({'data': data, 'filename': filename})\n","\n","                    excel_file = self.process_and_convert_to_excel(data, filename)\n","                    if excel_file:\n","                        created_files.append(excel_file)\n","\n","                except Exception as e:\n","                    print(f\"Error processing {filename}: {e}\")\n","                    continue\n","\n","            # Create combined file\n","            if all_data:\n","                print(f\"\\n--- Creating Combined Excel File ---\")\n","                combined_file = self.create_combined_excel(all_data)\n","                if combined_file:\n","                    created_files.append(combined_file)\n","\n","            print(f\"\\n=== Conversion Complete ===\")\n","            print(f\"Total Excel files created: {len(created_files)}\")\n","            print(f\"Each file contains:\")\n","            print(f\"   - Faculty_Data sheet: Essential faculty information\")\n","            print(f\"   - Summary_by_Designation sheet: Statistics by designation\")\n","            print(f\"   - University_Overview sheet: University-level statistics\")\n","\n","            # Download all created files\n","            if created_files:\n","                print(f\"\\n--- Downloading Files ---\")\n","                self.download_files(created_files)\n","\n","            return True\n","\n","        except Exception as e:\n","            print(f\"Error during execution: {e}\")\n","            return False\n","\n","# Example usage\n","if __name__ == \"__main__\":\n","    converter = FacultyDataToExcelConverter()\n","    success = converter.run()\n","\n","    if success:\n","        print(\"\\n‚úÖ All done! Your faculty data has been converted to Excel format with essential columns.\")\n","        print(\"\\nColumns included in each Excel file:\")\n","        print(\"‚Ä¢ university_name ‚Ä¢ name ‚Ä¢ age ‚Ä¢ designation ‚Ä¢ gender\")\n","        print(\"‚Ä¢ qualification ‚Ä¢ experience ‚Ä¢ phd_status ‚Ä¢ joining_date ‚Ä¢ career_stage ‚Ä¢ seniority_score\")\n","    else:\n","        print(\"\\n‚ùå Conversion failed. Please check the errors above.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":698},"id":"gn5NvM3rQ9tu","executionInfo":{"status":"ok","timestamp":1762853657739,"user_tz":-330,"elapsed":12484,"user":{"displayName":"Rahul Siddhu","userId":"12007764243202946991"}},"outputId":"df40de1d-0109-441f-b7bc-5685b4a22e46"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["=== Faculty Data to Excel Converter (Essential Columns) ===\n","\n","Columns included: name, age, designation, gender, qualification,\n","experience, phd_status, joining_date, career_stage, seniority_score\n","\n","Please select your JSON files to upload:\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","     <input type=\"file\" id=\"files-a7c8da79-6528-4dbf-8421-5fe275d7cb82\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-a7c8da79-6528-4dbf-8421-5fe275d7cb82\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script>// Copyright 2017 Google LLC\n","//\n","// Licensed under the Apache License, Version 2.0 (the \"License\");\n","// you may not use this file except in compliance with the License.\n","// You may obtain a copy of the License at\n","//\n","//      http://www.apache.org/licenses/LICENSE-2.0\n","//\n","// Unless required by applicable law or agreed to in writing, software\n","// distributed under the License is distributed on an \"AS IS\" BASIS,\n","// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","// See the License for the specific language governing permissions and\n","// limitations under the License.\n","\n","/**\n"," * @fileoverview Helpers for google.colab Python module.\n"," */\n","(function(scope) {\n","function span(text, styleAttributes = {}) {\n","  const element = document.createElement('span');\n","  element.textContent = text;\n","  for (const key of Object.keys(styleAttributes)) {\n","    element.style[key] = styleAttributes[key];\n","  }\n","  return element;\n","}\n","\n","// Max number of bytes which will be uploaded at a time.\n","const MAX_PAYLOAD_SIZE = 100 * 1024;\n","\n","function _uploadFiles(inputId, outputId) {\n","  const steps = uploadFilesStep(inputId, outputId);\n","  const outputElement = document.getElementById(outputId);\n","  // Cache steps on the outputElement to make it available for the next call\n","  // to uploadFilesContinue from Python.\n","  outputElement.steps = steps;\n","\n","  return _uploadFilesContinue(outputId);\n","}\n","\n","// This is roughly an async generator (not supported in the browser yet),\n","// where there are multiple asynchronous steps and the Python side is going\n","// to poll for completion of each step.\n","// This uses a Promise to block the python side on completion of each step,\n","// then passes the result of the previous step as the input to the next step.\n","function _uploadFilesContinue(outputId) {\n","  const outputElement = document.getElementById(outputId);\n","  const steps = outputElement.steps;\n","\n","  const next = steps.next(outputElement.lastPromiseValue);\n","  return Promise.resolve(next.value.promise).then((value) => {\n","    // Cache the last promise value to make it available to the next\n","    // step of the generator.\n","    outputElement.lastPromiseValue = value;\n","    return next.value.response;\n","  });\n","}\n","\n","/**\n"," * Generator function which is called between each async step of the upload\n"," * process.\n"," * @param {string} inputId Element ID of the input file picker element.\n"," * @param {string} outputId Element ID of the output display.\n"," * @return {!Iterable<!Object>} Iterable of next steps.\n"," */\n","function* uploadFilesStep(inputId, outputId) {\n","  const inputElement = document.getElementById(inputId);\n","  inputElement.disabled = false;\n","\n","  const outputElement = document.getElementById(outputId);\n","  outputElement.innerHTML = '';\n","\n","  const pickedPromise = new Promise((resolve) => {\n","    inputElement.addEventListener('change', (e) => {\n","      resolve(e.target.files);\n","    });\n","  });\n","\n","  const cancel = document.createElement('button');\n","  inputElement.parentElement.appendChild(cancel);\n","  cancel.textContent = 'Cancel upload';\n","  const cancelPromise = new Promise((resolve) => {\n","    cancel.onclick = () => {\n","      resolve(null);\n","    };\n","  });\n","\n","  // Wait for the user to pick the files.\n","  const files = yield {\n","    promise: Promise.race([pickedPromise, cancelPromise]),\n","    response: {\n","      action: 'starting',\n","    }\n","  };\n","\n","  cancel.remove();\n","\n","  // Disable the input element since further picks are not allowed.\n","  inputElement.disabled = true;\n","\n","  if (!files) {\n","    return {\n","      response: {\n","        action: 'complete',\n","      }\n","    };\n","  }\n","\n","  for (const file of files) {\n","    const li = document.createElement('li');\n","    li.append(span(file.name, {fontWeight: 'bold'}));\n","    li.append(span(\n","        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n","        `last modified: ${\n","            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n","                                    'n/a'} - `));\n","    const percent = span('0% done');\n","    li.appendChild(percent);\n","\n","    outputElement.appendChild(li);\n","\n","    const fileDataPromise = new Promise((resolve) => {\n","      const reader = new FileReader();\n","      reader.onload = (e) => {\n","        resolve(e.target.result);\n","      };\n","      reader.readAsArrayBuffer(file);\n","    });\n","    // Wait for the data to be ready.\n","    let fileData = yield {\n","      promise: fileDataPromise,\n","      response: {\n","        action: 'continue',\n","      }\n","    };\n","\n","    // Use a chunked sending to avoid message size limits. See b/62115660.\n","    let position = 0;\n","    do {\n","      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n","      const chunk = new Uint8Array(fileData, position, length);\n","      position += length;\n","\n","      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n","      yield {\n","        response: {\n","          action: 'append',\n","          file: file.name,\n","          data: base64,\n","        },\n","      };\n","\n","      let percentDone = fileData.byteLength === 0 ?\n","          100 :\n","          Math.round((position / fileData.byteLength) * 100);\n","      percent.textContent = `${percentDone}% done`;\n","\n","    } while (position < fileData.byteLength);\n","  }\n","\n","  // All done.\n","  yield {\n","    response: {\n","      action: 'complete',\n","    }\n","  };\n","}\n","\n","scope.google = scope.google || {};\n","scope.google.colab = scope.google.colab || {};\n","scope.google.colab._files = {\n","  _uploadFiles,\n","  _uploadFilesContinue,\n","};\n","})(self);\n","</script> "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Saving IITDM Kancheepuram 2024 (10)_faculty_data.json to IITDM Kancheepuram 2024 (10)_faculty_data (2).json\n","Found 1 JSON files: ['IITDM Kancheepuram 2024 (10)_faculty_data (2).json']\n","\n","--- Processing IITDM Kancheepuram 2024 (10)_faculty_data (2).json ---\n","JSON data from 'IITDM Kancheepuram 2024 (10)_faculty_data (2).json' loaded successfully!\n","Processing IITDM Kancheepuram 2024 (10) faculty data (2).json: Found 76 faculty records\n","‚úÖ Excel file created: faculty_excel_files/IITDM_Kancheepuram_2024_(10)_faculty_data_(2).json_faculty_data.xlsx\n","   - Faculty Data: 76 records\n","   - Designations: 4 unique designations\n","\n","--- Creating Combined Excel File ---\n","‚úÖ Combined Excel file created: faculty_excel_files/Combined_All_Universities_Faculty_Data.xlsx\n","   - Total faculty records: 76\n","   - Total universities: 1\n","\n","=== Conversion Complete ===\n","Total Excel files created: 2\n","Each file contains:\n","   - Faculty_Data sheet: Essential faculty information\n","   - Summary_by_Designation sheet: Statistics by designation\n","   - University_Overview sheet: University-level statistics\n","\n","--- Downloading Files ---\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["download(\"download_8fbba8bb-ced3-4f6d-8b09-a7feabcf0d62\", \"IITDM_Kancheepuram_2024_(10)_faculty_data_(2).json_faculty_data.xlsx\", 11324)"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["üì• Downloaded: faculty_excel_files/IITDM_Kancheepuram_2024_(10)_faculty_data_(2).json_faculty_data.xlsx\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["download(\"download_2a7f4d29-9dd7-4104-a947-f83014dfefdc\", \"Combined_All_Universities_Faculty_Data.xlsx\", 11911)"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["üì• Downloaded: faculty_excel_files/Combined_All_Universities_Faculty_Data.xlsx\n","\n","‚úÖ All done! Your faculty data has been converted to Excel format with essential columns.\n","\n","Columns included in each Excel file:\n","‚Ä¢ university_name ‚Ä¢ name ‚Ä¢ age ‚Ä¢ designation ‚Ä¢ gender\n","‚Ä¢ qualification ‚Ä¢ experience ‚Ä¢ phd_status ‚Ä¢ joining_date ‚Ä¢ career_stage ‚Ä¢ seniority_score\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nIzSW5x9yJbF"},"outputs":[],"source":["import json\n","import pandas as pd\n","from typing import List, Dict, Any\n","from collections import defaultdict\n","from datetime import datetime\n","from google.colab import files\n","import os\n","\n","class FacultySummaryConverter:\n","    def __init__(self):\n","        self.output_folder = \"faculty_summary_files\"\n","\n","        # Create output folder if it doesn't exist\n","        if not os.path.exists(self.output_folder):\n","            os.makedirs(self.output_folder)\n","\n","    def upload_files(self):\n","        \"\"\"Upload and select JSON files from local system\"\"\"\n","        print(\"Please select your JSON files to upload:\")\n","        uploaded = files.upload()\n","        if not uploaded:\n","            raise ValueError(\"No files were uploaded\")\n","        json_files = [filename for filename in uploaded.keys() if filename.endswith('.json')]\n","        print(f\"Found {len(json_files)} JSON files: {json_files}\")\n","        return json_files\n","\n","    def load_json_data(self, filename: str) -> Dict[Any, Any]:\n","        \"\"\"Load and parse JSON data from uploaded file\"\"\"\n","        try:\n","            with open(filename, 'r', encoding='utf-8') as file:\n","                data = json.load(file)\n","            print(f\"JSON data from '{filename}' loaded successfully!\")\n","            return data\n","        except json.JSONDecodeError as e:\n","            raise ValueError(f\"Invalid JSON format in file '{filename}': {e}\")\n","        except Exception as e:\n","            raise ValueError(f\"Error reading file '{filename}': {e}\")\n","\n","    def extract_faculty_records(self, data: Dict[str, Any]) -> List[Dict[str, Any]]:\n","        \"\"\"Extract faculty records from the JSON structure\"\"\"\n","        if 'payload' in data and 'faculty_records' in data['payload']:\n","            return data['payload']['faculty_records']\n","        elif 'faculty_records' in data:\n","            return data['faculty_records']\n","        else:\n","            raise ValueError(\"Could not find faculty_records in the JSON data\")\n","\n","    def create_designation_summary(self, faculty_records: List[Dict[str, Any]], university_name: str) -> pd.DataFrame:\n","        \"\"\"Create summary data grouped by designation with specified columns only\"\"\"\n","        grouped_faculties = defaultdict(list)\n","\n","        for record in faculty_records:\n","            designation = record.get('designation', 'Unknown Designation')\n","            grouped_faculties[designation].append(record)\n","\n","        summary_data = []\n","\n","        for designation, faculty_list in grouped_faculties.items():\n","            # Calculate basic statistics\n","            total_faculty = len(faculty_list)\n","\n","            # Gender distribution\n","            male_count = sum(1 for f in faculty_list if f.get('gender', '').lower() == 'male')\n","            female_count = sum(1 for f in faculty_list if f.get('gender', '').lower() == 'female')\n","\n","            # PhD status\n","            phd_holders = sum(1 for f in faculty_list if f.get('phd_status', '').lower() == 'yes')\n","\n","            # Average age\n","            ages = []\n","            for f in faculty_list:\n","                try:\n","                    age = int(f.get('age', 0))\n","                    if age > 0:\n","                        ages.append(age)\n","                except (ValueError, TypeError):\n","                    continue\n","            avg_age = sum(ages) / len(ages) if ages else 0\n","\n","            # Experience statistics\n","            experiences = []\n","            for f in faculty_list:\n","                try:\n","                    exp = int(f.get('experience', 0))\n","                    experiences.append(exp)\n","                except (ValueError, TypeError):\n","                    experiences.append(0)\n","\n","            avg_experience_months = sum(experiences) / len(experiences) if experiences else 0\n","            min_experience = min(experiences) if experiences else 0\n","            max_experience = max(experiences) if experiences else 0\n","\n","            # Only keep the requested columns\n","            summary_data.append({\n","                'university_name': university_name,\n","                'designation': designation,\n","                'total_faculty': total_faculty,\n","                'male_count': male_count,\n","                'female_count': female_count,\n","                'phd_holders': phd_holders,\n","                'avg_age': round(avg_age, 1),\n","                'avg_experience_months': round(avg_experience_months, 1),\n","                'min_experience': min_experience,\n","                'max_experience': max_experience\n","            })\n","\n","        return pd.DataFrame(summary_data)\n","\n","    def process_file_to_summary(self, data: Dict[str, Any], filename: str):\n","        \"\"\"Process faculty data and return summary DataFrame\"\"\"\n","        try:\n","            university_name = filename.replace('_faculty_data.json', '').replace(' (4)', '').replace('_', ' ').replace('(3)', '').strip()\n","            faculty_records = self.extract_faculty_records(data)\n","\n","            print(f\"Processing {university_name}: Found {len(faculty_records)} faculty records\")\n","\n","            # Create summary DataFrame\n","            summary_df = self.create_designation_summary(faculty_records, university_name)\n","\n","            print(f\"   - Designations: {len(summary_df)} unique designations\")\n","\n","            return summary_df\n","\n","        except Exception as e:\n","            print(f\"Error processing {filename}: {e}\")\n","            return None\n","\n","    def create_combined_summary(self, all_summaries: List[pd.DataFrame]):\n","        \"\"\"Create a combined summary Excel file with all universities\"\"\"\n","        try:\n","            # Combine all summary dataframes\n","            combined_summary_df = pd.concat(all_summaries, ignore_index=True)\n","\n","            # Create combined Excel file\n","            combined_filename = f\"{self.output_folder}/Combined_All_Universities_Summary.xlsx\"\n","            combined_summary_df.to_excel(combined_filename, sheet_name='All_Summaries', index=False)\n","\n","            print(f\"‚úÖ Combined summary Excel file created: {combined_filename}\")\n","            print(f\"   - Total summary records: {len(combined_summary_df)}\")\n","\n","            return combined_filename\n","\n","        except Exception as e:\n","            print(f\"Error creating combined summary: {e}\")\n","            return None\n","\n","    def download_files(self, file_paths: List[str]):\n","        \"\"\"Download the created Excel files\"\"\"\n","        for file_path in file_paths:\n","            if file_path and os.path.exists(file_path):\n","                files.download(file_path)\n","                print(f\"üì• Downloaded: {file_path}\")\n","\n","    def run(self):\n","        \"\"\"Main execution method\"\"\"\n","        try:\n","            print(\"=== Faculty Combined Summary Data Converter ===\\n\")\n","            print(\"Creating combined summary with columns:\")\n","            print(\"university_name, designation, total_faculty, male_count, female_count,\")\n","            print(\"phd_holders, avg_age, avg_experience_months, min_experience, max_experience\\n\")\n","\n","            filenames = self.upload_files()\n","\n","            all_summaries = []\n","\n","            # Process each file and collect summaries\n","            for filename in filenames:\n","                try:\n","                    print(f\"\\n--- Processing {filename} ---\")\n","                    data = self.load_json_data(filename)\n","\n","                    summary_df = self.process_file_to_summary(data, filename)\n","                    if summary_df is not None:\n","                        all_summaries.append(summary_df)\n","\n","                except Exception as e:\n","                    print(f\"Error processing {filename}: {e}\")\n","                    continue\n","\n","            # Create only the combined summary file\n","            if all_summaries:\n","                print(f\"\\n--- Creating Combined Summary File ---\")\n","                combined_file = self.create_combined_summary(all_summaries)\n","                if combined_file:\n","                    print(f\"\\n=== Conversion Complete ===\")\n","                    print(f\"Combined summary file created with data from {len(all_summaries)} universities\")\n","\n","                    # Download the combined file\n","                    print(f\"\\n--- Downloading File ---\")\n","                    self.download_files([combined_file])\n","\n","                    return True\n","            else:\n","                print(\"No valid data found to process\")\n","                return False\n","\n","        except Exception as e:\n","            print(f\"Error during execution: {e}\")\n","            return False\n","\n","# Example usage\n","if __name__ == \"__main__\":\n","    converter = FacultySummaryConverter()\n","    success = converter.run()\n","\n","    if success:\n","        print(\"\\n‚úÖ All done! Combined faculty summary data has been created.\")\n","        print(\"\\nThe file contains summary data from all universities with columns:\")\n","        print(\"‚Ä¢ university_name ‚Ä¢ designation ‚Ä¢ total_faculty ‚Ä¢ male_count ‚Ä¢ female_count\")\n","        print(\"‚Ä¢ phd_holders ‚Ä¢ avg_age ‚Ä¢ avg_experience_months ‚Ä¢ min_experience ‚Ä¢ max_experience\")\n","    else:\n","        print(\"\\n‚ùå Conversion failed. Please check the errors above.\")"]},{"cell_type":"code","source":["#code1*\n","import json\n","import pandas as pd\n","from typing import List, Dict, Any\n","from collections import defaultdict\n","from datetime import datetime\n","import gspread\n","from google.oauth2.service_account import Credentials\n","import os\n","from pathlib import Path\n","\n","class FacultyDataToSheetsConverter:\n","    def __init__(self):\n","        \"\"\"Initialize the converter\"\"\"\n","        self.credentials_path = None\n","        self.spreadsheet_url = None\n","        self.json_directory = None\n","        self.gc = None\n","        self.spreadsheet = None\n","\n","    def get_user_inputs(self):\n","        \"\"\"Get the 3 required inputs from the user\"\"\"\n","        print(\"=\" * 70)\n","        print(\"ü§ñ FACULTY DATA TO GOOGLE SHEETS CONVERTER\")\n","        print(\"=\" * 70)\n","        print(\"\\nI will ask you for 3 things. Please have them ready:\")\n","        print(\"  1Ô∏è‚É£  Your Google Credentials file (The Robot's Key üîë)\")\n","        print(\"  2Ô∏è‚É£  Your Google Sheet URL (The Address üè†)\")\n","        print(\"  3Ô∏è‚É£  Your JSON files folder (The Paperwork üìÇ)\")\n","        print(\"\\n\" + \"=\" * 70)\n","\n","        # Step 1: Get credentials path\n","        print(\"\\n\" + \"=\"*70)\n","        print(\"STEP 1: THE CREDENTIALS FILE (Robot's Key üîë)\")\n","        print(\"=\"*70)\n","        print(\"\\nWhat is it?\")\n","        print(\"  ‚Üí A .json file downloaded from Google Cloud Console\")\n","        print(\"  ‚Üí Contains your service account credentials\")\n","        print(\"\\nWhere to get it?\")\n","        print(\"  1. Go to: https://console.cloud.google.com/\")\n","        print(\"  2. Create/select a project\")\n","        print(\"  3. Enable Google Sheets API and Google Drive API\")\n","        print(\"  4. Create Service Account ‚Üí Download JSON key\")\n","        print(\"\\n\" + \"-\"*70)\n","\n","        while True:\n","            self.credentials_path = input(\"\\nüìù Enter the full path to your credentials.json file:\\n   > \").strip()\n","\n","            if os.path.exists(self.credentials_path):\n","                if self.credentials_path.endswith('.json'):\n","                    print(f\"   ‚úÖ Found credentials file!\")\n","                    break\n","                else:\n","                    print(f\"   ‚ùå File must be a .json file. Try again.\")\n","            else:\n","                print(f\"   ‚ùå File not found. Please check the path and try again.\")\n","\n","        # Step 2: Get spreadsheet URL\n","        print(\"\\n\" + \"=\"*70)\n","        print(\"STEP 2: THE GOOGLE SHEET URL (The Address üè†)\")\n","        print(\"=\"*70)\n","        print(\"\\nWhat is it?\")\n","        print(\"  ‚Üí The web link to your Google Spreadsheet\")\n","        print(\"  ‚Üí Looks like: https://docs.google.com/spreadsheets/d/XXXXX/edit\")\n","        print(\"\\nHow to get it?\")\n","        print(\"  1. Open Google Sheets: https://sheets.google.com\")\n","        print(\"  2. Create a new spreadsheet (or open existing one)\")\n","        print(\"  3. Copy the URL from your browser's address bar\")\n","        print(\"\\n‚ö†Ô∏è  IMPORTANT: You must SHARE your sheet with the service account email!\")\n","\n","        # Read credentials to show service account email\n","        try:\n","            with open(self.credentials_path, 'r') as f:\n","                creds_data = json.load(f)\n","                service_email = creds_data.get('client_email', 'Unknown')\n","                print(f\"\\nüìß Your Service Account Email: {service_email}\")\n","                print(f\"   ‚Üí Go to your Google Sheet\")\n","                print(f\"   ‚Üí Click 'Share' button\")\n","                print(f\"   ‚Üí Add this email with 'Editor' access\")\n","        except:\n","            pass\n","\n","        print(\"\\n\" + \"-\"*70)\n","        self.spreadsheet_url = input(\"\\nüìù Enter your Google Sheet URL:\\n   > \").strip()\n","        print(f\"   ‚úÖ Got spreadsheet URL!\")\n","\n","        # Step 3: Get JSON directory\n","        print(\"\\n\" + \"=\"*70)\n","        print(\"STEP 3: THE JSON FILES FOLDER (The Paperwork üìÇ)\")\n","        print(\"=\"*70)\n","        print(\"\\nWhat is it?\")\n","        print(\"  ‚Üí A folder on your computer containing JSON files\")\n","        print(\"  ‚Üí Each JSON file has faculty data for one university\")\n","        print(\"\\nExample:\")\n","        print(\"  ‚Üí /home/user/faculty_data/\")\n","        print(\"  ‚Üí C:\\\\Users\\\\YourName\\\\Documents\\\\faculty_files\\\\\")\n","        print(\"\\nüí° TIP: You can add more JSON files to this folder later\")\n","        print(\"        and run the script again. Duplicates will be skipped!\")\n","        print(\"\\n\" + \"-\"*70)\n","\n","        while True:\n","            self.json_directory = input(\"\\nüìù Enter the full path to your JSON files folder:\\n   > \").strip()\n","\n","            if os.path.exists(self.json_directory):\n","                if os.path.isdir(self.json_directory):\n","                    # Count JSON files\n","                    json_files = [f for f in os.listdir(self.json_directory) if f.endswith('.json')]\n","                    if json_files:\n","                        print(f\"   ‚úÖ Found {len(json_files)} JSON file(s) in this folder!\")\n","                        break\n","                    else:\n","                        print(f\"   ‚ö†Ô∏è  No JSON files found in this folder.\")\n","                        retry = input(\"   Do you want to try a different folder? (yes/no): \").strip().lower()\n","                        if retry != 'yes':\n","                            print(\"   Continuing anyway...\")\n","                            break\n","                else:\n","                    print(f\"   ‚ùå This is not a folder. Please enter a folder path.\")\n","            else:\n","                print(f\"   ‚ùå Folder not found. Please check the path and try again.\")\n","\n","        print(\"\\n\" + \"=\"*70)\n","        print(\"‚úÖ ALL INPUTS RECEIVED!\")\n","        print(\"=\"*70)\n","        print(f\"\\nüìã Summary:\")\n","        print(f\"   üîë Credentials: {self.credentials_path}\")\n","        print(f\"   üè† Sheet URL: {self.spreadsheet_url}\")\n","        print(f\"   üìÇ JSON Folder: {self.json_directory}\")\n","        print(\"\\n\" + \"=\"*70)\n","\n","        confirm = input(\"\\n‚è∏Ô∏è  Ready to start? (Press Enter to continue, or 'q' to quit): \").strip().lower()\n","        if confirm == 'q':\n","            print(\"\\nüëã Goodbye!\")\n","            return False\n","\n","        return True\n","\n","    def authenticate(self):\n","        \"\"\"Step 1: Authenticate using the credentials file (The Robot's Key üîë)\"\"\"\n","        try:\n","            print(\"\\nüîÑ Authenticating with Google...\")\n","\n","            # Define the scope\n","            scopes = [\n","                'https://www.googleapis.com/auth/spreadsheets',\n","                'https://www.googleapis.com/auth/drive'\n","            ]\n","\n","            # Load credentials\n","            creds = Credentials.from_service_account_file(\n","                self.credentials_path,\n","                scopes=scopes\n","            )\n","\n","            self.gc = gspread.authorize(creds)\n","\n","            print(f\"‚úÖ Authentication successful!\")\n","\n","        except Exception as e:\n","            raise Exception(f\"‚ùå Authentication failed: {e}\")\n","\n","    def connect_to_sheet(self):\n","        \"\"\"Step 2: Connect to the spreadsheet (The Address üè†)\"\"\"\n","        try:\n","            print(f\"\\nüîÑ Connecting to your Google Sheet...\")\n","\n","            self.spreadsheet = self.gc.open_by_url(self.spreadsheet_url)\n","\n","            print(f\"‚úÖ Successfully connected to: '{self.spreadsheet.title}'\")\n","\n","        except Exception as e:\n","            raise Exception(f\"‚ùå Connection failed: {e}\\n\" +\n","                          \"Make sure:\\n\" +\n","                          \"1. The URL is correct\\n\" +\n","                          \"2. You've shared the sheet with the service account email\")\n","\n","    def load_json_files(self) -> List[str]:\n","        \"\"\"Step 3: Load JSON files from directory (The Paperwork üìÇ)\"\"\"\n","        try:\n","            print(f\"\\nüîÑ Loading JSON files from folder...\")\n","\n","            # Get all JSON files\n","            json_files = []\n","            for file in os.listdir(self.json_directory):\n","                if file.endswith('.json'):\n","                    json_files.append(os.path.join(self.json_directory, file))\n","\n","            if not json_files:\n","                raise ValueError(f\"No JSON files found in: {self.json_directory}\")\n","\n","            print(f\"‚úÖ Found {len(json_files)} JSON files:\")\n","            for i, file in enumerate(json_files, 1):\n","                print(f\"   {i}. {os.path.basename(file)}\")\n","\n","            return json_files\n","\n","        except Exception as e:\n","            raise Exception(f\"‚ùå Failed to load JSON files: {e}\")\n","\n","    def load_json_data(self, filepath: str) -> Dict[Any, Any]:\n","        \"\"\"Load and parse JSON data from file\"\"\"\n","        try:\n","            with open(filepath, 'r', encoding='utf-8') as file:\n","                data = json.load(file)\n","            return data\n","        except json.JSONDecodeError as e:\n","            raise ValueError(f\"Invalid JSON format in file '{filepath}': {e}\")\n","        except Exception as e:\n","            raise ValueError(f\"Error reading file '{filepath}': {e}\")\n","\n","    def extract_faculty_records(self, data: Dict[str, Any]) -> List[Dict[str, Any]]:\n","        \"\"\"Extract faculty records from the JSON structure\"\"\"\n","        if 'payload' in data and 'faculty_records' in data['payload']:\n","            return data['payload']['faculty_records']\n","        elif 'faculty_records' in data:\n","            return data['faculty_records']\n","        else:\n","            raise ValueError(\"Could not find faculty_records in the JSON data\")\n","\n","    def extract_essential_faculty_data(self, record: Dict[str, Any], university_name: str) -> Dict[str, Any]:\n","        \"\"\"Extract only the essential columns\"\"\"\n","        return {\n","            'university_name': university_name,\n","            'name': record.get('name', ''),\n","            'age': record.get('age', ''),\n","            'designation': record.get('designation', ''),\n","            'gender': record.get('gender', ''),\n","            'qualification': record.get('qualification', ''),\n","            'experience': record.get('experience', ''),\n","            'phd_status': record.get('phd_status', ''),\n","            'joining_date': record.get('joining_date', ''),\n","            'career_stage': record.get('career_stage', ''),\n","            'seniority_score': record.get('seniority_score', ''),\n","        }\n","\n","    def count_professor_types(self, faculty_records: List[Dict[str, Any]]) -> Dict[str, int]:\n","        \"\"\"Count different types of professors\"\"\"\n","        counts = {\n","            'Professor': 0,\n","            'Associate Professor': 0,\n","            'Assistant Professor': 0,\n","            'Other': 0\n","        }\n","\n","        for record in faculty_records:\n","            designation = record.get('designation', '').lower()\n","            if 'professor' in designation and 'associate' not in designation and 'assistant' not in designation:\n","                counts['Professor'] += 1\n","            elif 'associate professor' in designation:\n","                counts['Associate Professor'] += 1\n","            elif 'assistant professor' in designation:\n","                counts['Assistant Professor'] += 1\n","            else:\n","                counts['Other'] += 1\n","\n","        return counts\n","\n","    def get_existing_universities(self, sheet_name: str) -> set:\n","        \"\"\"Get list of universities already in the sheet\"\"\"\n","        try:\n","            worksheet = self.spreadsheet.worksheet(sheet_name)\n","            data = worksheet.get_all_values()\n","            if len(data) > 1:  # Has header and data\n","                return set(row[0] for row in data[1:] if row and row[0])\n","            return set()\n","        except gspread.exceptions.WorksheetNotFound:\n","            return set()\n","\n","    def get_or_create_worksheet(self, sheet_name: str) -> Any:\n","        \"\"\"Get existing worksheet or create new one\"\"\"\n","        try:\n","            worksheet = self.spreadsheet.worksheet(sheet_name)\n","            return worksheet\n","        except gspread.exceptions.WorksheetNotFound:\n","            worksheet = self.spreadsheet.add_worksheet(title=sheet_name, rows=1000, cols=20)\n","            print(f\"   üìù Created new sheet: {sheet_name}\")\n","            return worksheet\n","\n","    def append_to_sheet(self, worksheet: Any, df: pd.DataFrame, skip_universities: set = None):\n","        \"\"\"Append data to worksheet, skipping duplicates\"\"\"\n","        existing_data = worksheet.get_all_values()\n","\n","        if not existing_data:\n","            # Sheet is empty, add headers and all data\n","            worksheet.update([df.columns.values.tolist()] + df.values.tolist())\n","            print(f\"   ‚úì Added {len(df)} records to {worksheet.title}\")\n","        else:\n","            # Filter out universities that already exist\n","            if skip_universities and 'university_name' in df.columns:\n","                original_count = len(df)\n","                df = df[~df['university_name'].isin(skip_universities)]\n","                skipped = original_count - len(df)\n","                if skipped > 0:\n","                    print(f\"   ‚ö†Ô∏è  Skipped {skipped} duplicate records\")\n","\n","            if len(df) > 0:\n","                # Append only new data\n","                worksheet.append_rows(df.values.tolist())\n","                print(f\"   ‚úì Added {len(df)} new records to {worksheet.title}\")\n","            else:\n","                print(f\"   ‚ÑπÔ∏è  No new records to add to {worksheet.title}\")\n","\n","    def process_json_files(self, json_files: List[str]):\n","        \"\"\"Process all JSON files and update the sheet\"\"\"\n","        try:\n","            print(f\"\\nüìä Processing JSON files and updating sheet...\")\n","\n","            combined_faculty = []\n","            combined_overview = []\n","\n","            # Get existing universities to avoid duplicates\n","            existing_universities = self.get_existing_universities('All_Faculty_Data')\n","            if existing_universities:\n","                print(f\"\\nüìã Found {len(existing_universities)} existing universities in sheet\")\n","                print(f\"   (These will be skipped to avoid duplicates)\")\n","\n","            processed_count = 0\n","            skipped_count = 0\n","\n","            for filepath in json_files:\n","                filename = os.path.basename(filepath)\n","                university_name = filename.replace('_faculty_data.json', '').replace(' (4)', '').replace('_', ' ').replace('(3)', '').strip()\n","\n","                # Skip if university already exists\n","                if university_name in existing_universities:\n","                    print(f\"\\n   ‚è≠Ô∏è  Skipping '{university_name}' - already exists\")\n","                    skipped_count += 1\n","                    continue\n","\n","                print(f\"\\n   üìÑ Processing: {university_name}\")\n","\n","                try:\n","                    data = self.load_json_data(filepath)\n","                    faculty_records = self.extract_faculty_records(data)\n","                    professor_counts = self.count_professor_types(faculty_records)\n","\n","                    # Add to combined faculty data\n","                    for record in faculty_records:\n","                        essential_record = self.extract_essential_faculty_data(record, university_name)\n","                        combined_faculty.append(essential_record)\n","\n","                    # Add to combined overview\n","                    combined_overview.append({\n","                        'university_name': university_name,\n","                        'total_faculty_count': len(faculty_records),\n","                        'professors': professor_counts['Professor'],\n","                        'associate_professors': professor_counts['Associate Professor'],\n","                        'assistant_professors': professor_counts['Assistant Professor'],\n","                        'other_designations': professor_counts['Other'],\n","                        'last_updated': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n","                        'source_file': filename\n","                    })\n","\n","                    processed_count += 1\n","                    print(f\"      ‚úì Found {len(faculty_records)} faculty members\")\n","                    print(f\"      ‚úì Professors: {professor_counts['Professor']}, \" +\n","                          f\"Associate: {professor_counts['Associate Professor']}, \" +\n","                          f\"Assistant: {professor_counts['Assistant Professor']}\")\n","\n","                except Exception as e:\n","                    print(f\"      ‚ùå Error: {e}\")\n","                    continue\n","\n","            if not combined_faculty:\n","                print(f\"\\n‚ö†Ô∏è  No new universities to add! (All {skipped_count} were duplicates)\")\n","                return\n","\n","            print(f\"\\nüì§ Uploading data to Google Sheet...\")\n","\n","            # Update All Faculty Data sheet\n","            faculty_df = pd.DataFrame(combined_faculty)\n","            faculty_sheet = self.get_or_create_worksheet('All_Faculty_Data')\n","            self.append_to_sheet(faculty_sheet, faculty_df, existing_universities)\n","\n","            # Update Universities Overview sheet\n","            overview_df = pd.DataFrame(combined_overview)\n","            overview_sheet = self.get_or_create_worksheet('Universities_Overview')\n","            self.append_to_sheet(overview_sheet, overview_df, existing_universities)\n","\n","            # Update Overall Statistics sheet\n","            self.update_overall_statistics()\n","\n","            print(f\"\\n‚úÖ Successfully updated Google Sheet!\")\n","            print(f\"   üìä New faculty records: {len(combined_faculty)}\")\n","            print(f\"   üèõÔ∏è  New universities: {processed_count}\")\n","            print(f\"   ‚è≠Ô∏è  Skipped duplicates: {skipped_count}\")\n","\n","        except Exception as e:\n","            print(f\"‚ùå Error processing files: {e}\")\n","            raise\n","\n","    def update_overall_statistics(self):\n","        \"\"\"Update or create overall statistics sheet\"\"\"\n","        try:\n","            # Get all data from sheets\n","            faculty_sheet = self.spreadsheet.worksheet('All_Faculty_Data')\n","            overview_sheet = self.spreadsheet.worksheet('Universities_Overview')\n","\n","            faculty_data = faculty_sheet.get_all_values()\n","            overview_data = overview_sheet.get_all_values()\n","\n","            total_faculty = len(faculty_data) - 1  # Exclude header\n","            total_universities = len(overview_data) - 1  # Exclude header\n","\n","            # Calculate professor totals from overview\n","            total_professors = 0\n","            total_associate = 0\n","            total_assistant = 0\n","\n","            if len(overview_data) > 1:\n","                overview_df = pd.DataFrame(overview_data[1:], columns=overview_data[0])\n","                total_professors = overview_df['professors'].astype(int).sum()\n","                total_associate = overview_df['associate_professors'].astype(int).sum()\n","                total_assistant = overview_df['assistant_professors'].astype(int).sum()\n","\n","            stats_data = {\n","                'metric': [\n","                    'Total Universities',\n","                    'Total Faculty Members',\n","                    'Total Professors',\n","                    'Total Associate Professors',\n","                    'Total Assistant Professors',\n","                    'Average Faculty per University',\n","                    'Last Updated'\n","                ],\n","                'value': [\n","                    total_universities,\n","                    total_faculty,\n","                    total_professors,\n","                    total_associate,\n","                    total_assistant,\n","                    round(total_faculty / total_universities, 1) if total_universities > 0 else 0,\n","                    datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n","                ]\n","            }\n","\n","            stats_df = pd.DataFrame(stats_data)\n","            stats_sheet = self.get_or_create_worksheet('Overall_Statistics')\n","\n","            # Clear and update statistics\n","            stats_sheet.clear()\n","            stats_sheet.update([stats_df.columns.values.tolist()] + stats_df.values.tolist())\n","\n","            print(f\"   ‚úì Updated Overall Statistics\")\n","\n","        except Exception as e:\n","            print(f\"   ‚ö†Ô∏è  Error updating statistics: {e}\")\n","\n","    def run(self):\n","        \"\"\"Main execution method - Asks for 3 inputs and processes\"\"\"\n","        try:\n","            # Get user inputs\n","            if not self.get_user_inputs():\n","                return False\n","\n","            print(\"\\n\" + \"=\"*70)\n","            print(\"üöÄ STARTING PROCESS...\")\n","            print(\"=\"*70)\n","\n","            # Step 1: Authenticate (The Key)\n","            self.authenticate()\n","\n","            # Step 2: Connect to Sheet (The Address)\n","            self.connect_to_sheet()\n","\n","            # Step 3: Load and Process JSON files (The Paperwork)\n","            json_files = self.load_json_files()\n","            self.process_json_files(json_files)\n","\n","            print(\"\\n\" + \"=\" * 70)\n","            print(\"‚úÖ ALL DONE! Your Google Sheet has been updated!\")\n","            print(\"=\" * 70)\n","            print(f\"\\nüîó View your sheet: {self.spreadsheet_url}\")\n","            print(\"\\nüí° You can run this script again anytime:\")\n","            print(\"   ‚Ä¢ Add new JSON files to the same folder\")\n","            print(\"   ‚Ä¢ Run the script again\")\n","            print(\"   ‚Ä¢ Only NEW universities will be added\")\n","            print(\"   ‚Ä¢ Existing ones will be skipped automatically\")\n","            print(\"\\n\" + \"=\" * 70)\n","\n","            return True\n","\n","        except Exception as e:\n","            print(\"\\n\" + \"=\" * 70)\n","            print(f\"‚ùå ERROR: {e}\")\n","            print(\"=\" * 70)\n","            return False\n","\n","\n","# ============================================================================\n","# RUN THE SCRIPT\n","# ============================================================================\n","\n","if __name__ == \"__main__\":\n","    converter = FacultyDataToSheetsConverter()\n","    success = converter.run()\n","\n","    if not success:\n","        print(\"\\nüí° Need help? Check the error messages above.\")\n","        print(\"   Common issues:\")\n","        print(\"   ‚Ä¢ Credentials file path is incorrect\")\n","        print(\"   ‚Ä¢ Sheet not shared with service account email\")\n","        print(\"   ‚Ä¢ JSON folder path is incorrect\")\n","        print(\"   ‚Ä¢ No JSON files in the specified folder\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"agIkHlZPgkCq","executionInfo":{"status":"error","timestamp":1762976107629,"user_tz":-330,"elapsed":310124,"user":{"displayName":"Rahul Siddhu","userId":"12007764243202946991"}},"outputId":"45900b0e-71f7-4ff9-fd4d-f1a48f65d231"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["======================================================================\n","ü§ñ FACULTY DATA TO GOOGLE SHEETS CONVERTER\n","======================================================================\n","\n","I will ask you for 3 things. Please have them ready:\n","  1Ô∏è‚É£  Your Google Credentials file (The Robot's Key üîë)\n","  2Ô∏è‚É£  Your Google Sheet URL (The Address üè†)\n","  3Ô∏è‚É£  Your JSON files folder (The Paperwork üìÇ)\n","\n","======================================================================\n","\n","======================================================================\n","STEP 1: THE CREDENTIALS FILE (Robot's Key üîë)\n","======================================================================\n","\n","What is it?\n","  ‚Üí A .json file downloaded from Google Cloud Console\n","  ‚Üí Contains your service account credentials\n","\n","Where to get it?\n","  1. Go to: https://console.cloud.google.com/\n","  2. Create/select a project\n","  3. Enable Google Sheets API and Google Drive API\n","  4. Create Service Account ‚Üí Download JSON key\n","\n","----------------------------------------------------------------------\n","\n","üìù Enter the full path to your credentials.json file:\n","   > /content/luminous-byway-468905-r1-d5b2959372cb.json\n","   ‚úÖ Found credentials file!\n","\n","======================================================================\n","STEP 2: THE GOOGLE SHEET URL (The Address üè†)\n","======================================================================\n","\n","What is it?\n","  ‚Üí The web link to your Google Spreadsheet\n","  ‚Üí Looks like: https://docs.google.com/spreadsheets/d/XXXXX/edit\n","\n","How to get it?\n","  1. Open Google Sheets: https://sheets.google.com\n","  2. Create a new spreadsheet (or open existing one)\n","  3. Copy the URL from your browser's address bar\n","\n","‚ö†Ô∏è  IMPORTANT: You must SHARE your sheet with the service account email!\n","\n","üìß Your Service Account Email: sheets-robot@luminous-byway-468905-r1.iam.gserviceaccount.com\n","   ‚Üí Go to your Google Sheet\n","   ‚Üí Click 'Share' button\n","   ‚Üí Add this email with 'Editor' access\n","\n","----------------------------------------------------------------------\n","\n","üìù Enter your Google Sheet URL:\n","   > https://docs.google.com/spreadsheets/d/1cJALZxGUKGt3fOsMSRtFcvYas1vhWEcDXwHslvaIxqs/edit?usp=sharing\n","   ‚úÖ Got spreadsheet URL!\n","\n","======================================================================\n","STEP 3: THE JSON FILES FOLDER (The Paperwork üìÇ)\n","======================================================================\n","\n","What is it?\n","  ‚Üí A folder on your computer containing JSON files\n","  ‚Üí Each JSON file has faculty data for one university\n","\n","Example:\n","  ‚Üí /home/user/faculty_data/\n","  ‚Üí C:\\Users\\YourName\\Documents\\faculty_files\\\n","\n","üí° TIP: You can add more JSON files to this folder later\n","        and run the script again. Duplicates will be skipped!\n","\n","----------------------------------------------------------------------\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"Interrupted by user","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-3239570007.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    493\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m     \u001b[0mconverter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFacultyDataToSheetsConverter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 495\u001b[0;31m     \u001b[0msuccess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconverter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    496\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    497\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipython-input-3239570007.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    450\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m             \u001b[0;31m# Get user inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 452\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_user_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    453\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipython-input-3239570007.py\u001b[0m in \u001b[0;36mget_user_inputs\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjson_directory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nüìù Enter the full path to your JSON files folder:\\n   > \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjson_directory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m   1175\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1176\u001b[0m             )\n\u001b[0;32m-> 1177\u001b[0;31m         return self._input_request(\n\u001b[0m\u001b[1;32m   1178\u001b[0m             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"shell\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m   1217\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1219\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1220\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1221\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"]}]},{"cell_type":"markdown","source":[],"metadata":{"id":"TEvzn597jxTv"}},{"cell_type":"code","source":["!pip install qdrant-client"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"a4xmSU6KWJYj","executionInfo":{"status":"ok","timestamp":1762534233875,"user_tz":-330,"elapsed":10790,"user":{"displayName":"Rahul Siddhu","userId":"12007764243202946991"}},"outputId":"299c0ee0-cf76-46f3-9eec-a6af3884bab3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting qdrant-client\n","  Downloading qdrant_client-1.15.1-py3-none-any.whl.metadata (11 kB)\n","Requirement already satisfied: grpcio>=1.41.0 in /usr/local/lib/python3.12/dist-packages (from qdrant-client) (1.76.0)\n","Requirement already satisfied: httpx>=0.20.0 in /usr/local/lib/python3.12/dist-packages (from httpx[http2]>=0.20.0->qdrant-client) (0.28.1)\n","Requirement already satisfied: numpy>=1.26 in /usr/local/lib/python3.12/dist-packages (from qdrant-client) (2.0.2)\n","Collecting portalocker<4.0,>=2.7.0 (from qdrant-client)\n","  Downloading portalocker-3.2.0-py3-none-any.whl.metadata (8.7 kB)\n","Requirement already satisfied: protobuf>=3.20.0 in /usr/local/lib/python3.12/dist-packages (from qdrant-client) (5.29.5)\n","Requirement already satisfied: pydantic!=2.0.*,!=2.1.*,!=2.2.0,>=1.10.8 in /usr/local/lib/python3.12/dist-packages (from qdrant-client) (2.11.10)\n","Requirement already satisfied: urllib3<3,>=1.26.14 in /usr/local/lib/python3.12/dist-packages (from qdrant-client) (2.5.0)\n","Requirement already satisfied: typing-extensions~=4.12 in /usr/local/lib/python3.12/dist-packages (from grpcio>=1.41.0->qdrant-client) (4.15.0)\n","Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client) (4.11.0)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client) (2025.10.5)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client) (1.0.9)\n","Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client) (3.11)\n","Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client) (0.16.0)\n","Requirement already satisfied: h2<5,>=3 in /usr/local/lib/python3.12/dist-packages (from httpx[http2]>=0.20.0->qdrant-client) (4.3.0)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic!=2.0.*,!=2.1.*,!=2.2.0,>=1.10.8->qdrant-client) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic!=2.0.*,!=2.1.*,!=2.2.0,>=1.10.8->qdrant-client) (2.33.2)\n","Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic!=2.0.*,!=2.1.*,!=2.2.0,>=1.10.8->qdrant-client) (0.4.2)\n","Requirement already satisfied: hyperframe<7,>=6.1 in /usr/local/lib/python3.12/dist-packages (from h2<5,>=3->httpx[http2]>=0.20.0->qdrant-client) (6.1.0)\n","Requirement already satisfied: hpack<5,>=4.1 in /usr/local/lib/python3.12/dist-packages (from h2<5,>=3->httpx[http2]>=0.20.0->qdrant-client) (4.1.0)\n","Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client) (1.3.1)\n","Downloading qdrant_client-1.15.1-py3-none-any.whl (337 kB)\n","\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m337.3/337.3 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading portalocker-3.2.0-py3-none-any.whl (22 kB)\n","Installing collected packages: portalocker, qdrant-client\n","Successfully installed portalocker-3.2.0 qdrant-client-1.15.1\n"]}]},{"cell_type":"code","source":["from qdrant_client import QdrantClient\n","from pprint import pprint\n","\n","# Initialize Qdrant client\n","QDRANT_URL = \"https://b5651607-31ce-49ba-916d-c35c89d731d2.us-east4-0.gcp.cloud.qdrant.io\"\n","QDRANT_API_KEY = \"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJhY2Nlc3MiOiJtIn0.0ApHZL4Qn_A8bx7FCC62nx-IOrHI84W7GZlUZEyVgKk\"\n","collection_name = \"Nirf_Report\"\n","\n","client = QdrantClient(\n","    url=QDRANT_URL,\n","    api_key=QDRANT_API_KEY\n",")\n","\n","print(\"=\" * 60)\n","print(\"DIAGNOSTIC: Checking Collection Contents\")\n","print(\"=\" * 60)\n","\n","# Get collection info\n","collection_info = client.get_collection(collection_name)\n","print(f\"\\nCollection: {collection_name}\")\n","print(f\"Total points: {collection_info.points_count}\")\n","print(f\"Vector size: {collection_info.config.params.vectors.size}\")\n","\n","# Get a sample of points to see what metadata exists\n","print(\"\\n\" + \"=\" * 60)\n","print(\"Sample Points (first 5):\")\n","print(\"=\" * 60)\n","\n","records, _ = client.scroll(\n","    collection_name=collection_name,\n","    limit=5,\n","    with_payload=True,\n","    with_vectors=False\n",")\n","\n","if not records:\n","    print(\"\\n‚ö†Ô∏è Collection is EMPTY - no points found!\")\n","else:\n","    for i, record in enumerate(records, 1):\n","        print(f\"\\n--- Point {i} (ID: {record.id}) ---\")\n","        print(\"Payload keys:\", list(record.payload.keys()) if record.payload else \"No payload\")\n","        if record.payload:\n","            print(\"Payload content:\")\n","            pprint(record.payload, indent=2)\n","\n","# Collect all unique metadata keys across all points\n","print(\"\\n\" + \"=\" * 60)\n","print(\"Analyzing ALL metadata fields in collection...\")\n","print(\"=\" * 60)\n","\n","all_keys = set()\n","offset = None\n","sample_count = 0\n","max_samples = 1000  # Check first 1000 points\n","\n","while sample_count < max_samples:\n","    records, next_offset = client.scroll(\n","        collection_name=collection_name,\n","        limit=100,\n","        offset=offset,\n","        with_payload=True,\n","        with_vectors=False\n","    )\n","\n","    if not records:\n","        break\n","\n","    for record in records:\n","        if record.payload:\n","            all_keys.update(record.payload.keys())\n","        sample_count += 1\n","\n","    if next_offset is None:\n","        break\n","    offset = next_offset\n","\n","print(f\"\\nAnalyzed {sample_count} points\")\n","print(f\"\\nAll unique metadata keys found:\")\n","if all_keys:\n","    for key in sorted(all_keys):\n","        print(f\"  - {key}\")\n","else:\n","    print(\"  (No metadata keys found)\")\n","\n","# Now check for the specific fields\n","print(\"\\n\" + \"=\" * 60)\n","print(\"Checking for target fields:\")\n","print(\"=\" * 60)\n","target_fields = [\"TLR\", \"RPC\", \"GO\", \"OI\", \"Perception\", \"Score\"]\n","\n","for field in target_fields:\n","    if field in all_keys:\n","        print(f\"  ‚úì {field} - FOUND\")\n","    else:\n","        print(f\"  ‚úó {field} - NOT FOUND\")\n","\n","print(\"\\n\" + \"=\" * 60)\n","print(\"Would you like to delete any of the fields listed above?\")\n","print(\"Please confirm the exact field names.\")\n","print(\"=\" * 60)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"L4KkLZVIWPgg","executionInfo":{"status":"ok","timestamp":1762234338353,"user_tz":-330,"elapsed":3599,"user":{"displayName":"Rahul Siddhu","userId":"12007764243202946991"}},"outputId":"af56c2a8-b0e5-4715-98b8-4b4b94de1916"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["============================================================\n","DIAGNOSTIC: Checking Collection Contents\n","============================================================\n","\n","Collection: Nirf_Report\n","Total points: 726\n","Vector size: 384\n","\n","============================================================\n","Sample Points (first 5):\n","============================================================\n","\n","--- Point 1 (ID: 000101d8-9c73-50ea-b4b7-2b55f1c7a90f) ---\n","Payload keys: ['institute_name', 'institute_code', 'content_type', 'chunk_index', 'total_chunks', 'content', 'content_length', 'original_id', 'source_file', 'item_index', 'vector_model', 'upload_timestamp', 'content_for_embedding', 'data_type', 'rank', 'city', 'state', 'tlr_score', 'rpc_score', 'go_score', 'oi_score', 'perception_score', 'overall_score']\n","Payload content:\n","{ 'chunk_index': 0,\n","  'city': 'Kalavakkam',\n","  'content': 'National Institutional Ranking Framework Ministry of Education '\n","             'Government of India Data Submitted by Institution for India '\n","             \"Rankings '2025' Institute Name: Sri Sivasubramaniya Nadar \"\n","             'College of Engineering [IR-E-C-16604]',\n","  'content_for_embedding': 'Institute: Sri Sivasubramaniya Nadar College of '\n","                           'Engineering | Code: IR-E-C-16604 | Content Type: '\n","                           'HEADER | Content: National Institutional Ranking '\n","                           'Framework Ministry of Education Government of '\n","                           'India Data Submitted by Institution for India '\n","                           \"Rankings '2025' Institute Name: Sri \"\n","                           'Sivasubramaniya Nadar College of Engineering '\n","                           '[IR-E-C-16604]',\n","  'content_length': 218,\n","  'content_type': 'HEADER',\n","  'data_type': 'NIRF_REPORT',\n","  'go_score': 70.01,\n","  'institute_code': 'IR-E-C-16604',\n","  'institute_name': 'Sri Sivasubramaniya Nadar College of Engineering',\n","  'item_index': 0,\n","  'oi_score': 57.78,\n","  'original_id': '000101d8-9c73-50ea-b4b7-2b55f1c7a90f',\n","  'overall_score': 56.08,\n","  'perception_score': 17.21,\n","  'rank': 47,\n","  'rpc_score': 43.96,\n","  'source_file': 'Sri Sivasubramaniya Nadar College of Engineering',\n","  'state': 'Tamil Nadu',\n","  'tlr_score': 71.29,\n","  'total_chunks': 1,\n","  'upload_timestamp': '2025-09-15T05:37:04.359711',\n","  'vector_model': 'all-MiniLM-L6-v2'}\n","\n","--- Point 2 (ID: 000accb1-406a-5950-9938-369e0f6e08c0) ---\n","Payload keys: ['institute_name', 'institute_code', 'content_type', 'chunk_index', 'total_chunks', 'content', 'content_length', 'original_id', 'source_file', 'item_index', 'vector_model', 'upload_timestamp', 'content_for_embedding', 'data_type', 'rank', 'city', 'state', 'tlr_score', 'rpc_score', 'go_score', 'oi_score', 'perception_score', 'overall_score']\n","Payload content:\n","{ 'chunk_index': 1,\n","  'city': 'Vaddeswaram',\n","  'content': 'Thousand Two Hundred And Thirty Four) '\n","             'Seminars/Conferences/Workshops 5532692 (Fifty Five Lakh Thirty '\n","             'Two Thousand Six Hundred and Ninety Two) 3805340 (Thirty Eight '\n","             'Lakh Five Thousand Three Hundred And Forty) 3607329 (Thirty Six '\n","             'Lakh Seven Thousand Three Hundred And Twenty Nine)',\n","  'content_for_embedding': 'Institute: Koneru Lakshmaiah Education Foundation '\n","                           'University (K L College of Engineering) | Code: '\n","                           'IR-E-U-0020 | Content Type: FINANCIAL_RESOURCES | '\n","                           'Content: Thousand Two Hundred And Thirty Four) '\n","                           'Seminars/Conferences/Workshops 5532692 (Fifty Five '\n","                           'Lakh Thirty Two Thousand Six Hundred and Ninety '\n","                           'Two) 3805340 (Thirty Eight Lakh Five Thousand '\n","                           'Three Hundred And Forty) 3607329 (Thirty Six Lakh '\n","                           'Seven Thousand Three Hundred And Twenty Nine)',\n","  'content_length': 278,\n","  'content_type': 'FINANCIAL_RESOURCES',\n","  'data_type': 'NIRF_REPORT',\n","  'go_score': 69.94,\n","  'institute_code': 'IR-E-U-0020',\n","  'institute_name': 'Koneru Lakshmaiah Education Foundation University (K L '\n","                    'College of Engineering)',\n","  'item_index': 6,\n","  'oi_score': 66.84,\n","  'original_id': '000accb1-406a-5950-9938-369e0f6e08c0',\n","  'overall_score': 58.95,\n","  'perception_score': 4.12,\n","  'rank': 35,\n","  'rpc_score': 48.67,\n","  'source_file': 'Koneru Lakshmaiah Education Foundation University _K L '\n","                 'College of Engineering_ AP',\n","  'state': 'Andhra Pradesh',\n","  'tlr_score': 77.55,\n","  'total_chunks': 2,\n","  'upload_timestamp': '2025-09-15T05:37:10.523579',\n","  'vector_model': 'all-MiniLM-L6-v2'}\n","\n","--- Point 3 (ID: 002fa70d-bbcb-59b4-84f8-4cb35b6d399b) ---\n","Payload keys: ['institute_name', 'institute_code', 'content_type', 'chunk_index', 'total_chunks', 'content', 'content_length', 'original_id', 'source_file', 'item_index', 'vector_model', 'upload_timestamp', 'content_for_embedding', 'data_type', 'rank', 'city', 'state', 'tlr_score', 'rpc_score', 'go_score', 'oi_score', 'perception_score', 'overall_score']\n","Payload content:\n","{ 'chunk_index': 0,\n","  'city': 'Guwahati',\n","  'content': 'PG [2 Years Program(s)]: Placement & higher studies for previous '\n","             '3 years Academic Year No. of first year students intake in the '\n","             'year No. of first year students admitted in the year Academic '\n","             'Year No. of students graduating in minimum stipulated time No. '\n","             'of students placed Median salary of placed graduates per '\n","             'annum(Amount in Rs.) No. of students selected for Higher Studies '\n","             '2020-21 825 668 2021-22 567 357 1350000(Rs Thirteen Lakh Fifty '\n","             'Thousand) 190 2021-22 873 842 2022-23 636 473 1200000(Rupees '\n","             'Twelve Lakhs) 151 2022-23 993 729 2023-24 599 440 1100000(Eleven '\n","             'lakh) 134',\n","  'content_for_embedding': 'Institute: Indian Institute of Technology Guwahati '\n","                           '| Code: IR-E-U-0053 | Content Type: '\n","                           'PLACEMENT_STUDIES | Content: PG [2 Years '\n","                           'Program(s)]: Placement & higher studies for '\n","                           'previous 3 years Academic Year No. of first year '\n","                           'students intake in the year No. of first year '\n","                           'students admitted in the year Academic Year No. of '\n","                           'students graduating in minimum stipulated time No. '\n","                           'of students placed Median salary of placed '\n","                           'graduates per annum(Amount in Rs.) No. of students '\n","                           'selected for Higher Studies 2020-21 825 668 '\n","                           '2021-22 567 357 1350000(Rs Thirteen Lakh Fifty '\n","                           'Thousand) 190 2021-22 873 842 2022-23 636 473 '\n","                           '1200000(Rupees Twelve Lakhs) 151 2022-23 993 729 '\n","                           '2023-24 599 440 1100000(Eleven lakh) 134',\n","  'content_length': 573,\n","  'content_type': 'PLACEMENT_STUDIES',\n","  'data_type': 'NIRF_REPORT',\n","  'go_score': 84.68,\n","  'institute_code': 'IR-E-U-0053',\n","  'institute_name': 'Indian Institute of Technology Guwahati',\n","  'item_index': 3,\n","  'oi_score': 61.4,\n","  'original_id': '002fa70d-bbcb-59b4-84f8-4cb35b6d399b',\n","  'overall_score': 72.24,\n","  'perception_score': 52.06,\n","  'rank': 8,\n","  'rpc_score': 72.89,\n","  'source_file': 'IIT_Guwahati',\n","  'state': 'Assam',\n","  'tlr_score': 73.6,\n","  'total_chunks': 1,\n","  'upload_timestamp': '2025-09-15T05:36:32.043881',\n","  'vector_model': 'all-MiniLM-L6-v2'}\n","\n","--- Point 4 (ID: 00526145-d498-5559-aa0b-658aa219ed25) ---\n","Payload keys: ['institute_name', 'institute_code', 'content_type', 'chunk_index', 'total_chunks', 'content', 'content_length', 'original_id', 'source_file', 'item_index', 'vector_model', 'upload_timestamp', 'content_for_embedding', 'data_type', 'rank', 'city', 'state', 'tlr_score', 'rpc_score', 'go_score', 'oi_score', 'perception_score', 'overall_score']\n","Payload content:\n","{ 'chunk_index': 1,\n","  'city': 'Hyderabad',\n","  'content': '49523506 (Four Crore Ninety Five Lakh Twenty Three Thousand Five '\n","             'Hundred and Six) 10407213 (One Crore Four Lakhs Seven Thousand '\n","             'Two Hundred and Thirteen) 3679015 (Thirty Six Lakhs Seventy Nine '\n","             'Thousand and Fifteen)',\n","  'content_for_embedding': 'Institute: International Institute of Information '\n","                           'Technology Hyderabad | Code: IR-E-U-0014 | Content '\n","                           'Type: FINANCIAL_RESOURCES | Content: 49523506 '\n","                           '(Four Crore Ninety Five Lakh Twenty Three Thousand '\n","                           'Five Hundred and Six) 10407213 (One Crore Four '\n","                           'Lakhs Seven Thousand Two Hundred and Thirteen) '\n","                           '3679015 (Thirty Six Lakhs Seventy Nine Thousand '\n","                           'and Fifteen)',\n","  'content_length': 214,\n","  'content_type': 'FINANCIAL_RESOURCES',\n","  'data_type': 'NIRF_REPORT',\n","  'go_score': 70.72,\n","  'institute_code': 'IR-E-U-0014',\n","  'institute_name': 'International Institute of Information Technology '\n","                    'Hyderabad',\n","  'item_index': 6,\n","  'oi_score': 63.32,\n","  'original_id': '00526145-d498-5559-aa0b-658aa219ed25',\n","  'overall_score': 58.45,\n","  'perception_score': 22.58,\n","  'rank': 38,\n","  'rpc_score': 43.22,\n","  'source_file': 'International Institute of Information Technology Hyderabad',\n","  'state': 'Telangana',\n","  'tlr_score': 75.84,\n","  'total_chunks': 2,\n","  'upload_timestamp': '2025-09-15T05:36:59.575202',\n","  'vector_model': 'all-MiniLM-L6-v2'}\n","\n","--- Point 5 (ID: 00720f11-3b85-5c6d-bfdd-0fa6d86bbb63) ---\n","Payload keys: ['institute_name', 'institute_code', 'content_type', 'chunk_index', 'total_chunks', 'content', 'content_length', 'original_id', 'source_file', 'item_index', 'vector_model', 'upload_timestamp', 'content_for_embedding', 'data_type', 'rank', 'city', 'state', 'tlr_score', 'rpc_score', 'go_score', 'oi_score', 'perception_score', 'overall_score']\n","Payload content:\n","{ 'chunk_index': 0,\n","  'city': 'Jodhpur',\n","  'content': 'Sponsored Research Details Financial Year 2023-24 2022-23 '\n","             '2021-22 Total no. of Sponsored Projects 360 269 220 Total no. of '\n","             'Funding Agencies 74 49 43 Total Amount Received (Amount in '\n","             'Rupees) 522852574 371553394 477446648 Amount Received in Words '\n","             'Fifty Two Crore Twenty Eight Lakh Fifty Two Thousand Five '\n","             'Hundred Seventy Four Only Thirty Seven Crore Fifteen Lakh Fifty '\n","             'Three Thousand Three Hundred Ninety Four Forty Seven Crore '\n","             'Seventy Four Lakh Forty Six Thousand Six Hundred Forty Eight',\n","  'content_for_embedding': 'Institute: Indian Institute of Technology Jodhpur '\n","                           '| Code: IR-E-U-0395 | Content Type: '\n","                           'SPONSORED_RESEARCH | Content: Sponsored Research '\n","                           'Details Financial Year 2023-24 2022-23 2021-22 '\n","                           'Total no. of Sponsored Projects 360 269 220 Total '\n","                           'no. of Funding Agencies 74 49 43 Total Amount '\n","                           'Received (Amount in Rupees) 522852574 371553394 '\n","                           '477446648 Amount Received in Words Fifty Two Crore '\n","                           'Twenty Eight Lakh Fifty Two Thousand Five Hundred '\n","                           'Seventy Four Only Thirty Seven Crore Fifteen Lakh '\n","                           'Fifty Three Thousand Three Hundred Ninety Four '\n","                           'Forty Seven Crore Seventy Four Lakh Forty Six '\n","                           'Thousand Six Hundred Forty Eight',\n","  'content_length': 486,\n","  'content_type': 'SPONSORED_RESEARCH',\n","  'data_type': 'NIRF_REPORT',\n","  'go_score': 70.43,\n","  'institute_code': 'IR-E-U-0395',\n","  'institute_name': 'Indian Institute of Technology Jodhpur',\n","  'item_index': 8,\n","  'oi_score': 66.41,\n","  'original_id': '00720f11-3b85-5c6d-bfdd-0fa6d86bbb63',\n","  'overall_score': 61.31,\n","  'perception_score': 12.93,\n","  'rank': 27,\n","  'rpc_score': 44.03,\n","  'source_file': 'IIT_Jodhpur',\n","  'state': 'Rajasthan',\n","  'tlr_score': 86.92,\n","  'total_chunks': 1,\n","  'upload_timestamp': '2025-09-15T05:36:51.834822',\n","  'vector_model': 'all-MiniLM-L6-v2'}\n","\n","============================================================\n","Analyzing ALL metadata fields in collection...\n","============================================================\n","\n","Analyzed 726 points\n","\n","All unique metadata keys found:\n","  - category\n","  - chunk_index\n","  - city\n","  - content\n","  - content_for_embedding\n","  - content_length\n","  - content_type\n","  - data_source\n","  - data_type\n","  - go_score\n","  - institute_code\n","  - institute_name\n","  - item_index\n","  - oi_score\n","  - original_id\n","  - overall_score\n","  - perception_score\n","  - processing_timestamp\n","  - rank\n","  - rpc_score\n","  - source_file\n","  - state\n","  - tlr_score\n","  - total_chunks\n","  - total_score\n","  - upload_timestamp\n","  - vector_model\n","\n","============================================================\n","Checking for target fields:\n","============================================================\n","  ‚úó TLR - NOT FOUND\n","  ‚úó RPC - NOT FOUND\n","  ‚úó GO - NOT FOUND\n","  ‚úó OI - NOT FOUND\n","  ‚úó Perception - NOT FOUND\n","  ‚úó Score - NOT FOUND\n","\n","============================================================\n","Would you like to delete any of the fields listed above?\n","Please confirm the exact field names.\n","============================================================\n"]}]},{"cell_type":"code","source":["from qdrant_client import QdrantClient\n","\n","# Initialize Qdrant client\n","QDRANT_URL = \"https://b5651607-31ce-49ba-916d-c35c89d731d2.us-east4-0.gcp.cloud.qdrant.io\"\n","QDRANT_API_KEY = \"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJhY2Nlc3MiOiJtIn0.0ApHZL4Qn_A8bx7FCC62nx-IOrHI84W7GZlUZEyVgKk\"\n","collection_name = \"Nirf_Report\"\n","\n","client = QdrantClient(\n","    url=QDRANT_URL,\n","    api_key=QDRANT_API_KEY\n",")\n","\n","# Correct field names (lowercase with underscores)\n","fields_to_delete = [\n","    \"tlr_score\",\n","    \"rpc_score\",\n","    \"go_score\",\n","    \"oi_score\",\n","    \"perception_score\",\n","    \"overall_score\",\n","    \"total_score\"\n","]\n","\n","print(f\"Starting metadata deletion from collection: {collection_name}\")\n","print(f\"Fields to delete: {fields_to_delete}\")\n","print(\"=\" * 60)\n","\n","# Get all points from the collection\n","offset = None\n","batch_size = 100\n","total_updated = 0\n","total_processed = 0\n","\n","while True:\n","    # Scroll through all points\n","    records, next_offset = client.scroll(\n","        collection_name=collection_name,\n","        limit=batch_size,\n","        offset=offset,\n","        with_payload=True,\n","        with_vectors=False\n","    )\n","\n","    if not records:\n","        break\n","\n","    # Process each point\n","    for record in records:\n","        point_id = record.id\n","        payload = record.payload\n","        total_processed += 1\n","\n","        # Check if any of the fields exist in the payload\n","        fields_present = [field for field in fields_to_delete if field in payload]\n","\n","        if fields_present:\n","            # Create a new payload without the specified fields\n","            new_payload = {k: v for k, v in payload.items() if k not in fields_to_delete}\n","\n","            # Overwrite the payload (this removes the old fields)\n","            client.overwrite_payload(\n","                collection_name=collection_name,\n","                points=[point_id],\n","                payload=new_payload\n","            )\n","\n","            total_updated += 1\n","            if total_updated <= 10:  # Show first 10 updates\n","                print(f\"‚úì Updated point {point_id}: Removed {fields_present}\")\n","            elif total_updated % 50 == 0:  # Then show every 50th\n","                print(f\"‚úì Progress: {total_updated} points updated...\")\n","\n","    # Check if we've reached the end\n","    if next_offset is None:\n","        break\n","\n","    offset = next_offset\n","\n","print(\"\\n\" + \"=\" * 60)\n","print(f\"COMPLETED!\")\n","print(f\"Total points processed: {total_processed}\")\n","print(f\"Total points updated: {total_updated}\")\n","print(f\"Points with no matching fields: {total_processed - total_updated}\")\n","print(\"=\" * 60)\n","print(\"\\nDeleted fields:\")\n","for field in fields_to_delete:\n","    print(f\"  ‚úì {field}\")\n","print(\"\\nAll specified metadata fields have been removed from the collection.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xJyCz_4fWuct","executionInfo":{"status":"ok","timestamp":1762234427479,"user_tz":-330,"elapsed":31332,"user":{"displayName":"Rahul Siddhu","userId":"12007764243202946991"}},"outputId":"56ad6fdd-0090-4379-88e2-22cb6910198a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Starting metadata deletion from collection: Nirf_Report\n","Fields to delete: ['tlr_score', 'rpc_score', 'go_score', 'oi_score', 'perception_score', 'overall_score', 'total_score']\n","============================================================\n","‚úì Updated point 000101d8-9c73-50ea-b4b7-2b55f1c7a90f: Removed ['tlr_score', 'rpc_score', 'go_score', 'oi_score', 'perception_score', 'overall_score']\n","‚úì Updated point 000accb1-406a-5950-9938-369e0f6e08c0: Removed ['tlr_score', 'rpc_score', 'go_score', 'oi_score', 'perception_score', 'overall_score']\n","‚úì Updated point 002fa70d-bbcb-59b4-84f8-4cb35b6d399b: Removed ['tlr_score', 'rpc_score', 'go_score', 'oi_score', 'perception_score', 'overall_score']\n","‚úì Updated point 00526145-d498-5559-aa0b-658aa219ed25: Removed ['tlr_score', 'rpc_score', 'go_score', 'oi_score', 'perception_score', 'overall_score']\n","‚úì Updated point 00720f11-3b85-5c6d-bfdd-0fa6d86bbb63: Removed ['tlr_score', 'rpc_score', 'go_score', 'oi_score', 'perception_score', 'overall_score']\n","‚úì Updated point 00a7c941-0ecb-53b7-bd39-ca52b75d9114: Removed ['tlr_score', 'rpc_score', 'go_score', 'oi_score', 'perception_score', 'overall_score']\n","‚úì Updated point 00aad4cf-dac5-583d-b689-4c4d2236deb3: Removed ['tlr_score', 'rpc_score', 'go_score', 'oi_score', 'perception_score', 'overall_score']\n","‚úì Updated point 0136a233-ae85-501c-a6c6-98c41df46aad: Removed ['tlr_score', 'rpc_score', 'go_score', 'oi_score', 'perception_score', 'overall_score']\n","‚úì Updated point 01a880d0-faa1-5d51-8d4e-5bc0b8fcb8b3: Removed ['tlr_score', 'rpc_score', 'go_score', 'oi_score', 'perception_score', 'overall_score', 'total_score']\n","‚úì Updated point 02ca4524-e8b8-5026-8851-5256d5e4344a: Removed ['tlr_score', 'rpc_score', 'go_score', 'oi_score', 'perception_score', 'overall_score']\n","‚úì Progress: 50 points updated...\n","‚úì Progress: 100 points updated...\n","\n","============================================================\n","COMPLETED!\n","Total points processed: 726\n","Total points updated: 148\n","Points with no matching fields: 578\n","============================================================\n","\n","Deleted fields:\n","  ‚úì tlr_score\n","  ‚úì rpc_score\n","  ‚úì go_score\n","  ‚úì oi_score\n","  ‚úì perception_score\n","  ‚úì overall_score\n","  ‚úì total_score\n","\n","All specified metadata fields have been removed from the collection.\n"]}]},{"cell_type":"code","source":["from qdrant_client import QdrantClient\n","\n","# Initialize Qdrant client\n","QDRANT_URL = \"https://b5651607-31ce-49ba-916d-c35c89d731d2.us-east4-0.gcp.cloud.qdrant.io\"\n","QDRANT_API_KEY = \"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJhY2Nlc3MiOiJtIn0.0ApHZL4Qn_A8bx7FCC62nx-IOrHI84W7GZlUZEyVgKk\"\n","collection_name = \"durden\"\n","\n","client = QdrantClient(\n","    url=QDRANT_URL,\n","    api_key=QDRANT_API_KEY\n",")\n","\n","# Mapping of content_type to NIRF category\n","CONTENT_TYPE_TO_NIRF_CATEGORY = {\n","    \"HEADER\": \"General\",\n","    \"SANCTIONED_INTAKE\": \"TLR\",\n","    \"STUDENT_STRENGTH\": \"OI\",\n","    \"students_strength\": \"OI\",\n","    \"FACULTY_DETAILS\": \"TLR\",\n","    \"PCS_FACILITIES\": \"OI\",\n","    \"PHD_DETAILS\": \"RP\",\n","    \"SPONSORED_RESEARCH\": \"RP\",\n","    \"CONSULTANCY_PROJECTS\": \"RP\",\n","    \"FINANCIAL_RESOURCES\": \"TLR\",\n","    \"PLACEMENT_STUDIES\": \"GO\",\n","    \"PG_PLACEMENT\": \"GO\",\n","    \"IPR\": \"RP\"\n","}\n","\n","print(\"=\" * 70)\n","print(f\"Adding 'Nirf_category' field to collection: {collection_name}\")\n","print(\"=\" * 70)\n","print(\"\\nContent Type to NIRF Category Mapping:\")\n","for content_type, category in CONTENT_TYPE_TO_NIRF_CATEGORY.items():\n","    print(f\"  {content_type:25} -> {category}\")\n","print(\"=\" * 70)\n","\n","# Statistics\n","stats = {\n","    \"total_processed\": 0,\n","    \"total_updated\": 0,\n","    \"no_content_type\": 0,\n","    \"unknown_content_type\": 0,\n","    \"category_counts\": {}\n","}\n","\n","offset = None\n","batch_size = 100\n","\n","while True:\n","    # Scroll through all points\n","    records, next_offset = client.scroll(\n","        collection_name=collection_name,\n","        limit=batch_size,\n","        offset=offset,\n","        with_payload=True,\n","        with_vectors=False\n","    )\n","\n","    if not records:\n","        break\n","\n","    # Process each point\n","    for record in records:\n","        point_id = record.id\n","        payload = record.payload\n","        stats[\"total_processed\"] += 1\n","\n","        # Get content_type from payload\n","        content_type = payload.get(\"content_type\")\n","\n","        if content_type is None:\n","            stats[\"no_content_type\"] += 1\n","            continue\n","\n","        # Map content_type to NIRF category\n","        nirf_category = CONTENT_TYPE_TO_NIRF_CATEGORY.get(content_type)\n","\n","        if nirf_category is None:\n","            stats[\"unknown_content_type\"] += 1\n","            if stats[\"unknown_content_type\"] <= 5:  # Show first 5 unknown types\n","                print(f\"‚ö†Ô∏è  Unknown content_type: '{content_type}' (Point ID: {point_id})\")\n","            continue\n","\n","        # Add Nirf_category to payload\n","        client.set_payload(\n","            collection_name=collection_name,\n","            points=[point_id],\n","            payload={\"Nirf_category\": nirf_category}\n","        )\n","\n","        stats[\"total_updated\"] += 1\n","        stats[\"category_counts\"][nirf_category] = stats[\"category_counts\"].get(nirf_category, 0) + 1\n","\n","        # Show progress\n","        if stats[\"total_updated\"] <= 10:\n","            print(f\"‚úì Point {point_id}: '{content_type}' -> Nirf_category: '{nirf_category}'\")\n","        elif stats[\"total_updated\"] % 100 == 0:\n","            print(f\"‚úì Progress: {stats['total_updated']} points updated...\")\n","\n","    # Check if we've reached the end\n","    if next_offset is None:\n","        break\n","\n","    offset = next_offset\n","\n","# Print summary\n","print(\"\\n\" + \"=\" * 70)\n","print(\"COMPLETED!\")\n","print(\"=\" * 70)\n","print(f\"\\nTotal points processed:       {stats['total_processed']}\")\n","print(f\"Total points updated:         {stats['total_updated']}\")\n","print(f\"Points with no content_type:  {stats['no_content_type']}\")\n","print(f\"Points with unknown content_type: {stats['unknown_content_type']}\")\n","\n","if stats[\"category_counts\"]:\n","    print(\"\\nNIRF Category Distribution:\")\n","    for category in sorted(stats[\"category_counts\"].keys()):\n","        count = stats[\"category_counts\"][category]\n","        percentage = (count / stats[\"total_updated\"] * 100) if stats[\"total_updated\"] > 0 else 0\n","        print(f\"  {category:10} : {count:5} points ({percentage:5.1f}%)\")\n","\n","print(\"\\n\" + \"=\" * 70)\n","print(\"‚úì 'Nirf_category' field has been added to all applicable points!\")\n","print(\"=\" * 70)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"esWLIGjmbdjk","executionInfo":{"status":"ok","timestamp":1762976222908,"user_tz":-330,"elapsed":22073,"user":{"displayName":"Rahul Siddhu","userId":"12007764243202946991"}},"outputId":"e1645792-438e-4920-cb56-a9a059b4d079"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["======================================================================\n","Adding 'Nirf_category' field to collection: durden\n","======================================================================\n","\n","Content Type to NIRF Category Mapping:\n","  HEADER                    -> General\n","  SANCTIONED_INTAKE         -> TLR\n","  STUDENT_STRENGTH          -> OI\n","  students_strength         -> OI\n","  FACULTY_DETAILS           -> TLR\n","  PCS_FACILITIES            -> OI\n","  PHD_DETAILS               -> RP\n","  SPONSORED_RESEARCH        -> RP\n","  CONSULTANCY_PROJECTS      -> RP\n","  FINANCIAL_RESOURCES       -> TLR\n","  PLACEMENT_STUDIES         -> GO\n","  PG_PLACEMENT              -> GO\n","  IPR                       -> RP\n","======================================================================\n","‚úì Point 0008f5fb-e110-542b-9750-10fd9e09e82a: 'STUDENT_STRENGTH' -> Nirf_category: 'OI'\n","‚úì Point 00335224-c119-53a6-839c-685ca365907f: 'PHD_DETAILS' -> Nirf_category: 'RP'\n","‚úì Point 004bde32-c884-5090-a56a-617217b02293: 'STUDENT_STRENGTH' -> Nirf_category: 'OI'\n","‚úì Point 005f9535-61d1-5b37-9d15-740d9838c721: 'STUDENT_STRENGTH' -> Nirf_category: 'OI'\n","‚úì Point 007b345c-8b2b-5cdc-81df-3793d14ae613: 'PHD_DETAILS' -> Nirf_category: 'RP'\n","‚úì Point 0087aa6d-45ec-51ba-acb7-d88d66657853: 'FINANCIAL_RESOURCES' -> Nirf_category: 'TLR'\n","‚úì Point 009798aa-7059-52f4-8d04-4e752cac0b00: 'students_strength' -> Nirf_category: 'OI'\n","‚úì Point 00fea554-ea86-5902-90d5-0bb2470be52d: 'FINANCIAL_RESOURCES' -> Nirf_category: 'TLR'\n","‚úì Point 00ff6e39-5653-5ef6-ade2-3d3ec0863781: 'FINANCIAL_RESOURCES' -> Nirf_category: 'TLR'\n","‚úì Point 0124f3d3-fb9d-5bc2-8a21-2674e5cd9db5: 'STUDENT_STRENGTH' -> Nirf_category: 'OI'\n","‚úì Progress: 100 points updated...\n","‚úì Progress: 200 points updated...\n","‚úì Progress: 300 points updated...\n","‚úì Progress: 400 points updated...\n","‚úì Progress: 500 points updated...\n","‚úì Progress: 600 points updated...\n","‚úì Progress: 700 points updated...\n","‚úì Progress: 800 points updated...\n","‚úì Progress: 900 points updated...\n","‚úì Progress: 1000 points updated...\n","‚úì Progress: 1100 points updated...\n","\n","======================================================================\n","COMPLETED!\n","======================================================================\n","\n","Total points processed:       1190\n","Total points updated:         1190\n","Points with no content_type:  0\n","Points with unknown content_type: 0\n","\n","NIRF Category Distribution:\n","  GO         :   111 points (  9.3%)\n","  General    :    98 points (  8.2%)\n","  OI         :   294 points ( 24.7%)\n","  RP         :   297 points ( 25.0%)\n","  TLR        :   390 points ( 32.8%)\n","\n","======================================================================\n","‚úì 'Nirf_category' field has been added to all applicable points!\n","======================================================================\n"]}]},{"cell_type":"code","source":["from qdrant_client import QdrantClient\n","from collections import Counter\n","\n","# Initialize Qdrant client\n","QDRANT_URL = \"https://b5651607-31ce-49ba-916d-c35c89d731d2.us-east4-0.gcp.cloud.qdrant.io\"\n","QDRANT_API_KEY = \"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJhY2Nlc3MiOiJtIn0.0ApHZL4Qn_A8bx7FCC62nx-IOrHI84W7GZlUZEyVgKk\"\n","collection_name = \"Nirf_Report\"\n","\n","client = QdrantClient(\n","    url=QDRANT_URL,\n","    api_key=QDRANT_API_KEY\n",")\n","\n","# Known content types (already mapped)\n","KNOWN_CONTENT_TYPES = {\n","    \"HEADER\",\n","    \"SANCTIONED_INTAKE\",\n","    \"STUDENT_STRENGTH\",\n","    \"students_strength\",\n","    \"FACULTY_DETAILS\",\n","    \"PCS_FACILITIES\",\n","    \"PHD_DETAILS\",\n","    \"SPONSORED_RESEARCH\",\n","    \"CONSULTANCY_PROJECTS\",\n","    \"FINANCIAL_RESOURCES\",\n","    \"PLACEMENT_STUDIES\",\n","    \"PG_PLACEMENT\",\n","    \"IPR\"\n","}\n","\n","print(\"=\" * 70)\n","print(\"Analyzing ALL content_type values in collection...\")\n","print(\"=\" * 70)\n","\n","# Collect all content types\n","all_content_types = []\n","no_content_type_count = 0\n","offset = None\n","batch_size = 100\n","total_processed = 0\n","\n","while True:\n","    records, next_offset = client.scroll(\n","        collection_name=collection_name,\n","        limit=batch_size,\n","        offset=offset,\n","        with_payload=True,\n","        with_vectors=False\n","    )\n","\n","    if not records:\n","        break\n","\n","    for record in records:\n","        total_processed += 1\n","        content_type = record.payload.get(\"content_type\")\n","\n","        if content_type is None:\n","            no_content_type_count += 1\n","        else:\n","            all_content_types.append(content_type)\n","\n","    if next_offset is None:\n","        break\n","\n","    offset = next_offset\n","\n","    if total_processed % 500 == 0:\n","        print(f\"Processed {total_processed} points...\")\n","\n","# Count occurrences\n","content_type_counts = Counter(all_content_types)\n","\n","print(f\"\\n‚úì Analysis complete! Processed {total_processed} points\")\n","print(f\"Points with no content_type: {no_content_type_count}\")\n","print(f\"Unique content_type values found: {len(content_type_counts)}\")\n","\n","print(\"\\n\" + \"=\" * 70)\n","print(\"ALL Content Types (sorted by frequency):\")\n","print(\"=\" * 70)\n","\n","for content_type, count in content_type_counts.most_common():\n","    status = \"‚úì KNOWN\" if content_type in KNOWN_CONTENT_TYPES else \"‚ö†Ô∏è  UNKNOWN\"\n","    percentage = (count / len(all_content_types) * 100) if all_content_types else 0\n","    print(f\"{status:12} | {content_type:30} | Count: {count:5} ({percentage:5.1f}%)\")\n","\n","# Separate list of unknown types\n","unknown_types = [ct for ct in content_type_counts.keys() if ct not in KNOWN_CONTENT_TYPES]\n","\n","if unknown_types:\n","    print(\"\\n\" + \"=\" * 70)\n","    print(\"UNKNOWN Content Types Summary:\")\n","    print(\"=\" * 70)\n","    for content_type in sorted(unknown_types):\n","        count = content_type_counts[content_type]\n","        print(f\"  '{content_type}' - {count} occurrences\")\n","\n","    print(f\"\\nTotal unknown types: {len(unknown_types)}\")\n","    print(f\"Total points with unknown types: {sum(content_type_counts[ct] for ct in unknown_types)}\")\n","else:\n","    print(\"\\n‚úì All content types are known and mapped!\")\n","\n","print(\"\\n\" + \"=\" * 70)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eP7IjxTKb-r-","executionInfo":{"status":"ok","timestamp":1762235782753,"user_tz":-330,"elapsed":3101,"user":{"displayName":"Rahul Siddhu","userId":"12007764243202946991"}},"outputId":"4f9156d3-d06d-4ec6-aebb-c7799baac9ed"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["======================================================================\n","Analyzing ALL content_type values in collection...\n","======================================================================\n","Processed 500 points...\n","\n","‚úì Analysis complete! Processed 726 points\n","Points with no content_type: 0\n","Unique content_type values found: 14\n","\n","======================================================================\n","ALL Content Types (sorted by frequency):\n","======================================================================\n","‚ö†Ô∏è  UNKNOWN  | NIRF_Ranking                   | Count:   102 ( 14.0%)\n","‚úì KNOWN      | FINANCIAL_RESOURCES            | Count:   100 ( 13.8%)\n","‚úì KNOWN      | HEADER                         | Count:    50 (  6.9%)\n","‚úì KNOWN      | PLACEMENT_STUDIES              | Count:    50 (  6.9%)\n","‚úì KNOWN      | SPONSORED_RESEARCH             | Count:    50 (  6.9%)\n","‚úì KNOWN      | PCS_FACILITIES                 | Count:    50 (  6.9%)\n","‚úì KNOWN      | PHD_DETAILS                    | Count:    50 (  6.9%)\n","‚úì KNOWN      | CONSULTANCY_PROJECTS           | Count:    50 (  6.9%)\n","‚úì KNOWN      | STUDENT_STRENGTH               | Count:    50 (  6.9%)\n","‚úì KNOWN      | students_strength              | Count:    50 (  6.9%)\n","‚úì KNOWN      | FACULTY_DETAILS                | Count:    50 (  6.9%)\n","‚úì KNOWN      | SANCTIONED_INTAKE              | Count:    50 (  6.9%)\n","‚úì KNOWN      | IPR                            | Count:    14 (  1.9%)\n","‚úì KNOWN      | PG_PLACEMENT                   | Count:    10 (  1.4%)\n","\n","======================================================================\n","UNKNOWN Content Types Summary:\n","======================================================================\n","  'NIRF_Ranking' - 102 occurrences\n","\n","Total unknown types: 1\n","Total points with unknown types: 102\n","\n","======================================================================\n"]}]},{"cell_type":"code","source":["from qdrant_client import QdrantClient\n","from pprint import pprint\n","\n","# Initialize Qdrant client\n","QDRANT_URL = \"https://b5651607-31ce-49ba-916d-c35c89d731d2.us-east4-0.gcp.cloud.qdrant.io\"\n","QDRANT_API_KEY = \"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJhY2Nlc3MiOiJtIn0.0ApHZL4Qn_A8bx7FCC62nx-IOrHI84W7GZlUZEyVgKk\"\n","collection_name = \"Nirf_Report\"\n","\n","client = QdrantClient(\n","    url=QDRANT_URL,\n","    api_key=QDRANT_API_KEY\n",")\n","\n","# Known content types\n","KNOWN_CONTENT_TYPES = {\n","    \"HEADER\", \"SANCTIONED_INTAKE\", \"STUDENT_STRENGTH\", \"students_strength\",\n","    \"FACULTY_DETAILS\", \"PCS_FACILITIES\", \"PHD_DETAILS\", \"SPONSORED_RESEARCH\",\n","    \"CONSULTANCY_PROJECTS\", \"FINANCIAL_RESOURCES\", \"PLACEMENT_STUDIES\",\n","    \"PG_PLACEMENT\", \"IPR\"\n","}\n","\n","print(\"=\" * 80)\n","print(\"Finding all points with UNKNOWN content_type...\")\n","print(\"=\" * 80)\n","\n","unknown_points = []\n","offset = None\n","batch_size = 100\n","total_processed = 0\n","\n","while True:\n","    records, next_offset = client.scroll(\n","        collection_name=collection_name,\n","        limit=batch_size,\n","        offset=offset,\n","        with_payload=True,\n","        with_vectors=False\n","    )\n","\n","    if not records:\n","        break\n","\n","    for record in records:\n","        total_processed += 1\n","        content_type = record.payload.get(\"content_type\")\n","\n","        if content_type and content_type not in KNOWN_CONTENT_TYPES:\n","            unknown_points.append({\n","                \"point_id\": record.id,\n","                \"content_type\": content_type,\n","                \"payload\": record.payload\n","            })\n","\n","    if next_offset is None:\n","        break\n","\n","    offset = next_offset\n","\n","print(f\"\\n‚úì Found {len(unknown_points)} points with unknown content_type\")\n","print(f\"Total points processed: {total_processed}\")\n","print(\"\\n\" + \"=\" * 80)\n","\n","# Display all unknown points\n","for i, point in enumerate(unknown_points, 1):\n","    print(f\"\\n{'='*80}\")\n","    print(f\"POINT #{i} of {len(unknown_points)}\")\n","    print(f\"{'='*80}\")\n","    print(f\"Point ID:      {point['point_id']}\")\n","    print(f\"Content Type:  {point['content_type']}\")\n","    print(f\"\\nFull Payload:\")\n","    print(\"-\" * 80)\n","\n","    # Display payload in a readable format\n","    for key, value in sorted(point['payload'].items()):\n","        if key == \"content\" or key == \"content_for_embedding\":\n","            # Truncate long content\n","            if isinstance(value, str) and len(value) > 200:\n","                print(f\"{key:25} : {value[:200]}... (truncated)\")\n","            else:\n","                print(f\"{key:25} : {value}\")\n","        else:\n","            print(f\"{key:25} : {value}\")\n","\n","    # Separator between points\n","    if i < len(unknown_points):\n","        print(\"\\n\" + \"‚îÄ\" * 80 + \"\\n\")\n","\n","print(\"\\n\" + \"=\" * 80)\n","print(\"SUMMARY\")\n","print(\"=\" * 80)\n","\n","# Group by content_type\n","from collections import defaultdict\n","by_content_type = defaultdict(list)\n","for point in unknown_points:\n","    by_content_type[point['content_type']].append(point['point_id'])\n","\n","print(f\"\\nUnknown content types found:\")\n","for content_type, point_ids in by_content_type.items():\n","    print(f\"\\n  '{content_type}': {len(point_ids)} points\")\n","    print(f\"    Sample IDs: {point_ids[:3]}\")\n","\n","print(\"\\n\" + \"=\" * 80)"],"metadata":{"id":"d6uW6KNwcc4_","executionInfo":{"status":"ok","timestamp":1762408277089,"user_tz":-330,"elapsed":3606,"user":{"displayName":"Rahul Siddhu","userId":"12007764243202946991"}},"outputId":"475a9a0f-6233-4213-f79b-69f224ff68e2","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["================================================================================\n","Finding all points with UNKNOWN content_type...\n","================================================================================\n","\n","‚úì Found 102 points with unknown content_type\n","Total points processed: 726\n","\n","================================================================================\n","\n","================================================================================\n","POINT #1 of 102\n","================================================================================\n","Point ID:      01a880d0-faa1-5d51-8d4e-5bc0b8fcb8b3\n","Content Type:  NIRF_Ranking\n","\n","Full Payload:\n","--------------------------------------------------------------------------------\n","category                  : Ranking_Metadata\n","city                      : Manipal\n","content                   : Institute: Manipal Institute of Technology, Rank: 59.0, City: Manipal, State: Karnataka\n","content_type              : NIRF_Ranking\n","data_source               : NIRF_Ranking_Table\n","institute_name            : Manipal Institute of Technology\n","processing_timestamp      : 2025-09-15T06:31:19.646999\n","rank                      : 59\n","state                     : Karnataka\n","\n","‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n","\n","\n","================================================================================\n","POINT #2 of 102\n","================================================================================\n","Point ID:      0a31c7e4-1921-5637-a3e1-a2a04c76b821\n","Content Type:  NIRF_Ranking\n","\n","Full Payload:\n","--------------------------------------------------------------------------------\n","category                  : Ranking_Metadata\n","city                      : Rourkela\n","content                   : Institute: National Institute of Technology Rourkela, Rank: 13.0, City: Rourkela, State: Odisha\n","content_type              : NIRF_Ranking\n","data_source               : NIRF_Ranking_Table\n","institute_name            : National Institute of Technology Rourkela\n","processing_timestamp      : 2025-09-15T06:31:19.639445\n","rank                      : 13\n","state                     : Odisha\n","\n","‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n","\n","\n","================================================================================\n","POINT #3 of 102\n","================================================================================\n","Point ID:      0be1c74c-dd8e-5a09-a539-63531c69dc75\n","Content Type:  NIRF_Ranking\n","\n","Full Payload:\n","--------------------------------------------------------------------------------\n","category                  : Ranking_Metadata\n","city                      : Howrah\n","content                   : Institute: Indian Institute of Engineering Science and Technology, Shibpur, Rank: 54.0, City: Howrah, State: West Bengal\n","content_type              : NIRF_Ranking\n","data_source               : NIRF_Ranking_Table\n","institute_name            : Indian Institute of Engineering Science and Technology, Shibpur\n","processing_timestamp      : 2025-09-15T06:31:19.646225\n","rank                      : 54\n","state                     : West Bengal\n","\n","‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n","\n","\n","================================================================================\n","POINT #4 of 102\n","================================================================================\n","Point ID:      10708f4d-9e71-5141-a07f-5753bf9a2a13\n","Content Type:  NIRF_Ranking\n","\n","Full Payload:\n","--------------------------------------------------------------------------------\n","category                  : Ranking_Metadata\n","city                      : Coimbatore\n","content                   : Institute: Sri Krishna College of Engineering and Technology, Rank: 100.0, City: Coimbatore, State: Tamil Nadu\n","content_type              : NIRF_Ranking\n","data_source               : NIRF_Ranking_Table\n","institute_name            : Sri Krishna College of Engineering and Technology\n","processing_timestamp      : 2025-09-15T06:31:19.653435\n","rank                      : 100\n","state                     : Tamil Nadu\n","\n","‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n","\n","\n","================================================================================\n","POINT #5 of 102\n","================================================================================\n","Point ID:      12a6df40-a765-52b1-85a5-e7d1307991f7\n","Content Type:  NIRF_Ranking\n","\n","Full Payload:\n","--------------------------------------------------------------------------------\n","category                  : Ranking_Metadata\n","city                      : Dharwad\n","content                   : Institute: Indian Institute of Technology Dharwad, Rank: 77.0, City: Dharwad, State: Karnataka\n","content_type              : NIRF_Ranking\n","data_source               : NIRF_Ranking_Table\n","institute_name            : Indian Institute of Technology Dharwad\n","processing_timestamp      : 2025-09-15T06:31:19.649851\n","rank                      : 77\n","state                     : Karnataka\n","\n","‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n","\n","\n","================================================================================\n","POINT #6 of 102\n","================================================================================\n","Point ID:      1423ca07-9cb0-5ee7-bd15-afb00f701cb4\n","Content Type:  NIRF_Ranking\n","\n","Full Payload:\n","--------------------------------------------------------------------------------\n","category                  : Ranking_Metadata\n","city                      : Mumbai\n","content                   : Institute: Institute of Chemical Technology, Rank: 41.0, City: Mumbai, State: Maharashtra\n","content_type              : NIRF_Ranking\n","data_source               : NIRF_Ranking_Table\n","institute_name            : Institute of Chemical Technology\n","processing_timestamp      : 2025-09-15T06:31:19.644131\n","rank                      : 41\n","state                     : Maharashtra\n","\n","‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n","\n","\n","================================================================================\n","POINT #7 of 102\n","================================================================================\n","Point ID:      18d25de2-9d0c-5573-9541-861a310af318\n","Content Type:  NIRF_Ranking\n","\n","Full Payload:\n","--------------------------------------------------------------------------------\n","category                  : Ranking_Metadata\n","city                      : Thanjavur\n","content                   : Institute: Shanmugha Arts Science Technology & Research Academy, Rank: 40.0, City: Thanjavur, State: Tamil Nadu\n","content_type              : NIRF_Ranking\n","data_source               : NIRF_Ranking_Table\n","institute_name            : Shanmugha Arts Science Technology & Research Academy\n","processing_timestamp      : 2025-09-15T06:31:19.643976\n","rank                      : 40\n","state                     : Tamil Nadu\n","\n","‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n","\n","\n","================================================================================\n","POINT #8 of 102\n","================================================================================\n","Point ID:      1cf05e1f-c1e3-57e3-a4ef-2fd474a871c2\n","Content Type:  NIRF_Ranking\n","\n","Full Payload:\n","--------------------------------------------------------------------------------\n","category                  : Ranking_Metadata\n","city                      : Aligarh\n","content                   : Institute: Aligarh Muslim University, Rank: 34.0, City: Aligarh, State: Uttar Pradesh\n","content_type              : NIRF_Ranking\n","data_source               : NIRF_Ranking_Table\n","institute_name            : Aligarh Muslim University\n","processing_timestamp      : 2025-09-15T06:31:19.643004\n","rank                      : 34\n","state                     : Uttar Pradesh\n","\n","‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n","\n","\n","================================================================================\n","POINT #9 of 102\n","================================================================================\n","Point ID:      239304c2-0db8-5e0e-87b3-cc31149e4cca\n","Content Type:  NIRF_Ranking\n","\n","Full Payload:\n","--------------------------------------------------------------------------------\n","category                  : Ranking_Metadata\n","city                      : Chennai\n","content                   : Institute: Vel Tech Rangarajan Dr. Sagunthala R & D Institute of Science and Technology, Rank: 87.0, City: Chennai, State: Tamil Nadu\n","content_type              : NIRF_Ranking\n","data_source               : NIRF_Ranking_Table\n","institute_name            : Vel Tech Rangarajan Dr. Sagunthala R & D Institute of Science and Technology\n","processing_timestamp      : 2025-09-15T06:31:19.651397\n","rank                      : 87\n","state                     : Tamil Nadu\n","\n","‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n","\n","\n","================================================================================\n","POINT #10 of 102\n","================================================================================\n","Point ID:      23b3d7f2-db61-550f-890d-277ea5649c9f\n","Content Type:  NIRF_Ranking\n","\n","Full Payload:\n","--------------------------------------------------------------------------------\n","category                  : Ranking_Metadata\n","city                      : Kurukshetra\n","content                   : Institute: National Institute of Technology Kurukshetra, Rank: 85.0, City: Kurukshetra, State: Haryana\n","content_type              : NIRF_Ranking\n","data_source               : NIRF_Ranking_Table\n","institute_name            : National Institute of Technology Kurukshetra\n","processing_timestamp      : 2025-09-15T06:31:19.651081\n","rank                      : 85\n","state                     : Haryana\n","\n","‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n","\n","\n","================================================================================\n","POINT #11 of 102\n","================================================================================\n","Point ID:      24547d74-eeb7-5e36-b602-170a9a1a64c6\n","Content Type:  NIRF_Ranking\n","\n","Full Payload:\n","--------------------------------------------------------------------------------\n","category                  : Ranking_Metadata\n","city                      : Bengaluru\n","content                   : Institute: International Institute of Information Technology Bangalore, Rank: 69.0, City: Bengaluru, State: Karnataka\n","content_type              : NIRF_Ranking\n","data_source               : NIRF_Ranking_Table\n","institute_name            : International Institute of Information Technology Bangalore\n","processing_timestamp      : 2025-09-15T06:31:19.648548\n","rank                      : 69\n","state                     : Karnataka\n","\n","‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n","\n","\n","================================================================================\n","POINT #12 of 102\n","================================================================================\n","Point ID:      26c81b76-7026-5d69-9974-9ba346ae33f6\n","Content Type:  NIRF_Ranking\n","\n","Full Payload:\n","--------------------------------------------------------------------------------\n","category                  : Ranking_Metadata\n","city                      : Rupnagar\n","content                   : Institute: Indian Institute of Technology Ropar, Rank: 32.0, City: Rupnagar, State: Punjab\n","content_type              : NIRF_Ranking\n","data_source               : NIRF_Ranking_Table\n","institute_name            : Indian Institute of Technology Ropar\n","processing_timestamp      : 2025-09-15T06:31:19.642638\n","rank                      : 32\n","state                     : Punjab\n","\n","‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n","\n","\n","================================================================================\n","POINT #13 of 102\n","================================================================================\n","Point ID:      28442e73-7203-5520-9258-4fca28007f94\n","Content Type:  NIRF_Ranking\n","\n","Full Payload:\n","--------------------------------------------------------------------------------\n","category                  : Ranking_Metadata\n","city                      : Warangal\n","content                   : Institute: SR University, Rank: 91.0, City: Warangal, State: Telangana\n","content_type              : NIRF_Ranking\n","data_source               : NIRF_Ranking_Table\n","institute_name            : SR University\n","processing_timestamp      : 2025-09-15T06:31:19.652026\n","rank                      : 91\n","state                     : Telangana\n","\n","‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n","\n","\n","================================================================================\n","POINT #14 of 102\n","================================================================================\n","Point ID:      287fb219-8da4-51d2-9f87-bc0d2ee049b6\n","Content Type:  NIRF_Ranking\n","\n","Full Payload:\n","--------------------------------------------------------------------------------\n","category                  : Ranking_Metadata\n","city                      : Bhubaneswar\n","content                   : Institute: Indian Institute of Technology Bhubaneswar, Rank: 39.0, City: Bhubaneswar, State: Odisha\n","content_type              : NIRF_Ranking\n","data_source               : NIRF_Ranking_Table\n","institute_name            : Indian Institute of Technology Bhubaneswar\n","processing_timestamp      : 2025-09-15T06:31:19.643813\n","rank                      : 39\n","state                     : Odisha\n","\n","‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n","\n","\n","================================================================================\n","POINT #15 of 102\n","================================================================================\n","Point ID:      28e6745e-938e-53a9-bb52-ba8696c4c86b\n","Content Type:  NIRF_Ranking\n","\n","Full Payload:\n","--------------------------------------------------------------------------------\n","category                  : Ranking_Metadata\n","city                      : Hyderabad\n","content                   : Institute: International Institute of Information Technology Hyderabad, Rank: 38.0, City: Hyderabad, State: Telangana\n","content_type              : NIRF_Ranking\n","data_source               : NIRF_Ranking_Table\n","institute_name            : International Institute of Information Technology Hyderabad\n","processing_timestamp      : 2025-09-15T06:31:19.643640\n","rank                      : 38\n","state                     : Telangana\n","\n","‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n","\n","\n","================================================================================\n","POINT #16 of 102\n","================================================================================\n","Point ID:      2a460abe-0065-524b-a975-149a607288da\n","Content Type:  NIRF_Ranking\n","\n","Full Payload:\n","--------------------------------------------------------------------------------\n","category                  : Ranking_Metadata\n","city                      : New Delhi\n","content                   : Institute: Indian Institute of Technology Delhi, Rank: 2.0, City: New Delhi, State: Delhi\n","content_type              : NIRF_Ranking\n","data_source               : NIRF_Ranking_Table\n","institute_name            : Indian Institute of Technology Delhi\n","processing_timestamp      : 2025-09-15T06:31:19.637565\n","rank                      : 2\n","state                     : Delhi\n","\n","‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n","\n","\n","================================================================================\n","POINT #17 of 102\n","================================================================================\n","Point ID:      32c9524d-68f0-555d-a815-55f3507ac285\n","Content Type:  NIRF_Ranking\n","\n","Full Payload:\n","--------------------------------------------------------------------------------\n","category                  : Ranking_Metadata\n","city                      : Gandhinagar\n","content                   : Institute: Pandit Deendayal Energy University, Rank: 98.0, City: Gandhinagar, State: Gujarat\n","content_type              : NIRF_Ranking\n","data_source               : NIRF_Ranking_Table\n","institute_name            : Pandit Deendayal Energy University\n","processing_timestamp      : 2025-09-15T06:31:19.653078\n","rank                      : 98\n","state                     : Gujarat\n","\n","‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n","\n","\n","================================================================================\n","POINT #18 of 102\n","================================================================================\n","Point ID:      3303914d-e396-55f1-abe8-1876d775a43a\n","Content Type:  NIRF_Ranking\n","\n","Full Payload:\n","--------------------------------------------------------------------------------\n","category                  : Ranking_Metadata\n","city                      : Palakkad\n","content                   : Institute: Indian Institute of Technology Palakkad, Rank: 64.0, City: Palakkad, State: Kerala\n","content_type              : NIRF_Ranking\n","data_source               : NIRF_Ranking_Table\n","institute_name            : Indian Institute of Technology Palakkad\n","processing_timestamp      : 2025-09-15T06:31:19.647759\n","rank                      : 64\n","state                     : Kerala\n","\n","‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n","\n","\n","================================================================================\n","POINT #19 of 102\n","================================================================================\n","Point ID:      33ae3839-84a7-559c-b2ad-c89add13775c\n","Content Type:  NIRF_Ranking\n","\n","Full Payload:\n","--------------------------------------------------------------------------------\n","category                  : Ranking_Metadata\n","city                      : Thiruvananthapuram\n","content                   : Institute: Indian Institute of Space Science and Technology, Rank: 61.0, City: Thiruvananthapuram, State: Kerala\n","content_type              : NIRF_Ranking\n","data_source               : NIRF_Ranking_Table\n","institute_name            : Indian Institute of Space Science and Technology\n","processing_timestamp      : 2025-09-15T06:31:19.647304\n","rank                      : 61\n","state                     : Kerala\n","\n","‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n","\n","\n","================================================================================\n","POINT #20 of 102\n","================================================================================\n","Point ID:      3440bc7c-c57b-5bed-95a7-ce5c295861cd\n","Content Type:  NIRF_Ranking\n","\n","Full Payload:\n","--------------------------------------------------------------------------------\n","category                  : Ranking_Metadata\n","city                      : Chennai\n","content                   : Institute: Anna University, Rank: 20.0, City: Chennai, State: Tamil Nadu\n","content_type              : NIRF_Ranking\n","data_source               : NIRF_Ranking_Table\n","institute_name            : Anna University\n","processing_timestamp      : 2025-09-15T06:31:19.640575\n","rank                      : 20\n","state                     : Tamil Nadu\n","\n","‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n","\n","\n","================================================================================\n","POINT #21 of 102\n","================================================================================\n","Point ID:      35f99f61-3875-58f7-a58e-99c241463132\n","Content Type:  NIRF_Ranking\n","\n","Full Payload:\n","--------------------------------------------------------------------------------\n","category                  : Ranking_Metadata\n","city                      : Vaddeswaram\n","content                   : Institute: Koneru Lakshmaiah Education Foundation University (K L College of Engineering), Rank: 35.0, City: Vaddeswaram, State: Andhra Pradesh\n","content_type              : NIRF_Ranking\n","data_source               : NIRF_Ranking_Table\n","institute_name            : Koneru Lakshmaiah Education Foundation University (K L College of Engineering)\n","processing_timestamp      : 2025-09-15T06:31:19.643170\n","rank                      : 35\n","state                     : Andhra Pradesh\n","\n","‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n","\n","\n","================================================================================\n","POINT #22 of 102\n","================================================================================\n","Point ID:      3adb6063-3c36-5a3e-9559-383cfa6f23f3\n","Content Type:  NIRF_Ranking\n","\n","Full Payload:\n","--------------------------------------------------------------------------------\n","category                  : Ranking_Metadata\n","city                      : Mohali\n","content                   : Institute: Chandigarh University, Rank: 31.0, City: Mohali, State: Punjab\n","content_type              : NIRF_Ranking\n","data_source               : NIRF_Ranking_Table\n","institute_name            : Chandigarh University\n","processing_timestamp      : 2025-09-15T06:31:19.642487\n","rank                      : 31\n","state                     : Punjab\n","\n","‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n","\n","\n","================================================================================\n","POINT #23 of 102\n","================================================================================\n","Point ID:      3c40fc53-fa80-5763-bc5a-104a633e4462\n","Content Type:  NIRF_Ranking\n","\n","Full Payload:\n","--------------------------------------------------------------------------------\n","category                  : Ranking_Metadata\n","city                      : Kozhikode\n","content                   : Institute: National Institute of Technology Calicut, Rank: 21.0, City: Kozhikode, State: Kerala\n","content_type              : NIRF_Ranking\n","data_source               : NIRF_Ranking_Table\n","institute_name            : National Institute of Technology Calicut\n","processing_timestamp      : 2025-09-15T06:31:19.640762\n","rank                      : 21\n","state                     : Kerala\n","\n","‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n","\n","\n","================================================================================\n","POINT #24 of 102\n","================================================================================\n","Point ID:      413f86dd-bdaa-57f2-8aff-331509c3c943\n","Content Type:  NIRF_Ranking\n","\n","Full Payload:\n","--------------------------------------------------------------------------------\n","category                  : Ranking_Metadata\n","city                      : Jamshedpur\n","content                   : Institute: National Institute of Technology, Jamshedpur, Rank: 82.0, City: Jamshedpur, State: Jharkhand\n","content_type              : NIRF_Ranking\n","data_source               : NIRF_Ranking_Table\n","institute_name            : National Institute of Technology, Jamshedpur\n","processing_timestamp      : 2025-09-15T06:31:19.650618\n","rank                      : 82\n","state                     : Jharkhand\n","\n","‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n","\n","\n","================================================================================\n","POINT #25 of 102\n","================================================================================\n","Point ID:      42537e3c-64e9-5146-a21b-7e09682af2d1\n","Content Type:  NIRF_Ranking\n","\n","Full Payload:\n","--------------------------------------------------------------------------------\n","category                  : Ranking_Metadata\n","city                      : Gwalior\n","content                   : Institute: Atal Bihari Vajpayee Indian Institute of Information Technology and Management, Rank: 96.0, City: Gwalior, State: Madhya Pradesh\n","content_type              : NIRF_Ranking\n","data_source               : NIRF_Ranking_Table\n","institute_name            : Atal Bihari Vajpayee Indian Institute of Information Technology and Management\n","processing_timestamp      : 2025-09-15T06:31:19.652780\n","rank                      : 96\n","state                     : Madhya Pradesh\n","\n","‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n","\n","\n","================================================================================\n","POINT #26 of 102\n","================================================================================\n","Point ID:      43f2428d-2147-5864-80fe-d487c742fe32\n","Content Type:  NIRF_Ranking\n","\n","Full Payload:\n","--------------------------------------------------------------------------------\n","category                  : Ranking_Metadata\n","city                      : Dhanbad\n","content                   : Institute: Indian Institute of Technology (Indian School of Mines), Rank: 15.0, City: Dhanbad, State: Jharkhand\n","content_type              : NIRF_Ranking\n","data_source               : NIRF_Ranking_Table\n","institute_name            : Indian Institute of Technology (Indian School of Mines)\n","processing_timestamp      : 2025-09-15T06:31:19.639787\n","rank                      : 15\n","state                     : Jharkhand\n","\n","‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n","\n","\n","================================================================================\n","POINT #27 of 102\n","================================================================================\n","Point ID:      44df2ed7-5403-5fcb-8e83-21927870545b\n","Content Type:  NIRF_Ranking\n","\n","Full Payload:\n","--------------------------------------------------------------------------------\n","category                  : Ranking_Metadata\n","city                      : Jalandhar\n","content                   : Institute: Dr. B R Ambedkar National Institute of Technology, Jalandhar, Rank: 55.0, City: Jalandhar, State: Punjab\n","content_type              : NIRF_Ranking\n","data_source               : NIRF_Ranking_Table\n","institute_name            : Dr. B R Ambedkar National Institute of Technology, Jalandhar\n","processing_timestamp      : 2025-09-15T06:31:19.646385\n","rank                      : 55\n","state                     : Punjab\n","\n","‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n","\n","\n","================================================================================\n","POINT #28 of 102\n","================================================================================\n","Point ID:      45b56892-2fe9-535d-8824-7b4453158275\n","Content Type:  NIRF_Ranking\n","\n","Full Payload:\n","--------------------------------------------------------------------------------\n","category                  : Ranking_Metadata\n","city                      : Bhubaneswar\n","content                   : Institute: C.V. Raman Global University, Odisha, Rank: 95.0, City: Bhubaneswar, State: Odisha\n","content_type              : NIRF_Ranking\n","data_source               : NIRF_Ranking_Table\n","institute_name            : C.V. Raman Global University, Odisha\n","processing_timestamp      : 2025-09-15T06:31:19.652618\n","rank                      : 95\n","state                     : Odisha\n","\n","‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n","\n","\n","================================================================================\n","POINT #29 of 102\n","================================================================================\n","Point ID:      4861d64a-fbc3-58f6-9033-d646d989645d\n","Content Type:  NIRF_Ranking\n","\n","Full Payload:\n","--------------------------------------------------------------------------------\n","category                  : Ranking_Metadata\n","city                      : Tirupati\n","content                   : Institute: Indian Institute of Technology, Tirupati, Rank: 57.0, City: Tirupati, State: Andhra Pradesh\n","content_type              : NIRF_Ranking\n","data_source               : NIRF_Ranking_Table\n","institute_name            : Indian Institute of Technology, Tirupati\n","processing_timestamp      : 2025-09-15T06:31:19.646678\n","rank                      : 57\n","state                     : Andhra Pradesh\n","\n","‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n","\n","\n","================================================================================\n","POINT #30 of 102\n","================================================================================\n","Point ID:      4afe74b6-0981-5548-bd2f-76df762151b3\n","Content Type:  NIRF_Ranking\n","\n","Full Payload:\n","--------------------------------------------------------------------------------\n","category                  : Ranking_Metadata\n","city                      : Bhubaneswar\n","content                   : Institute: Siksha `O` Anusandhan, Rank: 22.0, City: Bhubaneswar, State: Odisha\n","content_type              : NIRF_Ranking\n","data_source               : NIRF_Ranking_Table\n","institute_name            : Siksha `O` Anusandhan\n","processing_timestamp      : 2025-09-15T06:31:19.640978\n","rank                      : 22\n","state                     : Odisha\n","\n","‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n","\n","\n","================================================================================\n","POINT #31 of 102\n","================================================================================\n","Point ID:      4d702226-ed84-5b83-9230-7c4e4dc540df\n","Content Type:  NIRF_Ranking\n","\n","Full Payload:\n","--------------------------------------------------------------------------------\n","category                  : Ranking_Metadata\n","city                      : Bengaluru\n","content                   : Institute: M. S. Ramaiah Institute of Technology, Rank: 75.0, City: Bengaluru, State: Karnataka\n","content_type              : NIRF_Ranking\n","data_source               : NIRF_Ranking_Table\n","institute_name            : M. S. Ramaiah Institute of Technology\n","processing_timestamp      : 2025-09-15T06:31:19.649511\n","rank                      : 75\n","state                     : Karnataka\n","\n","‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n","\n","\n","================================================================================\n","POINT #32 of 102\n","================================================================================\n","Point ID:      527282af-ff9e-5be5-a928-458fe7f23b68\n","Content Type:  NIRF_Ranking\n","\n","Full Payload:\n","--------------------------------------------------------------------------------\n","category                  : Ranking_Metadata\n","city                      : Dehradun\n","content                   : Institute: UPES, Rank: 43.0, City: Dehradun, State: Uttarakhand\n","content_type              : NIRF_Ranking\n","data_source               : NIRF_Ranking_Table\n","institute_name            : UPES\n","processing_timestamp      : 2025-09-15T06:31:19.644469\n","rank                      : 43\n","state                     : Uttarakhand\n","\n","‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n","\n","\n","================================================================================\n","POINT #33 of 102\n","================================================================================\n","Point ID:      5d564a97-d647-5741-bbe0-25abcc6a866a\n","Content Type:  NIRF_Ranking\n","\n","Full Payload:\n","--------------------------------------------------------------------------------\n","category                  : Ranking_Metadata\n","city                      : Delhi\n","content                   : Institute: Netaji Subhas University of Technology (NSUT), Rank: 70.0, City: Delhi, State: Delhi\n","content_type              : NIRF_Ranking\n","data_source               : NIRF_Ranking_Table\n","institute_name            : Netaji Subhas University of Technology (NSUT)\n","processing_timestamp      : 2025-09-15T06:31:19.648696\n","rank                      : 70\n","state                     : Delhi\n","\n","‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n","\n","\n","================================================================================\n","POINT #34 of 102\n","================================================================================\n","Point ID:      62e0ea5b-d6ad-54bb-866c-64c224fb6022\n","Content Type:  NIRF_Ranking\n","\n","Full Payload:\n","--------------------------------------------------------------------------------\n","category                  : Ranking_Metadata\n","city                      : Warangal\n","content                   : Institute: National Institute of Technology Warangal, Rank: 28.0, City: Warangal, State: Telangana\n","content_type              : NIRF_Ranking\n","data_source               : NIRF_Ranking_Table\n","institute_name            : National Institute of Technology Warangal\n","processing_timestamp      : 2025-09-15T06:31:19.642001\n","rank                      : 28\n","state                     : Telangana\n","\n","‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n","\n","\n","================================================================================\n","POINT #35 of 102\n","================================================================================\n","Point ID:      63a0fb61-e3aa-5551-90ba-414e27920e2a\n","Content Type:  NIRF_Ranking\n","\n","Full Payload:\n","--------------------------------------------------------------------------------\n","category                  : Ranking_Metadata\n","city                      : Prayagraj\n","content                   : Institute: Motilal Nehru National Institute of Technology, Rank: 62.0, City: Prayagraj, State: Uttar Pradesh\n","content_type              : NIRF_Ranking\n","data_source               : NIRF_Ranking_Table\n","institute_name            : Motilal Nehru National Institute of Technology\n","processing_timestamp      : 2025-09-15T06:31:19.647454\n","rank                      : 62\n","state                     : Uttar Pradesh\n","\n","‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n","\n","\n","================================================================================\n","POINT #36 of 102\n","================================================================================\n","Point ID:      69704957-2760-5d56-a2e1-f859c0862d30\n","Content Type:  NIRF_Ranking\n","\n","Full Payload:\n","--------------------------------------------------------------------------------\n","category                  : Ranking_Metadata\n","city                      : Raipur\n","content                   : Institute: National Institute of Technology, Raipur, Rank: 86.0, City: Raipur, State: Chhattisgarh\n","content_type              : NIRF_Ranking\n","data_source               : NIRF_Ranking_Table\n","institute_name            : National Institute of Technology, Raipur\n","processing_timestamp      : 2025-09-15T06:31:19.651230\n","rank                      : 86\n","state                     : Chhattisgarh\n","\n","‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n","\n","\n","================================================================================\n","POINT #37 of 102\n","================================================================================\n","Point ID:      6a0dd05e-e444-5873-8ebb-9b645aa13aac\n","Content Type:  NIRF_Ranking\n","\n","Full Payload:\n","--------------------------------------------------------------------------------\n","category                  : Ranking_Metadata\n","city                      : Gorakhpur\n","content                   : Institute: Madan Mohan Malaviya University of Technology, Rank: 60.0, City: Gorakhpur, State: Uttar Pradesh\n","content_type              : NIRF_Ranking\n","data_source               : NIRF_Ranking_Table\n","institute_name            : Madan Mohan Malaviya University of Technology\n","processing_timestamp      : 2025-09-15T06:31:19.647151\n","rank                      : 60\n","state                     : Uttar Pradesh\n","\n","‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n","\n","\n","================================================================================\n","POINT #38 of 102\n","================================================================================\n","Point ID:      6caebc93-60c7-51c6-b657-b236cc351f23\n","Content Type:  NIRF_Ranking\n","\n","Full Payload:\n","--------------------------------------------------------------------------------\n","category                  : Ranking_Metadata\n","city                      : Bhopal\n","content                   : Institute: Maulana Azad National Institute of Technology, Rank: 81.0, City: Bhopal, State: Madhya Pradesh\n","content_type              : NIRF_Ranking\n","data_source               : NIRF_Ranking_Table\n","institute_name            : Maulana Azad National Institute of Technology\n","processing_timestamp      : 2025-09-15T06:31:19.650470\n","rank                      : 81\n","state                     : Madhya Pradesh\n","\n","‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n","\n","\n","================================================================================\n","POINT #39 of 102\n","================================================================================\n","Point ID:      6d7826b1-34ad-5322-9733-51acd5c40375\n","Content Type:  NIRF_Ranking\n","\n","Full Payload:\n","--------------------------------------------------------------------------------\n","category                  : Ranking_Metadata\n","city                      : Chennai\n","content                   : Institute: Saveetha Institute of Medical and Technical Sciences, Rank: 45.0, City: Chennai, State: Tamil Nadu\n","content_type              : NIRF_Ranking\n","data_source               : NIRF_Ranking_Table\n","institute_name            : Saveetha Institute of Medical and Technical Sciences\n","processing_timestamp      : 2025-09-15T06:31:19.644816\n","rank                      : 45\n","state                     : Tamil Nadu\n","\n","‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n","\n","\n","================================================================================\n","POINT #40 of 102\n","================================================================================\n","Point ID:      6f70cbe2-9005-5c43-b415-5804f44e11ee\n","Content Type:  NIRF_Ranking\n","\n","Full Payload:\n","--------------------------------------------------------------------------------\n","category                  : Ranking_Metadata\n","city                      : Srinagar\n","content                   : Institute: National Institute of Technology Srinagar, Rank: 73.0, City: Srinagar, State: Jammu and Kashmir\n","content_type              : NIRF_Ranking\n","data_source               : NIRF_Ranking_Table\n","institute_name            : National Institute of Technology Srinagar\n","processing_timestamp      : 2025-09-15T06:31:19.649205\n","rank                      : 73\n","state                     : Jammu and Kashmir\n","\n","‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n","\n","\n","================================================================================\n","POINT #41 of 102\n","================================================================================\n","Point ID:      705c07c2-46bc-509e-886e-9ff989a9a4fc\n","Content Type:  NIRF_Ranking\n","\n","Full Payload:\n","--------------------------------------------------------------------------------\n","category                  : Ranking_Metadata\n","city                      : Amethi\n","content                   : Institute: Rajiv Gandhi Institute of Petroleum Technology, Rank: 78.0, City: Amethi, State: Uttar Pradesh\n","content_type              : NIRF_Ranking\n","data_source               : NIRF_Ranking_Table\n","institute_name            : Rajiv Gandhi Institute of Petroleum Technology\n","processing_timestamp      : 2025-09-15T06:31:19.650003\n","rank                      : 78\n","state                     : Uttar Pradesh\n","\n","‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n","\n","\n","================================================================================\n","POINT #42 of 102\n","================================================================================\n","Point ID:      73a37490-e98d-5836-b3ee-6080abbe6f76\n","Content Type:  NIRF_Ranking\n","\n","Full Payload:\n","--------------------------------------------------------------------------------\n","category                  : Ranking_Metadata\n","city                      : Mandi\n","content                   : Institute: Indian Institute of Technology Mandi, Rank: 26.0, City: Mandi, State: Himachal Pradesh\n","content_type              : NIRF_Ranking\n","data_source               : NIRF_Ranking_Table\n","institute_name            : Indian Institute of Technology Mandi\n","processing_timestamp      : 2025-09-15T06:31:19.641634\n","rank                      : 26\n","state                     : Himachal Pradesh\n","\n","‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n","\n","\n","================================================================================\n","POINT #43 of 102\n","================================================================================\n","Point ID:      75e42a5b-8320-55ea-b249-0e829a8727f7\n","Content Type:  NIRF_Ranking\n","\n","Full Payload:\n","--------------------------------------------------------------------------------\n","category                  : Ranking_Metadata\n","city                      : Chandigarh\n","content                   : Institute: Panjab University, Rank: 93.0, City: Chandigarh, State: Chandigarh\n","content_type              : NIRF_Ranking\n","data_source               : NIRF_Ranking_Table\n","institute_name            : Panjab University\n","processing_timestamp      : 2025-09-15T06:31:19.652324\n","rank                      : 93\n","state                     : Chandigarh\n","\n","‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n","\n","\n","================================================================================\n","POINT #44 of 102\n","================================================================================\n","Point ID:      77aef6a1-16c5-50dc-9c1f-f78ddaad2ed1\n","Content Type:  NIRF_Ranking\n","\n","Full Payload:\n","--------------------------------------------------------------------------------\n","category                  : Ranking_Metadata\n","city                      : Bhubaneswar\n","content                   : Institute: Kalinga Institute of Industrial Technology, Rank: 36.0, City: Bhubaneswar, State: Odisha\n","content_type              : NIRF_Ranking\n","data_source               : NIRF_Ranking_Table\n","institute_name            : Kalinga Institute of Industrial Technology\n","processing_timestamp      : 2025-09-15T06:31:19.643330\n","rank                      : 36\n","state                     : Odisha\n","\n","‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n","\n","\n","================================================================================\n","POINT #45 of 102\n","================================================================================\n","Point ID:      807807ee-4386-5d8f-b959-f7121842f87f\n","Content Type:  NIRF_Ranking\n","\n","Full Payload:\n","--------------------------------------------------------------------------------\n","category                  : Ranking_Metadata\n","city                      : nan\n","content                   : Institute: nan, Rank: nan, City: nan, State: nan\n","content_type              : NIRF_Ranking\n","data_source               : NIRF_Ranking_Table\n","institute_name            : nan\n","processing_timestamp      : 2025-09-15T06:31:19.637148\n","rank                      : None\n","state                     : nan\n","\n","‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n","\n","\n","================================================================================\n","POINT #46 of 102\n","================================================================================\n","Point ID:      80beb887-ed98-5568-aa72-d5e523df1256\n","Content Type:  NIRF_Ranking\n","\n","Full Payload:\n","--------------------------------------------------------------------------------\n","category                  : Ranking_Metadata\n","city                      : Jaipur\n","content                   : Institute: Malaviya National Institute of Technology, Rank: 42.0, City: Jaipur, State: Rajasthan\n","content_type              : NIRF_Ranking\n","data_source               : NIRF_Ranking_Table\n","institute_name            : Malaviya National Institute of Technology\n","processing_timestamp      : 2025-09-15T06:31:19.644293\n","rank                      : 42\n","state                     : Rajasthan\n","\n","‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n","\n","\n","================================================================================\n","POINT #47 of 102\n","================================================================================\n","Point ID:      810f66c6-0560-583c-847b-218b763dd992\n","Content Type:  NIRF_Ranking\n","\n","Full Payload:\n","--------------------------------------------------------------------------------\n","category                  : Ranking_Metadata\n","city                      : Guwahati\n","content                   : Institute: Indian Institute of Technology Guwahati, Rank: 8.0, City: Guwahati, State: Assam\n","content_type              : NIRF_Ranking\n","data_source               : NIRF_Ranking_Table\n","institute_name            : Indian Institute of Technology Guwahati\n","processing_timestamp      : 2025-09-15T06:31:19.638609\n","rank                      : 8\n","state                     : Assam\n","\n","‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n","\n","\n","================================================================================\n","POINT #48 of 102\n","================================================================================\n","Point ID:      8205cf53-37a1-59bf-b58a-06e9a97a582a\n","Content Type:  NIRF_Ranking\n","\n","Full Payload:\n","--------------------------------------------------------------------------------\n","category                  : Ranking_Metadata\n","city                      : New Delhi\n","content                   : Institute: Delhi Technological University, Rank: 30.0, City: New Delhi, State: Delhi\n","content_type              : NIRF_Ranking\n","data_source               : NIRF_Ranking_Table\n","institute_name            : Delhi Technological University\n","processing_timestamp      : 2025-09-15T06:31:19.642328\n","rank                      : 30\n","state                     : Delhi\n","\n","‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n","\n","\n","================================================================================\n","POINT #49 of 102\n","================================================================================\n","Point ID:      8735b1e1-a9d6-53ed-a9e7-a6ed4fbcf351\n","Content Type:  NIRF_Ranking\n","\n","Full Payload:\n","--------------------------------------------------------------------------------\n","category                  : Ranking_Metadata\n","city                      : Bengaluru\n","content                   : Institute: Jain university,Bangalore, Rank: 84.0, City: Bengaluru, State: Karnataka\n","content_type              : NIRF_Ranking\n","data_source               : NIRF_Ranking_Table\n","institute_name            : Jain university,Bangalore\n","processing_timestamp      : 2025-09-15T06:31:19.650935\n","rank                      : 84\n","state                     : Karnataka\n","\n","‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n","\n","\n","================================================================================\n","POINT #50 of 102\n","================================================================================\n","Point ID:      8bac57ca-61cb-5075-9079-c2490777a832\n","Content Type:  NIRF_Ranking\n","\n","Full Payload:\n","--------------------------------------------------------------------------------\n","category                  : Ranking_Metadata\n","city                      : Kanpur\n","content                   : Institute: Indian Institute of Technology Kanpur, Rank: 4.0, City: Kanpur, State: Uttar Pradesh\n","content_type              : NIRF_Ranking\n","data_source               : NIRF_Ranking_Table\n","institute_name            : Indian Institute of Technology Kanpur\n","processing_timestamp      : 2025-09-15T06:31:19.637954\n","rank                      : 4\n","state                     : Uttar Pradesh\n","\n","‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n","\n","\n","================================================================================\n","POINT #51 of 102\n","================================================================================\n","Point ID:      8ceb87ba-1cbc-59d2-941d-8a32aaada660\n","Content Type:  NIRF_Ranking\n","\n","Full Payload:\n","--------------------------------------------------------------------------------\n","category                  : Ranking_Metadata\n","city                      : Silchar\n","content                   : Institute: National Institute of Technology Silchar, Rank: 50.0, City: Silchar, State: Assam\n","content_type              : NIRF_Ranking\n","data_source               : NIRF_Ranking_Table\n","institute_name            : National Institute of Technology Silchar\n","processing_timestamp      : 2025-09-15T06:31:19.645597\n","rank                      : 50\n","state                     : Assam\n","\n","‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n","\n","\n","================================================================================\n","POINT #52 of 102\n","================================================================================\n","Point ID:      9031d247-81a5-5202-ab11-1cb01d182f02\n","Content Type:  NIRF_Ranking\n","\n","Full Payload:\n","--------------------------------------------------------------------------------\n","category                  : Ranking_Metadata\n","city                      : Mumbai\n","content                   : Institute: Indian Institute of Technology Bombay, Rank: 3.0, City: Mumbai, State: Maharashtra\n","content_type              : NIRF_Ranking\n","data_source               : NIRF_Ranking_Table\n","institute_name            : Indian Institute of Technology Bombay\n","processing_timestamp      : 2025-09-15T06:31:19.637782\n","rank                      : 3\n","state                     : Maharashtra\n","\n","‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n","\n","\n","================================================================================\n","POINT #53 of 102\n","================================================================================\n","Point ID:      911cbbbc-3dd8-59ec-a7a1-092c26c724d2\n","Content Type:  NIRF_Ranking\n","\n","Full Payload:\n","--------------------------------------------------------------------------------\n","category                  : Ranking_Metadata\n","city                      : Chennai\n","content                   : Institute: Sathyabama Institute of Science and Technology, Rank: 67.0, City: Chennai, State: Tamil Nadu\n","content_type              : NIRF_Ranking\n","data_source               : NIRF_Ranking_Table\n","institute_name            : Sathyabama Institute of Science and Technology\n","processing_timestamp      : 2025-09-15T06:31:19.648398\n","rank                      : 67\n","state                     : Tamil Nadu\n","\n","‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n","\n","\n","================================================================================\n","POINT #54 of 102\n","================================================================================\n","Point ID:      93e55ad0-87fe-5a1a-bcdc-bb416262edf6\n","Content Type:  NIRF_Ranking\n","\n","Full Payload:\n","--------------------------------------------------------------------------------\n","category                  : Ranking_Metadata\n","city                      : Hyderabad\n","content                   : Institute: Indian Institute of Technology Hyderabad, Rank: 7.0, City: Hyderabad, State: Telangana\n","content_type              : NIRF_Ranking\n","data_source               : NIRF_Ranking_Table\n","institute_name            : Indian Institute of Technology Hyderabad\n","processing_timestamp      : 2025-09-15T06:31:19.638454\n","rank                      : 7\n","state                     : Telangana\n","\n","‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n","\n","\n","================================================================================\n","POINT #55 of 102\n","================================================================================\n","Point ID:      94cb2b92-1913-5c90-9924-0c0e78a280ff\n","Content Type:  NIRF_Ranking\n","\n","Full Payload:\n","--------------------------------------------------------------------------------\n","category                  : Ranking_Metadata\n","city                      : Jammu\n","content                   : Institute: Indian Institute of Technology Jammu, Rank: 56.0, City: Jammu, State: Jammu and Kashmir\n","content_type              : NIRF_Ranking\n","data_source               : NIRF_Ranking_Table\n","institute_name            : Indian Institute of Technology Jammu\n","processing_timestamp      : 2025-09-15T06:31:19.646533\n","rank                      : 56\n","state                     : Jammu and Kashmir\n","\n","‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n","\n","\n","================================================================================\n","POINT #56 of 102\n","================================================================================\n","Point ID:      94fabe6b-e36f-5447-b6a4-d2321f8ae9c0\n","Content Type:  NIRF_Ranking\n","\n","Full Payload:\n","--------------------------------------------------------------------------------\n","category                  : Ranking_Metadata\n","city                      : SURAT\n","content                   : Institute: Sardar Vallabhbhai National Institute of Technology, Rank: 66.0, City: SURAT, State: Gujarat\n","content_type              : NIRF_Ranking\n","data_source               : NIRF_Ranking_Table\n","institute_name            : Sardar Vallabhbhai National Institute of Technology\n","processing_timestamp      : 2025-09-15T06:31:19.648072\n","rank                      : 66\n","state                     : Gujarat\n","\n","‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n","\n","\n","================================================================================\n","POINT #57 of 102\n","================================================================================\n","Point ID:      957bd0b1-2875-5756-ab10-8163e697849a\n","Content Type:  NIRF_Ranking\n","\n","Full Payload:\n","--------------------------------------------------------------------------------\n","category                  : Ranking_Metadata\n","city                      : Surathkal\n","content                   : Institute: National Institute of Technology Karnataka, Surathkal, Rank: 17.0, City: Surathkal, State: Karnataka\n","content_type              : NIRF_Ranking\n","data_source               : NIRF_Ranking_Table\n","institute_name            : National Institute of Technology Karnataka, Surathkal\n","processing_timestamp      : 2025-09-15T06:31:19.640104\n","rank                      : 17\n","state                     : Karnataka\n","\n","‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n","\n","\n","================================================================================\n","POINT #58 of 102\n","================================================================================\n","Point ID:      96451d1d-3dda-5793-a909-45725678879d\n","Content Type:  NIRF_Ranking\n","\n","Full Payload:\n","--------------------------------------------------------------------------------\n","category                  : Ranking_Metadata\n","city                      : Shillong\n","content                   : Institute: National Institute of Technology Meghalaya, Rank: 83.0, City: Shillong, State: Meghalaya\n","content_type              : NIRF_Ranking\n","data_source               : NIRF_Ranking_Table\n","institute_name            : National Institute of Technology Meghalaya\n","processing_timestamp      : 2025-09-15T06:31:19.650781\n","rank                      : 83\n","state                     : Meghalaya\n","\n","‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n","\n","\n","================================================================================\n","POINT #59 of 102\n","================================================================================\n","Point ID:      96d2ffb3-27a0-5aa3-bb66-bdadd0247e6a\n","Content Type:  NIRF_Ranking\n","\n","Full Payload:\n","--------------------------------------------------------------------------------\n","category                  : Ranking_Metadata\n","city                      : Gandhinagar\n","content                   : Institute: Indian Institute of Technology Gandhinagar, Rank: 25.0, City: Gandhinagar, State: Gujarat\n","content_type              : NIRF_Ranking\n","data_source               : NIRF_Ranking_Table\n","institute_name            : Indian Institute of Technology Gandhinagar\n","processing_timestamp      : 2025-09-15T06:31:19.641475\n","rank                      : 25\n","state                     : Gujarat\n","\n","‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n","\n","\n","================================================================================\n","POINT #60 of 102\n","================================================================================\n","Point ID:      96ee2332-7d46-54f1-92f2-63496172cca8\n","Content Type:  NIRF_Ranking\n","\n","Full Payload:\n","--------------------------------------------------------------------------------\n","category                  : Ranking_Metadata\n","city                      : Nagpur\n","content                   : Institute: Visvesvaraya National Institute of Technology, Nagpur, Rank: 44.0, City: Nagpur, State: Maharashtra\n","content_type              : NIRF_Ranking\n","data_source               : NIRF_Ranking_Table\n","institute_name            : Visvesvaraya National Institute of Technology, Nagpur\n","processing_timestamp      : 2025-09-15T06:31:19.644630\n","rank                      : 44\n","state                     : Maharashtra\n","\n","‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n","\n","\n","================================================================================\n","POINT #61 of 102\n","================================================================================\n","Point ID:      9ca110bf-7f7e-5c98-9726-dc3cd4a6fb5e\n","Content Type:  NIRF_Ranking\n","\n","Full Payload:\n","--------------------------------------------------------------------------------\n","category                  : Ranking_Metadata\n","city                      : Chennai\n","content                   : Institute: Indian Institute of Technology Madras, Rank: 1.0, City: Chennai, State: Tamil Nadu\n","content_type              : NIRF_Ranking\n","data_source               : NIRF_Ranking_Table\n","institute_name            : Indian Institute of Technology Madras\n","processing_timestamp      : 2025-09-15T06:31:19.637372\n","rank                      : 1\n","state                     : Tamil Nadu\n","\n","‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n","\n","\n","================================================================================\n","POINT #62 of 102\n","================================================================================\n","Point ID:      9f4bd223-6ffe-58db-bf32-4d496fdf91d3\n","Content Type:  NIRF_Ranking\n","\n","Full Payload:\n","--------------------------------------------------------------------------------\n","category                  : Ranking_Metadata\n","city                      : Indore\n","content                   : Institute: Indian Institute of Technology Indore, Rank: 12.0, City: Indore, State: Madhya Pradesh\n","content_type              : NIRF_Ranking\n","data_source               : NIRF_Ranking_Table\n","institute_name            : Indian Institute of Technology Indore\n","processing_timestamp      : 2025-09-15T06:31:19.639284\n","rank                      : 12\n","state                     : Madhya Pradesh\n","\n","‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n","\n","\n","================================================================================\n","POINT #63 of 102\n","================================================================================\n","Point ID:      a4cf8ec0-68b9-5168-a296-6904fd5efcca\n","Content Type:  NIRF_Ranking\n","\n","Full Payload:\n","--------------------------------------------------------------------------------\n","category                  : Ranking_Metadata\n","city                      : Kolkata\n","content                   : Institute: Jadavpur University, Rank: 18.0, City: Kolkata, State: West Bengal\n","content_type              : NIRF_Ranking\n","data_source               : NIRF_Ranking_Table\n","institute_name            : Jadavpur University\n","processing_timestamp      : 2025-09-15T06:31:19.640254\n","rank                      : 18\n","state                     : West Bengal\n","\n","‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n","\n","\n","================================================================================\n","POINT #64 of 102\n","================================================================================\n","Point ID:      a58f0589-76d0-5f6a-90f2-9623db5c5991\n","Content Type:  NIRF_Ranking\n","\n","Full Payload:\n","--------------------------------------------------------------------------------\n","category                  : Ranking_Metadata\n","city                      : nan\n","content                   : Institute: nan, Rank: nan, City: nan, State: nan\n","content_type              : NIRF_Ranking\n","data_source               : NIRF_Ranking_Table\n","institute_name            : nan\n","processing_timestamp      : 2025-09-15T06:31:19.636860\n","rank                      : None\n","state                     : nan\n","\n","‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n","\n","\n","================================================================================\n","POINT #65 of 102\n","================================================================================\n","Point ID:      a65c1747-1e69-5b1f-867b-78ad7890665f\n","Content Type:  NIRF_Ranking\n","\n","Full Payload:\n","--------------------------------------------------------------------------------\n","category                  : Ranking_Metadata\n","city                      : Visakhapatnam\n","content                   : Institute: AU College of Engineering (A), Rank: 88.0, City: Visakhapatnam, State: Andhra Pradesh\n","content_type              : NIRF_Ranking\n","data_source               : NIRF_Ranking_Table\n","institute_name            : AU College of Engineering (A)\n","processing_timestamp      : 2025-09-15T06:31:19.651549\n","rank                      : 88\n","state                     : Andhra Pradesh\n","\n","‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n","\n","\n","================================================================================\n","POINT #66 of 102\n","================================================================================\n","Point ID:      acaa1f63-9da1-54da-9cac-3f6880fc1e5b\n","Content Type:  NIRF_Ranking\n","\n","Full Payload:\n","--------------------------------------------------------------------------------\n","category                  : Ranking_Metadata\n","city                      : Longowal\n","content                   : Institute: Sant Longowal Institute of Engineering & Technology, Rank: 79.0, City: Longowal, State: Punjab\n","content_type              : NIRF_Ranking\n","data_source               : NIRF_Ranking_Table\n","institute_name            : Sant Longowal Institute of Engineering & Technology\n","processing_timestamp      : 2025-09-15T06:31:19.650152\n","rank                      : 79\n","state                     : Punjab\n","\n","‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n","\n","\n","================================================================================\n","POINT #67 of 102\n","================================================================================\n","Point ID:      ada9e918-931d-5bd1-b6d8-5d1bcd3bef52\n","Content Type:  NIRF_Ranking\n","\n","Full Payload:\n","--------------------------------------------------------------------------------\n","category                  : Ranking_Metadata\n","city                      : Coimbatore\n","content                   : Institute: Amrita Vishwa Vidyapeetham, Rank: 23.0, City: Coimbatore, State: Tamil Nadu\n","content_type              : NIRF_Ranking\n","data_source               : NIRF_Ranking_Table\n","institute_name            : Amrita Vishwa Vidyapeetham\n","processing_timestamp      : 2025-09-15T06:31:19.641147\n","rank                      : 23\n","state                     : Tamil Nadu\n","\n","‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n","\n","\n","================================================================================\n","POINT #68 of 102\n","================================================================================\n","Point ID:      ae1d62ae-cd4b-5d05-a862-a94f41854058\n","Content Type:  NIRF_Ranking\n","\n","Full Payload:\n","--------------------------------------------------------------------------------\n","category                  : Ranking_Metadata\n","city                      : Dehradun\n","content                   : Institute: Graphic Era University, Rank: 52.0, City: Dehradun, State: Uttarakhand\n","content_type              : NIRF_Ranking\n","data_source               : NIRF_Ranking_Table\n","institute_name            : Graphic Era University\n","processing_timestamp      : 2025-09-15T06:31:19.645917\n","rank                      : 52\n","state                     : Uttarakhand\n","\n","‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n","\n","\n","================================================================================\n","POINT #69 of 102\n","================================================================================\n","Point ID:      ae4a0383-ad59-5173-9a87-9a235a29143f\n","Content Type:  NIRF_Ranking\n","\n","Full Payload:\n","--------------------------------------------------------------------------------\n","category                  : Ranking_Metadata\n","city                      : Rajpura\n","content                   : Institute: Chitkara University, Rank: 89.0, City: Rajpura, State: Punjab\n","content_type              : NIRF_Ranking\n","data_source               : NIRF_Ranking_Table\n","institute_name            : Chitkara University\n","processing_timestamp      : 2025-09-15T06:31:19.651697\n","rank                      : 89\n","state                     : Punjab\n","\n","‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n","\n","\n","================================================================================\n","POINT #70 of 102\n","================================================================================\n","Point ID:      b57bd810-e00c-5ec0-bdde-47f108dd46fe\n","Content Type:  NIRF_Ranking\n","\n","Full Payload:\n","--------------------------------------------------------------------------------\n","category                  : Ranking_Metadata\n","city                      : Hyderabad\n","content                   : Institute: Jawaharlal Nehru Technological University, Rank: 94.0, City: Hyderabad, State: Telangana\n","content_type              : NIRF_Ranking\n","data_source               : NIRF_Ranking_Table\n","institute_name            : Jawaharlal Nehru Technological University\n","processing_timestamp      : 2025-09-15T06:31:19.652473\n","rank                      : 94\n","state                     : Telangana\n","\n","‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n","\n","\n","================================================================================\n","POINT #71 of 102\n","================================================================================\n","Point ID:      b704ab6d-da5b-5aa1-9b8d-779e4c93fc90\n","Content Type:  NIRF_Ranking\n","\n","Full Payload:\n","--------------------------------------------------------------------------------\n","category                  : Ranking_Metadata\n","city                      : Patna\n","content                   : Institute: National Institute of Technology Patna, Rank: 53.0, City: Patna, State: Bihar\n","content_type              : NIRF_Ranking\n","data_source               : NIRF_Ranking_Table\n","institute_name            : National Institute of Technology Patna\n","processing_timestamp      : 2025-09-15T06:31:19.646073\n","rank                      : 53\n","state                     : Bihar\n","\n","‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n","\n","\n","================================================================================\n","POINT #72 of 102\n","================================================================================\n","Point ID:      b7eb36d9-5c86-56a0-b682-1356ed259f38\n","Content Type:  NIRF_Ranking\n","\n","Full Payload:\n","--------------------------------------------------------------------------------\n","category                  : Ranking_Metadata\n","city                      : Phagwara\n","content                   : Institute: Lovely Professional University, Rank: 48.0, City: Phagwara, State: Punjab\n","content_type              : NIRF_Ranking\n","data_source               : NIRF_Ranking_Table\n","institute_name            : Lovely Professional University\n","processing_timestamp      : 2025-09-15T06:31:19.645292\n","rank                      : 48\n","state                     : Punjab\n","\n","‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n","\n","\n","================================================================================\n","POINT #73 of 102\n","================================================================================\n","Point ID:      b879b9e3-3997-5fc2-9d3f-1f7480de7654\n","Content Type:  NIRF_Ranking\n","\n","Full Payload:\n","--------------------------------------------------------------------------------\n","category                  : Ranking_Metadata\n","city                      : Jaipur\n","content                   : Institute: Manipal University Jaipur, Rank: 58.0, City: Jaipur, State: Rajasthan\n","content_type              : NIRF_Ranking\n","data_source               : NIRF_Ranking_Table\n","institute_name            : Manipal University Jaipur\n","processing_timestamp      : 2025-09-15T06:31:19.646849\n","rank                      : 58\n","state                     : Rajasthan\n","\n","‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n","\n","\n","================================================================================\n","POINT #74 of 102\n","================================================================================\n","Point ID:      bb8b98b5-9b97-508b-9c1b-1ea74f284e78\n","Content Type:  NIRF_Ranking\n","\n","Full Payload:\n","--------------------------------------------------------------------------------\n","category                  : Ranking_Metadata\n","city                      : Karaikal\n","content                   : Institute: National Institute of Technology Puducherry, Rank: 99.0, City: Karaikal, State: Pondicherry\n","content_type              : NIRF_Ranking\n","data_source               : NIRF_Ranking_Table\n","institute_name            : National Institute of Technology Puducherry\n","processing_timestamp      : 2025-09-15T06:31:19.653222\n","rank                      : 99\n","state                     : Pondicherry\n","\n","‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n","\n","\n","================================================================================\n","POINT #75 of 102\n","================================================================================\n","Point ID:      bbb289c3-29b4-5d25-8892-32b37c2c6aa3\n","Content Type:  NIRF_Ranking\n","\n","Full Payload:\n","--------------------------------------------------------------------------------\n","category                  : Ranking_Metadata\n","city                      : Delhi\n","content                   : Institute: National Institute of Technology Delhi, Rank: 65.0, City: Delhi, State: Delhi\n","content_type              : NIRF_Ranking\n","data_source               : NIRF_Ranking_Table\n","institute_name            : National Institute of Technology Delhi\n","processing_timestamp      : 2025-09-15T06:31:19.647913\n","rank                      : 65\n","state                     : Delhi\n","\n","‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n","\n","\n","================================================================================\n","POINT #76 of 102\n","================================================================================\n","Point ID:      bbf3c9eb-2302-5849-935c-a9add307c8c2\n","Content Type:  NIRF_Ranking\n","\n","Full Payload:\n","--------------------------------------------------------------------------------\n","category                  : Ranking_Metadata\n","city                      : Tiruchirappalli\n","content                   : Institute: National Institute of Technology Tiruchirappalli, Rank: 9.0, City: Tiruchirappalli, State: Tamil Nadu\n","content_type              : NIRF_Ranking\n","data_source               : NIRF_Ranking_Table\n","institute_name            : National Institute of Technology Tiruchirappalli\n","processing_timestamp      : 2025-09-15T06:31:19.638792\n","rank                      : 9\n","state                     : Tamil Nadu\n","\n","‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n","\n","\n","================================================================================\n","POINT #77 of 102\n","================================================================================\n","Point ID:      c1241d8b-7290-5019-9746-b50afbee0456\n","Content Type:  NIRF_Ranking\n","\n","Full Payload:\n","--------------------------------------------------------------------------------\n","category                  : Ranking_Metadata\n","city                      : Kalavakkam\n","content                   : Institute: Sri Sivasubramaniya Nadar College of Engineering, Rank: 47.0, City: Kalavakkam, State: Tamil Nadu\n","content_type              : NIRF_Ranking\n","data_source               : NIRF_Ranking_Table\n","institute_name            : Sri Sivasubramaniya Nadar College of Engineering\n","processing_timestamp      : 2025-09-15T06:31:19.645130\n","rank                      : 47\n","state                     : Tamil Nadu\n","\n","‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n","\n","\n","================================================================================\n","POINT #78 of 102\n","================================================================================\n","Point ID:      c3b37b89-c8a1-55ff-b1cb-32d777520428\n","Content Type:  NIRF_Ranking\n","\n","Full Payload:\n","--------------------------------------------------------------------------------\n","category                  : Ranking_Metadata\n","city                      : Durgapur\n","content                   : Institute: National Institute of Technology Durgapur, Rank: 49.0, City: Durgapur, State: West Bengal\n","content_type              : NIRF_Ranking\n","data_source               : NIRF_Ranking_Table\n","institute_name            : National Institute of Technology Durgapur\n","processing_timestamp      : 2025-09-15T06:31:19.645447\n","rank                      : 49\n","state                     : West Bengal\n","\n","‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n","\n","\n","================================================================================\n","POINT #79 of 102\n","================================================================================\n","Point ID:      c98ac0a5-5506-5e43-9fa8-9ef6a876f396\n","Content Type:  NIRF_Ranking\n","\n","Full Payload:\n","--------------------------------------------------------------------------------\n","category                  : Ranking_Metadata\n","city                      : Ranchi\n","content                   : Institute: Birla Institute of Technology, Rank: 51.0, City: Ranchi, State: Jharkhand\n","content_type              : NIRF_Ranking\n","data_source               : NIRF_Ranking_Table\n","institute_name            : Birla Institute of Technology\n","processing_timestamp      : 2025-09-15T06:31:19.645759\n","rank                      : 51\n","state                     : Jharkhand\n","\n","‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n","\n","\n","================================================================================\n","POINT #80 of 102\n","================================================================================\n","Point ID:      cb43ecd4-21b0-5562-aaf1-2041dd51f44d\n","Content Type:  NIRF_Ranking\n","\n","Full Payload:\n","--------------------------------------------------------------------------------\n","category                  : Ranking_Metadata\n","city                      : Durg\n","content                   : Institute: Indian Institute of Technology Bhilai, Rank: 72.0, City: Durg, State: Chhattisgarh\n","content_type              : NIRF_Ranking\n","data_source               : NIRF_Ranking_Table\n","institute_name            : Indian Institute of Technology Bhilai\n","processing_timestamp      : 2025-09-15T06:31:19.649042\n","rank                      : 72\n","state                     : Chhattisgarh\n","\n","‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n","\n","\n","================================================================================\n","POINT #81 of 102\n","================================================================================\n","Point ID:      cd2a19d9-2c38-5b9e-acf3-edc0d90b5820\n","Content Type:  NIRF_Ranking\n","\n","Full Payload:\n","--------------------------------------------------------------------------------\n","category                  : Ranking_Metadata\n","city                      : Banasthali\n","content                   : Institute: Banasthali Vidyapith, Rank: 71.0, City: Banasthali, State: Rajasthan\n","content_type              : NIRF_Ranking\n","data_source               : NIRF_Ranking_Table\n","institute_name            : Banasthali Vidyapith\n","processing_timestamp      : 2025-09-15T06:31:19.648866\n","rank                      : 71\n","state                     : Rajasthan\n","\n","‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n","\n","\n","================================================================================\n","POINT #82 of 102\n","================================================================================\n","Point ID:      cec70688-7d50-56f5-a573-b4e04f762024\n","Content Type:  NIRF_Ranking\n","\n","Full Payload:\n","--------------------------------------------------------------------------------\n","category                  : Ranking_Metadata\n","city                      : Hyderabad\n","content                   : Institute: University of Hyderabad, Rank: 74.0, City: Hyderabad, State: Telangana\n","content_type              : NIRF_Ranking\n","data_source               : NIRF_Ranking_Table\n","institute_name            : University of Hyderabad\n","processing_timestamp      : 2025-09-15T06:31:19.649362\n","rank                      : 74\n","state                     : Telangana\n","\n","‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n","\n","\n","================================================================================\n","POINT #83 of 102\n","================================================================================\n","Point ID:      cfcc03a3-a539-53be-b73b-49e1a6ff11ac\n","Content Type:  NIRF_Ranking\n","\n","Full Payload:\n","--------------------------------------------------------------------------------\n","category                  : Ranking_Metadata\n","city                      : New Delhi\n","content                   : Institute: Jamia Millia Islamia, Rank: 24.0, City: New Delhi, State: Delhi\n","content_type              : NIRF_Ranking\n","data_source               : NIRF_Ranking_Table\n","institute_name            : Jamia Millia Islamia\n","processing_timestamp      : 2025-09-15T06:31:19.641314\n","rank                      : 24\n","state                     : Delhi\n","\n","‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n","\n","\n","================================================================================\n","POINT #84 of 102\n","================================================================================\n","Point ID:      d4654c79-9b4b-50d9-92d9-e7eabf234803\n","Content Type:  NIRF_Ranking\n","\n","Full Payload:\n","--------------------------------------------------------------------------------\n","category                  : Ranking_Metadata\n","city                      : New Delhi\n","content                   : Institute: Indraprastha Institute of Information Technology, Rank: 63.0, City: New Delhi, State: Delhi\n","content_type              : NIRF_Ranking\n","data_source               : NIRF_Ranking_Table\n","institute_name            : Indraprastha Institute of Information Technology\n","processing_timestamp      : 2025-09-15T06:31:19.647600\n","rank                      : 63\n","state                     : Delhi\n","\n","‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n","\n","\n","================================================================================\n","POINT #85 of 102\n","================================================================================\n","Point ID:      d626898a-2f00-56d3-976d-7d1699ba8f2c\n","Content Type:  NIRF_Ranking\n","\n","Full Payload:\n","--------------------------------------------------------------------------------\n","category                  : Ranking_Metadata\n","city                      : Hamirpur\n","content                   : Institute: National Institute of Technology Hamirpur, Rank: 97.0, City: Hamirpur, State: Himachal Pradesh\n","content_type              : NIRF_Ranking\n","data_source               : NIRF_Ranking_Table\n","institute_name            : National Institute of Technology Hamirpur\n","processing_timestamp      : 2025-09-15T06:31:19.652933\n","rank                      : 97\n","state                     : Himachal Pradesh\n","\n","‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n","\n","\n","================================================================================\n","POINT #86 of 102\n","================================================================================\n","Point ID:      d9ab97ac-72e8-5936-9f09-708e01e702d4\n","Content Type:  NIRF_Ranking\n","\n","Full Payload:\n","--------------------------------------------------------------------------------\n","category                  : Ranking_Metadata\n","city                      : Patiala\n","content                   : Institute: Thapar Institute of Engineering and Technology (Deemed-to-be-university), Rank: 29.0, City: Patiala, State: Punjab\n","content_type              : NIRF_Ranking\n","data_source               : NIRF_Ranking_Table\n","institute_name            : Thapar Institute of Engineering and Technology (Deemed-to-be-university)\n","processing_timestamp      : 2025-09-15T06:31:19.642166\n","rank                      : 29\n","state                     : Punjab\n","\n","‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n","\n","\n","================================================================================\n","POINT #87 of 102\n","================================================================================\n","Point ID:      dab373d2-e2a6-52c3-9fa4-c881c020f680\n","Content Type:  NIRF_Ranking\n","\n","Full Payload:\n","--------------------------------------------------------------------------------\n","category                  : Ranking_Metadata\n","city                      : Krishnan Koil\n","content                   : Institute: Kalasalingam Academy of Research and Education, Rank: 33.0, City: Krishnan Koil, State: Tamil Nadu\n","content_type              : NIRF_Ranking\n","data_source               : NIRF_Ranking_Table\n","institute_name            : Kalasalingam Academy of Research and Education\n","processing_timestamp      : 2025-09-15T06:31:19.642822\n","rank                      : 33\n","state                     : Tamil Nadu\n","\n","‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n","\n","\n","================================================================================\n","POINT #88 of 102\n","================================================================================\n","Point ID:      dc30e1e3-7639-59eb-bc7a-64d6414e37d8\n","Content Type:  NIRF_Ranking\n","\n","Full Payload:\n","--------------------------------------------------------------------------------\n","category                  : Ranking_Metadata\n","city                      : Pune\n","content                   : Institute: Symbiosis International, Rank: 46.0, City: Pune, State: Maharashtra\n","content_type              : NIRF_Ranking\n","data_source               : NIRF_Ranking_Table\n","institute_name            : Symbiosis International\n","processing_timestamp      : 2025-09-15T06:31:19.644979\n","rank                      : 46\n","state                     : Maharashtra\n","\n","‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n","\n","\n","================================================================================\n","POINT #89 of 102\n","================================================================================\n","Point ID:      e428284c-d883-5be9-8ce1-67a3ad4cc339\n","Content Type:  NIRF_Ranking\n","\n","Full Payload:\n","--------------------------------------------------------------------------------\n","category                  : Ranking_Metadata\n","city                      : Gautam Budh Nagar\n","content                   : Institute: Amity University, Rank: 37.0, City: Gautam Budh Nagar, State: Uttar Pradesh\n","content_type              : NIRF_Ranking\n","data_source               : NIRF_Ranking_Table\n","institute_name            : Amity University\n","processing_timestamp      : 2025-09-15T06:31:19.643486\n","rank                      : 37\n","state                     : Uttar Pradesh\n","\n","‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n","\n","\n","================================================================================\n","POINT #90 of 102\n","================================================================================\n","Point ID:      e529c5b1-cdaf-53e0-a2fa-8e0339661543\n","Content Type:  NIRF_Ranking\n","\n","Full Payload:\n","--------------------------------------------------------------------------------\n","category                  : Ranking_Metadata\n","city                      : Coimbatore\n","content                   : Institute: PSG College of Technology, Rank: 67.0, City: Coimbatore, State: Tamil Nadu\n","content_type              : NIRF_Ranking\n","data_source               : NIRF_Ranking_Table\n","institute_name            : PSG College of Technology\n","processing_timestamp      : 2025-09-15T06:31:19.648228\n","rank                      : 67\n","state                     : Tamil Nadu\n","\n","‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n","\n","\n","================================================================================\n","POINT #91 of 102\n","================================================================================\n","Point ID:      e96989e6-ddb7-5ee9-9be5-733e3ae0ebe1\n","Content Type:  NIRF_Ranking\n","\n","Full Payload:\n","--------------------------------------------------------------------------------\n","category                  : Ranking_Metadata\n","city                      : Pune\n","content                   : Institute: COEP Technological University, Rank: 90.0, City: Pune, State: Maharashtra\n","content_type              : NIRF_Ranking\n","data_source               : NIRF_Ranking_Table\n","institute_name            : COEP Technological University\n","processing_timestamp      : 2025-09-15T06:31:19.651876\n","rank                      : 90\n","state                     : Maharashtra\n","\n","‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n","\n","\n","================================================================================\n","POINT #92 of 102\n","================================================================================\n","Point ID:      eca6b046-440e-52f5-b57f-4e8ab3464342\n","Content Type:  NIRF_Ranking\n","\n","Full Payload:\n","--------------------------------------------------------------------------------\n","category                  : Ranking_Metadata\n","city                      : Roorkee\n","content                   : Institute: Indian Institute of Technology Roorkee, Rank: 6.0, City: Roorkee, State: Uttarakhand\n","content_type              : NIRF_Ranking\n","data_source               : NIRF_Ranking_Table\n","institute_name            : Indian Institute of Technology Roorkee\n","processing_timestamp      : 2025-09-15T06:31:19.638290\n","rank                      : 6\n","state                     : Uttarakhand\n","\n","‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n","\n","\n","================================================================================\n","POINT #93 of 102\n","================================================================================\n","Point ID:      ef162f5e-6780-5859-9b0a-d4423309df00\n","Content Type:  NIRF_Ranking\n","\n","Full Payload:\n","--------------------------------------------------------------------------------\n","category                  : Ranking_Metadata\n","city                      : Varanasi\n","content                   : Institute: Indian Institute of Technology (Banaras Hindu University) Varanasi, Rank: 10.0, City: Varanasi, State: Uttar Pradesh\n","content_type              : NIRF_Ranking\n","data_source               : NIRF_Ranking_Table\n","institute_name            : Indian Institute of Technology (Banaras Hindu University) Varanasi\n","processing_timestamp      : 2025-09-15T06:31:19.638966\n","rank                      : 10\n","state                     : Uttar Pradesh\n","\n","‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n","\n","\n","================================================================================\n","POINT #94 of 102\n","================================================================================\n","Point ID:      f60ac678-883e-5d05-b78e-46fc97702e66\n","Content Type:  NIRF_Ranking\n","\n","Full Payload:\n","--------------------------------------------------------------------------------\n","category                  : Ranking_Metadata\n","city                      : Patna\n","content                   : Institute: Indian Institute of Technology Patna, Rank: 19.0, City: Patna, State: Bihar\n","content_type              : NIRF_Ranking\n","data_source               : NIRF_Ranking_Table\n","institute_name            : Indian Institute of Technology Patna\n","processing_timestamp      : 2025-09-15T06:31:19.640422\n","rank                      : 19\n","state                     : Bihar\n","\n","‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n","\n","\n","================================================================================\n","POINT #95 of 102\n","================================================================================\n","Point ID:      f60c47cb-7433-51c3-89c2-13efe58d3656\n","Content Type:  NIRF_Ranking\n","\n","Full Payload:\n","--------------------------------------------------------------------------------\n","category                  : Ranking_Metadata\n","city                      : Bengaluru\n","content                   : Institute: Christ University, Rank: 76.0, City: Bengaluru, State: Karnataka\n","content_type              : NIRF_Ranking\n","data_source               : NIRF_Ranking_Table\n","institute_name            : Christ University\n","processing_timestamp      : 2025-09-15T06:31:19.649673\n","rank                      : 76\n","state                     : Karnataka\n","\n","‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n","\n","\n","================================================================================\n","POINT #96 of 102\n","================================================================================\n","Point ID:      f69831ea-6c2b-5430-b63d-ed1b9866dd05\n","Content Type:  NIRF_Ranking\n","\n","Full Payload:\n","--------------------------------------------------------------------------------\n","category                  : Ranking_Metadata\n","city                      : Chennai\n","content                   : Institute: S.R.M. Institute of Science and Technology, Rank: 14.0, City: Chennai, State: Tamil Nadu\n","content_type              : NIRF_Ranking\n","data_source               : NIRF_Ranking_Table\n","institute_name            : S.R.M. Institute of Science and Technology\n","processing_timestamp      : 2025-09-15T06:31:19.639607\n","rank                      : 14\n","state                     : Tamil Nadu\n","\n","‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n","\n","\n","================================================================================\n","POINT #97 of 102\n","================================================================================\n","Point ID:      f75dac09-2fb8-5b50-b82a-42710690e6f4\n","Content Type:  NIRF_Ranking\n","\n","Full Payload:\n","--------------------------------------------------------------------------------\n","category                  : Ranking_Metadata\n","city                      : Kharagpur\n","content                   : Institute: Indian Institute of Technology Kharagpur, Rank: 5.0, City: Kharagpur, State: West Bengal\n","content_type              : NIRF_Ranking\n","data_source               : NIRF_Ranking_Table\n","institute_name            : Indian Institute of Technology Kharagpur\n","processing_timestamp      : 2025-09-15T06:31:19.638118\n","rank                      : 5\n","state                     : West Bengal\n","\n","‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n","\n","\n","================================================================================\n","POINT #98 of 102\n","================================================================================\n","Point ID:      f81e32d8-6403-5c04-94c2-89554d7b3c34\n","Content Type:  NIRF_Ranking\n","\n","Full Payload:\n","--------------------------------------------------------------------------------\n","category                  : Ranking_Metadata\n","city                      : Pune\n","content                   : Institute: Defence Institute of Advanced Technology, Rank: 92.0, City: Pune, State: Maharashtra\n","content_type              : NIRF_Ranking\n","data_source               : NIRF_Ranking_Table\n","institute_name            : Defence Institute of Advanced Technology\n","processing_timestamp      : 2025-09-15T06:31:19.652171\n","rank                      : 92\n","state                     : Maharashtra\n","\n","‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n","\n","\n","================================================================================\n","POINT #99 of 102\n","================================================================================\n","Point ID:      fa9e4f30-5d38-53a9-80ac-085297ee80d3\n","Content Type:  NIRF_Ranking\n","\n","Full Payload:\n","--------------------------------------------------------------------------------\n","category                  : Ranking_Metadata\n","city                      : Jodhpur\n","content                   : Institute: Indian Institute of Technology Jodhpur, Rank: 27.0, City: Jodhpur, State: Rajasthan\n","content_type              : NIRF_Ranking\n","data_source               : NIRF_Ranking_Table\n","institute_name            : Indian Institute of Technology Jodhpur\n","processing_timestamp      : 2025-09-15T06:31:19.641817\n","rank                      : 27\n","state                     : Rajasthan\n","\n","‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n","\n","\n","================================================================================\n","POINT #100 of 102\n","================================================================================\n","Point ID:      ff300030-da08-5203-a105-7bb06de3f43c\n","Content Type:  NIRF_Ranking\n","\n","Full Payload:\n","--------------------------------------------------------------------------------\n","category                  : Ranking_Metadata\n","city                      : Vellore\n","content                   : Institute: Vellore Institute of Technology, Rank: 16.0, City: Vellore, State: Tamil Nadu\n","content_type              : NIRF_Ranking\n","data_source               : NIRF_Ranking_Table\n","institute_name            : Vellore Institute of Technology\n","processing_timestamp      : 2025-09-15T06:31:19.639950\n","rank                      : 16\n","state                     : Tamil Nadu\n","\n","‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n","\n","\n","================================================================================\n","POINT #101 of 102\n","================================================================================\n","Point ID:      ff7c1c9a-d9a5-51c0-b9c5-fed839f670ba\n","Content Type:  NIRF_Ranking\n","\n","Full Payload:\n","--------------------------------------------------------------------------------\n","category                  : Ranking_Metadata\n","city                      : Guntur\n","content                   : Institute: Vignan's Foundation for Science, Technology and Research, Rank: 80.0, City: Guntur, State: Andhra Pradesh\n","content_type              : NIRF_Ranking\n","data_source               : NIRF_Ranking_Table\n","institute_name            : Vignan's Foundation for Science, Technology and Research\n","processing_timestamp      : 2025-09-15T06:31:19.650314\n","rank                      : 80\n","state                     : Andhra Pradesh\n","\n","‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n","\n","\n","================================================================================\n","POINT #102 of 102\n","================================================================================\n","Point ID:      ffa18bfc-a757-5ab1-b049-ccca10f5f43c\n","Content Type:  NIRF_Ranking\n","\n","Full Payload:\n","--------------------------------------------------------------------------------\n","category                  : Ranking_Metadata\n","city                      : Pilani\n","content                   : Institute: Birla Institute of Technology & Science -Pilani, Rank: 11.0, City: Pilani, State: Rajasthan\n","content_type              : NIRF_Ranking\n","data_source               : NIRF_Ranking_Table\n","institute_name            : Birla Institute of Technology & Science -Pilani\n","processing_timestamp      : 2025-09-15T06:31:19.639122\n","rank                      : 11\n","state                     : Rajasthan\n","\n","================================================================================\n","SUMMARY\n","================================================================================\n","\n","Unknown content types found:\n","\n","  'NIRF_Ranking': 102 points\n","    Sample IDs: ['01a880d0-faa1-5d51-8d4e-5bc0b8fcb8b3', '0a31c7e4-1921-5637-a3e1-a2a04c76b821', '0be1c74c-dd8e-5a09-a539-63531c69dc75']\n","\n","================================================================================\n"]}]},{"cell_type":"code","source":["from qdrant_client import QdrantClient, models\n","import json\n","\n","# --- Qdrant Connection Details ---\n","QDRANT_URL = \"https://b5651607-31ce-49ba-916d-c35c89d731d2.us-east4-0.gcp.cloud.qdrant.io\"\n","QDRANT_API_KEY = \"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJhY2Nlc3MiOiJtIn0.0ApHZL4Qn_A8bx7FCC62nx-IOrHI84W7GZlUZEyVgKk\"\n","COLLECTION_NAME = \"durden\"\n","\n","# --- Connect to Qdrant Cloud ---\n","client = QdrantClient(url=QDRANT_URL, api_key=QDRANT_API_KEY)\n","\n","print(f\"üîó Connected to Qdrant collection: {COLLECTION_NAME}\")\n","\n","# --- Step 1: Check if the collection exists ---\n","try:\n","    info = client.get_collection(COLLECTION_NAME)\n","    print(f\"‚úÖ Collection found: {info.status}\")\n","except Exception as e:\n","    print(f\"‚ùå Error: Collection '{COLLECTION_NAME}' not found or cannot connect.\\n{e}\")\n","    exit()\n","\n","# --- Step 2: Sample one record to detect field names automatically ---\n","try:\n","    points = client.scroll(collection_name=COLLECTION_NAME, limit=1, with_payload=True)\n","    if not points or len(points[0]) == 0:\n","        print(\"‚ö†Ô∏è No data found in collection. Cannot auto-detect fields.\")\n","        exit()\n","\n","    sample_payload = points[0][0].payload\n","    print(f\"üì¶ Sample Payload:\\n{json.dumps(sample_payload, indent=2)}\")\n","\n","except Exception as e:\n","    print(f\"‚ùå Failed to fetch a sample payload: {e}\")\n","    exit()\n","\n","# --- Step 3: Define a mapping function for Python data types to Qdrant index types ---\n","def detect_field_schema(value):\n","    if isinstance(value, bool):\n","        return models.PayloadSchemaType.BOOL\n","    elif isinstance(value, int):\n","        return models.PayloadSchemaType.INTEGER\n","    elif isinstance(value, float):\n","        return models.PayloadSchemaType.FLOAT\n","    elif isinstance(value, dict):\n","        # Skip nested dicts, recommend flattening\n","        return None\n","    elif isinstance(value, list):\n","        if len(value) > 0 and isinstance(value[0], (int, float)):\n","            return models.PayloadSchemaType.FLOAT\n","        return models.PayloadSchemaType.KEYWORD\n","    else:\n","        return models.PayloadSchemaType.KEYWORD  # default for strings\n","\n","# --- Step 4: Create indexes for each field ---\n","for field_name, field_value in sample_payload.items():\n","    schema_type = detect_field_schema(field_value)\n","    if schema_type is None:\n","        print(f\"‚ö†Ô∏è Skipping nested field: {field_name}\")\n","        continue\n","\n","    try:\n","        client.create_payload_index(\n","            collection_name=COLLECTION_NAME,\n","            field_name=field_name,\n","            field_schema=schema_type\n","        )\n","        print(f\"‚úÖ Indexed field '{field_name}' as {schema_type.value}\")\n","    except Exception as e:\n","        print(f\"‚ö†Ô∏è Could not index '{field_name}': {e}\")\n","\n","# --- Step 5: List all created indexes ---\n","try:\n","    indexes = client.list_payload_indexes(COLLECTION_NAME)\n","    print(\"\\nüìò Indexes created in collection:\")\n","    for idx in indexes:\n","        print(f\" - {idx.field_name} ({idx.field_schema})\")\n","except Exception as e:\n","    print(f\"‚ùå Failed to fetch index list: {e}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2J55tg_Yt26Y","executionInfo":{"status":"ok","timestamp":1762976533757,"user_tz":-330,"elapsed":497,"user":{"displayName":"Rahul Siddhu","userId":"12007764243202946991"}},"outputId":"0eb4f159-a3f2-4358-c8c5-d981c07ee1fb"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["üîó Connected to Qdrant collection: durden\n","‚úÖ Collection found: green\n","üì¶ Sample Payload:\n","{\n","  \"metadata\": {\n","    \"institute_name\": \"National Institute of Technology Warangal\",\n","    \"institute_code\": \"IR-E-U-0025\",\n","    \"content_type\": \"STUDENT_STRENGTH\",\n","    \"chunk_index\": 0,\n","    \"total_chunks\": 1,\n","    \"content_length\": 850,\n","    \"original_id\": \"0008f5fb-e110-542b-9750-10fd9e09e82a\",\n","    \"source_file\": \"NIT Warangal (1)\",\n","    \"item_index\": 2,\n","    \"vector_model\": \"all-MiniLM-L6-v2\",\n","    \"upload_timestamp\": \"2025-11-12T18:51:38.954074\",\n","    \"content_for_embedding\": \"Institute: National Institute of Technology Warangal | Code: IR-E-U-0025 | Content Type: STUDENT_STRENGTH | Content: Total Actual Student Strength (Program(s) Offered by your Institution) (All programs of all years) No. of Male Students No. of Female Students Total Students Within State (Including male & female) Outside State (Including male & female) Outside Country (Including male & female) Economically Backward (Including male & female) Socially Challenged (SC+ST+OBC Including male & female) No. of students receiving full tuition fee reimbursement from the State and Central Government No. of students receiving full tuition fee reimbursement from Institution Funds No. of students receiving full tuition fee reimbursement from the Private Bodies No. of students who are not receiving full tuition fee reimbursement UG [4 Years Program(s)] 3378 888 4266 1925 1963 378 425 1963 259 1716 43 370 PG [2 Year Program(s)] 944 238 1182 496 686 0 105 560 6 239 0 420\",\n","    \"data_type\": \"NIRF_REPORT\",\n","    \"Nirf_category\": \"OI\"\n","  },\n","  \"content\": \"Total Actual Student Strength (Program(s) Offered by your Institution) (All programs of all years) No. of Male Students No. of Female Students Total Students Within State (Including male & female) Outside State (Including male & female) Outside Country (Including male & female) Economically Backward (Including male & female) Socially Challenged (SC+ST+OBC Including male & female) No. of students receiving full tuition fee reimbursement from the State and Central Government No. of students receiving full tuition fee reimbursement from Institution Funds No. of students receiving full tuition fee reimbursement from the Private Bodies No. of students who are not receiving full tuition fee reimbursement UG [4 Years Program(s)] 3378 888 4266 1925 1963 378 425 1963 259 1716 43 370 PG [2 Year Program(s)] 944 238 1182 496 686 0 105 560 6 239 0 420\"\n","}\n","‚ö†Ô∏è Skipping nested field: metadata\n","‚úÖ Indexed field 'content' as keyword\n","‚ùå Failed to fetch index list: 'QdrantClient' object has no attribute 'list_payload_indexes'\n"]}]},{"cell_type":"code","source":["from qdrant_client import QdrantClient\n","from qdrant_client.http.models import PointStruct\n","from tqdm import tqdm\n","\n","QDRANT_URL = \"https://b5651607-31ce-49ba-916d-c35c89d731d2.us-east4-0.gcp.cloud.qdrant.io\"\n","QDRANT_API_KEY = \"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJhY2Nlc3MiOiJtIn0.0ApHZL4Qn_A8bx7FCC62nx-IOrHI84W7GZlUZEyVgKk\"\n","COLLECTION_NAME = \"durden\"\n","client = QdrantClient(url=QDRANT_URL, api_key=QDRANT_API_KEY)\n","\n","# 1Ô∏è‚É£  Get all points in batches\n","limit = 100\n","offset = 0\n","total_converted = 0\n","\n","while True:\n","    points = client.scroll(\n","        collection_name=COLLECTION_NAME,\n","        limit=limit,\n","        offset=offset,\n","        with_payload=True,\n","        with_vectors=True\n","    )\n","    if not points[0]:\n","        break\n","\n","    new_points = []\n","    for p in points[0]:\n","        old_payload = p.payload or {}\n","\n","        # skip if already converted\n","        if \"metadata\" in old_payload:\n","            continue\n","\n","        payload = old_payload.get(\"payload\", old_payload)  # handle nested payload\n","        metadata = {k: v for k, v in payload.items() if k != \"content\"}\n","\n","        new_payload = {\n","            \"metadata\": metadata,\n","            \"content\": payload.get(\"content\", \"\")\n","        }\n","\n","        new_points.append(\n","            PointStruct(\n","                id=p.id,\n","                vector=p.vector,\n","                payload=new_payload\n","            )\n","        )\n","\n","    if new_points:\n","        client.upsert(collection_name=COLLECTION_NAME, points=new_points)\n","        total_converted += len(new_points)\n","        print(f\"Converted {total_converted} so far...\")\n","\n","    if len(points[0]) < limit:\n","        break\n","    offset += limit\n","\n","print(f\"‚úÖ Finished converting {total_converted} points.\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":356},"id":"X8Fem34JNtiF","executionInfo":{"status":"error","timestamp":1762976671162,"user_tz":-330,"elapsed":20471,"user":{"displayName":"Rahul Siddhu","userId":"12007764243202946991"}},"outputId":"f741d4d8-c299-40f0-ca80-96414999c75b"},"execution_count":null,"outputs":[{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-2328112053.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     points = client.scroll(\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0mcollection_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mCOLLECTION_NAME\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mlimit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlimit\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/qdrant_client/qdrant_client.py\u001b[0m in \u001b[0;36mscroll\u001b[0;34m(self, collection_name, scroll_filter, limit, order_by, offset, with_payload, with_vectors, consistency, shard_key_selector, timeout, **kwargs)\u001b[0m\n\u001b[1;32m   1457\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf\"Unknown arguments: {list(kwargs.keys())}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1459\u001b[0;31m         return self._client.scroll(\n\u001b[0m\u001b[1;32m   1460\u001b[0m             \u001b[0mcollection_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcollection_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1461\u001b[0m             \u001b[0mscroll_filter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscroll_filter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/qdrant_client/qdrant_remote.py\u001b[0m in \u001b[0;36mscroll\u001b[0;34m(self, collection_name, scroll_filter, limit, order_by, offset, with_payload, with_vectors, consistency, shard_key_selector, timeout, **kwargs)\u001b[0m\n\u001b[1;32m   1717\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1718\u001b[0m             scroll_result: Optional[models.ScrollResult] = (\n\u001b[0;32m-> 1719\u001b[0;31m                 self.openapi_client.points_api.scroll_points(\n\u001b[0m\u001b[1;32m   1720\u001b[0m                     \u001b[0mcollection_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcollection_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1721\u001b[0m                     \u001b[0mconsistency\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconsistency\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/qdrant_client/http/api/points_api.py\u001b[0m in \u001b[0;36mscroll_points\u001b[0;34m(self, collection_name, consistency, timeout, scroll_request)\u001b[0m\n\u001b[1;32m    934\u001b[0m         \u001b[0mScroll\u001b[0m \u001b[0mrequest\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mpaginate\u001b[0m \u001b[0mover\u001b[0m \u001b[0mall\u001b[0m \u001b[0mpoints\u001b[0m \u001b[0mwhich\u001b[0m \u001b[0mmatches\u001b[0m \u001b[0mgiven\u001b[0m \u001b[0mfiltering\u001b[0m \u001b[0mcondition\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m         \"\"\"\n\u001b[0;32m--> 936\u001b[0;31m         return self._build_for_scroll_points(\n\u001b[0m\u001b[1;32m    937\u001b[0m             \u001b[0mcollection_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcollection_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    938\u001b[0m             \u001b[0mconsistency\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconsistency\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/qdrant_client/http/api/points_api.py\u001b[0m in \u001b[0;36m_build_for_scroll_points\u001b[0;34m(self, collection_name, consistency, timeout, scroll_request)\u001b[0m\n\u001b[1;32m    408\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"Content-Type\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m             \u001b[0mheaders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Content-Type\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"application/json\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 410\u001b[0;31m         return self.api_client.request(\n\u001b[0m\u001b[1;32m    411\u001b[0m             \u001b[0mtype_\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInlineResponse20016\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    412\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"POST\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/qdrant_client/http/api_client.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, type_, method, url, path_params, **kwargs)\u001b[0m\n\u001b[1;32m     93\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"timeout\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"params\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"timeout\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0mrequest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0moverload\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/qdrant_client/http/api_client.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, type_)\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mRequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype_\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mType\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmiddleware\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_inner\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m429\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/qdrant_client/http/api_client.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, request, call_next)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mBaseMiddleware\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mRequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcall_next\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSend\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mResponse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcall_next\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/qdrant_client/http/api_client.py\u001b[0m in \u001b[0;36msend_inner\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    132\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msend_inner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mRequest\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mResponse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mResponseHandlingException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/httpx/_client.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, auth, follow_redirects)\u001b[0m\n\u001b[1;32m    912\u001b[0m         \u001b[0mauth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build_request_auth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 914\u001b[0;31m         response = self._send_handling_auth(\n\u001b[0m\u001b[1;32m    915\u001b[0m             \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m             \u001b[0mauth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mauth\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/httpx/_client.py\u001b[0m in \u001b[0;36m_send_handling_auth\u001b[0;34m(self, request, auth, follow_redirects, history)\u001b[0m\n\u001b[1;32m    940\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    941\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 942\u001b[0;31m                 response = self._send_handling_redirects(\n\u001b[0m\u001b[1;32m    943\u001b[0m                     \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m                     \u001b[0mfollow_redirects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfollow_redirects\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/httpx/_client.py\u001b[0m in \u001b[0;36m_send_handling_redirects\u001b[0;34m(self, request, follow_redirects, history)\u001b[0m\n\u001b[1;32m    977\u001b[0m                 \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    978\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 979\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_single_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    980\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event_hooks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"response\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/httpx/_client.py\u001b[0m in \u001b[0;36m_send_single_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m   1012\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrequest_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1014\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransport\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1015\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSyncByteStream\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/httpx/_transports/default.py\u001b[0m in \u001b[0;36mhandle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    248\u001b[0m         )\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mmap_httpcore_exceptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m             \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtyping\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/httpcore/_sync/connection_pool.py\u001b[0m in \u001b[0;36mhandle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_close_connections\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclosing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 256\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mexc\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m         \u001b[0;31m# Return the response. Note that in this case we still have to manage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/httpcore/_sync/connection_pool.py\u001b[0m in \u001b[0;36mhandle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    234\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m                     \u001b[0;31m# Send the request on the assigned connection.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 236\u001b[0;31m                     response = connection.handle_request(\n\u001b[0m\u001b[1;32m    237\u001b[0m                         \u001b[0mpool_request\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m                     )\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/httpcore/_sync/connection.py\u001b[0m in \u001b[0;36mhandle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    101\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_connection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_connect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mRequest\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mNetworkStream\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/httpcore/_sync/http11.py\u001b[0m in \u001b[0;36mhandle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    134\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"response_closed\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogger\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_response_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m     \u001b[0;31m# Sending the request...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/httpcore/_sync/http11.py\u001b[0m in \u001b[0;36mhandle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    104\u001b[0m                     \u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m                     \u001b[0mtrailing_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m                 ) = self._receive_response_headers(**kwargs)\n\u001b[0m\u001b[1;32m    107\u001b[0m                 trace.return_value = (\n\u001b[1;32m    108\u001b[0m                     \u001b[0mhttp_version\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/httpcore/_sync/http11.py\u001b[0m in \u001b[0;36m_receive_response_headers\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 177\u001b[0;31m             \u001b[0mevent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_receive_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    178\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh11\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mResponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/httpcore/_sync/http11.py\u001b[0m in \u001b[0;36m_receive_event\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mh11\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNEED_DATA\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m                 data = self._network_stream.read(\n\u001b[0m\u001b[1;32m    218\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mREAD_NUM_BYTES\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                 )\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/httpcore/_backends/sync.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, max_bytes, timeout)\u001b[0m\n\u001b[1;32m    126\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mmap_exceptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msettimeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_bytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.12/ssl.py\u001b[0m in \u001b[0;36mrecv\u001b[0;34m(self, buflen, flags)\u001b[0m\n\u001b[1;32m   1230\u001b[0m                     \u001b[0;34m\"non-zero flags not allowed in calls to recv() on %s\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1231\u001b[0m                     self.__class__)\n\u001b[0;32m-> 1232\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuflen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1233\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1234\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuflen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.12/ssl.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1103\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1105\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1106\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mSSLError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1107\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mSSL_ERROR_EOF\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuppress_ragged_eofs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":["\"\"\"from qdrant_client import QdrantClient\n","from qdrant_client.http.models import PointStruct\n","from tqdm import tqdm\n","\n","QDRANT_URL = \"https://b5651607-31ce-49ba-916d-c35c89d731d2.us-east4-0.gcp.cloud.qdrant.io\"\n","QDRANT_API_KEY = \"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJhY2Nlc3MiOiJtIn0.0ApHZL4Qn_A8bx7FCC62nx-IOrHI84W7GZlUZEyVgKk\"\n","COLLECTION_NAME = \"Nirf_Report\"\n","client = QdrantClient(url=QDRANT_URL, api_key=QDRANT_API_KEY)\n","\n","print(\"üîÑ UNDO: Reverting payload structure to original format...\")\n","print(\"=\" * 60)\n","\n","# 1Ô∏è‚É£ Get all points in batches\n","limit = 100\n","offset = 0\n","total_reverted = 0\n","skipped = 0\n","\n","while True:\n","    points = client.scroll(\n","        collection_name=COLLECTION_NAME,\n","        limit=limit,\n","        offset=offset,\n","        with_payload=True,\n","        with_vectors=True\n","    )\n","\n","    if not points[0]:\n","        break\n","\n","    reverted_points = []\n","\n","    for p in points[0]:\n","        old_payload = p.payload or {}\n","\n","        # Skip if already in original format (no \"metadata\" key)\n","        if \"metadata\" not in old_payload:\n","            skipped += 1\n","            continue\n","\n","        # Extract metadata and content\n","        metadata = old_payload.get(\"metadata\", {})\n","        content = old_payload.get(\"content\", \"\")\n","\n","        # Reconstruct original payload structure\n","        original_payload = {**metadata, \"content\": content}\n","\n","        reverted_points.append(\n","            PointStruct(\n","                id=p.id,\n","                vector=p.vector,\n","                payload=original_payload\n","            )\n","        )\n","\n","    # Update the points if any were reverted\n","    if reverted_points:\n","        client.upsert(collection_name=COLLECTION_NAME, points=reverted_points)\n","        total_reverted += len(reverted_points)\n","        print(f\"‚úì Reverted {total_reverted} points so far... (Skipped: {skipped})\")\n","\n","    # Check if we've processed all points\n","    if len(points[0]) < limit:\n","        break\n","\n","    offset += limit\n","\n","print(\"=\" * 60)\n","print(f\"‚úÖ UNDO COMPLETE!\")\n","print(f\"   üìä Total reverted: {total_reverted} points\")\n","print(f\"   ‚è≠Ô∏è  Skipped (already original format): {skipped} points\")\n","print(\"=\" * 60)\n","\n","# Verify the structure by showing a sample\n","print(\"\\nüîç Verifying: Showing sample point structure...\")\n","sample = client.scroll(\n","    collection_name=COLLECTION_NAME,\n","    limit=1,\n","    with_payload=True,\n","    with_vectors=False\n",")\n","\n","if sample[0]:\n","    print(\"\\nSample payload structure:\")\n","    print(f\"Keys: {list(sample[0][0].payload.keys())}\")\n","    print(f\"\\nFull payload preview:\")\n","    import json\n","    print(json.dumps(sample[0][0].payload, indent=2, default=str)[:500] + \"...\")\n","else:\n","    print(\"‚ö†Ô∏è  No points found in collection\")"],"metadata":{"id":"SZI2i9lHmH_D"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\"\"\"from qdrant_client import QdrantClient\n","from qdrant_client.http.models import PointStruct, Filter, FieldCondition, MatchValue\n","from tqdm import tqdm\n","import time\n","\n","QDRANT_URL = \"https://b5651607-31ce-49ba-916d-c35c89d731d2.us-east4-0.gcp.cloud.qdrant.io\"\n","QDRANT_API_KEY = \"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJhY2Nlc3MiOiJtIn0.0ApHZL4Qn_A8bx7FCC62nx-IOrHI84W7GZlUZEyVgKk\"\n","COLLECTION_NAME = \"Nirf_Report\"\n","client = QdrantClient(url=QDRANT_URL, api_key=QDRANT_API_KEY)\n","\n","# Configuration\n","BATCH_SIZE = 500  # Larger batches for faster processing\n","CHECKPOINT_FILE = \"conversion_checkpoint.txt\"\n","\n","def load_checkpoint():\n","    \"\"\"Load the last processed offset from checkpoint file\"\"\"\n","    try:\n","        with open(CHECKPOINT_FILE, 'r') as f:\n","            return int(f.read().strip())\n","    except FileNotFoundError:\n","        return 0\n","\n","def save_checkpoint(offset):\n","    \"\"\"Save current offset to checkpoint file\"\"\"\n","    with open(CHECKPOINT_FILE, 'w') as f:\n","        f.write(str(offset))\n","\n","def get_total_count():\n","    \"\"\"Get total count of points in collection\"\"\"\n","    collection_info = client.get_collection(COLLECTION_NAME)\n","    return collection_info.points_count\n","\n","def needs_conversion(payload):\n","    \"\"\"Check if a point needs conversion\"\"\"\n","    if not payload:\n","        return False\n","    # Already converted if it has 'metadata' key at root level\n","    if \"metadata\" in payload and \"content\" in payload:\n","        return False\n","    return True\n","\n","# Get starting point\n","start_offset = load_checkpoint()\n","total_points = get_total_count()\n","print(f\"üìä Total points in collection: {total_points}\")\n","print(f\"üîÑ Starting from offset: {start_offset}\")\n","\n","offset = start_offset\n","total_converted = 0\n","total_skipped = 0\n","start_time = time.time()\n","\n","# Progress bar\n","pbar = tqdm(total=total_points, initial=start_offset, desc=\"Processing points\")\n","\n","try:\n","    while offset < total_points:\n","        # Fetch batch with scroll\n","        points, next_offset = client.scroll(\n","            collection_name=COLLECTION_NAME,\n","            limit=BATCH_SIZE,\n","            offset=offset,\n","            with_payload=True,\n","            with_vectors=True\n","        )\n","\n","        if not points:\n","            break\n","\n","        # Filter points that need conversion\n","        points_to_convert = []\n","        for p in points:\n","            if needs_conversion(p.payload):\n","                old_payload = p.payload\n","                payload = old_payload.get(\"payload\", old_payload)\n","\n","                # Extract metadata and content\n","                metadata = {k: v for k, v in payload.items() if k != \"content\"}\n","                new_payload = {\n","                    \"metadata\": metadata,\n","                    \"content\": payload.get(\"content\", \"\")\n","                }\n","\n","                points_to_convert.append(\n","                    PointStruct(\n","                        id=p.id,\n","                        vector=p.vector,\n","                        payload=new_payload\n","                    )\n","                )\n","            else:\n","                total_skipped += 1\n","\n","        # Batch upsert if there are points to convert\n","        if points_to_convert:\n","            client.upsert(\n","                collection_name=COLLECTION_NAME,\n","                points=points_to_convert,\n","                wait=False  # Don't wait for indexing to complete\n","            )\n","            total_converted += len(points_to_convert)\n","\n","        # Update progress\n","        offset = next_offset if next_offset else offset + len(points)\n","        pbar.update(len(points))\n","        pbar.set_postfix({\n","            'converted': total_converted,\n","            'skipped': total_skipped,\n","            'rate': f\"{total_converted / (time.time() - start_time):.1f} pts/s\"\n","        })\n","\n","        # Save checkpoint every batch\n","        save_checkpoint(offset)\n","\n","        # Break if we've processed all points\n","        if len(points) < BATCH_SIZE or not next_offset:\n","            break\n","\n","except KeyboardInterrupt:\n","    print(f\"\\n‚ö†Ô∏è Interrupted! Progress saved at offset {offset}\")\n","    save_checkpoint(offset)\n","    pbar.close()\n","    exit(1)\n","\n","pbar.close()\n","elapsed = time.time() - start_time\n","\n","print(f\"\\n‚úÖ Conversion complete!\")\n","print(f\"   üìù Converted: {total_converted} points\")\n","print(f\"   ‚è≠Ô∏è  Skipped: {total_skipped} points (already converted)\")\n","print(f\"   ‚è±Ô∏è  Time: {elapsed:.2f}s ({total_converted / elapsed:.1f} points/sec)\")\n","print(f\"   üíæ Checkpoint saved at offset: {offset}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":263},"id":"APBmQoTbQHyJ","executionInfo":{"status":"error","timestamp":1762417218912,"user_tz":-330,"elapsed":1750,"user":{"displayName":"Rahul Siddhu","userId":"12007764243202946991"}},"outputId":"ad9f6582-045d-48c9-dc19-970ff9d339d8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["üìä Total points in collection: 726\n","üîÑ Starting from offset: 0\n"]},{"output_type":"stream","name":"stderr","text":["Processing points:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 500/726 [00:01<00:00, 463.63it/s, converted=400, skipped=100, rate=369.2 pts/s]"]},{"output_type":"error","ename":"TypeError","evalue":"'<' not supported between instances of 'str' and 'int'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-638762092.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m     \u001b[0;32mwhile\u001b[0m \u001b[0moffset\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mtotal_points\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m         \u001b[0;31m# Fetch batch with scroll\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         points, next_offset = client.scroll(\n","\u001b[0;31mTypeError\u001b[0m: '<' not supported between instances of 'str' and 'int'"]}]},{"cell_type":"code","source":["from qdrant_client import QdrantClient\n","from qdrant_client.http.models import PointStruct\n","from tqdm import tqdm\n","import time\n","\n","QDRANT_URL = \"https://b5651607-31ce-49ba-916d-c35c89d731d2.us-east4-0.gcp.cloud.qdrant.io\"\n","QDRANT_API_KEY = \"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJhY2Nlc3MiOiJtIn0.0ApHZL4Qn_A8bx7FCC62nx-IOrHI84W7GZlUZEyVgKk\"\n","COLLECTION_NAME = \"valid\"\n","client = QdrantClient(url=QDRANT_URL, api_key=QDRANT_API_KEY)\n","\n","# Configuration\n","BATCH_SIZE = 500  # Larger batches for faster processing\n","CHECKPOINT_FILE = \"conversion_checkpoint.txt\"\n","\n","def load_checkpoint():\n","    \"\"\"Load the last processed point ID from checkpoint file\"\"\"\n","    try:\n","        with open(CHECKPOINT_FILE, 'r') as f:\n","            content = f.read().strip()\n","            return content if content and content != \"None\" else None\n","    except FileNotFoundError:\n","        return None\n","\n","def save_checkpoint(point_id):\n","    \"\"\"Save current point ID to checkpoint file\"\"\"\n","    with open(CHECKPOINT_FILE, 'w') as f:\n","        f.write(str(point_id) if point_id else \"None\")\n","\n","def get_total_count():\n","    \"\"\"Get total count of points in collection\"\"\"\n","    collection_info = client.get_collection(COLLECTION_NAME)\n","    return collection_info.points_count\n","\n","def needs_conversion(payload):\n","    \"\"\"Check if a point needs conversion\"\"\"\n","    if not payload:\n","        return False\n","    # Already converted if it has 'metadata' key at root level\n","    if \"metadata\" in payload and \"content\" in payload:\n","        return False\n","    return True\n","\n","# Get starting point\n","start_offset = load_checkpoint()\n","total_points = get_total_count()\n","print(f\"üìä Total points in collection: {total_points}\")\n","if start_offset:\n","    print(f\"üîÑ Resuming from checkpoint: {start_offset}\")\n","else:\n","    print(f\"üîÑ Starting from beginning\")\n","\n","total_converted = 0\n","total_skipped = 0\n","processed_count = 0\n","start_time = time.time()\n","\n","# Progress bar\n","pbar = tqdm(total=total_points, desc=\"Processing points\")\n","\n","try:\n","    current_offset = start_offset\n","\n","    while True:\n","        # Fetch batch with scroll\n","        points, next_offset = client.scroll(\n","            collection_name=COLLECTION_NAME,\n","            limit=BATCH_SIZE,\n","            offset=current_offset,\n","            with_payload=True,\n","            with_vectors=True\n","        )\n","\n","        if not points:\n","            break\n","\n","        # Filter points that need conversion\n","        points_to_convert = []\n","        for p in points:\n","            if needs_conversion(p.payload):\n","                old_payload = p.payload\n","                payload = old_payload.get(\"payload\", old_payload)\n","\n","                # Extract metadata and content\n","                metadata = {k: v for k, v in payload.items() if k != \"content\"}\n","                new_payload = {\n","                    \"metadata\": metadata,\n","                    \"content\": payload.get(\"content\", \"\")\n","                }\n","\n","                points_to_convert.append(\n","                    PointStruct(\n","                        id=p.id,\n","                        vector=p.vector,\n","                        payload=new_payload\n","                    )\n","                )\n","            else:\n","                total_skipped += 1\n","\n","        # Batch upsert if there are points to convert\n","        if points_to_convert:\n","            client.upsert(\n","                collection_name=COLLECTION_NAME,\n","                points=points_to_convert,\n","                wait=False  # Don't wait for indexing to complete\n","            )\n","            total_converted += len(points_to_convert)\n","\n","        # Update progress\n","        processed_count += len(points)\n","        pbar.update(len(points))\n","        pbar.set_postfix({\n","            'converted': total_converted,\n","            'skipped': total_skipped,\n","            'rate': f\"{total_converted / (time.time() - start_time):.1f} pts/s\"\n","        })\n","\n","        # Save checkpoint (last point ID in this batch)\n","        if points:\n","            save_checkpoint(points[-1].id)\n","\n","        # Move to next batch\n","        current_offset = next_offset\n","\n","        # Break if no more points\n","        if not next_offset or len(points) < BATCH_SIZE:\n","            break\n","\n","except KeyboardInterrupt:\n","    print(f\"\\n‚ö†Ô∏è Interrupted! Progress saved at last point ID\")\n","    pbar.close()\n","    exit(1)\n","except Exception as e:\n","    print(f\"\\n‚ùå Error occurred: {e}\")\n","    print(f\"Progress saved. You can resume by running the script again.\")\n","    pbar.close()\n","    raise\n","\n","pbar.close()\n","elapsed = time.time() - start_time\n","\n","print(f\"\\n‚úÖ Conversion complete!\")\n","print(f\"   üìù Converted: {total_converted} points\")\n","print(f\"   ‚è≠Ô∏è  Skipped: {total_skipped} points (already converted)\")\n","print(f\"   ‚è±Ô∏è  Time: {elapsed:.2f}s ({total_converted / elapsed:.1f} points/sec)\" if elapsed > 0 else \"\")\n","print(f\"   üíæ Total processed: {processed_count}/{total_points}\")\n","\n","# Clean up checkpoint file when done\n","import os\n","if os.path.exists(CHECKPOINT_FILE):\n","    os.remove(CHECKPOINT_FILE)\n","    print(f\"   üóëÔ∏è  Checkpoint file removed\")"],"metadata":{"id":"UXHufLlAQUhB","executionInfo":{"status":"ok","timestamp":1762854354940,"user_tz":-330,"elapsed":3641,"user":{"displayName":"Rahul Siddhu","userId":"12007764243202946991"}},"outputId":"74b08278-062c-40e1-93ca-544f85c69104","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["üìä Total points in collection: 120\n","üîÑ Starting from beginning\n"]},{"output_type":"stream","name":"stderr","text":["Processing points: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 120/120 [00:02<00:00, 52.41it/s, converted=120, skipped=0, rate=52.4 pts/s]"]},{"output_type":"stream","name":"stdout","text":["\n","‚úÖ Conversion complete!\n","   üìù Converted: 120 points\n","   ‚è≠Ô∏è  Skipped: 0 points (already converted)\n","   ‚è±Ô∏è  Time: 2.29s (52.3 points/sec)\n","   üíæ Total processed: 120/120\n","   üóëÔ∏è  Checkpoint file removed\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]},{"cell_type":"code","source":["from qdrant_client import QdrantClient\n","from qdrant_client.http.models import PointStruct\n","from tqdm import tqdm\n","import time\n","\n","QDRANT_URL = \"https://b5651607-31ce-49ba-916d-c35c89d731d2.us-east4-0.gcp.cloud.qdrant.io\"\n","QDRANT_API_KEY = \"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJhY2Nlc3MiOiJtIn0.0ApHZL4Qn_A8bx7FCC62nx-IOrHI84W7GZlUZEyVgKk\"\n","COLLECTION_NAME = \"durden\"\n","client = QdrantClient(url=QDRANT_URL, api_key=QDRANT_API_KEY)\n","\n","# Configuration\n","BATCH_SIZE = 500  # Larger batches for faster processing\n","CHECKPOINT_FILE = \"conversion_checkpoint.txt\"\n","\n","def load_checkpoint():\n","    \"\"\"Load the last processed point ID from checkpoint file\"\"\"\n","    try:\n","        with open(CHECKPOINT_FILE, 'r') as f:\n","            content = f.read().strip()\n","            return content if content and content != \"None\" else None\n","    except FileNotFoundError:\n","        return None\n","\n","def save_checkpoint(point_id):\n","    \"\"\"Save current point ID to checkpoint file\"\"\"\n","    with open(CHECKPOINT_FILE, 'w') as f:\n","        f.write(str(point_id) if point_id else \"None\")\n","\n","def get_total_count():\n","    \"\"\"Get total count of points in collection\"\"\"\n","    collection_info = client.get_collection(COLLECTION_NAME)\n","    return collection_info.points_count\n","\n","def needs_conversion(payload):\n","    \"\"\"Check if a point needs conversion\"\"\"\n","    if not payload:\n","        return False\n","    # Already converted if it has 'metadata' key at root level\n","    if \"metadata\" in payload and \"content\" in payload:\n","        return False\n","    return True\n","\n","# Get starting point\n","start_offset = load_checkpoint()\n","total_points = get_total_count()\n","print(f\"üìä Total points in collection: {total_points}\")\n","if start_offset:\n","    print(f\"üîÑ Resuming from checkpoint: {start_offset}\")\n","else:\n","    print(f\"üîÑ Starting from beginning\")\n","\n","total_converted = 0\n","total_skipped = 0\n","processed_count = 0\n","start_time = time.time()\n","\n","# Progress bar\n","pbar = tqdm(total=total_points, desc=\"Processing points\")\n","\n","try:\n","    current_offset = start_offset\n","\n","    while True:\n","        # Fetch batch with scroll\n","        points, next_offset = client.scroll(\n","            collection_name=COLLECTION_NAME,\n","            limit=BATCH_SIZE,\n","            offset=current_offset,\n","            with_payload=True,\n","            with_vectors=True\n","        )\n","\n","        if not points:\n","            break\n","\n","        # Filter points that need conversion\n","        points_to_convert = []\n","        for p in points:\n","            if needs_conversion(p.payload):\n","                old_payload = p.payload\n","                payload = old_payload.get(\"payload\", old_payload)\n","\n","                # Extract metadata and content\n","                metadata = {k: v for k, v in payload.items() if k != \"content\"}\n","                new_payload = {\n","                    \"metadata\": metadata,\n","                    \"content\": payload.get(\"content\", \"\")\n","                }\n","\n","                points_to_convert.append(\n","                    PointStruct(\n","                        id=p.id,\n","                        vector=p.vector,\n","                        payload=new_payload\n","                    )\n","                )\n","            else:\n","                total_skipped += 1\n","\n","        # Batch upsert if there are points to convert\n","        if points_to_convert:\n","            client.upsert(\n","                collection_name=COLLECTION_NAME,\n","                points=points_to_convert,\n","                wait=False  # Don't wait for indexing to complete\n","            )\n","            total_converted += len(points_to_convert)\n","\n","        # Update progress\n","        processed_count += len(points)\n","        pbar.update(len(points))\n","        pbar.set_postfix({\n","            'converted': total_converted,\n","            'skipped': total_skipped,\n","            'rate': f\"{total_converted / (time.time() - start_time):.1f} pts/s\"\n","        })\n","\n","        # Save checkpoint (last point ID in this batch)\n","        if points:\n","            save_checkpoint(points[-1].id)\n","\n","        # Move to next batch\n","        current_offset = next_offset\n","\n","        # Break if no more points\n","        if not next_offset or len(points) < BATCH_SIZE:\n","            break\n","\n","except KeyboardInterrupt:\n","    print(f\"\\n‚ö†Ô∏è Interrupted! Progress saved at last point ID\")\n","    pbar.close()\n","    exit(1)\n","except Exception as e:\n","    print(f\"\\n‚ùå Error occurred: {e}\")\n","    print(f\"Progress saved. You can resume by running the script again.\")\n","    pbar.close()\n","    raise\n","\n","pbar.close()\n","elapsed = time.time() - start_time\n","\n","print(f\"\\n‚úÖ Conversion complete!\")\n","print(f\"   üìù Converted: {total_converted} points\")\n","print(f\"   ‚è≠Ô∏è  Skipped: {total_skipped} points (already converted)\")\n","print(f\"   ‚è±Ô∏è  Time: {elapsed:.2f}s ({total_converted / elapsed:.1f} points/sec)\" if elapsed > 0 else \"\")\n","print(f\"   üíæ Total processed: {processed_count}/{total_points}\")\n","\n","# Clean up checkpoint file when done\n","import os\n","if os.path.exists(CHECKPOINT_FILE):\n","    os.remove(CHECKPOINT_FILE)\n","    print(f\"   üóëÔ∏è  Checkpoint file removed\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"N3pvi-GZmaFn","executionInfo":{"status":"ok","timestamp":1762976725211,"user_tz":-330,"elapsed":3217,"user":{"displayName":"Rahul Siddhu","userId":"12007764243202946991"}},"outputId":"0c6971b6-825d-437e-ad6e-3d9674aa253f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["üìä Total points in collection: 1190\n","üîÑ Starting from beginning\n"]},{"output_type":"stream","name":"stderr","text":["Processing points: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1190/1190 [00:02<00:00, 466.11it/s, converted=1090, skipped=100, rate=426.1 pts/s]"]},{"output_type":"stream","name":"stdout","text":["\n","‚úÖ Conversion complete!\n","   üìù Converted: 1090 points\n","   ‚è≠Ô∏è  Skipped: 100 points (already converted)\n","   ‚è±Ô∏è  Time: 2.56s (425.6 points/sec)\n","   üíæ Total processed: 1190/1190\n","   üóëÔ∏è  Checkpoint file removed\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]},{"cell_type":"code","source":["from qdrant_client.http import models\n","from qdrant_client import QdrantClient\n","\n","client = QdrantClient(\n","    url=\"https://b5651607-31ce-49ba-916d-c35c89d731d2.us-east4-0.gcp.cloud.qdrant.io\",\n","    api_key=\"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJhY2Nlc3MiOiJtIn0.0ApHZL4Qn_A8bx7FCC62nx-IOrHI84W7GZlUZEyVgKk\"\n",")\n","\n","# Create keyword index for the nested field\n","client.create_payload_index(\n","    collection_name=\"durden\",\n","    field_name=\"metadata.institute_name\",\n","    field_schema=models.PayloadSchemaType.KEYWORD\n",")\n","\n","print(\"‚úÖ Index created successfully for metadata.institute_name\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":383},"id":"6v8FvLR_0YtX","executionInfo":{"status":"error","timestamp":1763025696121,"user_tz":-330,"elapsed":23,"user":{"displayName":"Rahul Siddhu","userId":"12007764243202946991"}},"outputId":"d5432395-f5c9-40cd-b9a0-f34eb368a079"},"execution_count":1,"outputs":[{"output_type":"error","ename":"ModuleNotFoundError","evalue":"No module named 'qdrant_client'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-3860088815.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mqdrant_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhttp\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mqdrant_client\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mQdrantClient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m client = QdrantClient(\n\u001b[1;32m      5\u001b[0m     \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"https://b5651607-31ce-49ba-916d-c35c89d731d2.us-east4-0.gcp.cloud.qdrant.io\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'qdrant_client'","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"],"errorDetails":{"actions":[{"action":"open_url","actionText":"Open Examples","url":"/notebooks/snippets/importing_libraries.ipynb"}]}}]},{"cell_type":"code","source":["\"\"\"from qdrant_client import QdrantClient\n","from qdrant_client.http import models\n","\n","client = QdrantClient(\n","    url=\"https://b5651607-31ce-49ba-916d-c35c89d731d2.us-east4-0.gcp.cloud.qdrant.io\",\n","    api_key=\"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJhY2Nlc3MiOiJtIn0.0ApHZL4Qn_A8bx7FCC62nx-IOrHI84W7GZlUZEyVgKk\"\n",")\n","\n","# Step 1: Retrieve all points where content_type = \"FACULTY_DETAILS\"\n","offset = None\n","updated_count = 0\n","\n","while True:\n","    results, next_offset = client.scroll(\n","        collection_name=\"valid\",\n","        scroll_filter=models.Filter(\n","            must=[\n","                models.FieldCondition(\n","                    key=\"metadata.content_type\",\n","                    match=models.MatchValue(value=\"FACULTY_DETAILS\")\n","                )\n","            ]\n","        ),\n","        limit=100,\n","        offset=offset,\n","        with_payload=True,\n","        with_vectors=False\n","    )\n","\n","    if not results:\n","        break\n","\n","    # Step 2: Update each point's metadata.Nirf_category to \"TLR\"\n","    for point in results:\n","        point.payload[\"metadata\"][\"Nirf_category\"] = \"TLR\"\n","\n","        client.upsert(\n","            collection_name=\"Nirf_Report\",\n","            points=[\n","                models.PointStruct(\n","                    id=point.id,\n","                    payload=point.payload,\n","                    vector=point.vector if point.vector else {}\n","                )\n","            ]\n","        )\n","        updated_count += 1\n","\n","    print(f\"‚úÖ Updated {len(results)} points in this batch\")\n","\n","    offset = next_offset\n","    if offset is None:\n","        break\n","\n","print(f\"‚úÖ Total points updated: {updated_count}\")\n","print(\"‚úÖ All FACULTY_DETAILS entries now have Nirf_category = 'TLR'\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6VFGB-ukmLrr","executionInfo":{"status":"ok","timestamp":1762909694429,"user_tz":-330,"elapsed":3937,"user":{"displayName":"Rahul Siddhu","userId":"12007764243202946991"}},"outputId":"96306d15-6c86-4ca9-da5c-3b4ba4bfa8e6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["‚úÖ Updated 10 points in this batch\n","‚úÖ Total points updated: 10\n","‚úÖ All FACULTY_DETAILS entries now have Nirf_category = 'TLR'\n"]}]},{"cell_type":"code","source":["#previously used Nirf_Report as ceoolection name and field name as metadat.Nirf_Category\n","from qdrant_client import QdrantClient\n","from qdrant_client.http import models\n","\n","client = QdrantClient(\n","    url=\"https://b5651607-31ce-49ba-916d-c35c89d731d2.us-east4-0.gcp.cloud.qdrant.io\",\n","    api_key=\"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJhY2Nlc3MiOiJtIn0.0ApHZL4Qn_A8bx7FCC62nx-IOrHI84W7GZlUZEyVgKk\"\n",")\n","\n","client.create_payload_index(\n","    collection_name=\"Placement_details_New\",\n","    field_name=\"metadata.branch\",\n","    field_schema=models.PayloadSchemaType.KEYWORD\n",")\n","\n","print(\"‚úÖ Index created successfully for metadata.branch\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HF1ePXQB8CFq","executionInfo":{"status":"ok","timestamp":1762836542654,"user_tz":-330,"elapsed":707,"user":{"displayName":"Rahul Siddhu","userId":"12007764243202946991"}},"outputId":"e5ce2a07-325f-4f1f-ea21-1e80f563e1c9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["‚úÖ Index created successfully for metadata.branch\n"]}]},{"cell_type":"code","source":["\"\"\"from qdrant_client import QdrantClient\n","\n","# ‚úÖ Connect to your Qdrant Cloud instance\n","client = QdrantClient(\n","    url=\"https://b5651607-31ce-49ba-916d-c35c89d731d2.us-east4-0.gcp.cloud.qdrant.io\",\n","    api_key=\"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJhY2Nlc3MiOiJtIn0.0ApHZL4Qn_A8bx7FCC62nx-IOrHI84W7GZlUZEyVgKk\"\n",")\n","\n","collection_name = \"Nirf_Report\"\n","updated_count = 0\n","\n","# Step 1Ô∏è‚É£: Filter all points with Nirf_category = \"RP\"\n","scroll_filter = {\n","    \"must\": [\n","        {\"key\": \"metadata.Nirf_category\", \"match\": {\"value\": \"RP\"}}\n","    ]\n","}\n","\n","points, next_page = client.scroll(\n","    collection_name=collection_name,\n","    scroll_filter=scroll_filter,\n","    with_payload=True,\n","    limit=100\n",")\n","\n","# Step 2Ô∏è‚É£: Update all matching points ‚Üí RPC\n","while points:\n","    for p in points:\n","        point_id = p.id\n","        client.set_payload(\n","            collection_name=collection_name,\n","            payload={\"metadata.Nirf_category\": \"RPC\"},\n","            points=[point_id]\n","        )\n","        updated_count += 1\n","\n","    if not next_page:\n","        break\n","\n","    points, next_page = client.scroll(\n","        collection_name=collection_name,\n","        scroll_filter=scroll_filter,\n","        with_payload=True,\n","        limit=100,\n","        offset=next_page\n","    )\n","\n","print(f\"‚úÖ Successfully updated {updated_count} points from 'rp' ‚Üí 'RPC' across all colleges!\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wuCuIbkfOTuT","executionInfo":{"status":"ok","timestamp":1762534392024,"user_tz":-330,"elapsed":8551,"user":{"displayName":"Rahul Siddhu","userId":"12007764243202946991"}},"outputId":"2ad09278-0f7d-451e-82fe-35f33891aada"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["‚úÖ Successfully updated 164 points from 'rp' ‚Üí 'RPC' across all colleges!\n"]}]},{"cell_type":"code","source":["from qdrant_client import QdrantClient\n","from collections import Counter\n","\n","client = QdrantClient(\n","    url=\"https://b5651607-31ce-49ba-916d-c35c89d731d2.us-east4-0.gcp.cloud.qdrant.io\",\n","    api_key=\"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJhY2Nlc3MiOiJtIn0.0ApHZL4Qn_A8bx7FCC62nx-IOrHI84W7GZlUZEyVgKk\"\n",")\n","\n","collection_name = \"Placement_details_New\"\n","cats = Counter()\n","\n","points, next_page = client.scroll(collection_name=collection_name, with_payload=True, limit=100)\n","\n","while points:\n","    for p in points:\n","        cat = p.payload.get(\"metadata\", {}).get(\"college_name\")\n","        if cat:\n","            cats[cat] += 1\n","    if not next_page:\n","        break\n","    points, next_page = client.scroll(\n","        collection_name=collection_name,\n","        with_payload=True,\n","        limit=100,\n","        offset=next_page\n","    )\n","\n","print(\"Unique Nirf_category values found in Qdrant:\")\n","for c, n in cats.items():\n","    print(f\"'{c}' ‚Äî {n} points\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Jd_6NrcFPqEA","executionInfo":{"status":"ok","timestamp":1762928145602,"user_tz":-330,"elapsed":1906,"user":{"displayName":"Rahul Siddhu","userId":"12007764243202946991"}},"outputId":"da585cd5-ae35-4933-c061-9be565d370e4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Unique Nirf_category values found in Qdrant:\n","'IIT BHU' ‚Äî 39 points\n","'NIT Trichy' ‚Äî 21 points\n","'IIT Bombay' ‚Äî 20 points\n","'Indian Institute of Technology, Madras' ‚Äî 39 points\n","'IIT Kharagpur' ‚Äî 11 points\n","'IIIT Delhi' ‚Äî 22 points\n","'IIT Guwahati' ‚Äî 28 points\n","'Jadavpur University' ‚Äî 1 points\n","'IIT Kanpur' ‚Äî 11 points\n","'IIT Roorkee' ‚Äî 19 points\n","'IIT Hyderabad' ‚Äî 14 points\n","'VIT Vellore' ‚Äî 2 points\n"]}]},{"cell_type":"code","source":["from qdrant_client import QdrantClient\n","from collections import Counter\n","\n","client = QdrantClient(\n","    url=\"https://b5651607-31ce-49ba-916d-c35c89d731d2.us-east4-0.gcp.cloud.qdrant.io\",\n","    api_key=\"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJhY2Nlc3MiOiJtIn0.0ApHZL4Qn_A8bx7FCC62nx-IOrHI84W7GZlUZEyVgKk\"\n",")\n","\n","collection_name = \"valid\"\n","cats = Counter()\n","\n","points, next_page = client.scroll(collection_name=collection_name, with_payload=True, limit=100)\n","\n","while points:\n","    for p in points:\n","        cat = p.payload.get(\"metadata\", {}).get(\"institute_name\")\n","        if cat:\n","            cats[cat] += 1\n","    if not next_page:\n","        break\n","    points, next_page = client.scroll(\n","        collection_name=collection_name,\n","        with_payload=True,\n","        limit=100,\n","        offset=next_page\n","    )\n","\n","print(\"Unique Nirf_category values found in Qdrant:\")\n","for c, n in cats.items():\n","    print(f\"'{c}' ‚Äî {n} points\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VCPW2jos3f66","executionInfo":{"status":"ok","timestamp":1762964472332,"user_tz":-330,"elapsed":6486,"user":{"displayName":"Rahul Siddhu","userId":"12007764243202946991"}},"outputId":"5b6dde66-91fa-495f-b5ff-864a2de5db1f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Unique Nirf_category values found in Qdrant:\n","'Madan Mohan Malaviya University of Technology' ‚Äî 12 points\n","'International Institute of Information Technology Hyderabad' ‚Äî 12 points\n","'SR University' ‚Äî 12 points\n","'Indian Institute of Technology Bhubaneswar' ‚Äî 12 points\n","'Banasthali Vidyapith' ‚Äî 12 points\n","'Indian Institute of Technology Patna' ‚Äî 12 points\n","'Vignan's Foundation for Science, Technology and Research' ‚Äî 12 points\n","'Christ University' ‚Äî 12 points\n","'Indraprastha Institute of Information Technology' ‚Äî 12 points\n","'Saveetha Institute of Medical and Technical Sciences' ‚Äî 12 points\n"]}]},{"cell_type":"code","source":["\"\"\"from qdrant_client import QdrantClient\n","\n","# ‚úÖ Connect to your Qdrant Cloud instance\n","client = QdrantClient(\n","    url=\"https://b5651607-31ce-49ba-916d-c35c89d731d2.us-east4-0.gcp.cloud.qdrant.io\",\n","    api_key=\"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJhY2Nlc3MiOiJtIn0.0ApHZL4Qn_A8bx7FCC62nx-IOrHI84W7GZlUZEyVgKk\"\n",")\n","\n","collection_name = \"Nirf_Report\"\n","updated_count = 0\n","\n","# Step 1Ô∏è‚É£: Filter all points with Nirf_category = \"RPC\"\n","scroll_filter = {\n","    \"must\": [\n","        {\"key\": \"metadata.Nirf_category\", \"match\": {\"value\": \"RPC\"}}\n","    ]\n","}\n","\n","points, next_page = client.scroll(\n","    collection_name=collection_name,\n","    scroll_filter=scroll_filter,\n","    with_payload=True,\n","    limit=100\n",")\n","\n","# Step 2Ô∏è‚É£: Update all matching points ‚Üí RP (undo)\n","while points:\n","    for p in points:\n","        point_id = p.id\n","        client.set_payload(\n","            collection_name=collection_name,\n","            payload={\"metadata.Nirf_category\": \"RP\"},\n","            points=[point_id]\n","        )\n","        updated_count += 1\n","\n","    if not next_page:\n","        break\n","\n","    points, next_page = client.scroll(\n","        collection_name=collection_name,\n","        scroll_filter=scroll_filter,\n","        with_payload=True,\n","        limit=100,\n","        offset=next_page\n","    )\n","\n","print(f\"‚úÖ Successfully reverted {updated_count} points from 'RPC' ‚Üí 'RP' across all colleges!\")\n","\"\"\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FbqjQIiKP7J1","executionInfo":{"status":"ok","timestamp":1762534604267,"user_tz":-330,"elapsed":591,"user":{"displayName":"Rahul Siddhu","userId":"12007764243202946991"}},"outputId":"2bb53a54-4e1a-4e1e-993d-a052287442be"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["‚úÖ Successfully reverted 0 points from 'RPC' ‚Üí 'RP' across all colleges!\n"]}]}],"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyM0qr9HC8TTI7xVu98nmSXH"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"f95ae79d5b8a41c2a8a4cc5d071dc168":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_92836fd9e6444b8a953e5820045426ab","IPY_MODEL_f4b9215cc4bf4265b4858ba864b5a072","IPY_MODEL_fdce9f4e403f403aaaefe9d91f405bd3"],"layout":"IPY_MODEL_991f4b1350eb4bd7b14670757e095a5d"}},"92836fd9e6444b8a953e5820045426ab":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9f8e9c6deb964e7f92a95be1777cd1ec","placeholder":"‚Äã","style":"IPY_MODEL_016bac5a4ada47498a131995b3f687d4","value":"modules.json:‚Äá100%"}},"f4b9215cc4bf4265b4858ba864b5a072":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_97b4a4229c0c440bab22532be039968a","max":349,"min":0,"orientation":"horizontal","style":"IPY_MODEL_3f60fa0ad2ca4a2da51fe861977529ec","value":349}},"fdce9f4e403f403aaaefe9d91f405bd3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_26334de40b254b02b3efef9518caebcd","placeholder":"‚Äã","style":"IPY_MODEL_e35c68829cfc4a8db0274a39e10ea6d0","value":"‚Äá349/349‚Äá[00:00&lt;00:00,‚Äá30.3kB/s]"}},"991f4b1350eb4bd7b14670757e095a5d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9f8e9c6deb964e7f92a95be1777cd1ec":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"016bac5a4ada47498a131995b3f687d4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"97b4a4229c0c440bab22532be039968a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3f60fa0ad2ca4a2da51fe861977529ec":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"26334de40b254b02b3efef9518caebcd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e35c68829cfc4a8db0274a39e10ea6d0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2cabb1e4f13c482b90fa7da2d88a886e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_1d5fea18e826425095cd200d4fe45a18","IPY_MODEL_b1aa6515a07549b098f74da12b1d9757","IPY_MODEL_108f94f7b958442f8f9a53b3a0ec090f"],"layout":"IPY_MODEL_1bc4cf22ff4d445d9006270014ebc612"}},"1d5fea18e826425095cd200d4fe45a18":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a5ce2f08cf094a9ab9784943454d95b6","placeholder":"‚Äã","style":"IPY_MODEL_16b604ba150b4f67b5a0caa85f2096c0","value":"config_sentence_transformers.json:‚Äá100%"}},"b1aa6515a07549b098f74da12b1d9757":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_691096338a1f428280e92b954e01fa65","max":116,"min":0,"orientation":"horizontal","style":"IPY_MODEL_65795ac97c2540e597384d00761c8cb8","value":116}},"108f94f7b958442f8f9a53b3a0ec090f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_984076454bfe4f99b41fd71f382af621","placeholder":"‚Äã","style":"IPY_MODEL_4252327f3c2a4ee392131163dc3e7054","value":"‚Äá116/116‚Äá[00:00&lt;00:00,‚Äá10.2kB/s]"}},"1bc4cf22ff4d445d9006270014ebc612":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a5ce2f08cf094a9ab9784943454d95b6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"16b604ba150b4f67b5a0caa85f2096c0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"691096338a1f428280e92b954e01fa65":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"65795ac97c2540e597384d00761c8cb8":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"984076454bfe4f99b41fd71f382af621":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4252327f3c2a4ee392131163dc3e7054":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"474510d6f3ef4309b4526077bbba531c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_32b22948ee5a42df9dabb840ffbfea23","IPY_MODEL_84221745a880475db0a3db28ff7be1de","IPY_MODEL_7698b8abf46a43038f4e6a8c64f4420f"],"layout":"IPY_MODEL_2d554dfefd83404a946faefd027c639c"}},"32b22948ee5a42df9dabb840ffbfea23":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7ee3327a332c4c01a23588e570595d0e","placeholder":"‚Äã","style":"IPY_MODEL_44929dca1b6f45358f831cdb7077f7e4","value":"README.md:‚Äá"}},"84221745a880475db0a3db28ff7be1de":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_46d0d5855e604a979b4669a9ebac7131","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_06463605d7504671b1399e0d8ecf07df","value":1}},"7698b8abf46a43038f4e6a8c64f4420f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bf6195ba2c08406da0720da1e5be9eb0","placeholder":"‚Äã","style":"IPY_MODEL_665d7b3a0b1b4b5587a681e1deb7f656","value":"‚Äá10.5k/?‚Äá[00:00&lt;00:00,‚Äá805kB/s]"}},"2d554dfefd83404a946faefd027c639c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7ee3327a332c4c01a23588e570595d0e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"44929dca1b6f45358f831cdb7077f7e4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"46d0d5855e604a979b4669a9ebac7131":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"06463605d7504671b1399e0d8ecf07df":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"bf6195ba2c08406da0720da1e5be9eb0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"665d7b3a0b1b4b5587a681e1deb7f656":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f9e09ae2bec24e98a9f2e5e11f441af5":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_5b02ed9ab01743fda0e00e2d9b0358b1","IPY_MODEL_1c7d2d385dda4e0093c102a901c663fd","IPY_MODEL_630caf65f78041db8187bc1dc0a1bdb5"],"layout":"IPY_MODEL_fe1396ff7efb4a3999f52a860865e7ca"}},"5b02ed9ab01743fda0e00e2d9b0358b1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a92ce7fa1a934f6a841732e225566b6e","placeholder":"‚Äã","style":"IPY_MODEL_b7dfc02e149348fdb83a2fdcebf6f10d","value":"sentence_bert_config.json:‚Äá100%"}},"1c7d2d385dda4e0093c102a901c663fd":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_95ce5b59004c4727b849017af5183335","max":53,"min":0,"orientation":"horizontal","style":"IPY_MODEL_9e1ff1796b6e460cb8a0d3d4be5aa145","value":53}},"630caf65f78041db8187bc1dc0a1bdb5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d1efe6b25c6549078d0cff3a5b24dba1","placeholder":"‚Äã","style":"IPY_MODEL_edfe7165a2ed42d880ddb33459be625b","value":"‚Äá53.0/53.0‚Äá[00:00&lt;00:00,‚Äá2.32kB/s]"}},"fe1396ff7efb4a3999f52a860865e7ca":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a92ce7fa1a934f6a841732e225566b6e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b7dfc02e149348fdb83a2fdcebf6f10d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"95ce5b59004c4727b849017af5183335":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9e1ff1796b6e460cb8a0d3d4be5aa145":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d1efe6b25c6549078d0cff3a5b24dba1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"edfe7165a2ed42d880ddb33459be625b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4201c962a7c34898b9c145509a417421":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_12689ec67dbf453293bc41d84e6a0acd","IPY_MODEL_1bb81b21220a48d3a6eb22dedb322b15","IPY_MODEL_9153d72f15a44f519c6c04384e6680e1"],"layout":"IPY_MODEL_c11fae1fbc714c0f962307008e1aab21"}},"12689ec67dbf453293bc41d84e6a0acd":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_edc1c2dcc8f2467e82f200cc40146504","placeholder":"‚Äã","style":"IPY_MODEL_97a15bb239204065ad94dc99525a3f13","value":"config.json:‚Äá100%"}},"1bb81b21220a48d3a6eb22dedb322b15":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_bc76c8060c814d3ab0f88634d252bf5c","max":612,"min":0,"orientation":"horizontal","style":"IPY_MODEL_9fb50acd4d6d4c92b68de022048fe031","value":612}},"9153d72f15a44f519c6c04384e6680e1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cec7971b034f46598128d6fe2288edfe","placeholder":"‚Äã","style":"IPY_MODEL_bb3205fc9a9546ffa11e2cf6dfe6d49d","value":"‚Äá612/612‚Äá[00:00&lt;00:00,‚Äá54.6kB/s]"}},"c11fae1fbc714c0f962307008e1aab21":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"edc1c2dcc8f2467e82f200cc40146504":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"97a15bb239204065ad94dc99525a3f13":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bc76c8060c814d3ab0f88634d252bf5c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9fb50acd4d6d4c92b68de022048fe031":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"cec7971b034f46598128d6fe2288edfe":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bb3205fc9a9546ffa11e2cf6dfe6d49d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2136d8917db44db98dcc02463900ea38":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_afc583540aa94f4cb6d4452cbb63885a","IPY_MODEL_639b79b4cc8a4d5ebbcacec19b70789e","IPY_MODEL_495682c792674272b7c883ccd1e2ea4d"],"layout":"IPY_MODEL_50fdfb38a869438d8d197cf4dd6c5875"}},"afc583540aa94f4cb6d4452cbb63885a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e8f0e4c491d24abf96eae6a47731d0ea","placeholder":"‚Äã","style":"IPY_MODEL_7d5f32aff01f4d84865d9f2c59517143","value":"model.safetensors:‚Äá100%"}},"639b79b4cc8a4d5ebbcacec19b70789e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d1f55b92f4494098801086a3dcd6211d","max":90868376,"min":0,"orientation":"horizontal","style":"IPY_MODEL_894777eb27624a978ac103296ff5f00a","value":90868376}},"495682c792674272b7c883ccd1e2ea4d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8c1de9be2c594726a765f422cd39cfd3","placeholder":"‚Äã","style":"IPY_MODEL_23ad568ddcfa44afa1fe9ff0f8696f89","value":"‚Äá90.9M/90.9M‚Äá[00:00&lt;00:00,‚Äá149MB/s]"}},"50fdfb38a869438d8d197cf4dd6c5875":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e8f0e4c491d24abf96eae6a47731d0ea":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7d5f32aff01f4d84865d9f2c59517143":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d1f55b92f4494098801086a3dcd6211d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"894777eb27624a978ac103296ff5f00a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"8c1de9be2c594726a765f422cd39cfd3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"23ad568ddcfa44afa1fe9ff0f8696f89":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"261bc4c738134c4f95663b3a1619d5a8":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_006c161197af41acbadd5e0f676a5c92","IPY_MODEL_9b981b350d0440e78edba331b61c0566","IPY_MODEL_4d644ea6bbfb407ca499fd40cc9ff896"],"layout":"IPY_MODEL_72314221e58c4ef8a9eb87fc6e9ada93"}},"006c161197af41acbadd5e0f676a5c92":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5af1e51430d740358eff5c36dbe02732","placeholder":"‚Äã","style":"IPY_MODEL_5683cc0b8e454e37acbd5619f6c2b6fe","value":"tokenizer_config.json:‚Äá100%"}},"9b981b350d0440e78edba331b61c0566":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e4ab760ebd4a45ae8ea5333411cbeec1","max":350,"min":0,"orientation":"horizontal","style":"IPY_MODEL_da39818314694f0d99636642c1fc5214","value":350}},"4d644ea6bbfb407ca499fd40cc9ff896":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_85eab87956cf485f86c786f5ca99a024","placeholder":"‚Äã","style":"IPY_MODEL_6abec0588f624a8fae8229a1d3020833","value":"‚Äá350/350‚Äá[00:00&lt;00:00,‚Äá28.5kB/s]"}},"72314221e58c4ef8a9eb87fc6e9ada93":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5af1e51430d740358eff5c36dbe02732":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5683cc0b8e454e37acbd5619f6c2b6fe":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e4ab760ebd4a45ae8ea5333411cbeec1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"da39818314694f0d99636642c1fc5214":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"85eab87956cf485f86c786f5ca99a024":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6abec0588f624a8fae8229a1d3020833":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"dba89de6b32947f894be0db0b2e76608":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e176bec1df0548baa4a584c28ee75ea0","IPY_MODEL_cea3836b13b84a80b762bd4e2e90654a","IPY_MODEL_4a507240ffe4408cbc5c895aa5286822"],"layout":"IPY_MODEL_29e3246d13f94e31aae2e757dcdec04a"}},"e176bec1df0548baa4a584c28ee75ea0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_45506525148c4a4ab239871852e45e62","placeholder":"‚Äã","style":"IPY_MODEL_b9c4048c9bbd4b99946779701bba2896","value":"vocab.txt:‚Äá"}},"cea3836b13b84a80b762bd4e2e90654a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_906ef68b391644b982c5a651a4fbb658","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_9b5deec2246b423aa6126382de7a178e","value":1}},"4a507240ffe4408cbc5c895aa5286822":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d2ecc1999ee04cafb720e683a04be86c","placeholder":"‚Äã","style":"IPY_MODEL_483960ae859f4e30b4b749519edf60ce","value":"‚Äá232k/?‚Äá[00:00&lt;00:00,‚Äá5.87MB/s]"}},"29e3246d13f94e31aae2e757dcdec04a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"45506525148c4a4ab239871852e45e62":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b9c4048c9bbd4b99946779701bba2896":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"906ef68b391644b982c5a651a4fbb658":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"9b5deec2246b423aa6126382de7a178e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d2ecc1999ee04cafb720e683a04be86c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"483960ae859f4e30b4b749519edf60ce":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4f2e748f10ac4bb6be8f19c014ca4fad":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_29fee262cf864ba1a91a385fde804c05","IPY_MODEL_50610ac336e74b9989b42d8da7c87028","IPY_MODEL_5dfada7e439845bc8da7ecbda4e1ae62"],"layout":"IPY_MODEL_125cbd168d284e0c8c58f2cdf70ad387"}},"29fee262cf864ba1a91a385fde804c05":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_17d0c20cb8774265af0a71ede5404498","placeholder":"‚Äã","style":"IPY_MODEL_8eaca7e348db44e79ad0fbad2e536307","value":"tokenizer.json:‚Äá"}},"50610ac336e74b9989b42d8da7c87028":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_58b671760f684dd7b54a881e79684090","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b8d983c70c9a41e39352680cc2ac4b43","value":1}},"5dfada7e439845bc8da7ecbda4e1ae62":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f61d544188284422a741ec165af45cf4","placeholder":"‚Äã","style":"IPY_MODEL_6ceae4fe18894f1f8c0576d819ac2a7f","value":"‚Äá466k/?‚Äá[00:00&lt;00:00,‚Äá21.2MB/s]"}},"125cbd168d284e0c8c58f2cdf70ad387":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"17d0c20cb8774265af0a71ede5404498":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8eaca7e348db44e79ad0fbad2e536307":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"58b671760f684dd7b54a881e79684090":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"b8d983c70c9a41e39352680cc2ac4b43":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f61d544188284422a741ec165af45cf4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6ceae4fe18894f1f8c0576d819ac2a7f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4462aa364be944ba8738efa9f8b1cac1":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_3550dd8c0e0d41dc89e94b69afabe161","IPY_MODEL_8fed12ca120e4ae7aae1c87083050a28","IPY_MODEL_39418b72ac10462e8585d5ff9be0598d"],"layout":"IPY_MODEL_220aca0009934f58b13ca4304330ad34"}},"3550dd8c0e0d41dc89e94b69afabe161":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6fac5237c2034504b530b81384d6c361","placeholder":"‚Äã","style":"IPY_MODEL_ae3e199b953c4c5b8da3c0e1a46c4126","value":"special_tokens_map.json:‚Äá100%"}},"8fed12ca120e4ae7aae1c87083050a28":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_3ebd1d5e90144d609dd77335b14decd5","max":112,"min":0,"orientation":"horizontal","style":"IPY_MODEL_6122445f687941b3be4d58b12385e76f","value":112}},"39418b72ac10462e8585d5ff9be0598d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_89763c9b063a40f5bbfa3ae3640bb2da","placeholder":"‚Äã","style":"IPY_MODEL_f3b03bf5960b4407ba29ad52b63148a0","value":"‚Äá112/112‚Äá[00:00&lt;00:00,‚Äá9.59kB/s]"}},"220aca0009934f58b13ca4304330ad34":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6fac5237c2034504b530b81384d6c361":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ae3e199b953c4c5b8da3c0e1a46c4126":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3ebd1d5e90144d609dd77335b14decd5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6122445f687941b3be4d58b12385e76f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"89763c9b063a40f5bbfa3ae3640bb2da":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f3b03bf5960b4407ba29ad52b63148a0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"dadf7eadc7114f85a0012f8288986a22":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_889eac2861a34d529a009c8c84106999","IPY_MODEL_07b37067529f44a9bd9dce7f2021aad0","IPY_MODEL_294b7620ecb24c31a68e55a6f81105a5"],"layout":"IPY_MODEL_5ef6cd4c99154fcea7b97e9026b54108"}},"889eac2861a34d529a009c8c84106999":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a122121140424e02ad51bf0fbbff7169","placeholder":"‚Äã","style":"IPY_MODEL_bf29d86cb10b4fbf855063604cc302e7","value":"config.json:‚Äá100%"}},"07b37067529f44a9bd9dce7f2021aad0":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_3e291645f4c14158b254f6b38a1e4582","max":190,"min":0,"orientation":"horizontal","style":"IPY_MODEL_887a7f86c72b4d0d917dfbc3495cdfa3","value":190}},"294b7620ecb24c31a68e55a6f81105a5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0242734b3f3d43d39eb48dff15121177","placeholder":"‚Äã","style":"IPY_MODEL_a076854a5f0844a5b9fea0062fe6f8b9","value":"‚Äá190/190‚Äá[00:00&lt;00:00,‚Äá16.5kB/s]"}},"5ef6cd4c99154fcea7b97e9026b54108":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a122121140424e02ad51bf0fbbff7169":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bf29d86cb10b4fbf855063604cc302e7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3e291645f4c14158b254f6b38a1e4582":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"887a7f86c72b4d0d917dfbc3495cdfa3":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"0242734b3f3d43d39eb48dff15121177":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a076854a5f0844a5b9fea0062fe6f8b9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}